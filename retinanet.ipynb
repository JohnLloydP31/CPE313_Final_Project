{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yhenon/pytorch-retinanet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TNky5Keu48U",
        "outputId": "83024c1c-22ef-49f1-ac5e-0ac72713aac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-retinanet'...\n",
            "remote: Enumerating objects: 232, done.\u001b[K\n",
            "remote: Total 232 (delta 0), reused 0 (delta 0), pack-reused 232 (from 2)\u001b[K\n",
            "Receiving objects: 100% (232/232), 1.02 MiB | 33.67 MiB/s, done.\n",
            "Resolving deltas: 100% (116/116), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv1gzM1cuseB",
        "outputId": "d4007a9e-5b71-4702-d90c-8045005f58f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tk-dev is already the newest version (8.6.11+1build2).\n",
            "python3-tk is already the newest version (3.10.8-1~22.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install tk-dev python3-tk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install pycocotools\n",
        "!pip install opencv-python\n",
        "!pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JF6MeHe4vQnj",
        "outputId": "c14cf75d-a3e5-4b61-e121-2c19cb05fa7e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (2.0.8)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pycocotools) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.17.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"pg2whkQiI3hA8J7eImEl\")\n",
        "project = rf.workspace(\"drowsy-detection-uxdzk\").project(\"fatigue-dataset\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"retinanet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2_1xZ7Zvp8-",
        "outputId": "efcd7d9b-a004-4913-8a4d-37f9b6011ae0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.64-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.4.26)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.2.1)\n",
            "Collecting pillow-heif>=0.18.0 (from roboflow)\n",
            "  Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.4.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.58.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.2)\n",
            "Downloading roboflow-1.1.64-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m130.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: filetype, python-dotenv, pillow-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.11.0.86\n",
            "    Uninstalling opencv-python-headless-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pillow-heif-0.22.0 python-dotenv-1.1.0 roboflow-1.1.64\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in fatigue-dataset-1 to retinanet:: 100%|██████████| 210659/210659 [00:03<00:00, 64519.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to fatigue-dataset-1 in retinanet:: 100%|██████████| 6000/6000 [00:01<00:00, 5450.84it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKSLW9lJ3My9",
        "outputId": "3a11f9dc-cdce-43ea-efc3-e478cfdc3e5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Collecting torch==2.7.0 (from torchvision)\n",
            "  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (4.13.2)\n",
            "Collecting sympy>=1.13.3 (from torch==2.7.0->torchvision)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0->torchvision) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch==2.7.0->torchvision)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.0 (from torch==2.7.0->torchvision)\n",
            "  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch==2.7.0->torchvision) (75.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.7.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.7.0->torchvision) (3.0.2)\n",
            "Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m126.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.0 torchvision-0.22.0 triton-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def find_csv_filename(folder_path):\n",
        "  \"\"\"Finds the filename of a CSV file in the specified folder.\n",
        "\n",
        "  Args:\n",
        "    folder_path: The path to the folder to search.\n",
        "\n",
        "  Returns:\n",
        "    The filename of the CSV file, or None if no CSV file is found.\n",
        "  \"\"\"\n",
        "  for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".csv\"):\n",
        "      return filename\n",
        "  return None\n",
        "\n",
        "# Example usage\n",
        "folder_path = \"/content/fatigue-dataset-1/train\"\n",
        "csv_filename = find_csv_filename(folder_path)\n",
        "\n",
        "if csv_filename:\n",
        "  print(f\"The CSV file is: {csv_filename}\")\n",
        "else:\n",
        "  print(\"No CSV file found in the folder.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rB5DH4M1wfdF",
        "outputId": "86ae26b0-5767-4792-9e58-3b3100c10cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The CSV file is: class_list.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/pytorch-retinanet\n",
        "!python train.py --dataset csv --csv_train \"/content/fatigue-dataset-1/train/_annotations.csv\" --csv_classes \"/content/fatigue-dataset-1/train/class_list.csv\" --csv_val \"/content/fatigue-dataset-1/valid/_annotations.csv\" --depth 50 --epochs 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSpy7z22vgC6",
        "outputId": "c341245e-03df-44aa-e8ac-4f2fc47da1fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 8 | Iteration: 368 | Classification loss: 0.00057 | Regression loss: 0.03248 | Running loss: 0.04363\n",
            "Epoch: 8 | Iteration: 369 | Classification loss: 0.00017 | Regression loss: 0.01984 | Running loss: 0.04361\n",
            "Epoch: 8 | Iteration: 370 | Classification loss: 0.00101 | Regression loss: 0.03618 | Running loss: 0.04358\n",
            "Epoch: 8 | Iteration: 371 | Classification loss: 0.00012 | Regression loss: 0.01283 | Running loss: 0.04358\n",
            "Epoch: 8 | Iteration: 372 | Classification loss: 0.00186 | Regression loss: 0.04965 | Running loss: 0.04361\n",
            "Epoch: 8 | Iteration: 373 | Classification loss: 0.00029 | Regression loss: 0.01967 | Running loss: 0.04361\n",
            "Epoch: 8 | Iteration: 374 | Classification loss: 0.00189 | Regression loss: 0.04089 | Running loss: 0.04364\n",
            "Epoch: 8 | Iteration: 375 | Classification loss: 0.00014 | Regression loss: 0.01169 | Running loss: 0.04363\n",
            "Epoch: 8 | Iteration: 376 | Classification loss: 0.00143 | Regression loss: 0.06920 | Running loss: 0.04358\n",
            "Epoch: 8 | Iteration: 377 | Classification loss: 0.00030 | Regression loss: 0.03392 | Running loss: 0.04336\n",
            "Epoch: 8 | Iteration: 378 | Classification loss: 0.00003 | Regression loss: 0.02513 | Running loss: 0.04333\n",
            "Epoch: 8 | Iteration: 379 | Classification loss: 0.00020 | Regression loss: 0.02824 | Running loss: 0.04332\n",
            "Epoch: 8 | Iteration: 380 | Classification loss: 0.00008 | Regression loss: 0.01871 | Running loss: 0.04329\n",
            "Epoch: 8 | Iteration: 381 | Classification loss: 0.00031 | Regression loss: 0.02951 | Running loss: 0.04328\n",
            "Epoch: 8 | Iteration: 382 | Classification loss: 0.00027 | Regression loss: 0.02689 | Running loss: 0.04327\n",
            "Epoch: 8 | Iteration: 383 | Classification loss: 0.00035 | Regression loss: 0.03838 | Running loss: 0.04321\n",
            "Epoch: 8 | Iteration: 384 | Classification loss: 0.01129 | Regression loss: 0.03826 | Running loss: 0.04317\n",
            "Epoch: 8 | Iteration: 385 | Classification loss: 0.00047 | Regression loss: 0.03547 | Running loss: 0.04315\n",
            "Epoch: 8 | Iteration: 386 | Classification loss: 0.00025 | Regression loss: 0.02402 | Running loss: 0.04286\n",
            "Epoch: 8 | Iteration: 387 | Classification loss: 0.00014 | Regression loss: 0.04455 | Running loss: 0.04276\n",
            "Epoch: 8 | Iteration: 388 | Classification loss: 0.00108 | Regression loss: 0.03568 | Running loss: 0.04278\n",
            "Epoch: 8 | Iteration: 389 | Classification loss: 0.00032 | Regression loss: 0.02577 | Running loss: 0.04277\n",
            "Epoch: 8 | Iteration: 390 | Classification loss: 0.00100 | Regression loss: 0.03770 | Running loss: 0.04270\n",
            "Epoch: 8 | Iteration: 391 | Classification loss: 0.02439 | Regression loss: 0.07691 | Running loss: 0.04284\n",
            "Epoch: 8 | Iteration: 392 | Classification loss: 0.00671 | Regression loss: 0.04732 | Running loss: 0.04290\n",
            "Epoch: 8 | Iteration: 393 | Classification loss: 0.00041 | Regression loss: 0.02487 | Running loss: 0.04288\n",
            "Epoch: 8 | Iteration: 394 | Classification loss: 0.00061 | Regression loss: 0.04440 | Running loss: 0.04289\n",
            "Epoch: 8 | Iteration: 395 | Classification loss: 0.00042 | Regression loss: 0.04773 | Running loss: 0.04290\n",
            "Epoch: 8 | Iteration: 396 | Classification loss: 0.00586 | Regression loss: 0.01825 | Running loss: 0.04289\n",
            "Epoch: 8 | Iteration: 397 | Classification loss: 0.00028 | Regression loss: 0.02860 | Running loss: 0.04289\n",
            "Epoch: 8 | Iteration: 398 | Classification loss: 0.00073 | Regression loss: 0.07206 | Running loss: 0.04300\n",
            "Epoch: 8 | Iteration: 399 | Classification loss: 0.00014 | Regression loss: 0.03290 | Running loss: 0.04304\n",
            "Epoch: 8 | Iteration: 400 | Classification loss: 0.00017 | Regression loss: 0.02303 | Running loss: 0.04302\n",
            "Epoch: 8 | Iteration: 401 | Classification loss: 0.00161 | Regression loss: 0.03301 | Running loss: 0.04303\n",
            "Epoch: 8 | Iteration: 402 | Classification loss: 0.00028 | Regression loss: 0.02827 | Running loss: 0.04303\n",
            "Epoch: 8 | Iteration: 403 | Classification loss: 0.00073 | Regression loss: 0.02486 | Running loss: 0.04303\n",
            "Epoch: 8 | Iteration: 404 | Classification loss: 0.00017 | Regression loss: 0.03776 | Running loss: 0.04307\n",
            "Epoch: 8 | Iteration: 405 | Classification loss: 0.00657 | Regression loss: 0.03278 | Running loss: 0.04305\n",
            "Epoch: 8 | Iteration: 406 | Classification loss: 0.00444 | Regression loss: 0.01305 | Running loss: 0.04306\n",
            "Epoch: 8 | Iteration: 407 | Classification loss: 0.00082 | Regression loss: 0.07068 | Running loss: 0.04307\n",
            "Epoch: 8 | Iteration: 408 | Classification loss: 0.00363 | Regression loss: 0.07849 | Running loss: 0.04317\n",
            "Epoch: 8 | Iteration: 409 | Classification loss: 0.00141 | Regression loss: 0.02393 | Running loss: 0.04318\n",
            "Epoch: 8 | Iteration: 410 | Classification loss: 0.00075 | Regression loss: 0.10663 | Running loss: 0.04336\n",
            "Epoch: 8 | Iteration: 411 | Classification loss: 0.01601 | Regression loss: 0.05674 | Running loss: 0.04348\n",
            "Epoch: 8 | Iteration: 412 | Classification loss: 0.01701 | Regression loss: 0.06650 | Running loss: 0.04359\n",
            "Epoch: 8 | Iteration: 413 | Classification loss: 0.00024 | Regression loss: 0.02777 | Running loss: 0.04357\n",
            "Epoch: 8 | Iteration: 414 | Classification loss: 0.00011 | Regression loss: 0.02538 | Running loss: 0.04351\n",
            "Epoch: 8 | Iteration: 415 | Classification loss: 0.00019 | Regression loss: 0.01952 | Running loss: 0.04348\n",
            "Epoch: 8 | Iteration: 416 | Classification loss: 0.01620 | Regression loss: 0.05032 | Running loss: 0.04350\n",
            "Epoch: 8 | Iteration: 417 | Classification loss: 0.00289 | Regression loss: 0.05897 | Running loss: 0.04360\n",
            "Epoch: 8 | Iteration: 418 | Classification loss: 0.00815 | Regression loss: 0.05376 | Running loss: 0.04368\n",
            "Epoch: 8 | Iteration: 419 | Classification loss: 0.00046 | Regression loss: 0.06314 | Running loss: 0.04378\n",
            "Epoch: 8 | Iteration: 420 | Classification loss: 0.00019 | Regression loss: 0.03272 | Running loss: 0.04379\n",
            "Epoch: 8 | Iteration: 421 | Classification loss: 0.00026 | Regression loss: 0.02171 | Running loss: 0.04370\n",
            "Epoch: 8 | Iteration: 422 | Classification loss: 0.00018 | Regression loss: 0.04445 | Running loss: 0.04371\n",
            "Epoch: 8 | Iteration: 423 | Classification loss: 0.00044 | Regression loss: 0.03804 | Running loss: 0.04191\n",
            "Epoch: 8 | Iteration: 424 | Classification loss: 0.00001 | Regression loss: 0.03971 | Running loss: 0.04193\n",
            "Epoch: 8 | Iteration: 425 | Classification loss: 0.00016 | Regression loss: 0.02723 | Running loss: 0.04186\n",
            "Epoch: 8 | Iteration: 426 | Classification loss: 0.00054 | Regression loss: 0.03847 | Running loss: 0.04189\n",
            "Epoch: 8 | Iteration: 427 | Classification loss: 0.00009 | Regression loss: 0.02496 | Running loss: 0.04186\n",
            "Epoch: 8 | Iteration: 428 | Classification loss: 0.00034 | Regression loss: 0.03633 | Running loss: 0.04186\n",
            "Epoch: 8 | Iteration: 429 | Classification loss: 0.00009 | Regression loss: 0.02436 | Running loss: 0.04186\n",
            "Epoch: 8 | Iteration: 430 | Classification loss: 0.00015 | Regression loss: 0.05733 | Running loss: 0.04194\n",
            "Epoch: 8 | Iteration: 431 | Classification loss: 0.00018 | Regression loss: 0.03579 | Running loss: 0.04193\n",
            "Epoch: 8 | Iteration: 432 | Classification loss: 0.00007 | Regression loss: 0.01931 | Running loss: 0.04194\n",
            "Epoch: 8 | Iteration: 433 | Classification loss: 0.00130 | Regression loss: 0.05039 | Running loss: 0.04188\n",
            "Epoch: 8 | Iteration: 434 | Classification loss: 0.00270 | Regression loss: 0.03372 | Running loss: 0.04182\n",
            "Epoch: 8 | Iteration: 435 | Classification loss: 0.00040 | Regression loss: 0.01329 | Running loss: 0.04181\n",
            "Epoch: 8 | Iteration: 436 | Classification loss: 0.00139 | Regression loss: 0.03004 | Running loss: 0.04183\n",
            "Epoch: 8 | Iteration: 437 | Classification loss: 0.00469 | Regression loss: 0.04472 | Running loss: 0.04185\n",
            "Epoch: 8 | Iteration: 438 | Classification loss: 0.00024 | Regression loss: 0.03948 | Running loss: 0.04188\n",
            "Epoch: 8 | Iteration: 439 | Classification loss: 0.00039 | Regression loss: 0.04746 | Running loss: 0.04189\n",
            "Epoch: 8 | Iteration: 440 | Classification loss: 0.00020 | Regression loss: 0.05117 | Running loss: 0.04197\n",
            "Epoch: 8 | Iteration: 441 | Classification loss: 0.00016 | Regression loss: 0.02227 | Running loss: 0.04198\n",
            "Epoch: 8 | Iteration: 442 | Classification loss: 0.00013 | Regression loss: 0.02339 | Running loss: 0.04196\n",
            "Epoch: 8 | Iteration: 443 | Classification loss: 0.39753 | Regression loss: 0.25238 | Running loss: 0.04309\n",
            "Epoch: 8 | Iteration: 444 | Classification loss: 0.00928 | Regression loss: 0.05433 | Running loss: 0.04319\n",
            "Epoch: 8 | Iteration: 445 | Classification loss: 0.00011 | Regression loss: 0.02808 | Running loss: 0.04310\n",
            "Epoch: 8 | Iteration: 446 | Classification loss: 0.00012 | Regression loss: 0.02893 | Running loss: 0.04309\n",
            "Epoch: 8 | Iteration: 447 | Classification loss: 0.00158 | Regression loss: 0.05589 | Running loss: 0.04313\n",
            "Epoch: 8 | Iteration: 448 | Classification loss: 0.00015 | Regression loss: 0.02762 | Running loss: 0.04312\n",
            "Epoch: 8 | Iteration: 449 | Classification loss: 0.00150 | Regression loss: 0.04690 | Running loss: 0.04310\n",
            "Epoch: 8 | Iteration: 450 | Classification loss: 0.16668 | Regression loss: 0.19509 | Running loss: 0.04377\n",
            "Epoch: 8 | Iteration: 451 | Classification loss: 0.00043 | Regression loss: 0.02188 | Running loss: 0.04357\n",
            "Epoch: 8 | Iteration: 452 | Classification loss: 0.00059 | Regression loss: 0.03711 | Running loss: 0.04358\n",
            "Epoch: 8 | Iteration: 453 | Classification loss: 0.00010 | Regression loss: 0.02487 | Running loss: 0.04360\n",
            "Epoch: 8 | Iteration: 454 | Classification loss: 0.00034 | Regression loss: 0.02431 | Running loss: 0.04361\n",
            "Epoch: 8 | Iteration: 455 | Classification loss: 0.00088 | Regression loss: 0.01840 | Running loss: 0.04361\n",
            "Epoch: 8 | Iteration: 456 | Classification loss: 0.00032 | Regression loss: 0.01519 | Running loss: 0.04356\n",
            "Epoch: 8 | Iteration: 457 | Classification loss: 0.00014 | Regression loss: 0.00964 | Running loss: 0.04351\n",
            "Epoch: 8 | Iteration: 458 | Classification loss: 0.00050 | Regression loss: 0.03359 | Running loss: 0.04349\n",
            "Epoch: 8 | Iteration: 459 | Classification loss: 0.00028 | Regression loss: 0.01617 | Running loss: 0.04333\n",
            "Epoch: 8 | Iteration: 460 | Classification loss: 0.00647 | Regression loss: 0.01535 | Running loss: 0.04328\n",
            "Epoch: 8 | Iteration: 461 | Classification loss: 0.00014 | Regression loss: 0.03080 | Running loss: 0.04320\n",
            "Epoch: 8 | Iteration: 462 | Classification loss: 0.00005 | Regression loss: 0.01229 | Running loss: 0.04316\n",
            "Epoch: 8 | Iteration: 463 | Classification loss: 0.00021 | Regression loss: 0.02036 | Running loss: 0.04317\n",
            "Epoch: 8 | Iteration: 464 | Classification loss: 0.07297 | Regression loss: 0.17214 | Running loss: 0.04363\n",
            "Epoch: 8 | Iteration: 465 | Classification loss: 0.00178 | Regression loss: 0.01676 | Running loss: 0.04361\n",
            "Epoch: 8 | Iteration: 466 | Classification loss: 0.00071 | Regression loss: 0.03898 | Running loss: 0.04362\n",
            "Epoch: 8 | Iteration: 467 | Classification loss: 0.00065 | Regression loss: 0.05428 | Running loss: 0.04363\n",
            "Epoch: 8 | Iteration: 468 | Classification loss: 0.00054 | Regression loss: 0.06071 | Running loss: 0.04373\n",
            "Epoch: 8 | Iteration: 469 | Classification loss: 0.00022 | Regression loss: 0.01440 | Running loss: 0.04371\n",
            "Epoch: 8 | Iteration: 470 | Classification loss: 0.17331 | Regression loss: 0.30865 | Running loss: 0.04448\n",
            "Epoch: 8 | Iteration: 471 | Classification loss: 0.00039 | Regression loss: 0.03681 | Running loss: 0.04448\n",
            "Epoch: 8 | Iteration: 472 | Classification loss: 0.00013 | Regression loss: 0.02782 | Running loss: 0.04434\n",
            "Epoch: 8 | Iteration: 473 | Classification loss: 0.00029 | Regression loss: 0.03433 | Running loss: 0.04433\n",
            "Epoch: 8 | Iteration: 474 | Classification loss: 0.00008 | Regression loss: 0.03459 | Running loss: 0.04434\n",
            "Epoch: 8 | Iteration: 475 | Classification loss: 0.00050 | Regression loss: 0.03483 | Running loss: 0.04433\n",
            "Epoch: 8 | Iteration: 476 | Classification loss: 0.00072 | Regression loss: 0.03523 | Running loss: 0.04436\n",
            "Epoch: 8 | Iteration: 477 | Classification loss: 0.00025 | Regression loss: 0.03174 | Running loss: 0.04432\n",
            "Epoch: 8 | Iteration: 478 | Classification loss: 0.00019 | Regression loss: 0.01804 | Running loss: 0.04431\n",
            "Epoch: 8 | Iteration: 479 | Classification loss: 0.00158 | Regression loss: 0.01016 | Running loss: 0.04423\n",
            "Epoch: 8 | Iteration: 480 | Classification loss: 0.00135 | Regression loss: 0.02596 | Running loss: 0.04424\n",
            "Epoch: 8 | Iteration: 481 | Classification loss: 0.00267 | Regression loss: 0.03902 | Running loss: 0.04428\n",
            "Epoch: 8 | Iteration: 482 | Classification loss: 0.00046 | Regression loss: 0.04696 | Running loss: 0.04431\n",
            "Epoch: 8 | Iteration: 483 | Classification loss: 0.00173 | Regression loss: 0.01844 | Running loss: 0.04429\n",
            "Epoch: 8 | Iteration: 484 | Classification loss: 0.00057 | Regression loss: 0.02896 | Running loss: 0.04433\n",
            "Epoch: 8 | Iteration: 485 | Classification loss: 0.00060 | Regression loss: 0.06691 | Running loss: 0.04440\n",
            "Epoch: 8 | Iteration: 486 | Classification loss: 0.04935 | Regression loss: 0.06202 | Running loss: 0.04458\n",
            "Epoch: 8 | Iteration: 487 | Classification loss: 0.00064 | Regression loss: 0.05642 | Running loss: 0.04459\n",
            "Epoch: 8 | Iteration: 488 | Classification loss: 0.00311 | Regression loss: 0.04273 | Running loss: 0.04464\n",
            "Epoch: 8 | Iteration: 489 | Classification loss: 0.00129 | Regression loss: 0.02607 | Running loss: 0.04462\n",
            "Epoch: 8 | Iteration: 490 | Classification loss: 0.00287 | Regression loss: 0.02966 | Running loss: 0.04450\n",
            "Epoch: 8 | Iteration: 491 | Classification loss: 0.00023 | Regression loss: 0.02714 | Running loss: 0.04450\n",
            "Epoch: 8 | Iteration: 492 | Classification loss: 0.00130 | Regression loss: 0.02871 | Running loss: 0.04447\n",
            "Epoch: 8 | Iteration: 493 | Classification loss: 0.00395 | Regression loss: 0.07480 | Running loss: 0.04449\n",
            "Epoch: 8 | Iteration: 494 | Classification loss: 0.00020 | Regression loss: 0.03437 | Running loss: 0.04451\n",
            "Epoch: 8 | Iteration: 495 | Classification loss: 0.00107 | Regression loss: 0.02453 | Running loss: 0.04452\n",
            "Epoch: 8 | Iteration: 496 | Classification loss: 0.00020 | Regression loss: 0.02907 | Running loss: 0.04447\n",
            "Epoch: 8 | Iteration: 497 | Classification loss: 0.00176 | Regression loss: 0.02699 | Running loss: 0.04447\n",
            "Epoch: 8 | Iteration: 498 | Classification loss: 0.00402 | Regression loss: 0.03625 | Running loss: 0.04443\n",
            "Epoch: 8 | Iteration: 499 | Classification loss: 0.03163 | Regression loss: 0.08611 | Running loss: 0.04462\n",
            "Epoch: 8 | Iteration: 500 | Classification loss: 0.00398 | Regression loss: 0.02516 | Running loss: 0.04459\n",
            "Epoch: 8 | Iteration: 501 | Classification loss: 0.00024 | Regression loss: 0.02141 | Running loss: 0.04455\n",
            "Epoch: 8 | Iteration: 502 | Classification loss: 0.00131 | Regression loss: 0.02734 | Running loss: 0.04457\n",
            "Epoch: 8 | Iteration: 503 | Classification loss: 0.00305 | Regression loss: 0.02017 | Running loss: 0.04459\n",
            "Epoch: 8 | Iteration: 504 | Classification loss: 0.00016 | Regression loss: 0.03480 | Running loss: 0.04460\n",
            "Epoch: 8 | Iteration: 505 | Classification loss: 0.01097 | Regression loss: 0.04501 | Running loss: 0.04462\n",
            "Epoch: 8 | Iteration: 506 | Classification loss: 0.00034 | Regression loss: 0.01162 | Running loss: 0.04453\n",
            "Epoch: 8 | Iteration: 507 | Classification loss: 0.06297 | Regression loss: 0.04709 | Running loss: 0.04457\n",
            "Epoch: 8 | Iteration: 508 | Classification loss: 0.00049 | Regression loss: 0.02623 | Running loss: 0.04456\n",
            "Epoch: 8 | Iteration: 509 | Classification loss: 0.00569 | Regression loss: 0.02174 | Running loss: 0.04454\n",
            "Epoch: 8 | Iteration: 510 | Classification loss: 0.00016 | Regression loss: 0.02401 | Running loss: 0.04453\n",
            "Epoch: 8 | Iteration: 511 | Classification loss: 0.00029 | Regression loss: 0.02398 | Running loss: 0.04450\n",
            "Epoch: 8 | Iteration: 512 | Classification loss: 0.20129 | Regression loss: 0.35748 | Running loss: 0.04557\n",
            "Epoch: 8 | Iteration: 513 | Classification loss: 0.01598 | Regression loss: 0.04402 | Running loss: 0.04563\n",
            "Epoch: 8 | Iteration: 514 | Classification loss: 0.00405 | Regression loss: 0.01341 | Running loss: 0.04563\n",
            "Epoch: 8 | Iteration: 515 | Classification loss: 0.00016 | Regression loss: 0.02135 | Running loss: 0.04563\n",
            "Epoch: 8 | Iteration: 516 | Classification loss: 0.01961 | Regression loss: 0.02846 | Running loss: 0.04564\n",
            "Epoch: 8 | Iteration: 517 | Classification loss: 0.00076 | Regression loss: 0.02121 | Running loss: 0.04559\n",
            "Epoch: 8 | Iteration: 518 | Classification loss: 0.00207 | Regression loss: 0.03073 | Running loss: 0.04559\n",
            "Epoch: 8 | Iteration: 519 | Classification loss: 0.00171 | Regression loss: 0.01905 | Running loss: 0.04551\n",
            "Epoch: 8 | Iteration: 520 | Classification loss: 0.00147 | Regression loss: 0.01968 | Running loss: 0.04550\n",
            "Epoch: 8 | Iteration: 521 | Classification loss: 0.00341 | Regression loss: 0.02460 | Running loss: 0.04549\n",
            "Epoch: 8 | Iteration: 522 | Classification loss: 0.00048 | Regression loss: 0.02519 | Running loss: 0.04549\n",
            "Epoch: 8 | Iteration: 523 | Classification loss: 0.00130 | Regression loss: 0.01259 | Running loss: 0.04546\n",
            "Epoch: 8 | Iteration: 524 | Classification loss: 0.00072 | Regression loss: 0.03289 | Running loss: 0.04541\n",
            "Epoch: 8 | Iteration: 525 | Classification loss: 0.00035 | Regression loss: 0.01095 | Running loss: 0.04535\n",
            "Epoch: 8 | Iteration: 526 | Classification loss: 0.00380 | Regression loss: 0.01936 | Running loss: 0.04534\n",
            "Epoch: 8 | Iteration: 527 | Classification loss: 0.00179 | Regression loss: 0.03081 | Running loss: 0.04531\n",
            "Epoch: 8 | Iteration: 528 | Classification loss: 0.00717 | Regression loss: 0.05150 | Running loss: 0.04532\n",
            "Epoch: 8 | Iteration: 529 | Classification loss: 0.00043 | Regression loss: 0.01897 | Running loss: 0.04529\n",
            "Epoch: 8 | Iteration: 530 | Classification loss: 0.00072 | Regression loss: 0.02154 | Running loss: 0.04527\n",
            "Epoch: 8 | Iteration: 531 | Classification loss: 0.00065 | Regression loss: 0.01726 | Running loss: 0.04526\n",
            "Epoch: 8 | Iteration: 532 | Classification loss: 0.00020 | Regression loss: 0.04462 | Running loss: 0.04516\n",
            "Epoch: 8 | Iteration: 533 | Classification loss: 0.01198 | Regression loss: 0.03124 | Running loss: 0.04521\n",
            "Epoch: 8 | Iteration: 534 | Classification loss: 0.00044 | Regression loss: 0.01712 | Running loss: 0.04517\n",
            "Epoch: 8 | Iteration: 535 | Classification loss: 0.00197 | Regression loss: 0.01805 | Running loss: 0.04513\n",
            "Epoch: 8 | Iteration: 536 | Classification loss: 0.00033 | Regression loss: 0.02617 | Running loss: 0.04510\n",
            "Epoch: 8 | Iteration: 537 | Classification loss: 0.00040 | Regression loss: 0.01491 | Running loss: 0.04509\n",
            "Epoch: 8 | Iteration: 538 | Classification loss: 0.00065 | Regression loss: 0.03588 | Running loss: 0.04514\n",
            "Epoch: 8 | Iteration: 539 | Classification loss: 0.00013 | Regression loss: 0.01933 | Running loss: 0.04516\n",
            "Epoch: 8 | Iteration: 540 | Classification loss: 0.00317 | Regression loss: 0.01324 | Running loss: 0.04513\n",
            "Epoch: 8 | Iteration: 541 | Classification loss: 0.00373 | Regression loss: 0.02515 | Running loss: 0.04509\n",
            "Epoch: 8 | Iteration: 542 | Classification loss: 0.00025 | Regression loss: 0.04248 | Running loss: 0.04494\n",
            "Epoch: 8 | Iteration: 543 | Classification loss: 0.00099 | Regression loss: 0.03244 | Running loss: 0.04494\n",
            "Epoch: 8 | Iteration: 544 | Classification loss: 0.00027 | Regression loss: 0.01584 | Running loss: 0.04494\n",
            "Epoch: 8 | Iteration: 545 | Classification loss: 0.00053 | Regression loss: 0.00722 | Running loss: 0.04490\n",
            "Epoch: 8 | Iteration: 546 | Classification loss: 0.00023 | Regression loss: 0.02832 | Running loss: 0.04484\n",
            "Epoch: 8 | Iteration: 547 | Classification loss: 0.00007 | Regression loss: 0.01445 | Running loss: 0.04484\n",
            "Epoch: 8 | Iteration: 548 | Classification loss: 0.00068 | Regression loss: 0.03428 | Running loss: 0.04484\n",
            "Epoch: 8 | Iteration: 549 | Classification loss: 0.00005 | Regression loss: 0.02143 | Running loss: 0.04486\n",
            "Epoch: 8 | Iteration: 550 | Classification loss: 0.00020 | Regression loss: 0.03891 | Running loss: 0.04489\n",
            "Epoch: 8 | Iteration: 551 | Classification loss: 0.00026 | Regression loss: 0.02380 | Running loss: 0.04492\n",
            "Epoch: 8 | Iteration: 552 | Classification loss: 0.00023 | Regression loss: 0.03055 | Running loss: 0.04485\n",
            "Epoch: 8 | Iteration: 553 | Classification loss: 0.00024 | Regression loss: 0.01704 | Running loss: 0.04483\n",
            "Epoch: 8 | Iteration: 554 | Classification loss: 0.00021 | Regression loss: 0.01973 | Running loss: 0.04481\n",
            "Epoch: 8 | Iteration: 555 | Classification loss: 0.00042 | Regression loss: 0.03068 | Running loss: 0.04482\n",
            "Epoch: 8 | Iteration: 556 | Classification loss: 0.00058 | Regression loss: 0.02602 | Running loss: 0.04474\n",
            "Epoch: 8 | Iteration: 557 | Classification loss: 0.00010 | Regression loss: 0.01757 | Running loss: 0.04464\n",
            "Epoch: 8 | Iteration: 558 | Classification loss: 0.00011 | Regression loss: 0.02211 | Running loss: 0.04462\n",
            "Epoch: 8 | Iteration: 559 | Classification loss: 0.00013 | Regression loss: 0.01158 | Running loss: 0.04461\n",
            "Epoch: 8 | Iteration: 560 | Classification loss: 0.00035 | Regression loss: 0.03081 | Running loss: 0.04464\n",
            "Epoch: 8 | Iteration: 561 | Classification loss: 0.00009 | Regression loss: 0.01345 | Running loss: 0.04451\n",
            "Epoch: 8 | Iteration: 562 | Classification loss: 0.00105 | Regression loss: 0.06108 | Running loss: 0.04449\n",
            "Epoch: 8 | Iteration: 563 | Classification loss: 0.00019 | Regression loss: 0.02032 | Running loss: 0.04431\n",
            "Epoch: 8 | Iteration: 564 | Classification loss: 0.00045 | Regression loss: 0.02096 | Running loss: 0.04431\n",
            "Epoch: 8 | Iteration: 565 | Classification loss: 0.00038 | Regression loss: 0.02684 | Running loss: 0.04426\n",
            "Epoch: 8 | Iteration: 566 | Classification loss: 0.00464 | Regression loss: 0.04624 | Running loss: 0.04433\n",
            "Epoch: 8 | Iteration: 567 | Classification loss: 0.00079 | Regression loss: 0.02801 | Running loss: 0.04422\n",
            "Epoch: 8 | Iteration: 568 | Classification loss: 0.06345 | Regression loss: 0.03635 | Running loss: 0.04425\n",
            "Epoch: 8 | Iteration: 569 | Classification loss: 0.00053 | Regression loss: 0.01424 | Running loss: 0.04424\n",
            "Epoch: 8 | Iteration: 570 | Classification loss: 0.00071 | Regression loss: 0.01859 | Running loss: 0.04423\n",
            "Epoch: 8 | Iteration: 571 | Classification loss: 0.06766 | Regression loss: 0.03210 | Running loss: 0.04438\n",
            "Epoch: 8 | Iteration: 572 | Classification loss: 0.00008 | Regression loss: 0.02295 | Running loss: 0.04430\n",
            "Epoch: 8 | Iteration: 573 | Classification loss: 0.04419 | Regression loss: 0.04340 | Running loss: 0.04430\n",
            "Epoch: 8 | Iteration: 574 | Classification loss: 0.00061 | Regression loss: 0.08586 | Running loss: 0.04442\n",
            "Epoch: 8 | Iteration: 575 | Classification loss: 0.00016 | Regression loss: 0.02855 | Running loss: 0.04439\n",
            "Epoch: 8 | Iteration: 576 | Classification loss: 0.00010 | Regression loss: 0.02062 | Running loss: 0.04431\n",
            "Epoch: 8 | Iteration: 577 | Classification loss: 0.00105 | Regression loss: 0.02644 | Running loss: 0.04429\n",
            "Epoch: 8 | Iteration: 578 | Classification loss: 0.00298 | Regression loss: 0.05746 | Running loss: 0.04431\n",
            "Epoch: 8 | Iteration: 579 | Classification loss: 0.00076 | Regression loss: 0.04757 | Running loss: 0.04437\n",
            "Epoch: 8 | Iteration: 580 | Classification loss: 0.00005 | Regression loss: 0.01714 | Running loss: 0.04433\n",
            "Epoch: 8 | Iteration: 581 | Classification loss: 0.00034 | Regression loss: 0.03943 | Running loss: 0.04436\n",
            "Epoch: 8 | Iteration: 582 | Classification loss: 0.00353 | Regression loss: 0.06523 | Running loss: 0.04438\n",
            "Epoch: 8 | Iteration: 583 | Classification loss: 0.00020 | Regression loss: 0.02990 | Running loss: 0.04439\n",
            "Epoch: 8 | Iteration: 584 | Classification loss: 0.00566 | Regression loss: 0.03136 | Running loss: 0.04442\n",
            "Epoch: 8 | Iteration: 585 | Classification loss: 0.00088 | Regression loss: 0.07559 | Running loss: 0.04453\n",
            "Epoch: 8 | Iteration: 586 | Classification loss: 0.00020 | Regression loss: 0.01251 | Running loss: 0.04416\n",
            "Epoch: 8 | Iteration: 587 | Classification loss: 0.03321 | Regression loss: 0.03565 | Running loss: 0.04420\n",
            "Epoch: 8 | Iteration: 588 | Classification loss: 0.00019 | Regression loss: 0.02142 | Running loss: 0.04420\n",
            "Epoch: 8 | Iteration: 589 | Classification loss: 0.00006 | Regression loss: 0.02301 | Running loss: 0.04411\n",
            "Epoch: 8 | Iteration: 590 | Classification loss: 0.02691 | Regression loss: 0.09568 | Running loss: 0.04428\n",
            "Epoch: 8 | Iteration: 591 | Classification loss: 0.00081 | Regression loss: 0.06665 | Running loss: 0.04435\n",
            "Epoch: 8 | Iteration: 592 | Classification loss: 0.00437 | Regression loss: 0.02408 | Running loss: 0.04435\n",
            "Epoch: 8 | Iteration: 593 | Classification loss: 0.00129 | Regression loss: 0.03941 | Running loss: 0.04432\n",
            "Epoch: 8 | Iteration: 594 | Classification loss: 0.00048 | Regression loss: 0.02459 | Running loss: 0.04421\n",
            "Epoch: 8 | Iteration: 595 | Classification loss: 0.00169 | Regression loss: 0.02695 | Running loss: 0.04410\n",
            "Epoch: 8 | Iteration: 596 | Classification loss: 0.00137 | Regression loss: 0.04007 | Running loss: 0.04415\n",
            "Epoch: 8 | Iteration: 597 | Classification loss: 0.00087 | Regression loss: 0.01334 | Running loss: 0.04412\n",
            "Epoch: 8 | Iteration: 598 | Classification loss: 0.00058 | Regression loss: 0.03925 | Running loss: 0.04416\n",
            "Epoch: 8 | Iteration: 599 | Classification loss: 0.00111 | Regression loss: 0.05920 | Running loss: 0.04410\n",
            "Epoch: 8 | Iteration: 600 | Classification loss: 0.00035 | Regression loss: 0.01787 | Running loss: 0.04406\n",
            "Epoch: 8 | Iteration: 601 | Classification loss: 0.00628 | Regression loss: 0.05558 | Running loss: 0.04413\n",
            "Epoch: 8 | Iteration: 602 | Classification loss: 0.00039 | Regression loss: 0.01128 | Running loss: 0.04407\n",
            "Epoch: 8 | Iteration: 603 | Classification loss: 0.00036 | Regression loss: 0.02835 | Running loss: 0.04410\n",
            "Epoch: 8 | Iteration: 604 | Classification loss: 0.00119 | Regression loss: 0.02277 | Running loss: 0.04413\n",
            "Epoch: 8 | Iteration: 605 | Classification loss: 0.00130 | Regression loss: 0.02054 | Running loss: 0.04414\n",
            "Epoch: 8 | Iteration: 606 | Classification loss: 0.00012 | Regression loss: 0.02236 | Running loss: 0.04398\n",
            "Epoch: 8 | Iteration: 607 | Classification loss: 0.00120 | Regression loss: 0.03796 | Running loss: 0.04398\n",
            "Epoch: 8 | Iteration: 608 | Classification loss: 0.00151 | Regression loss: 0.05793 | Running loss: 0.04406\n",
            "Epoch: 8 | Iteration: 609 | Classification loss: 0.00014 | Regression loss: 0.03364 | Running loss: 0.04403\n",
            "Epoch: 8 | Iteration: 610 | Classification loss: 0.00011 | Regression loss: 0.06065 | Running loss: 0.04409\n",
            "Epoch: 8 | Iteration: 611 | Classification loss: 0.00012 | Regression loss: 0.04360 | Running loss: 0.04407\n",
            "Epoch: 8 | Iteration: 612 | Classification loss: 0.00040 | Regression loss: 0.03773 | Running loss: 0.04404\n",
            "Epoch: 8 | Iteration: 613 | Classification loss: 0.00212 | Regression loss: 0.02223 | Running loss: 0.04403\n",
            "Epoch: 8 | Iteration: 614 | Classification loss: 0.00136 | Regression loss: 0.02194 | Running loss: 0.04403\n",
            "Epoch: 8 | Iteration: 615 | Classification loss: 0.00020 | Regression loss: 0.01430 | Running loss: 0.04398\n",
            "Epoch: 8 | Iteration: 616 | Classification loss: 0.00672 | Regression loss: 0.04233 | Running loss: 0.04403\n",
            "Epoch: 8 | Iteration: 617 | Classification loss: 0.00018 | Regression loss: 0.01374 | Running loss: 0.04401\n",
            "Epoch: 8 | Iteration: 618 | Classification loss: 0.01646 | Regression loss: 0.02264 | Running loss: 0.04404\n",
            "Epoch: 8 | Iteration: 619 | Classification loss: 0.00185 | Regression loss: 0.04032 | Running loss: 0.04402\n",
            "Epoch: 8 | Iteration: 620 | Classification loss: 0.00013 | Regression loss: 0.02677 | Running loss: 0.04384\n",
            "Epoch: 8 | Iteration: 621 | Classification loss: 0.00006 | Regression loss: 0.02148 | Running loss: 0.04384\n",
            "Epoch: 8 | Iteration: 622 | Classification loss: 0.00007 | Regression loss: 0.02075 | Running loss: 0.04383\n",
            "Epoch: 8 | Iteration: 623 | Classification loss: 0.00004 | Regression loss: 0.02614 | Running loss: 0.04382\n",
            "Epoch: 8 | Iteration: 624 | Classification loss: 0.00130 | Regression loss: 0.03549 | Running loss: 0.04385\n",
            "Epoch: 8 | Iteration: 625 | Classification loss: 0.00010 | Regression loss: 0.02304 | Running loss: 0.04386\n",
            "Epoch: 8 | Iteration: 626 | Classification loss: 0.00080 | Regression loss: 0.05893 | Running loss: 0.04395\n",
            "Epoch: 8 | Iteration: 627 | Classification loss: 0.04184 | Regression loss: 0.07744 | Running loss: 0.04411\n",
            "Epoch: 8 | Iteration: 628 | Classification loss: 0.01402 | Regression loss: 0.13293 | Running loss: 0.04438\n",
            "Epoch: 8 | Iteration: 629 | Classification loss: 0.00012 | Regression loss: 0.02610 | Running loss: 0.04439\n",
            "Epoch: 8 | Iteration: 630 | Classification loss: 0.00030 | Regression loss: 0.02979 | Running loss: 0.04442\n",
            "Epoch: 8 | Iteration: 631 | Classification loss: 0.00070 | Regression loss: 0.02619 | Running loss: 0.04443\n",
            "Epoch: 8 | Iteration: 632 | Classification loss: 0.00038 | Regression loss: 0.03474 | Running loss: 0.04445\n",
            "Epoch: 8 | Iteration: 633 | Classification loss: 0.00023 | Regression loss: 0.04861 | Running loss: 0.04450\n",
            "Epoch: 8 | Iteration: 634 | Classification loss: 0.00020 | Regression loss: 0.02971 | Running loss: 0.04451\n",
            "Epoch: 8 | Iteration: 635 | Classification loss: 0.00023 | Regression loss: 0.01389 | Running loss: 0.04452\n",
            "Epoch: 8 | Iteration: 636 | Classification loss: 0.00030 | Regression loss: 0.04374 | Running loss: 0.04446\n",
            "Epoch: 8 | Iteration: 637 | Classification loss: 0.00031 | Regression loss: 0.04166 | Running loss: 0.04446\n",
            "Epoch: 8 | Iteration: 638 | Classification loss: 0.00007 | Regression loss: 0.02798 | Running loss: 0.04442\n",
            "Epoch: 8 | Iteration: 639 | Classification loss: 0.00007 | Regression loss: 0.02101 | Running loss: 0.04441\n",
            "Epoch: 8 | Iteration: 640 | Classification loss: 0.03694 | Regression loss: 0.02730 | Running loss: 0.04447\n",
            "Epoch: 8 | Iteration: 641 | Classification loss: 0.00009 | Regression loss: 0.03212 | Running loss: 0.04439\n",
            "Epoch: 8 | Iteration: 642 | Classification loss: 0.00010 | Regression loss: 0.02472 | Running loss: 0.04438\n",
            "Epoch: 8 | Iteration: 643 | Classification loss: 0.00006 | Regression loss: 0.02000 | Running loss: 0.04434\n",
            "Epoch: 8 | Iteration: 644 | Classification loss: 0.00035 | Regression loss: 0.02511 | Running loss: 0.04435\n",
            "Epoch: 8 | Iteration: 645 | Classification loss: 0.00024 | Regression loss: 0.00969 | Running loss: 0.04426\n",
            "Epoch: 8 | Iteration: 646 | Classification loss: 0.00030 | Regression loss: 0.04565 | Running loss: 0.04429\n",
            "Epoch: 8 | Iteration: 647 | Classification loss: 0.00199 | Regression loss: 0.03168 | Running loss: 0.04432\n",
            "Epoch: 8 | Iteration: 648 | Classification loss: 0.00181 | Regression loss: 0.02453 | Running loss: 0.04433\n",
            "Epoch: 8 | Iteration: 649 | Classification loss: 0.00924 | Regression loss: 0.03748 | Running loss: 0.04434\n",
            "Epoch: 8 | Iteration: 650 | Classification loss: 0.00377 | Regression loss: 0.01848 | Running loss: 0.04431\n",
            "Epoch: 8 | Iteration: 651 | Classification loss: 0.00026 | Regression loss: 0.04133 | Running loss: 0.04436\n",
            "Epoch: 8 | Iteration: 652 | Classification loss: 0.00028 | Regression loss: 0.02098 | Running loss: 0.04434\n",
            "Epoch: 8 | Iteration: 653 | Classification loss: 0.00015 | Regression loss: 0.02968 | Running loss: 0.04433\n",
            "Epoch: 8 | Iteration: 654 | Classification loss: 0.11653 | Regression loss: 0.03865 | Running loss: 0.04460\n",
            "Epoch: 8 | Iteration: 655 | Classification loss: 0.00762 | Regression loss: 0.01949 | Running loss: 0.04458\n",
            "Epoch: 8 | Iteration: 656 | Classification loss: 0.00009 | Regression loss: 0.03948 | Running loss: 0.04456\n",
            "Epoch: 8 | Iteration: 657 | Classification loss: 0.00060 | Regression loss: 0.03684 | Running loss: 0.04460\n",
            "Epoch: 8 | Iteration: 658 | Classification loss: 0.01136 | Regression loss: 0.05648 | Running loss: 0.04470\n",
            "Epoch: 8 | Iteration: 659 | Classification loss: 0.00715 | Regression loss: 0.10237 | Running loss: 0.04488\n",
            "Epoch: 8 | Iteration: 660 | Classification loss: 0.00031 | Regression loss: 0.02789 | Running loss: 0.04485\n",
            "Epoch: 8 | Iteration: 661 | Classification loss: 0.00148 | Regression loss: 0.02713 | Running loss: 0.04486\n",
            "Epoch: 8 | Iteration: 662 | Classification loss: 0.00758 | Regression loss: 0.02767 | Running loss: 0.04490\n",
            "Epoch: 8 | Iteration: 663 | Classification loss: 0.00008 | Regression loss: 0.03700 | Running loss: 0.04492\n",
            "Epoch: 8 | Iteration: 664 | Classification loss: 0.00119 | Regression loss: 0.03867 | Running loss: 0.04495\n",
            "Epoch: 8 | Iteration: 665 | Classification loss: 0.22973 | Regression loss: 0.02235 | Running loss: 0.04524\n",
            "Epoch: 8 | Iteration: 666 | Classification loss: 0.00060 | Regression loss: 0.01683 | Running loss: 0.04518\n",
            "Epoch: 8 | Iteration: 667 | Classification loss: 0.05233 | Regression loss: 0.02975 | Running loss: 0.04526\n",
            "Epoch: 8 | Iteration: 668 | Classification loss: 0.00017 | Regression loss: 0.02526 | Running loss: 0.04522\n",
            "Epoch: 8 | Iteration: 669 | Classification loss: 0.00038 | Regression loss: 0.01896 | Running loss: 0.04520\n",
            "Epoch: 8 | Iteration: 670 | Classification loss: 0.00061 | Regression loss: 0.01509 | Running loss: 0.04517\n",
            "Epoch: 8 | Iteration: 671 | Classification loss: 0.00018 | Regression loss: 0.02696 | Running loss: 0.04516\n",
            "Epoch: 8 | Iteration: 672 | Classification loss: 0.00082 | Regression loss: 0.01984 | Running loss: 0.04515\n",
            "Epoch: 8 | Iteration: 673 | Classification loss: 0.00813 | Regression loss: 0.01946 | Running loss: 0.04512\n",
            "Epoch: 8 | Iteration: 674 | Classification loss: 0.02250 | Regression loss: 0.05871 | Running loss: 0.04524\n",
            "Epoch: 8 | Iteration: 675 | Classification loss: 0.00331 | Regression loss: 0.07655 | Running loss: 0.04522\n",
            "Epoch: 8 | Iteration: 676 | Classification loss: 0.00014 | Regression loss: 0.01092 | Running loss: 0.04521\n",
            "Epoch: 8 | Iteration: 677 | Classification loss: 0.02108 | Regression loss: 0.01998 | Running loss: 0.04526\n",
            "Epoch: 8 | Iteration: 678 | Classification loss: 0.00352 | Regression loss: 0.05125 | Running loss: 0.04531\n",
            "Epoch: 8 | Iteration: 679 | Classification loss: 0.00046 | Regression loss: 0.03634 | Running loss: 0.04534\n",
            "Epoch: 8 | Iteration: 680 | Classification loss: 0.00016 | Regression loss: 0.04756 | Running loss: 0.04535\n",
            "Epoch: 8 | Iteration: 681 | Classification loss: 0.00033 | Regression loss: 0.02506 | Running loss: 0.04530\n",
            "Epoch: 8 | Iteration: 682 | Classification loss: 0.00008 | Regression loss: 0.02691 | Running loss: 0.04527\n",
            "Epoch: 8 | Iteration: 683 | Classification loss: 0.05329 | Regression loss: 0.04906 | Running loss: 0.04543\n",
            "Epoch: 8 | Iteration: 684 | Classification loss: 0.00030 | Regression loss: 0.02325 | Running loss: 0.04541\n",
            "Epoch: 8 | Iteration: 685 | Classification loss: 0.00052 | Regression loss: 0.01239 | Running loss: 0.04539\n",
            "Epoch: 8 | Iteration: 686 | Classification loss: 0.00033 | Regression loss: 0.03449 | Running loss: 0.04540\n",
            "Epoch: 8 | Iteration: 687 | Classification loss: 0.00420 | Regression loss: 0.01294 | Running loss: 0.04541\n",
            "Epoch: 8 | Iteration: 688 | Classification loss: 0.00181 | Regression loss: 0.02545 | Running loss: 0.04540\n",
            "Epoch: 8 | Iteration: 689 | Classification loss: 0.00018 | Regression loss: 0.06124 | Running loss: 0.04549\n",
            "Epoch: 8 | Iteration: 690 | Classification loss: 0.00143 | Regression loss: 0.02194 | Running loss: 0.04549\n",
            "Epoch: 8 | Iteration: 691 | Classification loss: 0.00468 | Regression loss: 0.05536 | Running loss: 0.04557\n",
            "Epoch: 8 | Iteration: 692 | Classification loss: 0.00020 | Regression loss: 0.02437 | Running loss: 0.04557\n",
            "Epoch: 8 | Iteration: 693 | Classification loss: 0.00514 | Regression loss: 0.05536 | Running loss: 0.04566\n",
            "Epoch: 8 | Iteration: 694 | Classification loss: 0.00905 | Regression loss: 0.17353 | Running loss: 0.04594\n",
            "Epoch: 8 | Iteration: 695 | Classification loss: 0.00644 | Regression loss: 0.02578 | Running loss: 0.04591\n",
            "Epoch: 8 | Iteration: 696 | Classification loss: 0.00002 | Regression loss: 0.02962 | Running loss: 0.04594\n",
            "Epoch: 8 | Iteration: 697 | Classification loss: 0.00591 | Regression loss: 0.09777 | Running loss: 0.04605\n",
            "Epoch: 8 | Iteration: 698 | Classification loss: 0.39007 | Regression loss: 0.30415 | Running loss: 0.04737\n",
            "Epoch: 8 | Iteration: 699 | Classification loss: 0.00045 | Regression loss: 0.01635 | Running loss: 0.04734\n",
            "Epoch: 8 | Iteration: 700 | Classification loss: 0.00197 | Regression loss: 0.01643 | Running loss: 0.04704\n",
            "Epoch: 8 | Iteration: 701 | Classification loss: 0.00030 | Regression loss: 0.03100 | Running loss: 0.04702\n",
            "Epoch: 8 | Iteration: 702 | Classification loss: 0.02462 | Regression loss: 0.07900 | Running loss: 0.04719\n",
            "Epoch: 8 | Iteration: 703 | Classification loss: 0.00127 | Regression loss: 0.04859 | Running loss: 0.04722\n",
            "Epoch: 8 | Iteration: 704 | Classification loss: 0.00109 | Regression loss: 0.02572 | Running loss: 0.04722\n",
            "Epoch: 8 | Iteration: 705 | Classification loss: 0.03961 | Regression loss: 0.05500 | Running loss: 0.04733\n",
            "Epoch: 8 | Iteration: 706 | Classification loss: 0.00060 | Regression loss: 0.02259 | Running loss: 0.04732\n",
            "Epoch: 8 | Iteration: 707 | Classification loss: 0.00037 | Regression loss: 0.03406 | Running loss: 0.04733\n",
            "Epoch: 8 | Iteration: 708 | Classification loss: 0.00010 | Regression loss: 0.03694 | Running loss: 0.04725\n",
            "Epoch: 8 | Iteration: 709 | Classification loss: 0.00299 | Regression loss: 0.05642 | Running loss: 0.04576\n",
            "Epoch: 8 | Iteration: 710 | Classification loss: 0.03716 | Regression loss: 0.16547 | Running loss: 0.04607\n",
            "Epoch: 8 | Iteration: 711 | Classification loss: 0.00012 | Regression loss: 0.01982 | Running loss: 0.04603\n",
            "Epoch: 8 | Iteration: 712 | Classification loss: 0.00355 | Regression loss: 0.02575 | Running loss: 0.04604\n",
            "Epoch: 8 | Iteration: 713 | Classification loss: 0.00145 | Regression loss: 0.02330 | Running loss: 0.04579\n",
            "Epoch: 8 | Iteration: 714 | Classification loss: 0.04189 | Regression loss: 0.10235 | Running loss: 0.04600\n",
            "Epoch: 8 | Iteration: 715 | Classification loss: 0.00191 | Regression loss: 0.04804 | Running loss: 0.04606\n",
            "Epoch: 8 | Iteration: 716 | Classification loss: 0.01098 | Regression loss: 0.04500 | Running loss: 0.04613\n",
            "Epoch: 8 | Iteration: 717 | Classification loss: 0.00038 | Regression loss: 0.03512 | Running loss: 0.04593\n",
            "Epoch: 8 | Iteration: 718 | Classification loss: 0.00089 | Regression loss: 0.03385 | Running loss: 0.04597\n",
            "Epoch: 8 | Iteration: 719 | Classification loss: 0.00414 | Regression loss: 0.13151 | Running loss: 0.04619\n",
            "Epoch: 8 | Iteration: 720 | Classification loss: 0.00154 | Regression loss: 0.04048 | Running loss: 0.04620\n",
            "Epoch: 8 | Iteration: 721 | Classification loss: 0.00833 | Regression loss: 0.03950 | Running loss: 0.04625\n",
            "Epoch: 8 | Iteration: 722 | Classification loss: 0.00154 | Regression loss: 0.01325 | Running loss: 0.04620\n",
            "Epoch: 8 | Iteration: 723 | Classification loss: 0.00030 | Regression loss: 0.01530 | Running loss: 0.04610\n",
            "Epoch: 8 | Iteration: 724 | Classification loss: 0.00056 | Regression loss: 0.01641 | Running loss: 0.04608\n",
            "Epoch: 8 | Iteration: 725 | Classification loss: 0.00011 | Regression loss: 0.01263 | Running loss: 0.04605\n",
            "Epoch: 8 | Iteration: 726 | Classification loss: 0.00059 | Regression loss: 0.04935 | Running loss: 0.04605\n",
            "Epoch: 8 | Iteration: 727 | Classification loss: 0.01708 | Regression loss: 0.05097 | Running loss: 0.04612\n",
            "Epoch: 8 | Iteration: 728 | Classification loss: 0.00033 | Regression loss: 0.01490 | Running loss: 0.04609\n",
            "Epoch: 8 | Iteration: 729 | Classification loss: 0.00017 | Regression loss: 0.01388 | Running loss: 0.04603\n",
            "Epoch: 8 | Iteration: 730 | Classification loss: 0.00035 | Regression loss: 0.03246 | Running loss: 0.04586\n",
            "Epoch: 8 | Iteration: 731 | Classification loss: 0.00007 | Regression loss: 0.06053 | Running loss: 0.04591\n",
            "Epoch: 8 | Iteration: 732 | Classification loss: 0.00010 | Regression loss: 0.02930 | Running loss: 0.04590\n",
            "Epoch: 8 | Iteration: 733 | Classification loss: 0.00054 | Regression loss: 0.05190 | Running loss: 0.04591\n",
            "Epoch: 8 | Iteration: 734 | Classification loss: 0.00034 | Regression loss: 0.02285 | Running loss: 0.04588\n",
            "Epoch: 8 | Iteration: 735 | Classification loss: 0.00014 | Regression loss: 0.02080 | Running loss: 0.04586\n",
            "Epoch: 8 | Iteration: 736 | Classification loss: 0.00024 | Regression loss: 0.03019 | Running loss: 0.04585\n",
            "Epoch: 8 | Iteration: 737 | Classification loss: 0.00054 | Regression loss: 0.02809 | Running loss: 0.04585\n",
            "Epoch: 8 | Iteration: 738 | Classification loss: 0.00096 | Regression loss: 0.01979 | Running loss: 0.04579\n",
            "Epoch: 8 | Iteration: 739 | Classification loss: 0.00003 | Regression loss: 0.02988 | Running loss: 0.04578\n",
            "Epoch: 8 | Iteration: 740 | Classification loss: 0.00100 | Regression loss: 0.01233 | Running loss: 0.04575\n",
            "Epoch: 8 | Iteration: 741 | Classification loss: 0.00473 | Regression loss: 0.06666 | Running loss: 0.04582\n",
            "Epoch: 8 | Iteration: 742 | Classification loss: 0.08800 | Regression loss: 0.04897 | Running loss: 0.04597\n",
            "Epoch: 8 | Iteration: 743 | Classification loss: 0.00299 | Regression loss: 0.02224 | Running loss: 0.04594\n",
            "Epoch: 8 | Iteration: 744 | Classification loss: 0.00042 | Regression loss: 0.01808 | Running loss: 0.04592\n",
            "Epoch: 8 | Iteration: 745 | Classification loss: 0.00023 | Regression loss: 0.03228 | Running loss: 0.04593\n",
            "Epoch: 8 | Iteration: 746 | Classification loss: 0.00131 | Regression loss: 0.01584 | Running loss: 0.04590\n",
            "Epoch: 8 | Iteration: 747 | Classification loss: 0.00032 | Regression loss: 0.03839 | Running loss: 0.04589\n",
            "Epoch: 8 | Iteration: 748 | Classification loss: 0.00081 | Regression loss: 0.03570 | Running loss: 0.04590\n",
            "Epoch: 8 | Iteration: 749 | Classification loss: 0.00025 | Regression loss: 0.04057 | Running loss: 0.04597\n",
            "Epoch: 8 | Iteration: 750 | Classification loss: 0.00062 | Regression loss: 0.04666 | Running loss: 0.04601\n",
            "Epoch: 8 | Iteration: 751 | Classification loss: 0.00104 | Regression loss: 0.01700 | Running loss: 0.04597\n",
            "Epoch: 8 | Iteration: 752 | Classification loss: 0.00043 | Regression loss: 0.02719 | Running loss: 0.04600\n",
            "Epoch: 8 | Iteration: 753 | Classification loss: 0.00018 | Regression loss: 0.02702 | Running loss: 0.04602\n",
            "Epoch: 8 | Iteration: 754 | Classification loss: 0.00426 | Regression loss: 0.03839 | Running loss: 0.04602\n",
            "Epoch: 8 | Iteration: 755 | Classification loss: 0.00319 | Regression loss: 0.02678 | Running loss: 0.04594\n",
            "Epoch: 8 | Iteration: 756 | Classification loss: 0.00841 | Regression loss: 0.09985 | Running loss: 0.04609\n",
            "Epoch: 8 | Iteration: 757 | Classification loss: 0.00027 | Regression loss: 0.03781 | Running loss: 0.04609\n",
            "Epoch: 8 | Iteration: 758 | Classification loss: 0.01363 | Regression loss: 0.04926 | Running loss: 0.04601\n",
            "Epoch: 8 | Iteration: 759 | Classification loss: 0.00014 | Regression loss: 0.05171 | Running loss: 0.04609\n",
            "Epoch: 8 | Iteration: 760 | Classification loss: 0.00017 | Regression loss: 0.02406 | Running loss: 0.04608\n",
            "Epoch: 8 | Iteration: 761 | Classification loss: 0.00070 | Regression loss: 0.02001 | Running loss: 0.04606\n",
            "Epoch: 8 | Iteration: 762 | Classification loss: 0.01073 | Regression loss: 0.04697 | Running loss: 0.04613\n",
            "Epoch: 8 | Iteration: 763 | Classification loss: 0.00092 | Regression loss: 0.02282 | Running loss: 0.04606\n",
            "Epoch: 8 | Iteration: 764 | Classification loss: 0.00090 | Regression loss: 0.02667 | Running loss: 0.04604\n",
            "Epoch: 8 | Iteration: 765 | Classification loss: 0.00012 | Regression loss: 0.00860 | Running loss: 0.04597\n",
            "Epoch: 8 | Iteration: 766 | Classification loss: 0.00078 | Regression loss: 0.02745 | Running loss: 0.04598\n",
            "Epoch: 8 | Iteration: 767 | Classification loss: 0.00050 | Regression loss: 0.03187 | Running loss: 0.04600\n",
            "Epoch: 8 | Iteration: 768 | Classification loss: 0.00016 | Regression loss: 0.03448 | Running loss: 0.04603\n",
            "Epoch: 8 | Iteration: 769 | Classification loss: 0.01919 | Regression loss: 0.04027 | Running loss: 0.04596\n",
            "Epoch: 8 | Iteration: 770 | Classification loss: 0.00006 | Regression loss: 0.01753 | Running loss: 0.04597\n",
            "Epoch: 8 | Iteration: 771 | Classification loss: 0.00098 | Regression loss: 0.02489 | Running loss: 0.04575\n",
            "Epoch: 8 | Iteration: 772 | Classification loss: 0.00017 | Regression loss: 0.02109 | Running loss: 0.04576\n",
            "Epoch: 8 | Iteration: 773 | Classification loss: 0.00004 | Regression loss: 0.02416 | Running loss: 0.04575\n",
            "Epoch: 8 | Iteration: 774 | Classification loss: 0.00040 | Regression loss: 0.02110 | Running loss: 0.04549\n",
            "Epoch: 8 | Iteration: 775 | Classification loss: 0.00022 | Regression loss: 0.01088 | Running loss: 0.04547\n",
            "Epoch: 8 | Iteration: 776 | Classification loss: 0.00139 | Regression loss: 0.02201 | Running loss: 0.04543\n",
            "Epoch: 8 | Iteration: 777 | Classification loss: 0.00411 | Regression loss: 0.02906 | Running loss: 0.04542\n",
            "Epoch: 8 | Iteration: 778 | Classification loss: 0.03658 | Regression loss: 0.15531 | Running loss: 0.04577\n",
            "Epoch: 8 | Iteration: 779 | Classification loss: 0.00304 | Regression loss: 0.01928 | Running loss: 0.04551\n",
            "Epoch: 8 | Iteration: 780 | Classification loss: 0.00380 | Regression loss: 0.03601 | Running loss: 0.04548\n",
            "Epoch: 8 | Iteration: 781 | Classification loss: 0.00014 | Regression loss: 0.01331 | Running loss: 0.04545\n",
            "Epoch: 8 | Iteration: 782 | Classification loss: 0.00009 | Regression loss: 0.02140 | Running loss: 0.04535\n",
            "Epoch: 8 | Iteration: 783 | Classification loss: 0.00020 | Regression loss: 0.01863 | Running loss: 0.04535\n",
            "Epoch: 8 | Iteration: 784 | Classification loss: 0.00004 | Regression loss: 0.01609 | Running loss: 0.04534\n",
            "Epoch: 8 | Iteration: 785 | Classification loss: 0.00020 | Regression loss: 0.01008 | Running loss: 0.04485\n",
            "Epoch: 8 | Iteration: 786 | Classification loss: 0.01697 | Regression loss: 0.07428 | Running loss: 0.04494\n",
            "Epoch: 8 | Iteration: 787 | Classification loss: 0.00016 | Regression loss: 0.01056 | Running loss: 0.04491\n",
            "Epoch: 8 | Iteration: 788 | Classification loss: 0.00070 | Regression loss: 0.03775 | Running loss: 0.04489\n",
            "Epoch: 8 | Iteration: 789 | Classification loss: 0.04953 | Regression loss: 0.03309 | Running loss: 0.04488\n",
            "Epoch: 8 | Iteration: 790 | Classification loss: 0.00184 | Regression loss: 0.03048 | Running loss: 0.04476\n",
            "Epoch: 8 | Iteration: 791 | Classification loss: 0.00238 | Regression loss: 0.06129 | Running loss: 0.04483\n",
            "Epoch: 8 | Iteration: 792 | Classification loss: 0.00024 | Regression loss: 0.03697 | Running loss: 0.04485\n",
            "Epoch: 8 | Iteration: 793 | Classification loss: 0.00109 | Regression loss: 0.03066 | Running loss: 0.04486\n",
            "Epoch: 8 | Iteration: 794 | Classification loss: 0.00006 | Regression loss: 0.01869 | Running loss: 0.04474\n",
            "Epoch: 8 | Iteration: 795 | Classification loss: 0.00008 | Regression loss: 0.01733 | Running loss: 0.04469\n",
            "Epoch: 8 | Iteration: 796 | Classification loss: 0.00012 | Regression loss: 0.01768 | Running loss: 0.04469\n",
            "Epoch: 8 | Iteration: 797 | Classification loss: 0.00030 | Regression loss: 0.02164 | Running loss: 0.04469\n",
            "Epoch: 8 | Iteration: 798 | Classification loss: 0.00023 | Regression loss: 0.01209 | Running loss: 0.04466\n",
            "Epoch: 8 | Iteration: 799 | Classification loss: 0.00025 | Regression loss: 0.05050 | Running loss: 0.04471\n",
            "Epoch: 8 | Iteration: 800 | Classification loss: 0.00017 | Regression loss: 0.01738 | Running loss: 0.04472\n",
            "Epoch: 8 | Iteration: 801 | Classification loss: 0.00275 | Regression loss: 0.04901 | Running loss: 0.04475\n",
            "Epoch: 8 | Iteration: 802 | Classification loss: 0.00464 | Regression loss: 0.03525 | Running loss: 0.04479\n",
            "Epoch: 8 | Iteration: 803 | Classification loss: 0.00011 | Regression loss: 0.01246 | Running loss: 0.04478\n",
            "Epoch: 8 | Iteration: 804 | Classification loss: 0.00012 | Regression loss: 0.02524 | Running loss: 0.04479\n",
            "Epoch: 8 | Iteration: 805 | Classification loss: 0.00012 | Regression loss: 0.01247 | Running loss: 0.04479\n",
            "Epoch: 8 | Iteration: 806 | Classification loss: 0.00349 | Regression loss: 0.04306 | Running loss: 0.04487\n",
            "Epoch: 8 | Iteration: 807 | Classification loss: 0.00014 | Regression loss: 0.02334 | Running loss: 0.04485\n",
            "Epoch: 8 | Iteration: 808 | Classification loss: 0.00089 | Regression loss: 0.01863 | Running loss: 0.04486\n",
            "Epoch: 8 | Iteration: 809 | Classification loss: 0.00556 | Regression loss: 0.06407 | Running loss: 0.04493\n",
            "Epoch: 8 | Iteration: 810 | Classification loss: 0.00101 | Regression loss: 0.03148 | Running loss: 0.04492\n",
            "Epoch: 8 | Iteration: 811 | Classification loss: 0.00373 | Regression loss: 0.02515 | Running loss: 0.04491\n",
            "Epoch: 8 | Iteration: 812 | Classification loss: 0.00004 | Regression loss: 0.01006 | Running loss: 0.04488\n",
            "Epoch: 8 | Iteration: 813 | Classification loss: 0.00015 | Regression loss: 0.02578 | Running loss: 0.04476\n",
            "Epoch: 8 | Iteration: 814 | Classification loss: 0.00055 | Regression loss: 0.01734 | Running loss: 0.04471\n",
            "Epoch: 8 | Iteration: 815 | Classification loss: 0.00072 | Regression loss: 0.01398 | Running loss: 0.04467\n",
            "Epoch: 8 | Iteration: 816 | Classification loss: 0.00067 | Regression loss: 0.03608 | Running loss: 0.04468\n",
            "Epoch: 8 | Iteration: 817 | Classification loss: 0.00088 | Regression loss: 0.03982 | Running loss: 0.04465\n",
            "Epoch: 8 | Iteration: 818 | Classification loss: 0.00033 | Regression loss: 0.01593 | Running loss: 0.04466\n",
            "Epoch: 8 | Iteration: 819 | Classification loss: 0.00034 | Regression loss: 0.02858 | Running loss: 0.04468\n",
            "Epoch: 8 | Iteration: 820 | Classification loss: 0.01266 | Regression loss: 0.03152 | Running loss: 0.04461\n",
            "Epoch: 8 | Iteration: 821 | Classification loss: 0.00046 | Regression loss: 0.02202 | Running loss: 0.04457\n",
            "Epoch: 8 | Iteration: 822 | Classification loss: 0.00007 | Regression loss: 0.02981 | Running loss: 0.04461\n",
            "Epoch: 8 | Iteration: 823 | Classification loss: 0.82205 | Regression loss: 0.01903 | Running loss: 0.04624\n",
            "Epoch: 8 | Iteration: 824 | Classification loss: 0.00059 | Regression loss: 0.02720 | Running loss: 0.04624\n",
            "Epoch: 8 | Iteration: 825 | Classification loss: 0.00075 | Regression loss: 0.02214 | Running loss: 0.04624\n",
            "Epoch: 8 | Iteration: 826 | Classification loss: 0.00020 | Regression loss: 0.01346 | Running loss: 0.04619\n",
            "Epoch: 8 | Iteration: 827 | Classification loss: 0.00001 | Regression loss: 0.01930 | Running loss: 0.04618\n",
            "Epoch: 8 | Iteration: 828 | Classification loss: 0.00358 | Regression loss: 0.02067 | Running loss: 0.04617\n",
            "Epoch: 8 | Iteration: 829 | Classification loss: 0.00383 | Regression loss: 0.04438 | Running loss: 0.04624\n",
            "Epoch: 8 | Iteration: 830 | Classification loss: 0.01252 | Regression loss: 0.02918 | Running loss: 0.04621\n",
            "Epoch: 8 | Iteration: 831 | Classification loss: 0.00027 | Regression loss: 0.01841 | Running loss: 0.04619\n",
            "Epoch: 8 | Iteration: 832 | Classification loss: 0.00042 | Regression loss: 0.06736 | Running loss: 0.04623\n",
            "Epoch: 8 | Iteration: 833 | Classification loss: 0.26682 | Regression loss: 0.26834 | Running loss: 0.04725\n",
            "Epoch: 8 | Iteration: 834 | Classification loss: 0.00778 | Regression loss: 0.06370 | Running loss: 0.04733\n",
            "Epoch: 8 | Iteration: 835 | Classification loss: 0.00242 | Regression loss: 0.01980 | Running loss: 0.04733\n",
            "Epoch: 8 | Iteration: 836 | Classification loss: 0.00041 | Regression loss: 0.04651 | Running loss: 0.04739\n",
            "Epoch: 8 | Iteration: 837 | Classification loss: 0.00073 | Regression loss: 0.04001 | Running loss: 0.04735\n",
            "Epoch: 8 | Iteration: 838 | Classification loss: 0.00036 | Regression loss: 0.02123 | Running loss: 0.04737\n",
            "Epoch: 8 | Iteration: 839 | Classification loss: 0.00409 | Regression loss: 0.06755 | Running loss: 0.04745\n",
            "Epoch: 8 | Iteration: 840 | Classification loss: 0.00042 | Regression loss: 0.03299 | Running loss: 0.04744\n",
            "Epoch: 8 | Iteration: 841 | Classification loss: 0.00073 | Regression loss: 0.03866 | Running loss: 0.04748\n",
            "Epoch: 8 | Iteration: 842 | Classification loss: 0.00214 | Regression loss: 0.01207 | Running loss: 0.04747\n",
            "Epoch: 8 | Iteration: 843 | Classification loss: 0.00311 | Regression loss: 0.02078 | Running loss: 0.04744\n",
            "Epoch: 8 | Iteration: 844 | Classification loss: 0.00053 | Regression loss: 0.01813 | Running loss: 0.04742\n",
            "Epoch: 8 | Iteration: 845 | Classification loss: 0.00683 | Regression loss: 0.02414 | Running loss: 0.04743\n",
            "Epoch: 8 | Iteration: 846 | Classification loss: 0.00018 | Regression loss: 0.02266 | Running loss: 0.04745\n",
            "Epoch: 8 | Iteration: 847 | Classification loss: 0.00615 | Regression loss: 0.06322 | Running loss: 0.04751\n",
            "Epoch: 8 | Iteration: 848 | Classification loss: 0.01669 | Regression loss: 0.01664 | Running loss: 0.04754\n",
            "Epoch: 8 | Iteration: 849 | Classification loss: 0.00048 | Regression loss: 0.02219 | Running loss: 0.04750\n",
            "Epoch: 8 | Iteration: 850 | Classification loss: 0.00007 | Regression loss: 0.02454 | Running loss: 0.04750\n",
            "Epoch: 8 | Iteration: 851 | Classification loss: 0.00025 | Regression loss: 0.02203 | Running loss: 0.04749\n",
            "Epoch: 8 | Iteration: 852 | Classification loss: 0.00143 | Regression loss: 0.01818 | Running loss: 0.04737\n",
            "Epoch: 8 | Iteration: 853 | Classification loss: 0.03561 | Regression loss: 0.06572 | Running loss: 0.04746\n",
            "Epoch: 8 | Iteration: 854 | Classification loss: 0.00057 | Regression loss: 0.02003 | Running loss: 0.04743\n",
            "Epoch: 8 | Iteration: 855 | Classification loss: 0.00026 | Regression loss: 0.01794 | Running loss: 0.04635\n",
            "Epoch: 8 | Iteration: 856 | Classification loss: 0.00027 | Regression loss: 0.02998 | Running loss: 0.04635\n",
            "Epoch: 8 | Iteration: 857 | Classification loss: 0.00155 | Regression loss: 0.02723 | Running loss: 0.04636\n",
            "Epoch: 8 | Iteration: 858 | Classification loss: 0.00131 | Regression loss: 0.07333 | Running loss: 0.04648\n",
            "Epoch: 8 | Iteration: 859 | Classification loss: 0.00307 | Regression loss: 0.01415 | Running loss: 0.04647\n",
            "Epoch: 8 | Iteration: 860 | Classification loss: 0.00153 | Regression loss: 0.02939 | Running loss: 0.04649\n",
            "Epoch: 8 | Iteration: 861 | Classification loss: 0.01169 | Regression loss: 0.06743 | Running loss: 0.04660\n",
            "Epoch: 8 | Iteration: 862 | Classification loss: 0.00026 | Regression loss: 0.01566 | Running loss: 0.04658\n",
            "Epoch: 8 | Iteration: 863 | Classification loss: 0.03418 | Regression loss: 0.03933 | Running loss: 0.04637\n",
            "Epoch: 8 | Iteration: 864 | Classification loss: 0.00024 | Regression loss: 0.01715 | Running loss: 0.04635\n",
            "Epoch: 8 | Iteration: 865 | Classification loss: 0.00020 | Regression loss: 0.01884 | Running loss: 0.04632\n",
            "Epoch: 8 | Iteration: 866 | Classification loss: 0.00560 | Regression loss: 0.04030 | Running loss: 0.04639\n",
            "Epoch: 8 | Iteration: 867 | Classification loss: 0.00100 | Regression loss: 0.02891 | Running loss: 0.04640\n",
            "Epoch: 8 | Iteration: 868 | Classification loss: 0.00008 | Regression loss: 0.01735 | Running loss: 0.04637\n",
            "Epoch: 8 | Iteration: 869 | Classification loss: 0.00175 | Regression loss: 0.04377 | Running loss: 0.04642\n",
            "Epoch: 8 | Iteration: 870 | Classification loss: 0.00273 | Regression loss: 0.04268 | Running loss: 0.04643\n",
            "Epoch: 8 | Iteration: 871 | Classification loss: 0.00340 | Regression loss: 0.01668 | Running loss: 0.04645\n",
            "Epoch: 8 | Iteration: 872 | Classification loss: 0.00232 | Regression loss: 0.02499 | Running loss: 0.04640\n",
            "Epoch: 8 | Iteration: 873 | Classification loss: 0.00044 | Regression loss: 0.03150 | Running loss: 0.04642\n",
            "Epoch: 8 | Iteration: 874 | Classification loss: 0.00003 | Regression loss: 0.03765 | Running loss: 0.04641\n",
            "Epoch: 8 | Iteration: 875 | Classification loss: 0.14965 | Regression loss: 0.26925 | Running loss: 0.04723\n",
            "Epoch: 8 | Iteration: 876 | Classification loss: 0.00013 | Regression loss: 0.01591 | Running loss: 0.04712\n",
            "Epoch: 8 | Iteration: 877 | Classification loss: 0.00210 | Regression loss: 0.02323 | Running loss: 0.04710\n",
            "Epoch: 8 | Iteration: 878 | Classification loss: 0.00029 | Regression loss: 0.01789 | Running loss: 0.04709\n",
            "Epoch: 8 | Iteration: 879 | Classification loss: 0.00026 | Regression loss: 0.02966 | Running loss: 0.04709\n",
            "Epoch: 8 | Iteration: 880 | Classification loss: 0.00002 | Regression loss: 0.01445 | Running loss: 0.04708\n",
            "Epoch: 8 | Iteration: 881 | Classification loss: 0.00019 | Regression loss: 0.03880 | Running loss: 0.04710\n",
            "Epoch: 8 | Iteration: 882 | Classification loss: 0.00335 | Regression loss: 0.02202 | Running loss: 0.04709\n",
            "Epoch: 8 | Iteration: 883 | Classification loss: 0.00041 | Regression loss: 0.01242 | Running loss: 0.04704\n",
            "Epoch: 8 | Iteration: 884 | Classification loss: 0.00010 | Regression loss: 0.01476 | Running loss: 0.04697\n",
            "Epoch: 8 | Iteration: 885 | Classification loss: 0.00009 | Regression loss: 0.01414 | Running loss: 0.04693\n",
            "Epoch: 8 | Iteration: 886 | Classification loss: 0.00254 | Regression loss: 0.02537 | Running loss: 0.04694\n",
            "Epoch: 8 | Iteration: 887 | Classification loss: 0.00543 | Regression loss: 0.03644 | Running loss: 0.04693\n",
            "Epoch: 8 | Iteration: 888 | Classification loss: 0.00004 | Regression loss: 0.01176 | Running loss: 0.04688\n",
            "Epoch: 8 | Iteration: 889 | Classification loss: 0.00078 | Regression loss: 0.02075 | Running loss: 0.04687\n",
            "Epoch: 8 | Iteration: 890 | Classification loss: 0.00003 | Regression loss: 0.01816 | Running loss: 0.04683\n",
            "Epoch: 8 | Iteration: 891 | Classification loss: 0.00010 | Regression loss: 0.02478 | Running loss: 0.04668\n",
            "Epoch: 8 | Iteration: 892 | Classification loss: 0.00003 | Regression loss: 0.01570 | Running loss: 0.04660\n",
            "Epoch: 8 | Iteration: 893 | Classification loss: 0.00127 | Regression loss: 0.03615 | Running loss: 0.04663\n",
            "Epoch: 8 | Iteration: 894 | Classification loss: 0.00038 | Regression loss: 0.00956 | Running loss: 0.04656\n",
            "Epoch: 8 | Iteration: 895 | Classification loss: 0.00031 | Regression loss: 0.02375 | Running loss: 0.04651\n",
            "Epoch: 8 | Iteration: 896 | Classification loss: 0.00042 | Regression loss: 0.02957 | Running loss: 0.04652\n",
            "Epoch: 8 | Iteration: 897 | Classification loss: 0.00006 | Regression loss: 0.02256 | Running loss: 0.04651\n",
            "Epoch: 8 | Iteration: 898 | Classification loss: 0.00785 | Regression loss: 0.14108 | Running loss: 0.04666\n",
            "Epoch: 8 | Iteration: 899 | Classification loss: 0.00023 | Regression loss: 0.02316 | Running loss: 0.04664\n",
            "Epoch: 8 | Iteration: 900 | Classification loss: 0.00031 | Regression loss: 0.02593 | Running loss: 0.04665\n",
            "Epoch: 8 | Iteration: 901 | Classification loss: 0.00079 | Regression loss: 0.00944 | Running loss: 0.04660\n",
            "Epoch: 8 | Iteration: 902 | Classification loss: 0.00020 | Regression loss: 0.01440 | Running loss: 0.04657\n",
            "Epoch: 8 | Iteration: 903 | Classification loss: 0.00011 | Regression loss: 0.01088 | Running loss: 0.04654\n",
            "Epoch: 8 | Iteration: 904 | Classification loss: 0.00002 | Regression loss: 0.00620 | Running loss: 0.04648\n",
            "Epoch: 8 | Iteration: 905 | Classification loss: 0.01368 | Regression loss: 0.11190 | Running loss: 0.04665\n",
            "Epoch: 8 | Iteration: 906 | Classification loss: 0.00005 | Regression loss: 0.02417 | Running loss: 0.04666\n",
            "Epoch: 8 | Iteration: 907 | Classification loss: 0.00074 | Regression loss: 0.05129 | Running loss: 0.04662\n",
            "Epoch: 8 | Iteration: 908 | Classification loss: 0.00050 | Regression loss: 0.03513 | Running loss: 0.04653\n",
            "Epoch: 8 | Iteration: 909 | Classification loss: 0.00036 | Regression loss: 0.04767 | Running loss: 0.04658\n",
            "Epoch: 8 | Iteration: 910 | Classification loss: 0.00047 | Regression loss: 0.03822 | Running loss: 0.04644\n",
            "Epoch: 8 | Iteration: 911 | Classification loss: 0.00010 | Regression loss: 0.01094 | Running loss: 0.04632\n",
            "Epoch: 8 | Iteration: 912 | Classification loss: 0.00052 | Regression loss: 0.03054 | Running loss: 0.04621\n",
            "Epoch: 8 | Iteration: 913 | Classification loss: 0.00016 | Regression loss: 0.00921 | Running loss: 0.04617\n",
            "Epoch: 8 | Iteration: 914 | Classification loss: 0.00146 | Regression loss: 0.04168 | Running loss: 0.04621\n",
            "Epoch: 8 | Iteration: 915 | Classification loss: 0.00017 | Regression loss: 0.04726 | Running loss: 0.04626\n",
            "Epoch: 8 | Iteration: 916 | Classification loss: 0.00098 | Regression loss: 0.04395 | Running loss: 0.04622\n",
            "Epoch: 8 | Iteration: 917 | Classification loss: 0.00023 | Regression loss: 0.01477 | Running loss: 0.04613\n",
            "Epoch: 8 | Iteration: 918 | Classification loss: 0.00237 | Regression loss: 0.04930 | Running loss: 0.04611\n",
            "Epoch: 8 | Iteration: 919 | Classification loss: 0.00039 | Regression loss: 0.03269 | Running loss: 0.04605\n",
            "Epoch: 8 | Iteration: 920 | Classification loss: 0.00012 | Regression loss: 0.03261 | Running loss: 0.04605\n",
            "Epoch: 8 | Iteration: 921 | Classification loss: 0.00017 | Regression loss: 0.02703 | Running loss: 0.04606\n",
            "Epoch: 8 | Iteration: 922 | Classification loss: 0.00034 | Regression loss: 0.02599 | Running loss: 0.04602\n",
            "Epoch: 8 | Iteration: 923 | Classification loss: 0.13402 | Regression loss: 0.27531 | Running loss: 0.04676\n",
            "Epoch: 8 | Iteration: 924 | Classification loss: 0.00028 | Regression loss: 0.01306 | Running loss: 0.04671\n",
            "Epoch: 8 | Iteration: 925 | Classification loss: 0.00005 | Regression loss: 0.03873 | Running loss: 0.04673\n",
            "Epoch: 8 | Iteration: 926 | Classification loss: 0.00064 | Regression loss: 0.04719 | Running loss: 0.04675\n",
            "Epoch: 8 | Iteration: 927 | Classification loss: 0.00006 | Regression loss: 0.02626 | Running loss: 0.04675\n",
            "Epoch: 8 | Iteration: 928 | Classification loss: 0.00348 | Regression loss: 0.03611 | Running loss: 0.04676\n",
            "Epoch: 8 | Iteration: 929 | Classification loss: 0.00006 | Regression loss: 0.03909 | Running loss: 0.04679\n",
            "Epoch: 8 | Iteration: 930 | Classification loss: 0.00042 | Regression loss: 0.03268 | Running loss: 0.04674\n",
            "Epoch: 8 | Iteration: 931 | Classification loss: 0.00221 | Regression loss: 0.04150 | Running loss: 0.04675\n",
            "Epoch: 8 | Iteration: 932 | Classification loss: 0.00063 | Regression loss: 0.02237 | Running loss: 0.04676\n",
            "Epoch: 8 | Iteration: 933 | Classification loss: 0.01693 | Regression loss: 0.10731 | Running loss: 0.04691\n",
            "Epoch: 8 | Iteration: 934 | Classification loss: 0.00018 | Regression loss: 0.02918 | Running loss: 0.04689\n",
            "Epoch: 8 | Iteration: 935 | Classification loss: 0.00015 | Regression loss: 0.02428 | Running loss: 0.04691\n",
            "Epoch: 8 | Iteration: 936 | Classification loss: 0.00112 | Regression loss: 0.03192 | Running loss: 0.04692\n",
            "Epoch: 8 | Iteration: 937 | Classification loss: 0.00065 | Regression loss: 0.02193 | Running loss: 0.04686\n",
            "Epoch: 8 | Iteration: 938 | Classification loss: 0.00245 | Regression loss: 0.05498 | Running loss: 0.04690\n",
            "Epoch: 8 | Iteration: 939 | Classification loss: 0.00012 | Regression loss: 0.02536 | Running loss: 0.04685\n",
            "Epoch: 8 | Iteration: 940 | Classification loss: 0.00048 | Regression loss: 0.05336 | Running loss: 0.04686\n",
            "Epoch: 8 | Iteration: 941 | Classification loss: 0.00092 | Regression loss: 0.02005 | Running loss: 0.04685\n",
            "Epoch: 8 | Iteration: 942 | Classification loss: 0.00076 | Regression loss: 0.01533 | Running loss: 0.04684\n",
            "Epoch: 8 | Iteration: 943 | Classification loss: 0.00036 | Regression loss: 0.01520 | Running loss: 0.04557\n",
            "Epoch: 8 | Iteration: 944 | Classification loss: 0.00372 | Regression loss: 0.04611 | Running loss: 0.04554\n",
            "Epoch: 8 | Iteration: 945 | Classification loss: 0.00030 | Regression loss: 0.01690 | Running loss: 0.04552\n",
            "Epoch: 8 | Iteration: 946 | Classification loss: 0.00108 | Regression loss: 0.02014 | Running loss: 0.04551\n",
            "Epoch: 8 | Iteration: 947 | Classification loss: 0.00004 | Regression loss: 0.02623 | Running loss: 0.04544\n",
            "Epoch: 8 | Iteration: 948 | Classification loss: 0.00017 | Regression loss: 0.02824 | Running loss: 0.04545\n",
            "Epoch: 8 | Iteration: 949 | Classification loss: 0.00010 | Regression loss: 0.01639 | Running loss: 0.04538\n",
            "Epoch: 8 | Iteration: 950 | Classification loss: 0.00028 | Regression loss: 0.02935 | Running loss: 0.04472\n",
            "Epoch: 8 | Iteration: 951 | Classification loss: 0.00011 | Regression loss: 0.01365 | Running loss: 0.04470\n",
            "Epoch: 8 | Iteration: 952 | Classification loss: 0.00076 | Regression loss: 0.03061 | Running loss: 0.04469\n",
            "Epoch: 8 | Iteration: 953 | Classification loss: 0.00007 | Regression loss: 0.01373 | Running loss: 0.04466\n",
            "Epoch: 8 | Iteration: 954 | Classification loss: 0.00031 | Regression loss: 0.04452 | Running loss: 0.04471\n",
            "Epoch: 8 | Iteration: 955 | Classification loss: 0.00015 | Regression loss: 0.02167 | Running loss: 0.04471\n",
            "Epoch: 8 | Iteration: 956 | Classification loss: 0.00034 | Regression loss: 0.04673 | Running loss: 0.04477\n",
            "Epoch: 8 | Iteration: 957 | Classification loss: 0.00002 | Regression loss: 0.01894 | Running loss: 0.04479\n",
            "Epoch: 8 | Iteration: 958 | Classification loss: 0.00075 | Regression loss: 0.02055 | Running loss: 0.04477\n",
            "Epoch: 8 | Iteration: 959 | Classification loss: 0.00014 | Regression loss: 0.01654 | Running loss: 0.04477\n",
            "Epoch: 8 | Iteration: 960 | Classification loss: 0.00042 | Regression loss: 0.01865 | Running loss: 0.04476\n",
            "Epoch: 8 | Iteration: 961 | Classification loss: 0.00068 | Regression loss: 0.04214 | Running loss: 0.04478\n",
            "Epoch: 8 | Iteration: 962 | Classification loss: 0.00004 | Regression loss: 0.01972 | Running loss: 0.04480\n",
            "Epoch: 8 | Iteration: 963 | Classification loss: 0.00057 | Regression loss: 0.03040 | Running loss: 0.04482\n",
            "Epoch: 8 | Iteration: 964 | Classification loss: 0.00004 | Regression loss: 0.02625 | Running loss: 0.04438\n",
            "Epoch: 8 | Iteration: 965 | Classification loss: 0.00088 | Regression loss: 0.04216 | Running loss: 0.04443\n",
            "Epoch: 8 | Iteration: 966 | Classification loss: 0.00085 | Regression loss: 0.03411 | Running loss: 0.04442\n",
            "Epoch: 8 | Iteration: 967 | Classification loss: 0.00027 | Regression loss: 0.04009 | Running loss: 0.04439\n",
            "Epoch: 8 | Iteration: 968 | Classification loss: 0.00049 | Regression loss: 0.03007 | Running loss: 0.04433\n",
            "Epoch: 8 | Iteration: 969 | Classification loss: 0.00006 | Regression loss: 0.02621 | Running loss: 0.04436\n",
            "Epoch: 8 | Iteration: 970 | Classification loss: 0.00013 | Regression loss: 0.02483 | Running loss: 0.04344\n",
            "Epoch: 8 | Iteration: 971 | Classification loss: 0.00086 | Regression loss: 0.03587 | Running loss: 0.04344\n",
            "Epoch: 8 | Iteration: 972 | Classification loss: 0.00013 | Regression loss: 0.02082 | Running loss: 0.04343\n",
            "Epoch: 8 | Iteration: 973 | Classification loss: 0.00024 | Regression loss: 0.04082 | Running loss: 0.04344\n",
            "Epoch: 8 | Iteration: 974 | Classification loss: 0.00012 | Regression loss: 0.02494 | Running loss: 0.04342\n",
            "Epoch: 8 | Iteration: 975 | Classification loss: 0.00029 | Regression loss: 0.02279 | Running loss: 0.04340\n",
            "Epoch: 8 | Iteration: 976 | Classification loss: 0.00015 | Regression loss: 0.03805 | Running loss: 0.04340\n",
            "Epoch: 8 | Iteration: 977 | Classification loss: 0.17415 | Regression loss: 0.17663 | Running loss: 0.04404\n",
            "Epoch: 8 | Iteration: 978 | Classification loss: 0.00006 | Regression loss: 0.01512 | Running loss: 0.04403\n",
            "Epoch: 8 | Iteration: 979 | Classification loss: 0.00312 | Regression loss: 0.01720 | Running loss: 0.04405\n",
            "Epoch: 8 | Iteration: 980 | Classification loss: 0.00111 | Regression loss: 0.07005 | Running loss: 0.04414\n",
            "Epoch: 8 | Iteration: 981 | Classification loss: 0.00304 | Regression loss: 0.02430 | Running loss: 0.04411\n",
            "Epoch: 8 | Iteration: 982 | Classification loss: 0.00005 | Regression loss: 0.02612 | Running loss: 0.04407\n",
            "Epoch: 8 | Iteration: 983 | Classification loss: 0.10362 | Regression loss: 0.23558 | Running loss: 0.04470\n",
            "Epoch: 8 | Iteration: 984 | Classification loss: 0.00012 | Regression loss: 0.05438 | Running loss: 0.04475\n",
            "Epoch: 8 | Iteration: 985 | Classification loss: 0.00014 | Regression loss: 0.02963 | Running loss: 0.04468\n",
            "Epoch: 8 | Iteration: 986 | Classification loss: 0.00164 | Regression loss: 0.04385 | Running loss: 0.04455\n",
            "Epoch: 8 | Iteration: 987 | Classification loss: 0.00042 | Regression loss: 0.02302 | Running loss: 0.04448\n",
            "Epoch: 8 | Iteration: 988 | Classification loss: 0.00102 | Regression loss: 0.04475 | Running loss: 0.04448\n",
            "Epoch: 8 | Iteration: 989 | Classification loss: 0.00005 | Regression loss: 0.07102 | Running loss: 0.04457\n",
            "Epoch: 8 | Iteration: 990 | Classification loss: 0.00014 | Regression loss: 0.01454 | Running loss: 0.04453\n",
            "Epoch: 8 | Iteration: 991 | Classification loss: 0.00111 | Regression loss: 0.01390 | Running loss: 0.04451\n",
            "Epoch: 8 | Iteration: 992 | Classification loss: 0.00004 | Regression loss: 0.03479 | Running loss: 0.04452\n",
            "Epoch: 8 | Iteration: 993 | Classification loss: 0.00028 | Regression loss: 0.02901 | Running loss: 0.04442\n",
            "Epoch: 8 | Iteration: 994 | Classification loss: 0.00020 | Regression loss: 0.06044 | Running loss: 0.04447\n",
            "Epoch: 8 | Iteration: 995 | Classification loss: 0.00152 | Regression loss: 0.03739 | Running loss: 0.04450\n",
            "Epoch: 8 | Iteration: 996 | Classification loss: 0.00024 | Regression loss: 0.05038 | Running loss: 0.04454\n",
            "Epoch: 8 | Iteration: 997 | Classification loss: 0.00289 | Regression loss: 0.04090 | Running loss: 0.04457\n",
            "Epoch: 8 | Iteration: 998 | Classification loss: 0.00055 | Regression loss: 0.02683 | Running loss: 0.04454\n",
            "Epoch: 8 | Iteration: 999 | Classification loss: 0.00171 | Regression loss: 0.03740 | Running loss: 0.04438\n",
            "Epoch: 8 | Iteration: 1000 | Classification loss: 0.00108 | Regression loss: 0.04081 | Running loss: 0.04441\n",
            "Epoch: 8 | Iteration: 1001 | Classification loss: 0.00065 | Regression loss: 0.01660 | Running loss: 0.04440\n",
            "Epoch: 8 | Iteration: 1002 | Classification loss: 0.00005 | Regression loss: 0.02624 | Running loss: 0.04440\n",
            "Epoch: 8 | Iteration: 1003 | Classification loss: 0.00014 | Regression loss: 0.04818 | Running loss: 0.04445\n",
            "Epoch: 8 | Iteration: 1004 | Classification loss: 0.00013 | Regression loss: 0.04473 | Running loss: 0.04447\n",
            "Epoch: 8 | Iteration: 1005 | Classification loss: 0.00159 | Regression loss: 0.04573 | Running loss: 0.04445\n",
            "Epoch: 8 | Iteration: 1006 | Classification loss: 0.00017 | Regression loss: 0.03839 | Running loss: 0.04450\n",
            "Epoch: 8 | Iteration: 1007 | Classification loss: 0.00209 | Regression loss: 0.05653 | Running loss: 0.04440\n",
            "Epoch: 8 | Iteration: 1008 | Classification loss: 0.00011 | Regression loss: 0.02609 | Running loss: 0.04440\n",
            "Epoch: 8 | Iteration: 1009 | Classification loss: 0.00007 | Regression loss: 0.02413 | Running loss: 0.04439\n",
            "Epoch: 8 | Iteration: 1010 | Classification loss: 0.00019 | Regression loss: 0.02967 | Running loss: 0.04440\n",
            "Epoch: 8 | Iteration: 1011 | Classification loss: 0.00008 | Regression loss: 0.02730 | Running loss: 0.04441\n",
            "Epoch: 8 | Iteration: 1012 | Classification loss: 0.04398 | Regression loss: 0.10343 | Running loss: 0.04359\n",
            "Epoch: 8 | Iteration: 1013 | Classification loss: 0.00003 | Regression loss: 0.03543 | Running loss: 0.04354\n",
            "Epoch: 8 | Iteration: 1014 | Classification loss: 0.00037 | Regression loss: 0.02823 | Running loss: 0.04356\n",
            "Epoch: 8 | Iteration: 1015 | Classification loss: 0.00010 | Regression loss: 0.01878 | Running loss: 0.04356\n",
            "Epoch: 8 | Iteration: 1016 | Classification loss: 0.00016 | Regression loss: 0.03641 | Running loss: 0.04353\n",
            "Epoch: 8 | Iteration: 1017 | Classification loss: 0.00020 | Regression loss: 0.03095 | Running loss: 0.04355\n",
            "Epoch: 8 | Iteration: 1018 | Classification loss: 0.00003 | Regression loss: 0.01435 | Running loss: 0.04351\n",
            "Epoch: 8 | Iteration: 1019 | Classification loss: 0.00108 | Regression loss: 0.03388 | Running loss: 0.04354\n",
            "Epoch: 8 | Iteration: 1020 | Classification loss: 0.00003 | Regression loss: 0.04720 | Running loss: 0.04359\n",
            "Epoch: 8 | Iteration: 1021 | Classification loss: 0.00036 | Regression loss: 0.03235 | Running loss: 0.04360\n",
            "Epoch: 8 | Iteration: 1022 | Classification loss: 0.00040 | Regression loss: 0.04099 | Running loss: 0.04363\n",
            "Epoch: 8 | Iteration: 1023 | Classification loss: 0.00022 | Regression loss: 0.04009 | Running loss: 0.04369\n",
            "Epoch: 8 | Iteration: 1024 | Classification loss: 0.00001 | Regression loss: 0.03316 | Running loss: 0.04369\n",
            "Epoch: 8 | Iteration: 1025 | Classification loss: 0.00041 | Regression loss: 0.02650 | Running loss: 0.04372\n",
            "Epoch: 8 | Iteration: 1026 | Classification loss: 0.00013 | Regression loss: 0.02756 | Running loss: 0.04373\n",
            "Epoch: 8 | Iteration: 1027 | Classification loss: 0.00068 | Regression loss: 0.02782 | Running loss: 0.04372\n",
            "Epoch: 8 | Iteration: 1028 | Classification loss: 0.00075 | Regression loss: 0.00928 | Running loss: 0.04362\n",
            "Epoch: 8 | Iteration: 1029 | Classification loss: 0.00042 | Regression loss: 0.04038 | Running loss: 0.04366\n",
            "Epoch: 8 | Iteration: 1030 | Classification loss: 0.00072 | Regression loss: 0.01803 | Running loss: 0.04366\n",
            "Epoch: 8 | Iteration: 1031 | Classification loss: 0.00093 | Regression loss: 0.03665 | Running loss: 0.04370\n",
            "Epoch: 8 | Iteration: 1032 | Classification loss: 0.00215 | Regression loss: 0.04668 | Running loss: 0.04370\n",
            "Epoch: 8 | Iteration: 1033 | Classification loss: 0.00001 | Regression loss: 0.01748 | Running loss: 0.04365\n",
            "Epoch: 8 | Iteration: 1034 | Classification loss: 0.00012 | Regression loss: 0.01950 | Running loss: 0.04366\n",
            "Epoch: 8 | Iteration: 1035 | Classification loss: 0.00006 | Regression loss: 0.02317 | Running loss: 0.04366\n",
            "Epoch: 8 | Iteration: 1036 | Classification loss: 0.00020 | Regression loss: 0.02612 | Running loss: 0.04366\n",
            "Epoch: 8 | Iteration: 1037 | Classification loss: 0.00009 | Regression loss: 0.02018 | Running loss: 0.04367\n",
            "Epoch: 8 | Iteration: 1038 | Classification loss: 0.00008 | Regression loss: 0.02283 | Running loss: 0.04365\n",
            "Epoch: 8 | Iteration: 1039 | Classification loss: 0.00008 | Regression loss: 0.02537 | Running loss: 0.04366\n",
            "Epoch: 8 | Iteration: 1040 | Classification loss: 0.04109 | Regression loss: 0.04722 | Running loss: 0.04380\n",
            "Epoch: 8 | Iteration: 1041 | Classification loss: 0.00017 | Regression loss: 0.00974 | Running loss: 0.04376\n",
            "Epoch: 8 | Iteration: 1042 | Classification loss: 0.00004 | Regression loss: 0.02082 | Running loss: 0.04372\n",
            "Epoch: 8 | Iteration: 1043 | Classification loss: 0.00006 | Regression loss: 0.04715 | Running loss: 0.04375\n",
            "Epoch: 8 | Iteration: 1044 | Classification loss: 0.00002 | Regression loss: 0.03227 | Running loss: 0.04378\n",
            "Epoch: 8 | Iteration: 1045 | Classification loss: 0.00014 | Regression loss: 0.02384 | Running loss: 0.04381\n",
            "Epoch: 8 | Iteration: 1046 | Classification loss: 0.01506 | Regression loss: 0.05979 | Running loss: 0.04391\n",
            "Epoch: 8 | Iteration: 1047 | Classification loss: 0.00126 | Regression loss: 0.04613 | Running loss: 0.04397\n",
            "Epoch: 8 | Iteration: 1048 | Classification loss: 0.00010 | Regression loss: 0.03988 | Running loss: 0.04398\n",
            "Epoch: 8 | Iteration: 1049 | Classification loss: 0.00607 | Regression loss: 0.03032 | Running loss: 0.04401\n",
            "Epoch: 8 | Iteration: 1050 | Classification loss: 0.00212 | Regression loss: 0.12067 | Running loss: 0.04418\n",
            "Epoch: 8 | Iteration: 1051 | Classification loss: 0.00232 | Regression loss: 0.04354 | Running loss: 0.04422\n",
            "Epoch: 8 | Iteration: 1052 | Classification loss: 0.00029 | Regression loss: 0.03588 | Running loss: 0.04423\n",
            "Epoch: 8 | Iteration: 1053 | Classification loss: 0.00497 | Regression loss: 0.03423 | Running loss: 0.04428\n",
            "Epoch: 8 | Iteration: 1054 | Classification loss: 0.00072 | Regression loss: 0.02250 | Running loss: 0.04428\n",
            "Epoch: 8 | Iteration: 1055 | Classification loss: 0.00009 | Regression loss: 0.01304 | Running loss: 0.04425\n",
            "Epoch: 8 | Iteration: 1056 | Classification loss: 0.00013 | Regression loss: 0.05032 | Running loss: 0.04429\n",
            "Epoch: 8 | Iteration: 1057 | Classification loss: 0.00060 | Regression loss: 0.05910 | Running loss: 0.04438\n",
            "Epoch: 8 | Iteration: 1058 | Classification loss: 0.00017 | Regression loss: 0.01168 | Running loss: 0.04436\n",
            "Epoch: 8 | Iteration: 1059 | Classification loss: 0.00050 | Regression loss: 0.04622 | Running loss: 0.04443\n",
            "Epoch: 8 | Iteration: 1060 | Classification loss: 0.00006 | Regression loss: 0.02938 | Running loss: 0.04442\n",
            "Epoch: 8 | Iteration: 1061 | Classification loss: 0.00026 | Regression loss: 0.02081 | Running loss: 0.04444\n",
            "Epoch: 8 | Iteration: 1062 | Classification loss: 0.01047 | Regression loss: 0.01562 | Running loss: 0.04437\n",
            "Epoch: 8 | Iteration: 1063 | Classification loss: 0.00006 | Regression loss: 0.04450 | Running loss: 0.04442\n",
            "Epoch: 8 | Iteration: 1064 | Classification loss: 0.00034 | Regression loss: 0.06478 | Running loss: 0.04450\n",
            "Epoch: 8 | Iteration: 1065 | Classification loss: 0.00011 | Regression loss: 0.05313 | Running loss: 0.04456\n",
            "Epoch: 8 | Iteration: 1066 | Classification loss: 0.00034 | Regression loss: 0.02947 | Running loss: 0.04451\n",
            "Epoch: 8 | Iteration: 1067 | Classification loss: 0.00007 | Regression loss: 0.03044 | Running loss: 0.04452\n",
            "Epoch: 8 | Iteration: 1068 | Classification loss: 0.00007 | Regression loss: 0.01273 | Running loss: 0.04434\n",
            "Epoch: 8 | Iteration: 1069 | Classification loss: 0.00008 | Regression loss: 0.04337 | Running loss: 0.04440\n",
            "Epoch: 8 | Iteration: 1070 | Classification loss: 0.00066 | Regression loss: 0.03214 | Running loss: 0.04443\n",
            "Epoch: 8 | Iteration: 1071 | Classification loss: 0.00064 | Regression loss: 0.02574 | Running loss: 0.04428\n",
            "Epoch: 8 | Iteration: 1072 | Classification loss: 0.00022 | Regression loss: 0.05059 | Running loss: 0.04434\n",
            "Epoch: 8 | Iteration: 1073 | Classification loss: 0.00005 | Regression loss: 0.01853 | Running loss: 0.04420\n",
            "Epoch: 8 | Iteration: 1074 | Classification loss: 0.00003 | Regression loss: 0.01841 | Running loss: 0.04406\n",
            "Epoch: 8 | Iteration: 1075 | Classification loss: 0.00357 | Regression loss: 0.08381 | Running loss: 0.04418\n",
            "Epoch: 8 | Iteration: 1076 | Classification loss: 0.00106 | Regression loss: 0.06552 | Running loss: 0.04427\n",
            "Epoch: 8 | Iteration: 1077 | Classification loss: 0.00028 | Regression loss: 0.03231 | Running loss: 0.04428\n",
            "Epoch: 8 | Iteration: 1078 | Classification loss: 0.00005 | Regression loss: 0.01421 | Running loss: 0.04419\n",
            "Epoch: 8 | Iteration: 1079 | Classification loss: 0.00017 | Regression loss: 0.01930 | Running loss: 0.04413\n",
            "Epoch: 8 | Iteration: 1080 | Classification loss: 0.00006 | Regression loss: 0.01427 | Running loss: 0.04413\n",
            "Epoch: 8 | Iteration: 1081 | Classification loss: 0.00769 | Regression loss: 0.03865 | Running loss: 0.04414\n",
            "Epoch: 8 | Iteration: 1082 | Classification loss: 0.02118 | Regression loss: 0.07977 | Running loss: 0.04420\n",
            "Epoch: 8 | Iteration: 1083 | Classification loss: 0.00100 | Regression loss: 0.02676 | Running loss: 0.04420\n",
            "Epoch: 8 | Iteration: 1084 | Classification loss: 0.01596 | Regression loss: 0.04405 | Running loss: 0.04424\n",
            "Epoch: 8 | Iteration: 1085 | Classification loss: 0.00098 | Regression loss: 0.03268 | Running loss: 0.04416\n",
            "Epoch: 8 | Iteration: 1086 | Classification loss: 0.02469 | Regression loss: 0.06922 | Running loss: 0.04432\n",
            "Epoch: 8 | Iteration: 1087 | Classification loss: 0.00036 | Regression loss: 0.03812 | Running loss: 0.04426\n",
            "Epoch: 8 | Iteration: 1088 | Classification loss: 0.00023 | Regression loss: 0.02799 | Running loss: 0.04427\n",
            "Epoch: 8 | Iteration: 1089 | Classification loss: 0.00068 | Regression loss: 0.02787 | Running loss: 0.04428\n",
            "Epoch: 8 | Iteration: 1090 | Classification loss: 0.00002 | Regression loss: 0.01322 | Running loss: 0.04407\n",
            "Epoch: 8 | Iteration: 1091 | Classification loss: 0.00013 | Regression loss: 0.03814 | Running loss: 0.04401\n",
            "Epoch: 8 | Iteration: 1092 | Classification loss: 0.00221 | Regression loss: 0.03016 | Running loss: 0.04401\n",
            "Epoch: 8 | Iteration: 1093 | Classification loss: 0.00071 | Regression loss: 0.02920 | Running loss: 0.04399\n",
            "Epoch: 8 | Iteration: 1094 | Classification loss: 0.00155 | Regression loss: 0.03136 | Running loss: 0.04401\n",
            "Epoch: 8 | Iteration: 1095 | Classification loss: 0.00033 | Regression loss: 0.04078 | Running loss: 0.04403\n",
            "Epoch: 8 | Iteration: 1096 | Classification loss: 0.00108 | Regression loss: 0.07945 | Running loss: 0.04411\n",
            "Epoch: 8 | Iteration: 1097 | Classification loss: 0.00014 | Regression loss: 0.04774 | Running loss: 0.04418\n",
            "Epoch: 8 | Iteration: 1098 | Classification loss: 0.00020 | Regression loss: 0.02038 | Running loss: 0.04414\n",
            "Epoch: 8 | Iteration: 1099 | Classification loss: 0.00047 | Regression loss: 0.02539 | Running loss: 0.04407\n",
            "Epoch: 8 | Iteration: 1100 | Classification loss: 0.00063 | Regression loss: 0.02857 | Running loss: 0.04409\n",
            "Epoch: 8 | Iteration: 1101 | Classification loss: 0.00062 | Regression loss: 0.05843 | Running loss: 0.04409\n",
            "Epoch: 8 | Iteration: 1102 | Classification loss: 0.00394 | Regression loss: 0.03126 | Running loss: 0.04414\n",
            "Epoch: 8 | Iteration: 1103 | Classification loss: 0.00073 | Regression loss: 0.02403 | Running loss: 0.04413\n",
            "Epoch: 8 | Iteration: 1104 | Classification loss: 0.00038 | Regression loss: 0.02461 | Running loss: 0.04413\n",
            "Epoch: 8 | Iteration: 1105 | Classification loss: 0.00005 | Regression loss: 0.04260 | Running loss: 0.04417\n",
            "Epoch: 8 | Iteration: 1106 | Classification loss: 0.00006 | Regression loss: 0.02317 | Running loss: 0.04417\n",
            "Epoch: 8 | Iteration: 1107 | Classification loss: 0.00005 | Regression loss: 0.05728 | Running loss: 0.04421\n",
            "Epoch: 8 | Iteration: 1108 | Classification loss: 0.00017 | Regression loss: 0.05631 | Running loss: 0.04420\n",
            "Epoch: 8 | Iteration: 1109 | Classification loss: 0.00046 | Regression loss: 0.02521 | Running loss: 0.04419\n",
            "Epoch: 8 | Iteration: 1110 | Classification loss: 0.00190 | Regression loss: 0.06753 | Running loss: 0.04420\n",
            "Epoch: 8 | Iteration: 1111 | Classification loss: 0.00008 | Regression loss: 0.04287 | Running loss: 0.04420\n",
            "Epoch: 8 | Iteration: 1112 | Classification loss: 0.00019 | Regression loss: 0.05493 | Running loss: 0.04424\n",
            "Epoch: 8 | Iteration: 1113 | Classification loss: 0.00004 | Regression loss: 0.03642 | Running loss: 0.04426\n",
            "Epoch: 8 | Iteration: 1114 | Classification loss: 0.00016 | Regression loss: 0.03424 | Running loss: 0.04428\n",
            "Epoch: 8 | Iteration: 1115 | Classification loss: 0.00010 | Regression loss: 0.05238 | Running loss: 0.04436\n",
            "Epoch: 8 | Iteration: 1116 | Classification loss: 0.00005 | Regression loss: 0.02413 | Running loss: 0.04431\n",
            "Epoch: 8 | Iteration: 1117 | Classification loss: 0.00078 | Regression loss: 0.04648 | Running loss: 0.04438\n",
            "Epoch: 8 | Iteration: 1118 | Classification loss: 0.00011 | Regression loss: 0.02681 | Running loss: 0.04435\n",
            "Epoch: 8 | Iteration: 1119 | Classification loss: 0.00011 | Regression loss: 0.03544 | Running loss: 0.04434\n",
            "Epoch: 8 | Iteration: 1120 | Classification loss: 0.00076 | Regression loss: 0.02948 | Running loss: 0.04435\n",
            "Epoch: 8 | Iteration: 1121 | Classification loss: 0.00008 | Regression loss: 0.02570 | Running loss: 0.04435\n",
            "Epoch: 8 | Iteration: 1122 | Classification loss: 0.00006 | Regression loss: 0.03130 | Running loss: 0.04437\n",
            "Epoch: 8 | Iteration: 1123 | Classification loss: 0.00026 | Regression loss: 0.05544 | Running loss: 0.04443\n",
            "Epoch: 8 | Iteration: 1124 | Classification loss: 0.00006 | Regression loss: 0.02778 | Running loss: 0.04442\n",
            "Epoch: 8 | Iteration: 1125 | Classification loss: 0.00002 | Regression loss: 0.03860 | Running loss: 0.04445\n",
            "Epoch: 8 | Iteration: 1126 | Classification loss: 0.00011 | Regression loss: 0.03741 | Running loss: 0.04440\n",
            "Epoch: 8 | Iteration: 1127 | Classification loss: 0.00008 | Regression loss: 0.02689 | Running loss: 0.04422\n",
            "Epoch: 8 | Iteration: 1128 | Classification loss: 0.00004 | Regression loss: 0.01624 | Running loss: 0.04396\n",
            "Epoch: 8 | Iteration: 1129 | Classification loss: 0.29375 | Regression loss: 0.29620 | Running loss: 0.04508\n",
            "Epoch: 8 | Iteration: 1130 | Classification loss: 0.00017 | Regression loss: 0.03304 | Running loss: 0.04509\n",
            "Epoch: 8 | Iteration: 1131 | Classification loss: 0.00002 | Regression loss: 0.01532 | Running loss: 0.04507\n",
            "Epoch: 8 | Iteration: 1132 | Classification loss: 0.00044 | Regression loss: 0.03486 | Running loss: 0.04507\n",
            "Epoch: 8 | Iteration: 1133 | Classification loss: 0.00027 | Regression loss: 0.03484 | Running loss: 0.04504\n",
            "Epoch: 8 | Iteration: 1134 | Classification loss: 0.00103 | Regression loss: 0.03576 | Running loss: 0.04505\n",
            "Epoch: 8 | Iteration: 1135 | Classification loss: 0.00007 | Regression loss: 0.01604 | Running loss: 0.04506\n",
            "Epoch: 8 | Iteration: 1136 | Classification loss: 0.00038 | Regression loss: 0.01839 | Running loss: 0.04501\n",
            "Epoch: 8 | Iteration: 1137 | Classification loss: 0.00027 | Regression loss: 0.02648 | Running loss: 0.04498\n",
            "Epoch: 8 | Iteration: 1138 | Classification loss: 0.00013 | Regression loss: 0.02684 | Running loss: 0.04497\n",
            "Epoch: 8 | Iteration: 1139 | Classification loss: 0.00218 | Regression loss: 0.01123 | Running loss: 0.04496\n",
            "Epoch: 8 | Iteration: 1140 | Classification loss: 0.00003 | Regression loss: 0.01132 | Running loss: 0.04485\n",
            "Epoch: 8 | Iteration: 1141 | Classification loss: 0.00034 | Regression loss: 0.04388 | Running loss: 0.04488\n",
            "Epoch: 8 | Iteration: 1142 | Classification loss: 0.00257 | Regression loss: 0.04588 | Running loss: 0.04492\n",
            "Epoch: 8 | Iteration: 1143 | Classification loss: 0.00018 | Regression loss: 0.01715 | Running loss: 0.04492\n",
            "Epoch: 8 | Iteration: 1144 | Classification loss: 0.02266 | Regression loss: 0.12734 | Running loss: 0.04517\n",
            "Epoch: 8 | Iteration: 1145 | Classification loss: 0.00007 | Regression loss: 0.01599 | Running loss: 0.04518\n",
            "Epoch: 8 | Iteration: 1146 | Classification loss: 0.00007 | Regression loss: 0.01009 | Running loss: 0.04511\n",
            "Epoch: 8 | Iteration: 1147 | Classification loss: 0.00008 | Regression loss: 0.02308 | Running loss: 0.04509\n",
            "Epoch: 8 | Iteration: 1148 | Classification loss: 0.00073 | Regression loss: 0.01443 | Running loss: 0.04507\n",
            "Epoch: 8 | Iteration: 1149 | Classification loss: 0.00071 | Regression loss: 0.03231 | Running loss: 0.04504\n",
            "Epoch: 8 | Iteration: 1150 | Classification loss: 0.00047 | Regression loss: 0.02524 | Running loss: 0.04505\n",
            "Epoch: 8 | Iteration: 1151 | Classification loss: 0.00007 | Regression loss: 0.01750 | Running loss: 0.04500\n",
            "Epoch: 8 | Iteration: 1152 | Classification loss: 0.00007 | Regression loss: 0.01231 | Running loss: 0.04498\n",
            "Epoch: 8 | Iteration: 1153 | Classification loss: 0.00038 | Regression loss: 0.05859 | Running loss: 0.04504\n",
            "Epoch: 8 | Iteration: 1154 | Classification loss: 0.00016 | Regression loss: 0.01670 | Running loss: 0.04476\n",
            "Epoch: 8 | Iteration: 1155 | Classification loss: 0.00745 | Regression loss: 0.06944 | Running loss: 0.04486\n",
            "Epoch: 8 | Iteration: 1156 | Classification loss: 0.00020 | Regression loss: 0.01550 | Running loss: 0.04481\n",
            "Epoch: 8 | Iteration: 1157 | Classification loss: 0.00053 | Regression loss: 0.01970 | Running loss: 0.04478\n",
            "Epoch: 8 | Iteration: 1158 | Classification loss: 0.00021 | Regression loss: 0.00982 | Running loss: 0.04466\n",
            "Epoch: 8 | Iteration: 1159 | Classification loss: 0.00035 | Regression loss: 0.03804 | Running loss: 0.04452\n",
            "Epoch: 8 | Iteration: 1160 | Classification loss: 0.00004 | Regression loss: 0.01884 | Running loss: 0.04450\n",
            "Epoch: 8 | Iteration: 1161 | Classification loss: 0.00010 | Regression loss: 0.00919 | Running loss: 0.04446\n",
            "Epoch: 8 | Iteration: 1162 | Classification loss: 0.00006 | Regression loss: 0.03320 | Running loss: 0.04446\n",
            "Epoch: 8 | Iteration: 1163 | Classification loss: 0.00026 | Regression loss: 0.03661 | Running loss: 0.04446\n",
            "Epoch: 8 | Iteration: 1164 | Classification loss: 0.11842 | Regression loss: 0.08317 | Running loss: 0.04478\n",
            "Epoch: 8 | Iteration: 1165 | Classification loss: 0.00131 | Regression loss: 0.03199 | Running loss: 0.04434\n",
            "Epoch: 8 | Iteration: 1166 | Classification loss: 0.00020 | Regression loss: 0.01467 | Running loss: 0.04434\n",
            "Epoch: 8 | Iteration: 1167 | Classification loss: 0.00041 | Regression loss: 0.01300 | Running loss: 0.04420\n",
            "Epoch: 8 | Iteration: 1168 | Classification loss: 0.00065 | Regression loss: 0.03169 | Running loss: 0.04422\n",
            "Epoch: 8 | Iteration: 1169 | Classification loss: 0.00303 | Regression loss: 0.08501 | Running loss: 0.04435\n",
            "Epoch: 8 | Iteration: 1170 | Classification loss: 0.00065 | Regression loss: 0.01896 | Running loss: 0.04436\n",
            "Epoch: 8 | Iteration: 1171 | Classification loss: 0.00043 | Regression loss: 0.03290 | Running loss: 0.04437\n",
            "Epoch: 8 | Iteration: 1172 | Classification loss: 0.00018 | Regression loss: 0.02278 | Running loss: 0.04438\n",
            "Epoch: 8 | Iteration: 1173 | Classification loss: 0.00039 | Regression loss: 0.07492 | Running loss: 0.04447\n",
            "Epoch: 8 | Iteration: 1174 | Classification loss: 0.00004 | Regression loss: 0.02505 | Running loss: 0.04436\n",
            "Epoch: 8 | Iteration: 1175 | Classification loss: 0.00199 | Regression loss: 0.05180 | Running loss: 0.04431\n",
            "Epoch: 8 | Iteration: 1176 | Classification loss: 0.05508 | Regression loss: 0.03020 | Running loss: 0.04446\n",
            "Epoch: 8 | Iteration: 1177 | Classification loss: 0.00139 | Regression loss: 0.02872 | Running loss: 0.04444\n",
            "Epoch: 8 | Iteration: 1178 | Classification loss: 0.00166 | Regression loss: 0.02849 | Running loss: 0.04439\n",
            "Epoch: 8 | Iteration: 1179 | Classification loss: 0.00021 | Regression loss: 0.02891 | Running loss: 0.04437\n",
            "Epoch: 8 | Iteration: 1180 | Classification loss: 0.00021 | Regression loss: 0.02485 | Running loss: 0.04433\n",
            "Epoch: 8 | Iteration: 1181 | Classification loss: 0.00242 | Regression loss: 0.04920 | Running loss: 0.04438\n",
            "Epoch: 8 | Iteration: 1182 | Classification loss: 0.00382 | Regression loss: 0.05247 | Running loss: 0.04444\n",
            "Epoch: 8 | Iteration: 1183 | Classification loss: 0.00029 | Regression loss: 0.02627 | Running loss: 0.04429\n",
            "Epoch: 8 | Iteration: 1184 | Classification loss: 0.00065 | Regression loss: 0.04731 | Running loss: 0.04433\n",
            "Epoch: 8 | Iteration: 1185 | Classification loss: 0.00016 | Regression loss: 0.02862 | Running loss: 0.04437\n",
            "Epoch: 8 | Iteration: 1186 | Classification loss: 0.00007 | Regression loss: 0.01208 | Running loss: 0.04432\n",
            "Epoch: 8 | Iteration: 1187 | Classification loss: 0.00049 | Regression loss: 0.03422 | Running loss: 0.04436\n",
            "Epoch: 8 | Iteration: 1188 | Classification loss: 0.00072 | Regression loss: 0.02491 | Running loss: 0.04435\n",
            "Epoch: 8 | Iteration: 1189 | Classification loss: 0.00004 | Regression loss: 0.01506 | Running loss: 0.04426\n",
            "Epoch: 8 | Iteration: 1190 | Classification loss: 0.00010 | Regression loss: 0.01865 | Running loss: 0.04425\n",
            "Epoch: 8 | Iteration: 1191 | Classification loss: 0.00008 | Regression loss: 0.02699 | Running loss: 0.04418\n",
            "Epoch: 8 | Iteration: 1192 | Classification loss: 0.00036 | Regression loss: 0.03192 | Running loss: 0.04420\n",
            "Epoch: 8 | Iteration: 1193 | Classification loss: 0.00040 | Regression loss: 0.02452 | Running loss: 0.04413\n",
            "Epoch: 8 | Iteration: 1194 | Classification loss: 0.00011 | Regression loss: 0.03720 | Running loss: 0.04384\n",
            "Epoch: 8 | Iteration: 1195 | Classification loss: 0.00039 | Regression loss: 0.07171 | Running loss: 0.04392\n",
            "Epoch: 8 | Iteration: 1196 | Classification loss: 0.00017 | Regression loss: 0.03577 | Running loss: 0.04393\n",
            "Epoch: 8 | Iteration: 1197 | Classification loss: 0.00009 | Regression loss: 0.03796 | Running loss: 0.04380\n",
            "Epoch: 8 | Iteration: 1198 | Classification loss: 0.00039 | Regression loss: 0.05115 | Running loss: 0.04251\n",
            "Epoch: 8 | Iteration: 1199 | Classification loss: 0.00455 | Regression loss: 0.05219 | Running loss: 0.04259\n",
            "Epoch: 8 | Iteration: 1200 | Classification loss: 0.00022 | Regression loss: 0.04022 | Running loss: 0.04264\n",
            "Epoch: 8 | Iteration: 1201 | Classification loss: 0.00005 | Regression loss: 0.03689 | Running loss: 0.04265\n",
            "Epoch: 8 | Iteration: 1202 | Classification loss: 0.00447 | Regression loss: 0.03306 | Running loss: 0.04252\n",
            "Epoch: 8 | Iteration: 1203 | Classification loss: 0.00014 | Regression loss: 0.06763 | Running loss: 0.04255\n",
            "Epoch: 8 | Iteration: 1204 | Classification loss: 0.00013 | Regression loss: 0.04175 | Running loss: 0.04258\n",
            "Epoch: 8 | Iteration: 1205 | Classification loss: 0.00004 | Regression loss: 0.02141 | Running loss: 0.04244\n",
            "Epoch: 8 | Iteration: 1206 | Classification loss: 0.00026 | Regression loss: 0.04786 | Running loss: 0.04249\n",
            "Epoch: 8 | Iteration: 1207 | Classification loss: 0.00011 | Regression loss: 0.02739 | Running loss: 0.04247\n",
            "Epoch: 8 | Iteration: 1208 | Classification loss: 0.00006 | Regression loss: 0.03964 | Running loss: 0.04248\n",
            "Epoch: 8 | Iteration: 1209 | Classification loss: 0.00073 | Regression loss: 0.03244 | Running loss: 0.04243\n",
            "Epoch: 8 | Iteration: 1210 | Classification loss: 0.00010 | Regression loss: 0.02318 | Running loss: 0.04207\n",
            "Epoch: 8 | Iteration: 1211 | Classification loss: 0.00080 | Regression loss: 0.01260 | Running loss: 0.04205\n",
            "Epoch: 8 | Iteration: 1212 | Classification loss: 0.03407 | Regression loss: 0.31457 | Running loss: 0.04269\n",
            "Epoch: 8 | Iteration: 1213 | Classification loss: 0.00032 | Regression loss: 0.02335 | Running loss: 0.04269\n",
            "Epoch: 8 | Iteration: 1214 | Classification loss: 0.00096 | Regression loss: 0.03454 | Running loss: 0.04247\n",
            "Epoch: 8 | Iteration: 1215 | Classification loss: 0.00116 | Regression loss: 0.02017 | Running loss: 0.04242\n",
            "Epoch: 8 | Iteration: 1216 | Classification loss: 0.00362 | Regression loss: 0.04411 | Running loss: 0.04240\n",
            "Epoch: 8 | Iteration: 1217 | Classification loss: 0.00008 | Regression loss: 0.03710 | Running loss: 0.04240\n",
            "Epoch: 8 | Iteration: 1218 | Classification loss: 0.02729 | Regression loss: 0.09099 | Running loss: 0.04257\n",
            "Epoch: 8 | Iteration: 1219 | Classification loss: 0.00020 | Regression loss: 0.02189 | Running loss: 0.04234\n",
            "Epoch: 8 | Iteration: 1220 | Classification loss: 0.00023 | Regression loss: 0.02578 | Running loss: 0.04231\n",
            "Epoch: 8 | Iteration: 1221 | Classification loss: 0.00012 | Regression loss: 0.01510 | Running loss: 0.04225\n",
            "Epoch: 8 | Iteration: 1222 | Classification loss: 0.00013 | Regression loss: 0.01615 | Running loss: 0.04225\n",
            "Epoch: 8 | Iteration: 1223 | Classification loss: 0.00004 | Regression loss: 0.00943 | Running loss: 0.04224\n",
            "Epoch: 8 | Iteration: 1224 | Classification loss: 0.00021 | Regression loss: 0.03817 | Running loss: 0.04228\n",
            "Epoch: 8 | Iteration: 1225 | Classification loss: 0.00082 | Regression loss: 0.07287 | Running loss: 0.04240\n",
            "Epoch: 8 | Iteration: 1226 | Classification loss: 0.00007 | Regression loss: 0.02712 | Running loss: 0.04236\n",
            "Epoch: 8 | Iteration: 1227 | Classification loss: 0.00004 | Regression loss: 0.02805 | Running loss: 0.04228\n",
            "Epoch: 8 | Iteration: 1228 | Classification loss: 0.00025 | Regression loss: 0.02430 | Running loss: 0.04229\n",
            "Epoch: 8 | Iteration: 1229 | Classification loss: 0.00274 | Regression loss: 0.06237 | Running loss: 0.04240\n",
            "Epoch: 8 | Iteration: 1230 | Classification loss: 0.00004 | Regression loss: 0.02088 | Running loss: 0.04237\n",
            "Epoch: 8 | Iteration: 1231 | Classification loss: 0.00039 | Regression loss: 0.02082 | Running loss: 0.04229\n",
            "Epoch: 8 | Iteration: 1232 | Classification loss: 0.00283 | Regression loss: 0.06474 | Running loss: 0.04237\n",
            "Epoch: 8 | Iteration: 1233 | Classification loss: 0.00101 | Regression loss: 0.01899 | Running loss: 0.04231\n",
            "Epoch: 8 | Iteration: 1234 | Classification loss: 0.00005 | Regression loss: 0.04275 | Running loss: 0.04234\n",
            "Epoch: 8 | Iteration: 1235 | Classification loss: 0.00025 | Regression loss: 0.01799 | Running loss: 0.04234\n",
            "Epoch: 8 | Iteration: 1236 | Classification loss: 0.00004 | Regression loss: 0.02042 | Running loss: 0.04232\n",
            "Epoch: 8 | Iteration: 1237 | Classification loss: 0.00016 | Regression loss: 0.01584 | Running loss: 0.04229\n",
            "Epoch: 8 | Iteration: 1238 | Classification loss: 0.00016 | Regression loss: 0.01809 | Running loss: 0.04229\n",
            "Epoch: 8 | Iteration: 1239 | Classification loss: 0.00002 | Regression loss: 0.03008 | Running loss: 0.04229\n",
            "Epoch: 8 | Iteration: 1240 | Classification loss: 0.00003 | Regression loss: 0.03375 | Running loss: 0.04233\n",
            "Epoch: 8 | Iteration: 1241 | Classification loss: 0.00021 | Regression loss: 0.03868 | Running loss: 0.04226\n",
            "Epoch: 8 | Iteration: 1242 | Classification loss: 0.00090 | Regression loss: 0.05223 | Running loss: 0.04210\n",
            "Epoch: 8 | Iteration: 1243 | Classification loss: 0.00861 | Regression loss: 0.12211 | Running loss: 0.04231\n",
            "Epoch: 8 | Iteration: 1244 | Classification loss: 0.00007 | Regression loss: 0.00851 | Running loss: 0.04229\n",
            "Epoch: 8 | Iteration: 1245 | Classification loss: 0.00007 | Regression loss: 0.01924 | Running loss: 0.04226\n",
            "Epoch: 8 | Iteration: 1246 | Classification loss: 0.00045 | Regression loss: 0.01398 | Running loss: 0.04226\n",
            "Epoch: 8 | Iteration: 1247 | Classification loss: 0.00005 | Regression loss: 0.03594 | Running loss: 0.04225\n",
            "Epoch: 8 | Iteration: 1248 | Classification loss: 0.00033 | Regression loss: 0.07286 | Running loss: 0.04232\n",
            "Epoch: 8 | Iteration: 1249 | Classification loss: 0.00021 | Regression loss: 0.01600 | Running loss: 0.04228\n",
            "Epoch: 8 | Iteration: 1250 | Classification loss: 0.00004 | Regression loss: 0.02224 | Running loss: 0.04223\n",
            "Epoch: 8 | Iteration: 1251 | Classification loss: 0.00008 | Regression loss: 0.02590 | Running loss: 0.04224\n",
            "Epoch: 8 | Iteration: 1252 | Classification loss: 0.00007 | Regression loss: 0.02566 | Running loss: 0.04224\n",
            "Epoch: 8 | Iteration: 1253 | Classification loss: 0.03347 | Regression loss: 0.14056 | Running loss: 0.04253\n",
            "Epoch: 8 | Iteration: 1254 | Classification loss: 0.00015 | Regression loss: 0.01479 | Running loss: 0.04248\n",
            "Epoch: 8 | Iteration: 1255 | Classification loss: 0.00052 | Regression loss: 0.05695 | Running loss: 0.04253\n",
            "Epoch: 8 | Iteration: 1256 | Classification loss: 0.25894 | Regression loss: 0.27280 | Running loss: 0.04338\n",
            "Epoch: 8 | Iteration: 1257 | Classification loss: 0.00036 | Regression loss: 0.02439 | Running loss: 0.04335\n",
            "Epoch: 8 | Iteration: 1258 | Classification loss: 0.00011 | Regression loss: 0.01829 | Running loss: 0.04326\n",
            "Epoch: 8 | Iteration: 1259 | Classification loss: 0.00185 | Regression loss: 0.07211 | Running loss: 0.04331\n",
            "Epoch: 8 | Iteration: 1260 | Classification loss: 0.02627 | Regression loss: 0.04090 | Running loss: 0.04339\n",
            "Epoch: 8 | Iteration: 1261 | Classification loss: 0.00653 | Regression loss: 0.06906 | Running loss: 0.04350\n",
            "Epoch: 8 | Iteration: 1262 | Classification loss: 0.00053 | Regression loss: 0.02077 | Running loss: 0.04343\n",
            "Epoch: 8 | Iteration: 1263 | Classification loss: 0.00018 | Regression loss: 0.01995 | Running loss: 0.04342\n",
            "Epoch: 8 | Iteration: 1264 | Classification loss: 0.00105 | Regression loss: 0.06476 | Running loss: 0.04350\n",
            "Epoch: 8 | Iteration: 1265 | Classification loss: 0.00002 | Regression loss: 0.02681 | Running loss: 0.04353\n",
            "Epoch: 8 | Iteration: 1266 | Classification loss: 0.00021 | Regression loss: 0.04839 | Running loss: 0.04358\n",
            "Epoch: 8 | Iteration: 1267 | Classification loss: 0.04908 | Regression loss: 0.04797 | Running loss: 0.04370\n",
            "Epoch: 8 | Iteration: 1268 | Classification loss: 0.00014 | Regression loss: 0.02582 | Running loss: 0.04369\n",
            "Epoch: 8 | Iteration: 1269 | Classification loss: 0.00057 | Regression loss: 0.03969 | Running loss: 0.04365\n",
            "Epoch: 8 | Iteration: 1270 | Classification loss: 0.00014 | Regression loss: 0.02677 | Running loss: 0.04367\n",
            "Epoch: 8 | Iteration: 1271 | Classification loss: 0.00004 | Regression loss: 0.02774 | Running loss: 0.04367\n",
            "Epoch: 8 | Iteration: 1272 | Classification loss: 0.00167 | Regression loss: 0.06470 | Running loss: 0.04376\n",
            "Epoch: 8 | Iteration: 1273 | Classification loss: 0.00138 | Regression loss: 0.03112 | Running loss: 0.04378\n",
            "Epoch: 8 | Iteration: 1274 | Classification loss: 0.00037 | Regression loss: 0.02564 | Running loss: 0.04379\n",
            "Epoch: 8 | Iteration: 1275 | Classification loss: 0.00018 | Regression loss: 0.03900 | Running loss: 0.04384\n",
            "Epoch: 8 | Iteration: 1276 | Classification loss: 0.00003 | Regression loss: 0.04320 | Running loss: 0.04388\n",
            "Epoch: 8 | Iteration: 1277 | Classification loss: 0.00035 | Regression loss: 0.01459 | Running loss: 0.04385\n",
            "Epoch: 8 | Iteration: 1278 | Classification loss: 0.00062 | Regression loss: 0.02659 | Running loss: 0.04352\n",
            "Epoch: 8 | Iteration: 1279 | Classification loss: 0.00058 | Regression loss: 0.02523 | Running loss: 0.04352\n",
            "Epoch: 8 | Iteration: 1280 | Classification loss: 0.00029 | Regression loss: 0.05540 | Running loss: 0.04356\n",
            "Epoch: 8 | Iteration: 1281 | Classification loss: 0.00011 | Regression loss: 0.02858 | Running loss: 0.04359\n",
            "Epoch: 8 | Iteration: 1282 | Classification loss: 0.00004 | Regression loss: 0.03005 | Running loss: 0.04360\n",
            "Epoch: 8 | Iteration: 1283 | Classification loss: 0.00006 | Regression loss: 0.02501 | Running loss: 0.04362\n",
            "Epoch: 8 | Iteration: 1284 | Classification loss: 0.00002 | Regression loss: 0.04537 | Running loss: 0.04367\n",
            "Epoch: 8 | Iteration: 1285 | Classification loss: 0.01545 | Regression loss: 0.04654 | Running loss: 0.04378\n",
            "Epoch: 8 | Iteration: 1286 | Classification loss: 0.00094 | Regression loss: 0.03744 | Running loss: 0.04367\n",
            "Epoch: 8 | Iteration: 1287 | Classification loss: 0.00011 | Regression loss: 0.03115 | Running loss: 0.04371\n",
            "Epoch: 8 | Iteration: 1288 | Classification loss: 0.00035 | Regression loss: 0.03715 | Running loss: 0.04371\n",
            "Epoch: 8 | Iteration: 1289 | Classification loss: 0.00006 | Regression loss: 0.02930 | Running loss: 0.04360\n",
            "Epoch: 8 | Iteration: 1290 | Classification loss: 0.00067 | Regression loss: 0.03850 | Running loss: 0.04362\n",
            "Epoch: 8 | Iteration: 1291 | Classification loss: 0.00023 | Regression loss: 0.04403 | Running loss: 0.04358\n",
            "Epoch: 8 | Iteration: 1292 | Classification loss: 0.00012 | Regression loss: 0.02741 | Running loss: 0.04356\n",
            "Epoch: 8 | Iteration: 1293 | Classification loss: 0.00011 | Regression loss: 0.02598 | Running loss: 0.04355\n",
            "Epoch: 8 | Iteration: 1294 | Classification loss: 0.00017 | Regression loss: 0.03498 | Running loss: 0.04358\n",
            "Epoch: 8 | Iteration: 1295 | Classification loss: 0.00037 | Regression loss: 0.02688 | Running loss: 0.04360\n",
            "Epoch: 8 | Iteration: 1296 | Classification loss: 0.00073 | Regression loss: 0.01707 | Running loss: 0.04360\n",
            "Epoch: 8 | Iteration: 1297 | Classification loss: 0.00035 | Regression loss: 0.04528 | Running loss: 0.04365\n",
            "Epoch: 8 | Iteration: 1298 | Classification loss: 0.00021 | Regression loss: 0.02202 | Running loss: 0.04367\n",
            "Epoch: 8 | Iteration: 1299 | Classification loss: 0.00001 | Regression loss: 0.01360 | Running loss: 0.04359\n",
            "Epoch: 8 | Iteration: 1300 | Classification loss: 0.00458 | Regression loss: 0.04037 | Running loss: 0.04365\n",
            "Epoch: 8 | Iteration: 1301 | Classification loss: 0.00008 | Regression loss: 0.03513 | Running loss: 0.04362\n",
            "Epoch: 8 | Iteration: 1302 | Classification loss: 0.00130 | Regression loss: 0.01783 | Running loss: 0.04357\n",
            "Epoch: 8 | Iteration: 1303 | Classification loss: 0.00001 | Regression loss: 0.01895 | Running loss: 0.04359\n",
            "Epoch: 8 | Iteration: 1304 | Classification loss: 0.01329 | Regression loss: 0.05164 | Running loss: 0.04367\n",
            "Epoch: 8 | Iteration: 1305 | Classification loss: 0.00008 | Regression loss: 0.03025 | Running loss: 0.04370\n",
            "Epoch: 8 | Iteration: 1306 | Classification loss: 0.00007 | Regression loss: 0.03061 | Running loss: 0.04367\n",
            "Epoch: 8 | Iteration: 1307 | Classification loss: 0.00037 | Regression loss: 0.04465 | Running loss: 0.04371\n",
            "Epoch: 8 | Iteration: 1308 | Classification loss: 0.11280 | Regression loss: 0.23954 | Running loss: 0.04438\n",
            "Epoch: 8 | Iteration: 1309 | Classification loss: 0.00091 | Regression loss: 0.03793 | Running loss: 0.04432\n",
            "Epoch: 8 | Iteration: 1310 | Classification loss: 0.00033 | Regression loss: 0.03283 | Running loss: 0.04432\n",
            "Epoch: 8 | Iteration: 1311 | Classification loss: 0.00032 | Regression loss: 0.03191 | Running loss: 0.04433\n",
            "Epoch: 8 | Iteration: 1312 | Classification loss: 0.00010 | Regression loss: 0.01865 | Running loss: 0.04434\n",
            "Epoch: 8 | Iteration: 1313 | Classification loss: 0.00507 | Regression loss: 0.04948 | Running loss: 0.04440\n",
            "Epoch: 8 | Iteration: 1314 | Classification loss: 0.00124 | Regression loss: 0.03546 | Running loss: 0.04444\n",
            "Epoch: 8 | Iteration: 1315 | Classification loss: 0.00084 | Regression loss: 0.02050 | Running loss: 0.04445\n",
            "Epoch: 8 | Iteration: 1316 | Classification loss: 0.00029 | Regression loss: 0.03171 | Running loss: 0.04444\n",
            "Epoch: 8 | Iteration: 1317 | Classification loss: 0.00008 | Regression loss: 0.03142 | Running loss: 0.04442\n",
            "Epoch: 8 | Iteration: 1318 | Classification loss: 0.00005 | Regression loss: 0.01225 | Running loss: 0.04442\n",
            "Epoch: 8 | Iteration: 1319 | Classification loss: 0.00528 | Regression loss: 0.05333 | Running loss: 0.04447\n",
            "Epoch: 8 | Iteration: 1320 | Classification loss: 0.00007 | Regression loss: 0.01968 | Running loss: 0.04443\n",
            "Epoch: 8 | Iteration: 1321 | Classification loss: 0.00021 | Regression loss: 0.04917 | Running loss: 0.04448\n",
            "Epoch: 8 | Iteration: 1322 | Classification loss: 0.00072 | Regression loss: 0.02150 | Running loss: 0.04446\n",
            "Epoch: 8 | Iteration: 1323 | Classification loss: 0.00007 | Regression loss: 0.03105 | Running loss: 0.04284\n",
            "Epoch: 8 | Iteration: 1324 | Classification loss: 0.00028 | Regression loss: 0.03082 | Running loss: 0.04285\n",
            "Epoch: 8 | Iteration: 1325 | Classification loss: 0.00132 | Regression loss: 0.03056 | Running loss: 0.04287\n",
            "Epoch: 8 | Iteration: 1326 | Classification loss: 0.00009 | Regression loss: 0.02285 | Running loss: 0.04289\n",
            "Epoch: 8 | Iteration: 1327 | Classification loss: 0.02859 | Regression loss: 0.07228 | Running loss: 0.04305\n",
            "Epoch: 8 | Iteration: 1328 | Classification loss: 0.00003 | Regression loss: 0.04168 | Running loss: 0.04309\n",
            "Epoch: 8 | Iteration: 1329 | Classification loss: 0.00047 | Regression loss: 0.03611 | Running loss: 0.04306\n",
            "Epoch: 8 | Iteration: 1330 | Classification loss: 0.00320 | Regression loss: 0.05080 | Running loss: 0.04309\n",
            "Epoch: 8 | Iteration: 1331 | Classification loss: 0.03451 | Regression loss: 0.05543 | Running loss: 0.04323\n",
            "Epoch: 8 | Iteration: 1332 | Classification loss: 0.00024 | Regression loss: 0.04040 | Running loss: 0.04318\n",
            "Epoch: 8 | Iteration: 1333 | Classification loss: 0.00037 | Regression loss: 0.06248 | Running loss: 0.04223\n",
            "Epoch: 8 | Iteration: 1334 | Classification loss: 0.00010 | Regression loss: 0.06582 | Running loss: 0.04222\n",
            "Epoch: 8 | Iteration: 1335 | Classification loss: 0.00010 | Regression loss: 0.01720 | Running loss: 0.04221\n",
            "Epoch: 8 | Iteration: 1336 | Classification loss: 0.00004 | Regression loss: 0.03308 | Running loss: 0.04218\n",
            "Epoch: 8 | Iteration: 1337 | Classification loss: 0.00052 | Regression loss: 0.03541 | Running loss: 0.04217\n",
            "Epoch: 8 | Iteration: 1338 | Classification loss: 0.00008 | Regression loss: 0.02329 | Running loss: 0.04218\n",
            "Epoch: 8 | Iteration: 1339 | Classification loss: 0.00546 | Regression loss: 0.02325 | Running loss: 0.04209\n",
            "Epoch: 8 | Iteration: 1340 | Classification loss: 0.00080 | Regression loss: 0.02987 | Running loss: 0.04208\n",
            "Epoch: 8 | Iteration: 1341 | Classification loss: 0.00003 | Regression loss: 0.02683 | Running loss: 0.04206\n",
            "Epoch: 8 | Iteration: 1342 | Classification loss: 0.00034 | Regression loss: 0.01169 | Running loss: 0.04206\n",
            "Epoch: 8 | Iteration: 1343 | Classification loss: 0.00018 | Regression loss: 0.01534 | Running loss: 0.04204\n",
            "Epoch: 8 | Iteration: 1344 | Classification loss: 0.00024 | Regression loss: 0.04813 | Running loss: 0.04210\n",
            "Epoch: 8 | Iteration: 1345 | Classification loss: 0.00022 | Regression loss: 0.02814 | Running loss: 0.04209\n",
            "Epoch: 8 | Iteration: 1346 | Classification loss: 0.00113 | Regression loss: 0.04054 | Running loss: 0.04213\n",
            "Epoch: 8 | Iteration: 1347 | Classification loss: 0.00205 | Regression loss: 0.05067 | Running loss: 0.04210\n",
            "Epoch: 8 | Iteration: 1348 | Classification loss: 0.00037 | Regression loss: 0.04746 | Running loss: 0.04213\n",
            "Epoch: 8 | Iteration: 1349 | Classification loss: 0.00013 | Regression loss: 0.02980 | Running loss: 0.04214\n",
            "Epoch: 8 | Iteration: 1350 | Classification loss: 0.00002 | Regression loss: 0.03639 | Running loss: 0.04216\n",
            "Epoch: 8 | Iteration: 1351 | Classification loss: 0.00005 | Regression loss: 0.01910 | Running loss: 0.04216\n",
            "Epoch: 8 | Iteration: 1352 | Classification loss: 0.00011 | Regression loss: 0.01375 | Running loss: 0.04215\n",
            "Epoch: 8 | Iteration: 1353 | Classification loss: 0.00047 | Regression loss: 0.02132 | Running loss: 0.04199\n",
            "Epoch: 8 | Iteration: 1354 | Classification loss: 0.00016 | Regression loss: 0.01767 | Running loss: 0.04198\n",
            "Epoch: 8 | Iteration: 1355 | Classification loss: 0.00005 | Regression loss: 0.01480 | Running loss: 0.04198\n",
            "Epoch: 8 | Iteration: 1356 | Classification loss: 0.00032 | Regression loss: 0.01271 | Running loss: 0.04194\n",
            "Epoch: 8 | Iteration: 1357 | Classification loss: 0.00026 | Regression loss: 0.01143 | Running loss: 0.04191\n",
            "Epoch: 8 | Iteration: 1358 | Classification loss: 0.00044 | Regression loss: 0.01680 | Running loss: 0.04179\n",
            "Epoch: 8 | Iteration: 1359 | Classification loss: 0.00419 | Regression loss: 0.08055 | Running loss: 0.04193\n",
            "Epoch: 8 | Iteration: 1360 | Classification loss: 0.00005 | Regression loss: 0.01173 | Running loss: 0.04189\n",
            "Epoch: 8 | Iteration: 1361 | Classification loss: 0.00087 | Regression loss: 0.01840 | Running loss: 0.04177\n",
            "Epoch: 8 | Iteration: 1362 | Classification loss: 0.00012 | Regression loss: 0.01301 | Running loss: 0.04176\n",
            "Epoch: 8 | Iteration: 1363 | Classification loss: 0.01460 | Regression loss: 0.09523 | Running loss: 0.04184\n",
            "Epoch: 8 | Iteration: 1364 | Classification loss: 0.00029 | Regression loss: 0.02427 | Running loss: 0.04185\n",
            "Epoch: 8 | Iteration: 1365 | Classification loss: 0.00008 | Regression loss: 0.02503 | Running loss: 0.04186\n",
            "Epoch: 8 | Iteration: 1366 | Classification loss: 0.00013 | Regression loss: 0.03783 | Running loss: 0.04185\n",
            "Epoch: 8 | Iteration: 1367 | Classification loss: 0.00025 | Regression loss: 0.02699 | Running loss: 0.04184\n",
            "Epoch: 8 | Iteration: 1368 | Classification loss: 0.00257 | Regression loss: 0.05969 | Running loss: 0.04193\n",
            "Epoch: 8 | Iteration: 1369 | Classification loss: 0.00002 | Regression loss: 0.01480 | Running loss: 0.04187\n",
            "Epoch: 8 | Iteration: 1370 | Classification loss: 0.00004 | Regression loss: 0.02497 | Running loss: 0.04183\n",
            "Epoch: 8 | Iteration: 1371 | Classification loss: 0.00016 | Regression loss: 0.02447 | Running loss: 0.04184\n",
            "Epoch: 8 | Iteration: 1372 | Classification loss: 0.00845 | Regression loss: 0.03417 | Running loss: 0.04187\n",
            "Epoch: 8 | Iteration: 1373 | Classification loss: 0.00005 | Regression loss: 0.02056 | Running loss: 0.04185\n",
            "Epoch: 8 | Iteration: 1374 | Classification loss: 0.00006 | Regression loss: 0.02046 | Running loss: 0.04181\n",
            "Epoch: 8 | Iteration: 1375 | Classification loss: 0.00022 | Regression loss: 0.02492 | Running loss: 0.04102\n",
            "Epoch: 8 | Iteration: 1376 | Classification loss: 0.00032 | Regression loss: 0.02959 | Running loss: 0.04105\n",
            "Epoch: 8 | Iteration: 1377 | Classification loss: 0.00018 | Regression loss: 0.04282 | Running loss: 0.04109\n",
            "Epoch: 8 | Iteration: 1378 | Classification loss: 0.00002 | Regression loss: 0.01785 | Running loss: 0.04109\n",
            "Epoch: 8 | Iteration: 1379 | Classification loss: 0.00045 | Regression loss: 0.03044 | Running loss: 0.04109\n",
            "Epoch: 8 | Iteration: 1380 | Classification loss: 0.00010 | Regression loss: 0.03023 | Running loss: 0.04112\n",
            "Epoch: 8 | Iteration: 1381 | Classification loss: 0.00008 | Regression loss: 0.01163 | Running loss: 0.04107\n",
            "Epoch: 8 | Iteration: 1382 | Classification loss: 0.00007 | Regression loss: 0.02428 | Running loss: 0.04106\n",
            "Epoch: 8 | Iteration: 1383 | Classification loss: 0.00003 | Regression loss: 0.02998 | Running loss: 0.04110\n",
            "Epoch: 8 | Iteration: 1384 | Classification loss: 0.00432 | Regression loss: 0.04558 | Running loss: 0.04117\n",
            "Epoch: 8 | Iteration: 1385 | Classification loss: 0.00017 | Regression loss: 0.02397 | Running loss: 0.04119\n",
            "Epoch: 8 | Iteration: 1386 | Classification loss: 0.31334 | Regression loss: 0.37116 | Running loss: 0.04250\n",
            "Epoch: 8 | Iteration: 1387 | Classification loss: 0.00002 | Regression loss: 0.01271 | Running loss: 0.04244\n",
            "Epoch: 8 | Iteration: 1388 | Classification loss: 0.00006 | Regression loss: 0.01971 | Running loss: 0.04246\n",
            "Epoch: 8 | Iteration: 1389 | Classification loss: 0.00073 | Regression loss: 0.04546 | Running loss: 0.04251\n",
            "Epoch: 8 | Iteration: 1390 | Classification loss: 0.00011 | Regression loss: 0.02280 | Running loss: 0.04252\n",
            "Epoch: 8 | Iteration: 1391 | Classification loss: 0.02730 | Regression loss: 0.04601 | Running loss: 0.04261\n",
            "Epoch: 8 | Iteration: 1392 | Classification loss: 0.00031 | Regression loss: 0.04055 | Running loss: 0.04266\n",
            "Epoch: 8 | Iteration: 1393 | Classification loss: 0.00011 | Regression loss: 0.02750 | Running loss: 0.04264\n",
            "Epoch: 8 | Iteration: 1394 | Classification loss: 0.00007 | Regression loss: 0.01420 | Running loss: 0.04265\n",
            "Epoch: 8 | Iteration: 1395 | Classification loss: 0.00015 | Regression loss: 0.02010 | Running loss: 0.04265\n",
            "Epoch: 8 | Iteration: 1396 | Classification loss: 0.00003 | Regression loss: 0.01924 | Running loss: 0.04262\n",
            "Epoch: 8 | Iteration: 1397 | Classification loss: 0.00028 | Regression loss: 0.02417 | Running loss: 0.04263\n",
            "Epoch: 8 | Iteration: 1398 | Classification loss: 0.00007 | Regression loss: 0.02190 | Running loss: 0.04237\n",
            "Epoch: 8 | Iteration: 1399 | Classification loss: 0.00565 | Regression loss: 0.04231 | Running loss: 0.04242\n",
            "Epoch: 8 | Iteration: 1400 | Classification loss: 0.00125 | Regression loss: 0.08744 | Running loss: 0.04255\n",
            "Epoch: 8 | Iteration: 1401 | Classification loss: 0.00015 | Regression loss: 0.03224 | Running loss: 0.04259\n",
            "Epoch: 8 | Iteration: 1402 | Classification loss: 0.00022 | Regression loss: 0.04491 | Running loss: 0.04265\n",
            "Epoch: 8 | Iteration: 1403 | Classification loss: 0.00004 | Regression loss: 0.04195 | Running loss: 0.04272\n",
            "Epoch: 8 | Iteration: 1404 | Classification loss: 0.00004 | Regression loss: 0.02563 | Running loss: 0.04275\n",
            "Epoch: 8 | Iteration: 1405 | Classification loss: 0.00634 | Regression loss: 0.04782 | Running loss: 0.04261\n",
            "Epoch: 8 | Iteration: 1406 | Classification loss: 0.00070 | Regression loss: 0.04359 | Running loss: 0.04265\n",
            "Epoch: 8 | Iteration: 1407 | Classification loss: 0.00002 | Regression loss: 0.01710 | Running loss: 0.04258\n",
            "Epoch: 8 | Iteration: 1408 | Classification loss: 0.00031 | Regression loss: 0.03895 | Running loss: 0.04259\n",
            "Epoch: 8 | Iteration: 1409 | Classification loss: 0.00009 | Regression loss: 0.02679 | Running loss: 0.04255\n",
            "Epoch: 8 | Iteration: 1410 | Classification loss: 0.00007 | Regression loss: 0.02030 | Running loss: 0.04251\n",
            "Epoch: 8 | Iteration: 1411 | Classification loss: 0.00125 | Regression loss: 0.04539 | Running loss: 0.04258\n",
            "Epoch: 8 | Iteration: 1412 | Classification loss: 0.00304 | Regression loss: 0.03641 | Running loss: 0.04260\n",
            "Epoch: 8 | Iteration: 1413 | Classification loss: 0.00009 | Regression loss: 0.04247 | Running loss: 0.04266\n",
            "Epoch: 8 | Iteration: 1414 | Classification loss: 0.00039 | Regression loss: 0.03483 | Running loss: 0.04265\n",
            "Epoch: 8 | Iteration: 1415 | Classification loss: 0.00032 | Regression loss: 0.07247 | Running loss: 0.04270\n",
            "Epoch: 8 | Iteration: 1416 | Classification loss: 0.00003 | Regression loss: 0.02505 | Running loss: 0.04266\n",
            "Epoch: 8 | Iteration: 1417 | Classification loss: 0.00025 | Regression loss: 0.06410 | Running loss: 0.04276\n",
            "Epoch: 8 | Iteration: 1418 | Classification loss: 0.00076 | Regression loss: 0.03601 | Running loss: 0.04273\n",
            "Epoch: 8 | Iteration: 1419 | Classification loss: 0.01638 | Regression loss: 0.05304 | Running loss: 0.04280\n",
            "Epoch: 8 | Iteration: 1420 | Classification loss: 0.02965 | Regression loss: 0.07692 | Running loss: 0.04295\n",
            "Epoch: 8 | Iteration: 1421 | Classification loss: 0.03487 | Regression loss: 0.06330 | Running loss: 0.04309\n",
            "Epoch: 8 | Iteration: 1422 | Classification loss: 0.00146 | Regression loss: 0.02701 | Running loss: 0.04309\n",
            "Epoch: 8 | Iteration: 1423 | Classification loss: 0.00044 | Regression loss: 0.05915 | Running loss: 0.04240\n",
            "Epoch: 8 | Iteration: 1424 | Classification loss: 0.00077 | Regression loss: 0.03916 | Running loss: 0.04245\n",
            "Epoch: 8 | Iteration: 1425 | Classification loss: 0.00138 | Regression loss: 0.04236 | Running loss: 0.04246\n",
            "Epoch: 8 | Iteration: 1426 | Classification loss: 0.00020 | Regression loss: 0.04268 | Running loss: 0.04245\n",
            "Epoch: 8 | Iteration: 1427 | Classification loss: 0.00005 | Regression loss: 0.03145 | Running loss: 0.04246\n",
            "Epoch: 8 | Iteration: 1428 | Classification loss: 0.00027 | Regression loss: 0.01599 | Running loss: 0.04241\n",
            "Epoch: 8 | Iteration: 1429 | Classification loss: 0.00018 | Regression loss: 0.02776 | Running loss: 0.04239\n",
            "Epoch: 8 | Iteration: 1430 | Classification loss: 0.00029 | Regression loss: 0.03595 | Running loss: 0.04240\n",
            "Epoch: 8 | Iteration: 1431 | Classification loss: 0.00023 | Regression loss: 0.01633 | Running loss: 0.04234\n",
            "Epoch: 8 | Iteration: 1432 | Classification loss: 0.00042 | Regression loss: 0.03377 | Running loss: 0.04236\n",
            "Epoch: 8 | Iteration: 1433 | Classification loss: 0.00012 | Regression loss: 0.01956 | Running loss: 0.04216\n",
            "Epoch: 8 | Iteration: 1434 | Classification loss: 0.00021 | Regression loss: 0.02603 | Running loss: 0.04215\n",
            "Epoch: 8 | Iteration: 1435 | Classification loss: 0.00016 | Regression loss: 0.01790 | Running loss: 0.04214\n",
            "Epoch: 8 | Iteration: 1436 | Classification loss: 0.00016 | Regression loss: 0.03120 | Running loss: 0.04213\n",
            "Epoch: 8 | Iteration: 1437 | Classification loss: 0.00013 | Regression loss: 0.01380 | Running loss: 0.04212\n",
            "Epoch: 8 | Iteration: 1438 | Classification loss: 0.00012 | Regression loss: 0.03009 | Running loss: 0.04206\n",
            "Epoch: 8 | Iteration: 1439 | Classification loss: 0.00021 | Regression loss: 0.04806 | Running loss: 0.04211\n",
            "Epoch: 8 | Iteration: 1440 | Classification loss: 0.00022 | Regression loss: 0.02378 | Running loss: 0.04205\n",
            "Epoch: 8 | Iteration: 1441 | Classification loss: 0.00101 | Regression loss: 0.02100 | Running loss: 0.04205\n",
            "Epoch: 8 | Iteration: 1442 | Classification loss: 0.00092 | Regression loss: 0.03548 | Running loss: 0.04209\n",
            "Epoch: 8 | Iteration: 1443 | Classification loss: 0.00021 | Regression loss: 0.01617 | Running loss: 0.04209\n",
            "Epoch: 8 | Iteration: 1444 | Classification loss: 0.02850 | Regression loss: 0.11838 | Running loss: 0.04229\n",
            "Epoch: 8 | Iteration: 1445 | Classification loss: 0.00095 | Regression loss: 0.04707 | Running loss: 0.04235\n",
            "Epoch: 8 | Iteration: 1446 | Classification loss: 0.00020 | Regression loss: 0.01533 | Running loss: 0.04234\n",
            "Epoch: 8 | Iteration: 1447 | Classification loss: 0.07208 | Regression loss: 0.03185 | Running loss: 0.04249\n",
            "Epoch: 8 | Iteration: 1448 | Classification loss: 0.01507 | Regression loss: 0.09523 | Running loss: 0.04265\n",
            "Epoch: 8 | Iteration: 1449 | Classification loss: 0.00002 | Regression loss: 0.02351 | Running loss: 0.04267\n",
            "Epoch: 8 | Iteration: 1450 | Classification loss: 0.00004 | Regression loss: 0.03504 | Running loss: 0.04268\n",
            "Epoch: 8 | Iteration: 1451 | Classification loss: 0.00369 | Regression loss: 0.04079 | Running loss: 0.04274\n",
            "Epoch: 8 | Iteration: 1452 | Classification loss: 0.00015 | Regression loss: 0.02468 | Running loss: 0.04273\n",
            "Epoch: 8 | Iteration: 1453 | Classification loss: 0.00087 | Regression loss: 0.01416 | Running loss: 0.04273\n",
            "Epoch: 8 | Iteration: 1454 | Classification loss: 0.00008 | Regression loss: 0.03240 | Running loss: 0.04271\n",
            "Epoch: 8 | Iteration: 1455 | Classification loss: 0.00005 | Regression loss: 0.03109 | Running loss: 0.04272\n",
            "Epoch: 8 | Iteration: 1456 | Classification loss: 0.00847 | Regression loss: 0.08715 | Running loss: 0.04282\n",
            "Epoch: 8 | Iteration: 1457 | Classification loss: 0.00147 | Regression loss: 0.08107 | Running loss: 0.04295\n",
            "Epoch: 8 | Iteration: 1458 | Classification loss: 0.00014 | Regression loss: 0.01985 | Running loss: 0.04295\n",
            "Epoch: 8 | Iteration: 1459 | Classification loss: 0.29438 | Regression loss: 0.03739 | Running loss: 0.04358\n",
            "Epoch: 8 | Iteration: 1460 | Classification loss: 0.00011 | Regression loss: 0.01349 | Running loss: 0.04357\n",
            "Epoch: 8 | Iteration: 1461 | Classification loss: 0.00201 | Regression loss: 0.02985 | Running loss: 0.04354\n",
            "Epoch: 8 | Iteration: 1462 | Classification loss: 0.00013 | Regression loss: 0.01771 | Running loss: 0.04354\n",
            "Epoch: 8 | Iteration: 1463 | Classification loss: 0.00016 | Regression loss: 0.01806 | Running loss: 0.04351\n",
            "Epoch: 8 | Iteration: 1464 | Classification loss: 0.00021 | Regression loss: 0.02609 | Running loss: 0.04351\n",
            "Epoch: 8 | Iteration: 1465 | Classification loss: 0.00011 | Regression loss: 0.02431 | Running loss: 0.04348\n",
            "Epoch: 8 | Iteration: 1466 | Classification loss: 0.00004 | Regression loss: 0.01339 | Running loss: 0.04343\n",
            "Epoch: 8 | Iteration: 1467 | Classification loss: 0.00006 | Regression loss: 0.02231 | Running loss: 0.04340\n",
            "Epoch: 8 | Iteration: 1468 | Classification loss: 0.00051 | Regression loss: 0.02484 | Running loss: 0.04339\n",
            "Epoch: 8 | Iteration: 1469 | Classification loss: 0.00008 | Regression loss: 0.02490 | Running loss: 0.04338\n",
            "Epoch: 8 | Iteration: 1470 | Classification loss: 0.00011 | Regression loss: 0.03667 | Running loss: 0.04341\n",
            "Epoch: 8 | Iteration: 1471 | Classification loss: 0.00001 | Regression loss: 0.01935 | Running loss: 0.04337\n",
            "Epoch: 8 | Iteration: 1472 | Classification loss: 0.01162 | Regression loss: 0.06983 | Running loss: 0.04349\n",
            "Epoch: 8 | Iteration: 1473 | Classification loss: 0.00006 | Regression loss: 0.03965 | Running loss: 0.04349\n",
            "Epoch: 8 | Iteration: 1474 | Classification loss: 0.00011 | Regression loss: 0.03186 | Running loss: 0.04351\n",
            "Epoch: 8 | Iteration: 1475 | Classification loss: 0.00477 | Regression loss: 0.04399 | Running loss: 0.04356\n",
            "Epoch: 8 | Iteration: 1476 | Classification loss: 0.00052 | Regression loss: 0.05449 | Running loss: 0.04359\n",
            "Epoch: 8 | Iteration: 1477 | Classification loss: 0.00015 | Regression loss: 0.03678 | Running loss: 0.04296\n",
            "Epoch: 8 | Iteration: 1478 | Classification loss: 0.00108 | Regression loss: 0.02825 | Running loss: 0.04299\n",
            "Epoch: 8 | Iteration: 1479 | Classification loss: 0.00047 | Regression loss: 0.04809 | Running loss: 0.04305\n",
            "Epoch: 8 | Iteration: 1480 | Classification loss: 0.00027 | Regression loss: 0.03038 | Running loss: 0.04297\n",
            "Epoch: 8 | Iteration: 1481 | Classification loss: 0.00017 | Regression loss: 0.02059 | Running loss: 0.04295\n",
            "Epoch: 8 | Iteration: 1482 | Classification loss: 0.00035 | Regression loss: 0.04070 | Running loss: 0.04298\n",
            "Epoch: 8 | Iteration: 1483 | Classification loss: 0.00014 | Regression loss: 0.01974 | Running loss: 0.04234\n",
            "Epoch: 8 | Iteration: 1484 | Classification loss: 0.00047 | Regression loss: 0.05826 | Running loss: 0.04235\n",
            "Epoch: 8 | Iteration: 1485 | Classification loss: 0.00114 | Regression loss: 0.05275 | Running loss: 0.04240\n",
            "Epoch: 8 | Iteration: 1486 | Classification loss: 0.00281 | Regression loss: 0.03539 | Running loss: 0.04239\n",
            "Epoch: 8 | Iteration: 1487 | Classification loss: 0.00010 | Regression loss: 0.04078 | Running loss: 0.04242\n",
            "Epoch: 8 | Iteration: 1488 | Classification loss: 0.00004 | Regression loss: 0.03382 | Running loss: 0.04240\n",
            "Epoch: 8 | Iteration: 1489 | Classification loss: 0.00116 | Regression loss: 0.03369 | Running loss: 0.04233\n",
            "Epoch: 8 | Iteration: 1490 | Classification loss: 0.00055 | Regression loss: 0.01522 | Running loss: 0.04233\n",
            "Epoch: 8 | Iteration: 1491 | Classification loss: 0.00037 | Regression loss: 0.02147 | Running loss: 0.04234\n",
            "Epoch: 8 | Iteration: 1492 | Classification loss: 0.00018 | Regression loss: 0.01529 | Running loss: 0.04230\n",
            "Epoch: 8 | Iteration: 1493 | Classification loss: 0.00026 | Regression loss: 0.01656 | Running loss: 0.04228\n",
            "Epoch: 8 | Iteration: 1494 | Classification loss: 0.00024 | Regression loss: 0.01892 | Running loss: 0.04219\n",
            "Epoch: 8 | Iteration: 1495 | Classification loss: 0.00012 | Regression loss: 0.01053 | Running loss: 0.04214\n",
            "Epoch: 8 | Iteration: 1496 | Classification loss: 0.00006 | Regression loss: 0.02488 | Running loss: 0.04209\n",
            "Epoch: 8 | Iteration: 1497 | Classification loss: 0.00003 | Regression loss: 0.01756 | Running loss: 0.04203\n",
            "Epoch: 8 | Iteration: 1498 | Classification loss: 0.00007 | Regression loss: 0.02176 | Running loss: 0.04202\n",
            "Epoch: 8 | Iteration: 1499 | Classification loss: 0.00385 | Regression loss: 0.03850 | Running loss: 0.04203\n",
            "Epoch: 8 | Iteration: 1500 | Classification loss: 0.00185 | Regression loss: 0.09989 | Running loss: 0.04215\n",
            "Epoch: 8 | Iteration: 1501 | Classification loss: 0.00001 | Regression loss: 0.02368 | Running loss: 0.04216\n",
            "Epoch: 8 | Iteration: 1502 | Classification loss: 0.00055 | Regression loss: 0.03847 | Running loss: 0.04219\n",
            "Epoch: 8 | Iteration: 1503 | Classification loss: 0.00186 | Regression loss: 0.03266 | Running loss: 0.04216\n",
            "Epoch: 8 | Iteration: 1504 | Classification loss: 0.00007 | Regression loss: 0.02383 | Running loss: 0.04212\n",
            "Epoch: 8 | Iteration: 1505 | Classification loss: 0.00018 | Regression loss: 0.02599 | Running loss: 0.04208\n",
            "Epoch: 8 | Iteration: 1506 | Classification loss: 0.00001 | Regression loss: 0.02996 | Running loss: 0.04206\n",
            "Epoch: 8 | Iteration: 1507 | Classification loss: 0.00053 | Regression loss: 0.02140 | Running loss: 0.04199\n",
            "Epoch: 8 | Iteration: 1508 | Classification loss: 0.00002 | Regression loss: 0.02808 | Running loss: 0.04199\n",
            "Epoch: 8 | Iteration: 1509 | Classification loss: 0.00029 | Regression loss: 0.02778 | Running loss: 0.04200\n",
            "Epoch: 8 | Iteration: 1510 | Classification loss: 0.00003 | Regression loss: 0.02759 | Running loss: 0.04199\n",
            "Epoch: 8 | Iteration: 1511 | Classification loss: 0.00004 | Regression loss: 0.04539 | Running loss: 0.04203\n",
            "Epoch: 8 | Iteration: 1512 | Classification loss: 0.00039 | Regression loss: 0.03382 | Running loss: 0.04180\n",
            "Epoch: 8 | Iteration: 1513 | Classification loss: 0.00022 | Regression loss: 0.05223 | Running loss: 0.04184\n",
            "Epoch: 8 | Iteration: 1514 | Classification loss: 0.00251 | Regression loss: 0.09052 | Running loss: 0.04197\n",
            "Epoch: 8 | Iteration: 1515 | Classification loss: 0.00008 | Regression loss: 0.03123 | Running loss: 0.04199\n",
            "Epoch: 8 | Iteration: 1516 | Classification loss: 0.00007 | Regression loss: 0.02233 | Running loss: 0.04196\n",
            "Epoch: 8 | Iteration: 1517 | Classification loss: 0.00375 | Regression loss: 0.06330 | Running loss: 0.04203\n",
            "Epoch: 8 | Iteration: 1518 | Classification loss: 0.00136 | Regression loss: 0.03749 | Running loss: 0.04208\n",
            "Epoch: 8 | Iteration: 1519 | Classification loss: 0.00002 | Regression loss: 0.01625 | Running loss: 0.04205\n",
            "Epoch: 8 | Iteration: 1520 | Classification loss: 0.00251 | Regression loss: 0.08626 | Running loss: 0.04213\n",
            "Epoch: 8 | Iteration: 1521 | Classification loss: 0.00007 | Regression loss: 0.02679 | Running loss: 0.04212\n",
            "Epoch: 8 | Iteration: 1522 | Classification loss: 0.00003 | Regression loss: 0.02727 | Running loss: 0.04209\n",
            "Epoch: 8 | Iteration: 1523 | Classification loss: 0.00011 | Regression loss: 0.03631 | Running loss: 0.04208\n",
            "Epoch: 8 | Iteration: 1524 | Classification loss: 0.00004 | Regression loss: 0.03023 | Running loss: 0.04207\n",
            "Epoch: 8 | Iteration: 1525 | Classification loss: 0.00006 | Regression loss: 0.04034 | Running loss: 0.04210\n",
            "Epoch: 8 | Iteration: 1526 | Classification loss: 0.00243 | Regression loss: 0.03629 | Running loss: 0.04212\n",
            "Epoch: 8 | Iteration: 1527 | Classification loss: 0.00515 | Regression loss: 0.16594 | Running loss: 0.04241\n",
            "Epoch: 8 | Iteration: 1528 | Classification loss: 0.00226 | Regression loss: 0.02578 | Running loss: 0.04244\n",
            "Epoch: 8 | Iteration: 1529 | Classification loss: 0.00021 | Regression loss: 0.02545 | Running loss: 0.04241\n",
            "Epoch: 8 | Iteration: 1530 | Classification loss: 0.00014 | Regression loss: 0.01443 | Running loss: 0.04241\n",
            "Epoch: 8 | Iteration: 1531 | Classification loss: 0.00009 | Regression loss: 0.01452 | Running loss: 0.04236\n",
            "Epoch: 8 | Iteration: 1532 | Classification loss: 0.00025 | Regression loss: 0.02350 | Running loss: 0.04231\n",
            "Epoch: 8 | Iteration: 1533 | Classification loss: 0.00026 | Regression loss: 0.10505 | Running loss: 0.04249\n",
            "Epoch: 8 | Iteration: 1534 | Classification loss: 0.00042 | Regression loss: 0.05454 | Running loss: 0.04256\n",
            "Epoch: 8 | Iteration: 1535 | Classification loss: 0.00031 | Regression loss: 0.01277 | Running loss: 0.04254\n",
            "Epoch: 8 | Iteration: 1536 | Classification loss: 0.00005 | Regression loss: 0.03834 | Running loss: 0.04256\n",
            "Epoch: 8 | Iteration: 1537 | Classification loss: 0.00002 | Regression loss: 0.02490 | Running loss: 0.04257\n",
            "Epoch: 8 | Iteration: 1538 | Classification loss: 0.00597 | Regression loss: 0.13262 | Running loss: 0.04280\n",
            "Epoch: 8 | Iteration: 1539 | Classification loss: 0.00006 | Regression loss: 0.01620 | Running loss: 0.04278\n",
            "Epoch: 8 | Iteration: 1540 | Classification loss: 0.00052 | Regression loss: 0.02658 | Running loss: 0.04266\n",
            "Epoch: 8 | Iteration: 1541 | Classification loss: 0.00074 | Regression loss: 0.05312 | Running loss: 0.04275\n",
            "Epoch: 8 | Iteration: 1542 | Classification loss: 0.00009 | Regression loss: 0.01035 | Running loss: 0.04273\n",
            "Epoch: 8 | Iteration: 1543 | Classification loss: 0.00009 | Regression loss: 0.01357 | Running loss: 0.04266\n",
            "Epoch: 8 | Iteration: 1544 | Classification loss: 0.00063 | Regression loss: 0.01403 | Running loss: 0.04262\n",
            "Epoch: 8 | Iteration: 1545 | Classification loss: 0.00007 | Regression loss: 0.01922 | Running loss: 0.04262\n",
            "Epoch: 8 | Iteration: 1546 | Classification loss: 0.00005 | Regression loss: 0.02415 | Running loss: 0.04251\n",
            "Epoch: 8 | Iteration: 1547 | Classification loss: 0.00006 | Regression loss: 0.01894 | Running loss: 0.04246\n",
            "Epoch: 8 | Iteration: 1548 | Classification loss: 0.00005 | Regression loss: 0.02241 | Running loss: 0.04242\n",
            "Epoch: 8 | Iteration: 1549 | Classification loss: 0.00026 | Regression loss: 0.02952 | Running loss: 0.04241\n",
            "Epoch: 8 | Iteration: 1550 | Classification loss: 0.00052 | Regression loss: 0.02356 | Running loss: 0.04221\n",
            "Epoch: 8 | Iteration: 1551 | Classification loss: 0.00012 | Regression loss: 0.01575 | Running loss: 0.04215\n",
            "Epoch: 8 | Iteration: 1552 | Classification loss: 0.00021 | Regression loss: 0.01798 | Running loss: 0.04212\n",
            "Epoch: 8 | Iteration: 1553 | Classification loss: 0.00015 | Regression loss: 0.01590 | Running loss: 0.04207\n",
            "Epoch: 8 | Iteration: 1554 | Classification loss: 0.00012 | Regression loss: 0.06046 | Running loss: 0.04214\n",
            "Epoch: 8 | Iteration: 1555 | Classification loss: 0.00022 | Regression loss: 0.03711 | Running loss: 0.04219\n",
            "Epoch: 8 | Iteration: 1556 | Classification loss: 0.00007 | Regression loss: 0.02670 | Running loss: 0.04215\n",
            "Epoch: 8 | Iteration: 1557 | Classification loss: 0.00105 | Regression loss: 0.02509 | Running loss: 0.04208\n",
            "Epoch: 8 | Iteration: 1558 | Classification loss: 0.00016 | Regression loss: 0.02311 | Running loss: 0.04210\n",
            "Epoch: 8 | Iteration: 1559 | Classification loss: 0.00058 | Regression loss: 0.06490 | Running loss: 0.04214\n",
            "Epoch: 8 | Iteration: 1560 | Classification loss: 0.00067 | Regression loss: 0.01910 | Running loss: 0.04212\n",
            "Epoch: 8 | Iteration: 1561 | Classification loss: 0.00276 | Regression loss: 0.07928 | Running loss: 0.04224\n",
            "Epoch: 8 | Iteration: 1562 | Classification loss: 0.00006 | Regression loss: 0.01017 | Running loss: 0.04221\n",
            "Epoch: 8 | Iteration: 1563 | Classification loss: 0.00019 | Regression loss: 0.01743 | Running loss: 0.04216\n",
            "Epoch: 8 | Iteration: 1564 | Classification loss: 0.00067 | Regression loss: 0.03293 | Running loss: 0.04209\n",
            "Epoch: 8 | Iteration: 1565 | Classification loss: 0.00008 | Regression loss: 0.01867 | Running loss: 0.04202\n",
            "Epoch: 8 | Iteration: 1566 | Classification loss: 0.00013 | Regression loss: 0.01815 | Running loss: 0.04200\n",
            "Epoch: 8 | Iteration: 1567 | Classification loss: 0.00015 | Regression loss: 0.04442 | Running loss: 0.04203\n",
            "Epoch: 8 | Iteration: 1568 | Classification loss: 0.00015 | Regression loss: 0.01999 | Running loss: 0.04204\n",
            "Epoch: 8 | Iteration: 1569 | Classification loss: 0.00145 | Regression loss: 0.02267 | Running loss: 0.04200\n",
            "Epoch: 8 | Iteration: 1570 | Classification loss: 0.00003 | Regression loss: 0.01101 | Running loss: 0.04196\n",
            "Epoch: 8 | Iteration: 1571 | Classification loss: 0.00015 | Regression loss: 0.02429 | Running loss: 0.04196\n",
            "Epoch: 8 | Iteration: 1572 | Classification loss: 0.00940 | Regression loss: 0.01247 | Running loss: 0.04190\n",
            "Epoch: 8 | Iteration: 1573 | Classification loss: 0.00001 | Regression loss: 0.01983 | Running loss: 0.04190\n",
            "Epoch: 8 | Iteration: 1574 | Classification loss: 0.00014 | Regression loss: 0.01966 | Running loss: 0.04190\n",
            "Epoch: 8 | Iteration: 1575 | Classification loss: 0.00008 | Regression loss: 0.03803 | Running loss: 0.04181\n",
            "Epoch: 8 | Iteration: 1576 | Classification loss: 0.00022 | Regression loss: 0.04184 | Running loss: 0.04176\n",
            "Epoch: 8 | Iteration: 1577 | Classification loss: 0.00016 | Regression loss: 0.01558 | Running loss: 0.04172\n",
            "Epoch: 8 | Iteration: 1578 | Classification loss: 0.00021 | Regression loss: 0.01639 | Running loss: 0.04173\n",
            "Epoch: 8 | Iteration: 1579 | Classification loss: 0.00009 | Regression loss: 0.02342 | Running loss: 0.04174\n",
            "Epoch: 8 | Iteration: 1580 | Classification loss: 0.00019 | Regression loss: 0.03250 | Running loss: 0.04177\n",
            "Epoch: 8 | Iteration: 1581 | Classification loss: 0.00172 | Regression loss: 0.02201 | Running loss: 0.04173\n",
            "Epoch: 8 | Iteration: 1582 | Classification loss: 0.00124 | Regression loss: 0.01538 | Running loss: 0.04156\n",
            "Epoch: 8 | Iteration: 1583 | Classification loss: 0.00004 | Regression loss: 0.01567 | Running loss: 0.04153\n",
            "Epoch: 8 | Iteration: 1584 | Classification loss: 0.00015 | Regression loss: 0.04623 | Running loss: 0.04151\n",
            "Epoch: 8 | Iteration: 1585 | Classification loss: 0.00004 | Regression loss: 0.01270 | Running loss: 0.04147\n",
            "Epoch: 8 | Iteration: 1586 | Classification loss: 0.00017 | Regression loss: 0.03517 | Running loss: 0.04135\n",
            "Epoch: 8 | Iteration: 1587 | Classification loss: 0.00009 | Regression loss: 0.01872 | Running loss: 0.04131\n",
            "Epoch: 8 | Iteration: 1588 | Classification loss: 0.00534 | Regression loss: 0.03535 | Running loss: 0.04133\n",
            "Epoch: 8 | Iteration: 1589 | Classification loss: 0.00219 | Regression loss: 0.02984 | Running loss: 0.04134\n",
            "Epoch: 8 | Iteration: 1590 | Classification loss: 0.01937 | Regression loss: 0.09670 | Running loss: 0.04155\n",
            "Epoch: 8 | Iteration: 1591 | Classification loss: 0.00021 | Regression loss: 0.02998 | Running loss: 0.04153\n",
            "Epoch: 8 | Iteration: 1592 | Classification loss: 0.00067 | Regression loss: 0.02719 | Running loss: 0.04152\n",
            "Epoch: 8 | Iteration: 1593 | Classification loss: 0.00014 | Regression loss: 0.02475 | Running loss: 0.04151\n",
            "Epoch: 8 | Iteration: 1594 | Classification loss: 0.00570 | Regression loss: 0.01883 | Running loss: 0.04149\n",
            "Epoch: 8 | Iteration: 1595 | Classification loss: 0.00005 | Regression loss: 0.01570 | Running loss: 0.04144\n",
            "Epoch: 8 | Iteration: 1596 | Classification loss: 0.02886 | Regression loss: 0.14837 | Running loss: 0.04164\n",
            "Epoch: 8 | Iteration: 1597 | Classification loss: 0.00015 | Regression loss: 0.03169 | Running loss: 0.04161\n",
            "Epoch: 8 | Iteration: 1598 | Classification loss: 0.00024 | Regression loss: 0.05251 | Running loss: 0.04167\n",
            "Epoch: 8 | Iteration: 1599 | Classification loss: 0.00013 | Regression loss: 0.02302 | Running loss: 0.04166\n",
            "Epoch: 8 | Iteration: 1600 | Classification loss: 0.00011 | Regression loss: 0.04815 | Running loss: 0.04170\n",
            "Epoch: 8 | Iteration: 1601 | Classification loss: 0.00001 | Regression loss: 0.02145 | Running loss: 0.04163\n",
            "Epoch: 8 | Iteration: 1602 | Classification loss: 0.00041 | Regression loss: 0.01295 | Running loss: 0.04158\n",
            "Epoch: 8 | Iteration: 1603 | Classification loss: 0.00039 | Regression loss: 0.01522 | Running loss: 0.04157\n",
            "Epoch: 8 | Iteration: 1604 | Classification loss: 0.00030 | Regression loss: 0.05597 | Running loss: 0.04163\n",
            "Epoch: 8 | Iteration: 1605 | Classification loss: 0.00079 | Regression loss: 0.03975 | Running loss: 0.04162\n",
            "Epoch: 8 | Iteration: 1606 | Classification loss: 0.00343 | Regression loss: 0.01847 | Running loss: 0.04162\n",
            "Epoch: 8 | Iteration: 1607 | Classification loss: 0.00082 | Regression loss: 0.03900 | Running loss: 0.04159\n",
            "Epoch: 8 | Iteration: 1608 | Classification loss: 0.00041 | Regression loss: 0.01563 | Running loss: 0.04150\n",
            "Epoch: 8 | Iteration: 1609 | Classification loss: 0.01538 | Regression loss: 0.04582 | Running loss: 0.04158\n",
            "Epoch: 8 | Iteration: 1610 | Classification loss: 0.00008 | Regression loss: 0.01816 | Running loss: 0.04147\n",
            "Epoch: 8 | Iteration: 1611 | Classification loss: 0.00129 | Regression loss: 0.03745 | Running loss: 0.04147\n",
            "Epoch: 8 | Iteration: 1612 | Classification loss: 0.00002 | Regression loss: 0.01439 | Running loss: 0.04138\n",
            "Epoch: 8 | Iteration: 1613 | Classification loss: 2.08669 | Regression loss: 0.02020 | Running loss: 0.04552\n",
            "Epoch: 8 | Iteration: 1614 | Classification loss: 0.00069 | Regression loss: 0.02323 | Running loss: 0.04550\n",
            "Epoch: 8 | Iteration: 1615 | Classification loss: 0.00010 | Regression loss: 0.01357 | Running loss: 0.04543\n",
            "Epoch: 8 | Iteration: 1616 | Classification loss: 0.00048 | Regression loss: 0.02331 | Running loss: 0.04543\n",
            "Epoch: 8 | Iteration: 1617 | Classification loss: 0.01826 | Regression loss: 0.02469 | Running loss: 0.04542\n",
            "Epoch: 8 | Iteration: 1618 | Classification loss: 0.00030 | Regression loss: 0.02508 | Running loss: 0.04541\n",
            "Epoch: 8 | Iteration: 1619 | Classification loss: 0.00036 | Regression loss: 0.03953 | Running loss: 0.04542\n",
            "Epoch: 8 | Iteration: 1620 | Classification loss: 0.00081 | Regression loss: 0.06223 | Running loss: 0.04549\n",
            "Epoch: 8 | Iteration: 1621 | Classification loss: 0.03659 | Regression loss: 0.03534 | Running loss: 0.04558\n",
            "Epoch: 8 | Iteration: 1622 | Classification loss: 0.00043 | Regression loss: 0.04074 | Running loss: 0.04560\n",
            "Epoch: 8 | Iteration: 1623 | Classification loss: 0.00011 | Regression loss: 0.02587 | Running loss: 0.04554\n",
            "Epoch: 8 | Iteration: 1624 | Classification loss: 0.00576 | Regression loss: 0.08808 | Running loss: 0.04567\n",
            "Epoch: 8 | Iteration: 1625 | Classification loss: 0.00751 | Regression loss: 0.02786 | Running loss: 0.04567\n",
            "Epoch: 8 | Iteration: 1626 | Classification loss: 0.00002 | Regression loss: 0.01166 | Running loss: 0.04561\n",
            "Epoch: 8 | Iteration: 1627 | Classification loss: 0.00043 | Regression loss: 0.02848 | Running loss: 0.04562\n",
            "Epoch: 8 | Iteration: 1628 | Classification loss: 0.00806 | Regression loss: 0.05295 | Running loss: 0.04571\n",
            "Epoch: 8 | Iteration: 1629 | Classification loss: 0.00051 | Regression loss: 0.04486 | Running loss: 0.04462\n",
            "Epoch: 8 | Iteration: 1630 | Classification loss: 0.00697 | Regression loss: 0.02565 | Running loss: 0.04462\n",
            "Epoch: 8 | Iteration: 1631 | Classification loss: 0.00047 | Regression loss: 0.02774 | Running loss: 0.04464\n",
            "Epoch: 8 | Iteration: 1632 | Classification loss: 0.00080 | Regression loss: 0.02647 | Running loss: 0.04463\n",
            "Epoch: 8 | Iteration: 1633 | Classification loss: 0.00018 | Regression loss: 0.03244 | Running loss: 0.04462\n",
            "Epoch: 8 | Iteration: 1634 | Classification loss: 0.00312 | Regression loss: 0.02762 | Running loss: 0.04461\n",
            "Epoch: 8 | Iteration: 1635 | Classification loss: 0.00306 | Regression loss: 0.04799 | Running loss: 0.04468\n",
            "Epoch: 8 | Iteration: 1636 | Classification loss: 0.01448 | Regression loss: 0.04804 | Running loss: 0.04477\n",
            "Epoch: 8 | Iteration: 1637 | Classification loss: 0.00126 | Regression loss: 0.01330 | Running loss: 0.04474\n",
            "Epoch: 8 | Iteration: 1638 | Classification loss: 0.00094 | Regression loss: 0.01602 | Running loss: 0.04472\n",
            "Epoch: 8 | Iteration: 1639 | Classification loss: 0.00030 | Regression loss: 0.00790 | Running loss: 0.04471\n",
            "Epoch: 8 | Iteration: 1640 | Classification loss: 0.40211 | Regression loss: 0.24795 | Running loss: 0.04599\n",
            "Epoch: 8 | Iteration: 1641 | Classification loss: 0.00007 | Regression loss: 0.04328 | Running loss: 0.04599\n",
            "Epoch: 8 | Iteration: 1642 | Classification loss: 0.00018 | Regression loss: 0.03359 | Running loss: 0.04596\n",
            "Epoch: 8 | Iteration: 1643 | Classification loss: 0.00083 | Regression loss: 0.05613 | Running loss: 0.04604\n",
            "Epoch: 8 | Iteration: 1644 | Classification loss: 0.00248 | Regression loss: 0.02920 | Running loss: 0.04580\n",
            "Epoch: 8 | Iteration: 1645 | Classification loss: 0.03809 | Regression loss: 0.02613 | Running loss: 0.04590\n",
            "Epoch: 8 | Iteration: 1646 | Classification loss: 0.01253 | Regression loss: 0.07655 | Running loss: 0.04606\n",
            "Epoch: 8 | Iteration: 1647 | Classification loss: 0.00102 | Regression loss: 0.03791 | Running loss: 0.04609\n",
            "Epoch: 8 | Iteration: 1648 | Classification loss: 0.00074 | Regression loss: 0.03688 | Running loss: 0.04613\n",
            "Epoch: 8 | Iteration: 1649 | Classification loss: 0.00107 | Regression loss: 0.02512 | Running loss: 0.04612\n",
            "Epoch: 8 | Iteration: 1650 | Classification loss: 0.00015 | Regression loss: 0.02239 | Running loss: 0.04611\n",
            "Epoch: 8 | Iteration: 1651 | Classification loss: 0.01820 | Regression loss: 0.02379 | Running loss: 0.04616\n",
            "Epoch: 8 | Iteration: 1652 | Classification loss: 0.00017 | Regression loss: 0.03354 | Running loss: 0.04620\n",
            "Epoch: 8 | Iteration: 1653 | Classification loss: 0.00013 | Regression loss: 0.03898 | Running loss: 0.04616\n",
            "Epoch: 8 | Iteration: 1654 | Classification loss: 0.00008 | Regression loss: 0.02399 | Running loss: 0.04618\n",
            "Epoch: 8 | Iteration: 1655 | Classification loss: 0.04689 | Regression loss: 0.04526 | Running loss: 0.04621\n",
            "Epoch: 8 | Iteration: 1656 | Classification loss: 0.00081 | Regression loss: 0.02039 | Running loss: 0.04622\n",
            "Epoch: 8 | Iteration: 1657 | Classification loss: 0.00393 | Regression loss: 0.02273 | Running loss: 0.04623\n",
            "Epoch: 8 | Iteration: 1658 | Classification loss: 0.00254 | Regression loss: 0.04904 | Running loss: 0.04632\n",
            "Epoch: 8 | Iteration: 1659 | Classification loss: 0.00906 | Regression loss: 0.14490 | Running loss: 0.04655\n",
            "Epoch: 8 | Iteration: 1660 | Classification loss: 0.00129 | Regression loss: 0.04471 | Running loss: 0.04660\n",
            "Epoch: 8 | Iteration: 1661 | Classification loss: 0.00416 | Regression loss: 0.04027 | Running loss: 0.04667\n",
            "Epoch: 8 | Iteration: 1662 | Classification loss: 0.00089 | Regression loss: 0.05759 | Running loss: 0.04672\n",
            "Epoch: 8 | Iteration: 1663 | Classification loss: 0.00059 | Regression loss: 0.01496 | Running loss: 0.04668\n",
            "Epoch: 8 | Iteration: 1664 | Classification loss: 0.01552 | Regression loss: 0.01605 | Running loss: 0.04634\n",
            "Epoch: 8 | Iteration: 1665 | Classification loss: 0.00068 | Regression loss: 0.03566 | Running loss: 0.04634\n",
            "Epoch: 8 | Iteration: 1666 | Classification loss: 0.00037 | Regression loss: 0.03674 | Running loss: 0.04639\n",
            "Epoch: 8 | Iteration: 1667 | Classification loss: 0.00365 | Regression loss: 0.01680 | Running loss: 0.04640\n",
            "Epoch: 8 | Iteration: 1668 | Classification loss: 0.00015 | Regression loss: 0.02239 | Running loss: 0.04638\n",
            "Epoch: 8 | Iteration: 1669 | Classification loss: 0.00042 | Regression loss: 0.02329 | Running loss: 0.04626\n",
            "Epoch: 8 | Iteration: 1670 | Classification loss: 0.00047 | Regression loss: 0.02523 | Running loss: 0.04627\n",
            "Epoch: 8 | Iteration: 1671 | Classification loss: 0.00038 | Regression loss: 0.02780 | Running loss: 0.04626\n",
            "Epoch: 8 | Iteration: 1672 | Classification loss: 0.00041 | Regression loss: 0.03295 | Running loss: 0.04628\n",
            "Epoch: 8 | Iteration: 1673 | Classification loss: 0.00052 | Regression loss: 0.02397 | Running loss: 0.04618\n",
            "Epoch: 8 | Iteration: 1674 | Classification loss: 0.00240 | Regression loss: 0.04866 | Running loss: 0.04623\n",
            "Epoch: 8 | Iteration: 1675 | Classification loss: 0.00375 | Regression loss: 0.04335 | Running loss: 0.04621\n",
            "Epoch: 8 | Iteration: 1676 | Classification loss: 0.17582 | Regression loss: 0.04546 | Running loss: 0.04649\n",
            "Epoch: 8 | Iteration: 1677 | Classification loss: 0.00125 | Regression loss: 0.05567 | Running loss: 0.04654\n",
            "Epoch: 8 | Iteration: 1678 | Classification loss: 0.00024 | Regression loss: 0.04711 | Running loss: 0.04657\n",
            "Epoch: 8 | Iteration: 1679 | Classification loss: 0.00019 | Regression loss: 0.05124 | Running loss: 0.04662\n",
            "Epoch: 8 | Iteration: 1680 | Classification loss: 0.00144 | Regression loss: 0.02918 | Running loss: 0.04663\n",
            "Epoch: 8 | Iteration: 1681 | Classification loss: 0.00083 | Regression loss: 0.03195 | Running loss: 0.04659\n",
            "Epoch: 8 | Iteration: 1682 | Classification loss: 0.00019 | Regression loss: 0.03262 | Running loss: 0.04655\n",
            "Epoch: 8 | Iteration: 1683 | Classification loss: 0.00293 | Regression loss: 0.02431 | Running loss: 0.04655\n",
            "Epoch: 8 | Iteration: 1684 | Classification loss: 0.00030 | Regression loss: 0.03361 | Running loss: 0.04652\n",
            "Epoch: 8 | Iteration: 1685 | Classification loss: 0.00014 | Regression loss: 0.02219 | Running loss: 0.04651\n",
            "Epoch: 8 | Iteration: 1686 | Classification loss: 0.00131 | Regression loss: 0.02639 | Running loss: 0.04654\n",
            "Epoch: 8 | Iteration: 1687 | Classification loss: 0.01821 | Regression loss: 0.08351 | Running loss: 0.04667\n",
            "Epoch: 8 | Iteration: 1688 | Classification loss: 0.00033 | Regression loss: 0.02548 | Running loss: 0.04667\n",
            "Epoch: 8 | Iteration: 1689 | Classification loss: 0.00053 | Regression loss: 0.01660 | Running loss: 0.04668\n",
            "Epoch: 8 | Iteration: 1690 | Classification loss: 0.01675 | Regression loss: 0.02505 | Running loss: 0.04672\n",
            "Epoch: 8 | Iteration: 1691 | Classification loss: 0.00010 | Regression loss: 0.04032 | Running loss: 0.04675\n",
            "Epoch: 8 | Iteration: 1692 | Classification loss: 0.00026 | Regression loss: 0.04512 | Running loss: 0.04677\n",
            "Epoch: 8 | Iteration: 1693 | Classification loss: 1.06072 | Regression loss: 0.03253 | Running loss: 0.04891\n",
            "Epoch: 8 | Iteration: 1694 | Classification loss: 0.00174 | Regression loss: 0.08611 | Running loss: 0.04901\n",
            "Epoch: 8 | Iteration: 1695 | Classification loss: 0.00020 | Regression loss: 0.06199 | Running loss: 0.04899\n",
            "Epoch: 8 | Iteration: 1696 | Classification loss: 0.00524 | Regression loss: 0.06566 | Running loss: 0.04906\n",
            "Epoch: 8 | Iteration: 1697 | Classification loss: 0.05249 | Regression loss: 0.05374 | Running loss: 0.04920\n",
            "Epoch: 8 | Iteration: 1698 | Classification loss: 0.23928 | Regression loss: 0.24592 | Running loss: 0.05007\n",
            "Epoch: 8 | Iteration: 1699 | Classification loss: 0.00016 | Regression loss: 0.02650 | Running loss: 0.05001\n",
            "Epoch: 8 | Iteration: 1700 | Classification loss: 0.00546 | Regression loss: 0.02483 | Running loss: 0.04999\n",
            "Epoch: 8 | Iteration: 1701 | Classification loss: 0.00283 | Regression loss: 0.03142 | Running loss: 0.04998\n",
            "Epoch: 8 | Iteration: 1702 | Classification loss: 0.00466 | Regression loss: 0.01369 | Running loss: 0.04994\n",
            "Epoch: 8 | Iteration: 1703 | Classification loss: 0.03497 | Regression loss: 0.06225 | Running loss: 0.05000\n",
            "Epoch: 8 | Iteration: 1704 | Classification loss: 0.00706 | Regression loss: 0.08932 | Running loss: 0.05011\n",
            "Epoch: 8 | Iteration: 1705 | Classification loss: 0.00020 | Regression loss: 0.01321 | Running loss: 0.05009\n",
            "Epoch: 8 | Iteration: 1706 | Classification loss: 0.09395 | Regression loss: 0.01197 | Running loss: 0.05021\n",
            "Epoch: 8 | Iteration: 1707 | Classification loss: 0.00017 | Regression loss: 0.03007 | Running loss: 0.05022\n",
            "Epoch: 8 | Iteration: 1708 | Classification loss: 0.00238 | Regression loss: 0.03362 | Running loss: 0.05021\n",
            "Epoch: 8 | Iteration: 1709 | Classification loss: 0.00034 | Regression loss: 0.01586 | Running loss: 0.05017\n",
            "Epoch: 8 | Iteration: 1710 | Classification loss: 0.02643 | Regression loss: 0.03714 | Running loss: 0.05025\n",
            "Epoch: 8 | Iteration: 1711 | Classification loss: 0.00031 | Regression loss: 0.01873 | Running loss: 0.05027\n",
            "Epoch: 8 | Iteration: 1712 | Classification loss: 0.00076 | Regression loss: 0.01484 | Running loss: 0.04960\n",
            "Epoch: 8 | Iteration: 1713 | Classification loss: 0.00061 | Regression loss: 0.02042 | Running loss: 0.04959\n",
            "Epoch: 8 | Iteration: 1714 | Classification loss: 0.00133 | Regression loss: 0.01903 | Running loss: 0.04956\n",
            "Epoch: 8 | Iteration: 1715 | Classification loss: 0.00328 | Regression loss: 0.01702 | Running loss: 0.04956\n",
            "Epoch: 8 | Iteration: 1716 | Classification loss: 0.03941 | Regression loss: 0.03715 | Running loss: 0.04962\n",
            "Epoch: 8 | Iteration: 1717 | Classification loss: 0.00053 | Regression loss: 0.03131 | Running loss: 0.04961\n",
            "Epoch: 8 | Iteration: 1718 | Classification loss: 0.01100 | Regression loss: 0.06947 | Running loss: 0.04953\n",
            "Epoch: 8 | Iteration: 1719 | Classification loss: 0.00227 | Regression loss: 0.02052 | Running loss: 0.04953\n",
            "Epoch: 8 | Iteration: 1720 | Classification loss: 0.00371 | Regression loss: 0.01513 | Running loss: 0.04952\n",
            "Epoch: 8 | Iteration: 1721 | Classification loss: 0.00015 | Regression loss: 0.01392 | Running loss: 0.04952\n",
            "Epoch: 8 | Iteration: 1722 | Classification loss: 0.00164 | Regression loss: 0.04527 | Running loss: 0.04958\n",
            "Epoch: 8 | Iteration: 1723 | Classification loss: 0.00669 | Regression loss: 0.02033 | Running loss: 0.04961\n",
            "Epoch: 8 | Iteration: 1724 | Classification loss: 0.05971 | Regression loss: 0.28143 | Running loss: 0.05022\n",
            "Epoch: 8 | Iteration: 1725 | Classification loss: 0.00064 | Regression loss: 0.01284 | Running loss: 0.05010\n",
            "Epoch: 8 | Iteration: 1726 | Classification loss: 0.00017 | Regression loss: 0.03132 | Running loss: 0.05011\n",
            "Epoch: 8 | Iteration: 1727 | Classification loss: 0.00052 | Regression loss: 0.01312 | Running loss: 0.05008\n",
            "Epoch: 8 | Iteration: 1728 | Classification loss: 0.00534 | Regression loss: 0.04983 | Running loss: 0.05014\n",
            "Epoch: 8 | Iteration: 1729 | Classification loss: 0.03307 | Regression loss: 0.03407 | Running loss: 0.05014\n",
            "Epoch: 8 | Iteration: 1730 | Classification loss: 0.00030 | Regression loss: 0.02516 | Running loss: 0.05015\n",
            "Epoch: 8 | Iteration: 1731 | Classification loss: 0.02416 | Regression loss: 0.01771 | Running loss: 0.05020\n",
            "Epoch: 8 | Iteration: 1732 | Classification loss: 0.00209 | Regression loss: 0.02320 | Running loss: 0.05011\n",
            "Epoch: 8 | Iteration: 1733 | Classification loss: 0.00038 | Regression loss: 0.02492 | Running loss: 0.05012\n",
            "Epoch: 8 | Iteration: 1734 | Classification loss: 0.00687 | Regression loss: 0.04201 | Running loss: 0.05013\n",
            "Epoch: 8 | Iteration: 1735 | Classification loss: 0.00013 | Regression loss: 0.02938 | Running loss: 0.05016\n",
            "Epoch: 8 | Iteration: 1736 | Classification loss: 0.00053 | Regression loss: 0.03697 | Running loss: 0.05019\n",
            "Epoch: 8 | Iteration: 1737 | Classification loss: 0.00157 | Regression loss: 0.00952 | Running loss: 0.05018\n",
            "Epoch: 8 | Iteration: 1738 | Classification loss: 0.00007 | Regression loss: 0.00686 | Running loss: 0.05016\n",
            "Epoch: 8 | Iteration: 1739 | Classification loss: 0.02845 | Regression loss: 0.06383 | Running loss: 0.05028\n",
            "Epoch: 8 | Iteration: 1740 | Classification loss: 0.00541 | Regression loss: 0.03021 | Running loss: 0.05029\n",
            "Epoch: 8 | Iteration: 1741 | Classification loss: 0.00030 | Regression loss: 0.03198 | Running loss: 0.05027\n",
            "Epoch: 8 | Iteration: 1742 | Classification loss: 0.27593 | Regression loss: 0.02797 | Running loss: 0.05077\n",
            "Epoch: 8 | Iteration: 1743 | Classification loss: 0.00075 | Regression loss: 0.05440 | Running loss: 0.05062\n",
            "Epoch: 8 | Iteration: 1744 | Classification loss: 0.00044 | Regression loss: 0.02395 | Running loss: 0.05065\n",
            "Epoch: 8 | Iteration: 1745 | Classification loss: 0.00163 | Regression loss: 0.07838 | Running loss: 0.05078\n",
            "Epoch: 8 | Iteration: 1746 | Classification loss: 0.00053 | Regression loss: 0.03642 | Running loss: 0.05082\n",
            "Epoch: 8 | Iteration: 1747 | Classification loss: 0.00234 | Regression loss: 0.02706 | Running loss: 0.05081\n",
            "Epoch: 8 | Iteration: 1748 | Classification loss: 0.00055 | Regression loss: 0.02600 | Running loss: 0.05071\n",
            "Epoch: 8 | Iteration: 1749 | Classification loss: 0.00049 | Regression loss: 0.01851 | Running loss: 0.05072\n",
            "Epoch: 8 | Iteration: 1750 | Classification loss: 0.00080 | Regression loss: 0.02328 | Running loss: 0.05072\n",
            "Epoch: 8 | Iteration: 1751 | Classification loss: 0.00057 | Regression loss: 0.03328 | Running loss: 0.05074\n",
            "Epoch: 8 | Iteration: 1752 | Classification loss: 0.00014 | Regression loss: 0.03165 | Running loss: 0.05075\n",
            "Epoch: 8 | Iteration: 1753 | Classification loss: 0.00112 | Regression loss: 0.01498 | Running loss: 0.05044\n",
            "Epoch: 8 | Iteration: 1754 | Classification loss: 0.00066 | Regression loss: 0.04100 | Running loss: 0.05049\n",
            "Epoch: 8 | Iteration: 1755 | Classification loss: 0.03306 | Regression loss: 0.06637 | Running loss: 0.05057\n",
            "Epoch: 8 | Iteration: 1756 | Classification loss: 0.00035 | Regression loss: 0.01417 | Running loss: 0.04954\n",
            "Epoch: 8 | Iteration: 1757 | Classification loss: 0.00141 | Regression loss: 0.04476 | Running loss: 0.04958\n",
            "Epoch: 8 | Iteration: 1758 | Classification loss: 0.00364 | Regression loss: 0.02228 | Running loss: 0.04960\n",
            "Epoch: 8 | Iteration: 1759 | Classification loss: 0.00006 | Regression loss: 0.04651 | Running loss: 0.04954\n",
            "Epoch: 8 | Iteration: 1760 | Classification loss: 0.00059 | Regression loss: 0.04473 | Running loss: 0.04950\n",
            "Epoch: 8 | Iteration: 1761 | Classification loss: 0.29198 | Regression loss: 0.00890 | Running loss: 0.04995\n",
            "Epoch: 8 | Iteration: 1762 | Classification loss: 0.00009 | Regression loss: 0.02911 | Running loss: 0.04996\n",
            "Epoch: 8 | Iteration: 1763 | Classification loss: 0.00006 | Regression loss: 0.02890 | Running loss: 0.04998\n",
            "Epoch: 8 | Iteration: 1764 | Classification loss: 0.00187 | Regression loss: 0.10766 | Running loss: 0.05007\n",
            "Epoch: 8 | Iteration: 1765 | Classification loss: 0.00097 | Regression loss: 0.04354 | Running loss: 0.05010\n",
            "Epoch: 8 | Iteration: 1766 | Classification loss: 0.00053 | Regression loss: 0.03807 | Running loss: 0.05008\n",
            "Epoch: 8 | Iteration: 1767 | Classification loss: 0.00254 | Regression loss: 0.02938 | Running loss: 0.04995\n",
            "Epoch: 8 | Iteration: 1768 | Classification loss: 0.00032 | Regression loss: 0.01498 | Running loss: 0.04993\n",
            "Epoch: 8 | Iteration: 1769 | Classification loss: 0.00008 | Regression loss: 0.01614 | Running loss: 0.04988\n",
            "Epoch: 8 | Iteration: 1770 | Classification loss: 0.00044 | Regression loss: 0.04830 | Running loss: 0.04993\n",
            "Epoch: 8 | Iteration: 1771 | Classification loss: 0.00121 | Regression loss: 0.04034 | Running loss: 0.04996\n",
            "Epoch: 8 | Iteration: 1772 | Classification loss: 0.00031 | Regression loss: 0.03754 | Running loss: 0.04990\n",
            "Epoch: 8 | Iteration: 1773 | Classification loss: 1.02812 | Regression loss: 0.04687 | Running loss: 0.05198\n",
            "Epoch: 8 | Iteration: 1774 | Classification loss: 0.00045 | Regression loss: 0.01535 | Running loss: 0.05196\n",
            "Epoch: 8 | Iteration: 1775 | Classification loss: 0.00221 | Regression loss: 0.04645 | Running loss: 0.05198\n",
            "Epoch: 8 | Iteration: 1776 | Classification loss: 0.00014 | Regression loss: 0.02064 | Running loss: 0.05194\n",
            "Epoch: 8 | Iteration: 1777 | Classification loss: 0.00019 | Regression loss: 0.02370 | Running loss: 0.05196\n",
            "Epoch: 8 | Iteration: 1778 | Classification loss: 0.00018 | Regression loss: 0.01549 | Running loss: 0.05193\n",
            "Epoch: 8 | Iteration: 1779 | Classification loss: 0.32822 | Regression loss: 0.41483 | Running loss: 0.05337\n",
            "Epoch: 8 | Iteration: 1780 | Classification loss: 0.00030 | Regression loss: 0.04073 | Running loss: 0.05334\n",
            "Epoch: 8 | Iteration: 1781 | Classification loss: 0.00333 | Regression loss: 0.04279 | Running loss: 0.05337\n",
            "Epoch: 8 | Iteration: 1782 | Classification loss: 0.00055 | Regression loss: 0.03768 | Running loss: 0.05339\n",
            "Epoch: 8 | Iteration: 1783 | Classification loss: 0.01435 | Regression loss: 0.06620 | Running loss: 0.05350\n",
            "Epoch: 8 | Iteration: 1784 | Classification loss: 0.00033 | Regression loss: 0.03708 | Running loss: 0.05348\n",
            "Epoch: 8 | Iteration: 1785 | Classification loss: 0.00394 | Regression loss: 0.02446 | Running loss: 0.05342\n",
            "Epoch: 8 | Iteration: 1786 | Classification loss: 0.08479 | Regression loss: 0.04882 | Running loss: 0.05361\n",
            "Epoch: 8 | Iteration: 1787 | Classification loss: 0.00408 | Regression loss: 0.02000 | Running loss: 0.05359\n",
            "Epoch: 8 | Iteration: 1788 | Classification loss: 0.00359 | Regression loss: 0.03998 | Running loss: 0.05360\n",
            "Epoch: 8 | Iteration: 1789 | Classification loss: 0.00040 | Regression loss: 0.04430 | Running loss: 0.05364\n",
            "Epoch: 8 | Iteration: 1790 | Classification loss: 0.00130 | Regression loss: 0.03769 | Running loss: 0.05364\n",
            "Epoch: 8 | Iteration: 1791 | Classification loss: 0.00113 | Regression loss: 0.03456 | Running loss: 0.05362\n",
            "Epoch: 8 | Iteration: 1792 | Classification loss: 0.00016 | Regression loss: 0.03170 | Running loss: 0.05363\n",
            "Epoch: 8 | Iteration: 1793 | Classification loss: 0.00542 | Regression loss: 0.01499 | Running loss: 0.05362\n",
            "Epoch: 8 | Iteration: 1794 | Classification loss: 0.00089 | Regression loss: 0.02086 | Running loss: 0.05359\n",
            "Epoch: 8 | Iteration: 1795 | Classification loss: 0.00047 | Regression loss: 0.02203 | Running loss: 0.05358\n",
            "Epoch: 8 | Iteration: 1796 | Classification loss: 0.00025 | Regression loss: 0.01801 | Running loss: 0.05358\n",
            "Epoch: 8 | Iteration: 1797 | Classification loss: 0.00098 | Regression loss: 0.01370 | Running loss: 0.05352\n",
            "Epoch: 8 | Iteration: 1798 | Classification loss: 0.08551 | Regression loss: 0.17207 | Running loss: 0.05399\n",
            "Epoch: 8 | Iteration: 1799 | Classification loss: 0.00013 | Regression loss: 0.02006 | Running loss: 0.05400\n",
            "Epoch: 8 | Iteration: 1800 | Classification loss: 0.00210 | Regression loss: 0.04467 | Running loss: 0.05401\n",
            "Epoch: 8 | Iteration: 1801 | Classification loss: 0.00158 | Regression loss: 0.01744 | Running loss: 0.05397\n",
            "Epoch: 8 | Iteration: 1802 | Classification loss: 0.00017 | Regression loss: 0.01808 | Running loss: 0.05397\n",
            "Epoch: 8 | Iteration: 1803 | Classification loss: 0.00056 | Regression loss: 0.02803 | Running loss: 0.05399\n",
            "Epoch: 8 | Iteration: 1804 | Classification loss: 0.00095 | Regression loss: 0.01226 | Running loss: 0.05389\n",
            "Epoch: 8 | Iteration: 1805 | Classification loss: 0.00074 | Regression loss: 0.01859 | Running loss: 0.05387\n",
            "Epoch: 8 | Iteration: 1806 | Classification loss: 0.00165 | Regression loss: 0.04804 | Running loss: 0.05390\n",
            "Epoch: 8 | Iteration: 1807 | Classification loss: 0.00010 | Regression loss: 0.02122 | Running loss: 0.05386\n",
            "Epoch: 8 | Iteration: 1808 | Classification loss: 0.00150 | Regression loss: 0.02030 | Running loss: 0.05319\n",
            "Epoch: 8 | Iteration: 1809 | Classification loss: 0.00397 | Regression loss: 0.01423 | Running loss: 0.05315\n",
            "Epoch: 8 | Iteration: 1810 | Classification loss: 0.00029 | Regression loss: 0.02683 | Running loss: 0.05314\n",
            "Epoch: 8 | Iteration: 1811 | Classification loss: 0.00227 | Regression loss: 0.01709 | Running loss: 0.05312\n",
            "Epoch: 8 | Iteration: 1812 | Classification loss: 0.00066 | Regression loss: 0.02700 | Running loss: 0.05313\n",
            "Epoch: 8 | Iteration: 1813 | Classification loss: 0.00114 | Regression loss: 0.01858 | Running loss: 0.05306\n",
            "Epoch: 8 | Iteration: 1814 | Classification loss: 0.00075 | Regression loss: 0.03094 | Running loss: 0.05305\n",
            "Epoch: 8 | Iteration: 1815 | Classification loss: 0.00105 | Regression loss: 0.06791 | Running loss: 0.05315\n",
            "Epoch: 8 | Iteration: 1816 | Classification loss: 0.00119 | Regression loss: 0.05114 | Running loss: 0.05319\n",
            "Epoch: 8 | Iteration: 1817 | Classification loss: 0.00094 | Regression loss: 0.02933 | Running loss: 0.05319\n",
            "Epoch: 8 | Iteration: 1818 | Classification loss: 0.00021 | Regression loss: 0.01060 | Running loss: 0.05318\n",
            "Epoch: 8 | Iteration: 1819 | Classification loss: 0.00004 | Regression loss: 0.01678 | Running loss: 0.05310\n",
            "Epoch: 8 | Iteration: 1820 | Classification loss: 0.00021 | Regression loss: 0.05305 | Running loss: 0.05317\n",
            "Epoch: 8 | Iteration: 1821 | Classification loss: 0.00157 | Regression loss: 0.01731 | Running loss: 0.05311\n",
            "Epoch: 8 | Iteration: 1822 | Classification loss: 0.00660 | Regression loss: 0.02181 | Running loss: 0.05312\n",
            "Epoch: 8 | Iteration: 1823 | Classification loss: 0.00019 | Regression loss: 0.01788 | Running loss: 0.05309\n",
            "Epoch: 8 | Iteration: 1824 | Classification loss: 0.00060 | Regression loss: 0.03267 | Running loss: 0.05310\n",
            "Epoch: 8 | Iteration: 1825 | Classification loss: 0.00020 | Regression loss: 0.02722 | Running loss: 0.05309\n",
            "Epoch: 8 | Iteration: 1826 | Classification loss: 0.00074 | Regression loss: 0.02458 | Running loss: 0.05309\n",
            "Epoch: 8 | Iteration: 1827 | Classification loss: 0.00030 | Regression loss: 0.04076 | Running loss: 0.05297\n",
            "Epoch: 8 | Iteration: 1828 | Classification loss: 0.00092 | Regression loss: 0.03205 | Running loss: 0.05296\n",
            "Epoch: 8 | Iteration: 1829 | Classification loss: 0.00095 | Regression loss: 0.02092 | Running loss: 0.05293\n",
            "Epoch: 8 | Iteration: 1830 | Classification loss: 0.00209 | Regression loss: 0.02344 | Running loss: 0.05287\n",
            "Epoch: 8 | Iteration: 1831 | Classification loss: 0.00238 | Regression loss: 0.02751 | Running loss: 0.05275\n",
            "Epoch: 8 | Iteration: 1832 | Classification loss: 0.00040 | Regression loss: 0.01737 | Running loss: 0.05270\n",
            "Epoch: 8 | Iteration: 1833 | Classification loss: 0.00632 | Regression loss: 0.03832 | Running loss: 0.05267\n",
            "Epoch: 8 | Iteration: 1834 | Classification loss: 0.00053 | Regression loss: 0.02497 | Running loss: 0.05259\n",
            "Epoch: 8 | Iteration: 1835 | Classification loss: 0.00072 | Regression loss: 0.02869 | Running loss: 0.05261\n",
            "Epoch: 8 | Iteration: 1836 | Classification loss: 0.00414 | Regression loss: 0.06867 | Running loss: 0.05269\n",
            "Epoch: 8 | Iteration: 1837 | Classification loss: 0.00071 | Regression loss: 0.05188 | Running loss: 0.05272\n",
            "Epoch: 8 | Iteration: 1838 | Classification loss: 0.00018 | Regression loss: 0.03118 | Running loss: 0.05274\n",
            "Epoch: 8 | Iteration: 1839 | Classification loss: 0.00110 | Regression loss: 0.03495 | Running loss: 0.05275\n",
            "Epoch: 8 | Iteration: 1840 | Classification loss: 0.00033 | Regression loss: 0.05854 | Running loss: 0.05281\n",
            "Epoch: 8 | Iteration: 1841 | Classification loss: 0.00053 | Regression loss: 0.04154 | Running loss: 0.05284\n",
            "Epoch: 8 | Iteration: 1842 | Classification loss: 0.00040 | Regression loss: 0.03301 | Running loss: 0.05288\n",
            "Epoch: 8 | Iteration: 1843 | Classification loss: 0.02110 | Regression loss: 0.07428 | Running loss: 0.05304\n",
            "Epoch: 8 | Iteration: 1844 | Classification loss: 0.00040 | Regression loss: 0.02520 | Running loss: 0.05300\n",
            "Epoch: 8 | Iteration: 1845 | Classification loss: 0.00021 | Regression loss: 0.01895 | Running loss: 0.05298\n",
            "Epoch: 8 | Iteration: 1846 | Classification loss: 0.00055 | Regression loss: 0.03796 | Running loss: 0.05297\n",
            "Epoch: 8 | Iteration: 1847 | Classification loss: 0.01017 | Regression loss: 0.07282 | Running loss: 0.05303\n",
            "Epoch: 8 | Iteration: 1848 | Classification loss: 0.00030 | Regression loss: 0.04817 | Running loss: 0.05303\n",
            "Epoch: 8 | Iteration: 1849 | Classification loss: 0.00006 | Regression loss: 0.05329 | Running loss: 0.05308\n",
            "Epoch: 8 | Iteration: 1850 | Classification loss: 0.00024 | Regression loss: 0.03042 | Running loss: 0.05307\n",
            "Epoch: 8 | Iteration: 1851 | Classification loss: 0.00212 | Regression loss: 0.04419 | Running loss: 0.05312\n",
            "Epoch: 8 | Iteration: 1852 | Classification loss: 0.00032 | Regression loss: 0.02676 | Running loss: 0.05315\n",
            "Epoch: 8 | Iteration: 1853 | Classification loss: 0.00031 | Regression loss: 0.01869 | Running loss: 0.05315\n",
            "Epoch: 8 | Iteration: 1854 | Classification loss: 0.00026 | Regression loss: 0.02245 | Running loss: 0.05316\n",
            "Epoch: 8 | Iteration: 1855 | Classification loss: 0.00075 | Regression loss: 0.02982 | Running loss: 0.05319\n",
            "Epoch: 8 | Iteration: 1856 | Classification loss: 0.00712 | Regression loss: 0.01792 | Running loss: 0.05321\n",
            "Epoch: 8 | Iteration: 1857 | Classification loss: 0.00166 | Regression loss: 0.01810 | Running loss: 0.05323\n",
            "Epoch: 8 | Iteration: 1858 | Classification loss: 0.00146 | Regression loss: 0.02142 | Running loss: 0.05324\n",
            "Epoch: 8 | Iteration: 1859 | Classification loss: 0.00123 | Regression loss: 0.09242 | Running loss: 0.05326\n",
            "Epoch: 8 | Iteration: 1860 | Classification loss: 0.00012 | Regression loss: 0.02665 | Running loss: 0.05329\n",
            "Epoch: 8 | Iteration: 1861 | Classification loss: 0.00012 | Regression loss: 0.01483 | Running loss: 0.05328\n",
            "Epoch: 8 | Iteration: 1862 | Classification loss: 0.00006 | Regression loss: 0.02008 | Running loss: 0.05329\n",
            "Epoch: 8 | Iteration: 1863 | Classification loss: 0.00025 | Regression loss: 0.02146 | Running loss: 0.05312\n",
            "Epoch: 8 | Iteration: 1864 | Classification loss: 0.00018 | Regression loss: 0.01537 | Running loss: 0.05310\n",
            "Epoch: 8 | Iteration: 1865 | Classification loss: 0.00014 | Regression loss: 0.01271 | Running loss: 0.05307\n",
            "Epoch: 8 | Iteration: 1866 | Classification loss: 0.00059 | Regression loss: 0.02541 | Running loss: 0.05305\n",
            "Epoch: 8 | Iteration: 1867 | Classification loss: 0.00180 | Regression loss: 0.02962 | Running loss: 0.05306\n",
            "Epoch: 8 | Iteration: 1868 | Classification loss: 0.00047 | Regression loss: 0.02654 | Running loss: 0.05299\n",
            "Epoch: 8 | Iteration: 1869 | Classification loss: 0.00014 | Regression loss: 0.02238 | Running loss: 0.05300\n",
            "Epoch: 8 | Iteration: 1870 | Classification loss: 0.00024 | Regression loss: 0.04296 | Running loss: 0.05304\n",
            "Epoch: 8 | Iteration: 1871 | Classification loss: 0.49067 | Regression loss: 0.34786 | Running loss: 0.05467\n",
            "Epoch: 8 | Iteration: 1872 | Classification loss: 0.00015 | Regression loss: 0.02552 | Running loss: 0.05463\n",
            "Epoch: 8 | Iteration: 1873 | Classification loss: 0.00007 | Regression loss: 0.04416 | Running loss: 0.05468\n",
            "Epoch: 8 | Iteration: 1874 | Classification loss: 0.00058 | Regression loss: 0.04816 | Running loss: 0.05474\n",
            "Epoch: 8 | Iteration: 1875 | Classification loss: 0.00016 | Regression loss: 0.02061 | Running loss: 0.05473\n",
            "Epoch: 8 | Iteration: 1876 | Classification loss: 0.00205 | Regression loss: 0.06114 | Running loss: 0.05479\n",
            "Epoch: 8 | Iteration: 1877 | Classification loss: 0.00218 | Regression loss: 0.03553 | Running loss: 0.05478\n",
            "Epoch: 8 | Iteration: 1878 | Classification loss: 0.00048 | Regression loss: 0.03017 | Running loss: 0.05481\n",
            "Epoch: 8 | Iteration: 1879 | Classification loss: 0.00195 | Regression loss: 0.06035 | Running loss: 0.05487\n",
            "Epoch: 8 | Iteration: 1880 | Classification loss: 0.00024 | Regression loss: 0.02326 | Running loss: 0.05486\n",
            "Epoch: 8 | Iteration: 1881 | Classification loss: 0.00210 | Regression loss: 0.01900 | Running loss: 0.05488\n",
            "Epoch: 8 | Iteration: 1882 | Classification loss: 0.00019 | Regression loss: 0.01938 | Running loss: 0.05487\n",
            "Epoch: 8 | Iteration: 1883 | Classification loss: 0.00005 | Regression loss: 0.04481 | Running loss: 0.05490\n",
            "Epoch: 8 | Iteration: 1884 | Classification loss: 0.00093 | Regression loss: 0.02055 | Running loss: 0.05484\n",
            "Epoch: 8 | Iteration: 1885 | Classification loss: 0.00008 | Regression loss: 0.03507 | Running loss: 0.05486\n",
            "Epoch: 8 | Iteration: 1886 | Classification loss: 0.00146 | Regression loss: 0.05850 | Running loss: 0.05361\n",
            "Epoch: 8 | Iteration: 1887 | Classification loss: 0.00167 | Regression loss: 0.07498 | Running loss: 0.05374\n",
            "Epoch: 8 | Iteration: 1888 | Classification loss: 0.00024 | Regression loss: 0.06008 | Running loss: 0.05382\n",
            "Epoch: 8 | Iteration: 1889 | Classification loss: 0.10500 | Regression loss: 0.35997 | Running loss: 0.05466\n",
            "Epoch: 8 | Iteration: 1890 | Classification loss: 0.00005 | Regression loss: 0.01668 | Running loss: 0.05465\n",
            "Epoch: 8 | Iteration: 1891 | Classification loss: 0.00039 | Regression loss: 0.03871 | Running loss: 0.05458\n",
            "Epoch: 8 | Iteration: 1892 | Classification loss: 0.00027 | Regression loss: 0.02393 | Running loss: 0.05455\n",
            "Epoch: 8 | Iteration: 1893 | Classification loss: 0.00024 | Regression loss: 0.01998 | Running loss: 0.05453\n",
            "Epoch: 8 | Iteration: 1894 | Classification loss: 0.05224 | Regression loss: 0.05244 | Running loss: 0.05471\n",
            "Epoch: 8 | Iteration: 1895 | Classification loss: 0.00010 | Regression loss: 0.01437 | Running loss: 0.05470\n",
            "Epoch: 8 | Iteration: 1896 | Classification loss: 0.00008 | Regression loss: 0.01149 | Running loss: 0.05468\n",
            "Epoch: 8 | Iteration: 1897 | Classification loss: 0.00015 | Regression loss: 0.01474 | Running loss: 0.05467\n",
            "Epoch: 8 | Iteration: 1898 | Classification loss: 0.00019 | Regression loss: 0.01143 | Running loss: 0.05464\n",
            "Epoch: 8 | Iteration: 1899 | Classification loss: 0.00009 | Regression loss: 0.00383 | Running loss: 0.05456\n",
            "Epoch: 8 | Iteration: 1900 | Classification loss: 0.04309 | Regression loss: 0.12976 | Running loss: 0.05472\n",
            "Epoch: 8 | Iteration: 1901 | Classification loss: 0.00100 | Regression loss: 0.02654 | Running loss: 0.05471\n",
            "Epoch: 8 | Iteration: 1902 | Classification loss: 0.00190 | Regression loss: 0.03110 | Running loss: 0.05469\n",
            "Epoch: 8 | Iteration: 1903 | Classification loss: 0.00076 | Regression loss: 0.01628 | Running loss: 0.05464\n",
            "Epoch: 8 | Iteration: 1904 | Classification loss: 0.00038 | Regression loss: 0.03321 | Running loss: 0.05466\n",
            "Epoch: 8 | Iteration: 1905 | Classification loss: 0.00077 | Regression loss: 0.01354 | Running loss: 0.05458\n",
            "Epoch: 8 | Iteration: 1906 | Classification loss: 0.00038 | Regression loss: 0.01455 | Running loss: 0.05452\n",
            "Epoch: 8 | Iteration: 1907 | Classification loss: 0.00054 | Regression loss: 0.02386 | Running loss: 0.05453\n",
            "Epoch: 8 | Iteration: 1908 | Classification loss: 0.00031 | Regression loss: 0.01356 | Running loss: 0.05448\n",
            "Epoch: 8 | Iteration: 1909 | Classification loss: 0.00120 | Regression loss: 0.04580 | Running loss: 0.05452\n",
            "Epoch: 8 | Iteration: 1910 | Classification loss: 0.00007 | Regression loss: 0.04423 | Running loss: 0.05457\n",
            "Epoch: 8 | Iteration: 1911 | Classification loss: 0.00037 | Regression loss: 0.02311 | Running loss: 0.05452\n",
            "Epoch: 8 | Iteration: 1912 | Classification loss: 0.00023 | Regression loss: 0.04473 | Running loss: 0.05453\n",
            "Epoch: 8 | Iteration: 1913 | Classification loss: 0.00096 | Regression loss: 0.04713 | Running loss: 0.05455\n",
            "Epoch: 8 | Iteration: 1914 | Classification loss: 0.02728 | Regression loss: 0.04332 | Running loss: 0.05462\n",
            "Epoch: 8 | Iteration: 1915 | Classification loss: 0.00032 | Regression loss: 0.01138 | Running loss: 0.05449\n",
            "Epoch: 8 | Iteration: 1916 | Classification loss: 0.00103 | Regression loss: 0.02442 | Running loss: 0.05450\n",
            "Epoch: 8 | Iteration: 1917 | Classification loss: 0.00129 | Regression loss: 0.01616 | Running loss: 0.05440\n",
            "Epoch: 8 | Iteration: 1918 | Classification loss: 0.00077 | Regression loss: 0.02228 | Running loss: 0.05437\n",
            "Epoch: 8 | Iteration: 1919 | Classification loss: 0.00040 | Regression loss: 0.02788 | Running loss: 0.05429\n",
            "Epoch: 8 | Iteration: 1920 | Classification loss: 0.00009 | Regression loss: 0.03175 | Running loss: 0.05414\n",
            "Epoch: 8 | Iteration: 1921 | Classification loss: 0.00014 | Regression loss: 0.03019 | Running loss: 0.05401\n",
            "Epoch: 8 | Iteration: 1922 | Classification loss: 0.00053 | Regression loss: 0.03260 | Running loss: 0.05402\n",
            "Epoch: 8 | Iteration: 1923 | Classification loss: 0.00031 | Regression loss: 0.02817 | Running loss: 0.05395\n",
            "Epoch: 8 | Iteration: 1924 | Classification loss: 0.00032 | Regression loss: 0.01591 | Running loss: 0.05391\n",
            "Epoch: 8 | Iteration: 1925 | Classification loss: 0.00013 | Regression loss: 0.03739 | Running loss: 0.05389\n",
            "Epoch: 8 | Iteration: 1926 | Classification loss: 0.00023 | Regression loss: 0.04390 | Running loss: 0.05390\n",
            "Epoch: 8 | Iteration: 1927 | Classification loss: 0.00057 | Regression loss: 0.04763 | Running loss: 0.05393\n",
            "Epoch: 8 | Iteration: 1928 | Classification loss: 0.02062 | Regression loss: 0.06198 | Running loss: 0.05406\n",
            "Epoch: 8 | Iteration: 1929 | Classification loss: 0.00119 | Regression loss: 0.01619 | Running loss: 0.05404\n",
            "Epoch: 8 | Iteration: 1930 | Classification loss: 0.00006 | Regression loss: 0.01046 | Running loss: 0.05399\n",
            "Epoch: 8 | Iteration: 1931 | Classification loss: 0.00026 | Regression loss: 0.02930 | Running loss: 0.05402\n",
            "Epoch: 8 | Iteration: 1932 | Classification loss: 0.00527 | Regression loss: 0.07696 | Running loss: 0.05411\n",
            "Epoch: 8 | Iteration: 1933 | Classification loss: 0.00082 | Regression loss: 0.02680 | Running loss: 0.05413\n",
            "Epoch: 8 | Iteration: 1934 | Classification loss: 0.02379 | Regression loss: 0.03641 | Running loss: 0.05420\n",
            "Epoch: 8 | Iteration: 1935 | Classification loss: 0.00268 | Regression loss: 0.05674 | Running loss: 0.05428\n",
            "Epoch: 8 | Iteration: 1936 | Classification loss: 0.00010 | Regression loss: 0.01907 | Running loss: 0.05425\n",
            "Epoch: 8 | Iteration: 1937 | Classification loss: 0.00644 | Regression loss: 0.03497 | Running loss: 0.05431\n",
            "Epoch: 8 | Iteration: 1938 | Classification loss: 0.00059 | Regression loss: 0.03408 | Running loss: 0.05432\n",
            "Epoch: 8 | Iteration: 1939 | Classification loss: 0.00014 | Regression loss: 0.02905 | Running loss: 0.05428\n",
            "Epoch: 8 | Iteration: 1940 | Classification loss: 0.00007 | Regression loss: 0.01226 | Running loss: 0.05426\n",
            "Epoch: 8 | Iteration: 1941 | Classification loss: 0.00009 | Regression loss: 0.04108 | Running loss: 0.05429\n",
            "Epoch: 8 | Iteration: 1942 | Classification loss: 0.00046 | Regression loss: 0.01320 | Running loss: 0.05425\n",
            "Epoch: 8 | Iteration: 1943 | Classification loss: 0.00042 | Regression loss: 0.04510 | Running loss: 0.05431\n",
            "Epoch: 8 | Iteration: 1944 | Classification loss: 0.00081 | Regression loss: 0.04065 | Running loss: 0.05410\n",
            "Epoch: 8 | Iteration: 1945 | Classification loss: 0.00118 | Regression loss: 0.03459 | Running loss: 0.05407\n",
            "Epoch: 8 | Iteration: 1946 | Classification loss: 0.00040 | Regression loss: 0.02673 | Running loss: 0.05410\n",
            "Epoch: 8 | Iteration: 1947 | Classification loss: 0.00005 | Regression loss: 0.01542 | Running loss: 0.05392\n",
            "Epoch: 8 | Iteration: 1948 | Classification loss: 0.00043 | Regression loss: 0.03881 | Running loss: 0.05378\n",
            "Epoch: 8 | Iteration: 1949 | Classification loss: 0.00015 | Regression loss: 0.01687 | Running loss: 0.05376\n",
            "Epoch: 8 | Iteration: 1950 | Classification loss: 0.00005 | Regression loss: 0.01945 | Running loss: 0.05373\n",
            "Epoch: 8 | Iteration: 1951 | Classification loss: 0.00011 | Regression loss: 0.01830 | Running loss: 0.05368\n",
            "Epoch: 8 | Iteration: 1952 | Classification loss: 0.00021 | Regression loss: 0.02243 | Running loss: 0.05368\n",
            "Epoch: 8 | Iteration: 1953 | Classification loss: 0.00135 | Regression loss: 0.04105 | Running loss: 0.05373\n",
            "Epoch: 8 | Iteration: 1954 | Classification loss: 0.00046 | Regression loss: 0.05020 | Running loss: 0.05377\n",
            "Epoch: 8 | Iteration: 1955 | Classification loss: 0.04793 | Regression loss: 0.28812 | Running loss: 0.05438\n",
            "Epoch: 8 | Iteration: 1956 | Classification loss: 0.00022 | Regression loss: 0.03866 | Running loss: 0.05426\n",
            "Epoch: 8 | Iteration: 1957 | Classification loss: 0.00156 | Regression loss: 0.03858 | Running loss: 0.05418\n",
            "Epoch: 8 | Iteration: 1958 | Classification loss: 0.00038 | Regression loss: 0.01504 | Running loss: 0.05417\n",
            "Epoch: 8 | Iteration: 1959 | Classification loss: 0.00003 | Regression loss: 0.01052 | Running loss: 0.05353\n",
            "Epoch: 8 | Iteration: 1960 | Classification loss: 0.01587 | Regression loss: 0.12662 | Running loss: 0.05378\n",
            "Epoch: 8 | Iteration: 1961 | Classification loss: 0.00029 | Regression loss: 0.03245 | Running loss: 0.05379\n",
            "Epoch: 8 | Iteration: 1962 | Classification loss: 0.00010 | Regression loss: 0.01787 | Running loss: 0.05379\n",
            "Epoch: 8 | Iteration: 1963 | Classification loss: 0.00161 | Regression loss: 0.03580 | Running loss: 0.05382\n",
            "Epoch: 8 | Iteration: 1964 | Classification loss: 0.00008 | Regression loss: 0.01320 | Running loss: 0.05380\n",
            "Epoch: 8 | Iteration: 1965 | Classification loss: 0.00036 | Regression loss: 0.01752 | Running loss: 0.05379\n",
            "Epoch: 8 | Iteration: 1966 | Classification loss: 0.00049 | Regression loss: 0.04836 | Running loss: 0.05386\n",
            "Epoch: 8 | Iteration: 1967 | Classification loss: 0.00027 | Regression loss: 0.01016 | Running loss: 0.05383\n",
            "Epoch: 8 | Iteration: 1968 | Classification loss: 0.00516 | Regression loss: 0.02521 | Running loss: 0.05384\n",
            "Epoch: 8 | Iteration: 1969 | Classification loss: 0.00087 | Regression loss: 0.05929 | Running loss: 0.05391\n",
            "Epoch: 8 | Iteration: 1970 | Classification loss: 0.00022 | Regression loss: 0.03532 | Running loss: 0.05391\n",
            "Epoch: 8 | Iteration: 1971 | Classification loss: 0.00015 | Regression loss: 0.01420 | Running loss: 0.05390\n",
            "Epoch: 8 | Iteration: 1972 | Classification loss: 0.00028 | Regression loss: 0.03146 | Running loss: 0.05380\n",
            "Epoch: 8 | Iteration: 1973 | Classification loss: 0.00241 | Regression loss: 0.01222 | Running loss: 0.05375\n",
            "Epoch: 8 | Iteration: 1974 | Classification loss: 0.00021 | Regression loss: 0.01832 | Running loss: 0.05372\n",
            "Epoch: 8 | Iteration: 1975 | Classification loss: 0.00004 | Regression loss: 0.01312 | Running loss: 0.05365\n",
            "Epoch: 8 | Iteration: 1976 | Classification loss: 0.00017 | Regression loss: 0.00956 | Running loss: 0.05356\n",
            "Epoch: 8 | Iteration: 1977 | Classification loss: 0.00035 | Regression loss: 0.02036 | Running loss: 0.05353\n",
            "Epoch: 8 | Iteration: 1978 | Classification loss: 0.00008 | Regression loss: 0.00882 | Running loss: 0.05349\n",
            "Epoch: 8 | Iteration: 1979 | Classification loss: 0.00067 | Regression loss: 0.03496 | Running loss: 0.05346\n",
            "Epoch: 8 | Iteration: 1980 | Classification loss: 0.00737 | Regression loss: 0.10251 | Running loss: 0.05362\n",
            "Epoch: 8 | Iteration: 1981 | Classification loss: 0.00013 | Regression loss: 0.06342 | Running loss: 0.05371\n",
            "Epoch: 8 | Iteration: 1982 | Classification loss: 0.00035 | Regression loss: 0.01573 | Running loss: 0.05366\n",
            "Epoch: 8 | Iteration: 1983 | Classification loss: 0.00007 | Regression loss: 0.02253 | Running loss: 0.05366\n",
            "Epoch: 8 | Iteration: 1984 | Classification loss: 0.00004 | Regression loss: 0.02280 | Running loss: 0.05359\n",
            "Epoch: 8 | Iteration: 1985 | Classification loss: 0.00024 | Regression loss: 0.07352 | Running loss: 0.05363\n",
            "Epoch: 8 | Iteration: 1986 | Classification loss: 0.01055 | Regression loss: 0.11132 | Running loss: 0.05380\n",
            "Epoch: 8 | Iteration: 1987 | Classification loss: 0.00010 | Regression loss: 0.03938 | Running loss: 0.05380\n",
            "Epoch: 8 | Iteration: 1988 | Classification loss: 0.00045 | Regression loss: 0.02512 | Running loss: 0.05378\n",
            "Epoch: 8 | Iteration: 1989 | Classification loss: 0.00074 | Regression loss: 0.02371 | Running loss: 0.05376\n",
            "Epoch: 8 | Iteration: 1990 | Classification loss: 0.00256 | Regression loss: 0.01012 | Running loss: 0.05375\n",
            "Epoch: 8 | Iteration: 1991 | Classification loss: 0.00021 | Regression loss: 0.02171 | Running loss: 0.05375\n",
            "Epoch: 8 | Iteration: 1992 | Classification loss: 0.00007 | Regression loss: 0.01400 | Running loss: 0.05375\n",
            "Epoch: 8 | Iteration: 1993 | Classification loss: 0.00031 | Regression loss: 0.02155 | Running loss: 0.05376\n",
            "Epoch: 8 | Iteration: 1994 | Classification loss: 0.00387 | Regression loss: 0.08752 | Running loss: 0.05390\n",
            "Epoch: 8 | Iteration: 1995 | Classification loss: 0.00033 | Regression loss: 0.05797 | Running loss: 0.05400\n",
            "Epoch: 8 | Iteration: 1996 | Classification loss: 0.00006 | Regression loss: 0.02245 | Running loss: 0.05399\n",
            "Epoch: 8 | Iteration: 1997 | Classification loss: 0.00061 | Regression loss: 0.02137 | Running loss: 0.05400\n",
            "Epoch: 8 | Iteration: 1998 | Classification loss: 0.00009 | Regression loss: 0.02952 | Running loss: 0.05402\n",
            "Epoch: 8 | Iteration: 1999 | Classification loss: 0.00017 | Regression loss: 0.01827 | Running loss: 0.05397\n",
            "Epoch: 8 | Iteration: 2000 | Classification loss: 0.00003 | Regression loss: 0.04561 | Running loss: 0.05386\n",
            "Epoch: 8 | Iteration: 2001 | Classification loss: 0.00015 | Regression loss: 0.01915 | Running loss: 0.05385\n",
            "Epoch: 8 | Iteration: 2002 | Classification loss: 0.00009 | Regression loss: 0.02357 | Running loss: 0.05382\n",
            "Epoch: 8 | Iteration: 2003 | Classification loss: 0.00050 | Regression loss: 0.04478 | Running loss: 0.05384\n",
            "Epoch: 8 | Iteration: 2004 | Classification loss: 0.00013 | Regression loss: 0.03845 | Running loss: 0.05387\n",
            "Epoch: 8 | Iteration: 2005 | Classification loss: 0.00033 | Regression loss: 0.01581 | Running loss: 0.05385\n",
            "Epoch: 8 | Iteration: 2006 | Classification loss: 0.00366 | Regression loss: 0.03048 | Running loss: 0.05386\n",
            "Epoch: 8 | Iteration: 2007 | Classification loss: 0.00015 | Regression loss: 0.01099 | Running loss: 0.05384\n",
            "Epoch: 8 | Iteration: 2008 | Classification loss: 0.00133 | Regression loss: 0.03292 | Running loss: 0.05385\n",
            "Epoch: 8 | Iteration: 2009 | Classification loss: 0.00003 | Regression loss: 0.02249 | Running loss: 0.05384\n",
            "Epoch: 8 | Iteration: 2010 | Classification loss: 0.00030 | Regression loss: 0.04267 | Running loss: 0.05387\n",
            "Epoch: 8 | Iteration: 2011 | Classification loss: 0.00004 | Regression loss: 0.01807 | Running loss: 0.05381\n",
            "Epoch: 8 | Iteration: 2012 | Classification loss: 0.00010 | Regression loss: 0.01694 | Running loss: 0.05378\n",
            "Epoch: 8 | Iteration: 2013 | Classification loss: 0.00016 | Regression loss: 0.03055 | Running loss: 0.05374\n",
            "Epoch: 8 | Iteration: 2014 | Classification loss: 0.00042 | Regression loss: 0.02790 | Running loss: 0.05361\n",
            "Epoch: 8 | Iteration: 2015 | Classification loss: 0.00008 | Regression loss: 0.05747 | Running loss: 0.05366\n",
            "Epoch: 8 | Iteration: 2016 | Classification loss: 0.00014 | Regression loss: 0.02439 | Running loss: 0.05366\n",
            "Epoch: 8 | Iteration: 2017 | Classification loss: 0.00079 | Regression loss: 0.03183 | Running loss: 0.05359\n",
            "Epoch: 8 | Iteration: 2018 | Classification loss: 0.00156 | Regression loss: 0.02489 | Running loss: 0.05357\n",
            "Epoch: 8 | Iteration: 2019 | Classification loss: 0.00010 | Regression loss: 0.03948 | Running loss: 0.05362\n",
            "Epoch: 8 | Iteration: 2020 | Classification loss: 0.00030 | Regression loss: 0.03955 | Running loss: 0.05352\n",
            "Epoch: 8 | Iteration: 2021 | Classification loss: 0.00014 | Regression loss: 0.03013 | Running loss: 0.05353\n",
            "Epoch: 8 | Iteration: 2022 | Classification loss: 0.00005 | Regression loss: 0.02046 | Running loss: 0.05351\n",
            "Epoch: 8 | Iteration: 2023 | Classification loss: 0.00040 | Regression loss: 0.03583 | Running loss: 0.05351\n",
            "Epoch: 8 | Iteration: 2024 | Classification loss: 0.00010 | Regression loss: 0.05615 | Running loss: 0.05356\n",
            "Epoch: 8 | Iteration: 2025 | Classification loss: 0.00002 | Regression loss: 0.03581 | Running loss: 0.05355\n",
            "Epoch: 8 | Iteration: 2026 | Classification loss: 0.00020 | Regression loss: 0.02427 | Running loss: 0.05353\n",
            "Epoch: 8 | Iteration: 2027 | Classification loss: 0.00004 | Regression loss: 0.03450 | Running loss: 0.05325\n",
            "Epoch: 8 | Iteration: 2028 | Classification loss: 0.00036 | Regression loss: 0.02882 | Running loss: 0.05325\n",
            "Epoch: 8 | Iteration: 2029 | Classification loss: 0.00395 | Regression loss: 0.04488 | Running loss: 0.05330\n",
            "Epoch: 8 | Iteration: 2030 | Classification loss: 0.00034 | Regression loss: 0.02288 | Running loss: 0.05332\n",
            "Epoch: 8 | Iteration: 2031 | Classification loss: 0.00016 | Regression loss: 0.01003 | Running loss: 0.05331\n",
            "Epoch: 8 | Iteration: 2032 | Classification loss: 0.00115 | Regression loss: 0.09463 | Running loss: 0.05345\n",
            "Epoch: 8 | Iteration: 2033 | Classification loss: 0.00018 | Regression loss: 0.01532 | Running loss: 0.05327\n",
            "Epoch: 8 | Iteration: 2034 | Classification loss: 0.00028 | Regression loss: 0.03295 | Running loss: 0.05323\n",
            "Epoch: 8 | Iteration: 2035 | Classification loss: 0.00005 | Regression loss: 0.02299 | Running loss: 0.05325\n",
            "Epoch: 8 | Iteration: 2036 | Classification loss: 0.00015 | Regression loss: 0.03229 | Running loss: 0.05324\n",
            "Epoch: 8 | Iteration: 2037 | Classification loss: 0.00008 | Regression loss: 0.03332 | Running loss: 0.05326\n",
            "Epoch: 8 | Iteration: 2038 | Classification loss: 0.00011 | Regression loss: 0.02069 | Running loss: 0.05302\n",
            "Epoch: 8 | Iteration: 2039 | Classification loss: 0.00085 | Regression loss: 0.03407 | Running loss: 0.05306\n",
            "Epoch: 8 | Iteration: 2040 | Classification loss: 0.00014 | Regression loss: 0.01349 | Running loss: 0.05303\n",
            "Epoch: 8 | Iteration: 2041 | Classification loss: 0.00090 | Regression loss: 0.02009 | Running loss: 0.05296\n",
            "Epoch: 8 | Iteration: 2042 | Classification loss: 0.00010 | Regression loss: 0.02019 | Running loss: 0.05298\n",
            "Epoch: 8 | Iteration: 2043 | Classification loss: 0.00075 | Regression loss: 0.02356 | Running loss: 0.05301\n",
            "Epoch: 8 | Iteration: 2044 | Classification loss: 0.00003 | Regression loss: 0.03868 | Running loss: 0.05305\n",
            "Epoch: 8 | Iteration: 2045 | Classification loss: 0.00323 | Regression loss: 0.04028 | Running loss: 0.05310\n",
            "Epoch: 8 | Iteration: 2046 | Classification loss: 0.00015 | Regression loss: 0.03704 | Running loss: 0.05313\n",
            "Epoch: 8 | Iteration: 2047 | Classification loss: 0.00026 | Regression loss: 0.05020 | Running loss: 0.05319\n",
            "Epoch: 8 | Iteration: 2048 | Classification loss: 0.00028 | Regression loss: 0.01091 | Running loss: 0.05317\n",
            "Epoch: 8 | Iteration: 2049 | Classification loss: 0.00025 | Regression loss: 0.01113 | Running loss: 0.05313\n",
            "Epoch: 8 | Iteration: 2050 | Classification loss: 0.00023 | Regression loss: 0.02423 | Running loss: 0.05313\n",
            "Epoch: 8 | Iteration: 2051 | Classification loss: 0.00007 | Regression loss: 0.01755 | Running loss: 0.05314\n",
            "Epoch: 8 | Iteration: 2052 | Classification loss: 0.00003 | Regression loss: 0.01344 | Running loss: 0.05313\n",
            "Epoch: 8 | Iteration: 2053 | Classification loss: 0.00015 | Regression loss: 0.01625 | Running loss: 0.05313\n",
            "Epoch: 8 | Iteration: 2054 | Classification loss: 0.00005 | Regression loss: 0.01346 | Running loss: 0.05303\n",
            "Epoch: 8 | Iteration: 2055 | Classification loss: 0.00009 | Regression loss: 0.03101 | Running loss: 0.05302\n",
            "Epoch: 8 | Iteration: 2056 | Classification loss: 0.00009 | Regression loss: 0.01226 | Running loss: 0.05299\n",
            "Epoch: 8 | Iteration: 2057 | Classification loss: 0.00036 | Regression loss: 0.03956 | Running loss: 0.05302\n",
            "Epoch: 8 | Iteration: 2058 | Classification loss: 0.00008 | Regression loss: 0.01474 | Running loss: 0.05300\n",
            "Epoch: 8 | Iteration: 2059 | Classification loss: 0.00006 | Regression loss: 0.03394 | Running loss: 0.05294\n",
            "Epoch: 8 | Iteration: 2060 | Classification loss: 0.00005 | Regression loss: 0.02431 | Running loss: 0.05295\n",
            "Epoch: 8 | Iteration: 2061 | Classification loss: 0.00014 | Regression loss: 0.02295 | Running loss: 0.05283\n",
            "Epoch: 8 | Iteration: 2062 | Classification loss: 0.00015 | Regression loss: 0.05359 | Running loss: 0.05292\n",
            "Epoch: 8 | Iteration: 2063 | Classification loss: 0.00023 | Regression loss: 0.02007 | Running loss: 0.05292\n",
            "Epoch: 8 | Iteration: 2064 | Classification loss: 0.01743 | Regression loss: 0.08632 | Running loss: 0.05306\n",
            "Epoch: 8 | Iteration: 2065 | Classification loss: 0.00195 | Regression loss: 0.04910 | Running loss: 0.05313\n",
            "Epoch: 8 | Iteration: 2066 | Classification loss: 0.00045 | Regression loss: 0.03323 | Running loss: 0.05316\n",
            "Epoch: 8 | Iteration: 2067 | Classification loss: 0.00024 | Regression loss: 0.02851 | Running loss: 0.05313\n",
            "Epoch: 8 | Iteration: 2068 | Classification loss: 0.00006 | Regression loss: 0.01216 | Running loss: 0.05311\n",
            "Epoch: 8 | Iteration: 2069 | Classification loss: 0.00009 | Regression loss: 0.02484 | Running loss: 0.05311\n",
            "Epoch: 8 | Iteration: 2070 | Classification loss: 0.00011 | Regression loss: 0.01091 | Running loss: 0.05311\n",
            "Epoch: 8 | Iteration: 2071 | Classification loss: 0.00025 | Regression loss: 0.02257 | Running loss: 0.05311\n",
            "Epoch: 8 | Iteration: 2072 | Classification loss: 0.00009 | Regression loss: 0.02180 | Running loss: 0.05311\n",
            "Epoch: 8 | Iteration: 2073 | Classification loss: 0.00588 | Regression loss: 0.08914 | Running loss: 0.05326\n",
            "Epoch: 8 | Iteration: 2074 | Classification loss: 0.21593 | Regression loss: 0.38981 | Running loss: 0.05443\n",
            "Epoch: 8 | Iteration: 2075 | Classification loss: 0.00007 | Regression loss: 0.03108 | Running loss: 0.05442\n",
            "Epoch: 8 | Iteration: 2076 | Classification loss: 0.00049 | Regression loss: 0.02178 | Running loss: 0.05438\n",
            "Epoch: 8 | Iteration: 2077 | Classification loss: 0.00028 | Regression loss: 0.03115 | Running loss: 0.05441\n",
            "Epoch: 8 | Iteration: 2078 | Classification loss: 0.00010 | Regression loss: 0.02696 | Running loss: 0.05443\n",
            "Epoch: 8 | Iteration: 2079 | Classification loss: 0.00007 | Regression loss: 0.01837 | Running loss: 0.05442\n",
            "Epoch: 8 | Iteration: 2080 | Classification loss: 0.00253 | Regression loss: 0.01587 | Running loss: 0.05439\n",
            "Epoch: 8 | Iteration: 2081 | Classification loss: 0.00007 | Regression loss: 0.04452 | Running loss: 0.05443\n",
            "Epoch: 8 | Iteration: 2082 | Classification loss: 0.00026 | Regression loss: 0.01824 | Running loss: 0.05444\n",
            "Epoch: 8 | Iteration: 2083 | Classification loss: 0.00007 | Regression loss: 0.04542 | Running loss: 0.05450\n",
            "Epoch: 8 | Iteration: 2084 | Classification loss: 0.00012 | Regression loss: 0.01560 | Running loss: 0.05444\n",
            "Epoch: 8 | Iteration: 2085 | Classification loss: 0.00016 | Regression loss: 0.02516 | Running loss: 0.05446\n",
            "Epoch: 8 | Iteration: 2086 | Classification loss: 0.00087 | Regression loss: 0.01557 | Running loss: 0.05442\n",
            "Epoch: 8 | Iteration: 2087 | Classification loss: 0.00004 | Regression loss: 0.01572 | Running loss: 0.05442\n",
            "Epoch: 8 | Iteration: 2088 | Classification loss: 0.00027 | Regression loss: 0.01744 | Running loss: 0.05437\n",
            "Epoch: 8 | Iteration: 2089 | Classification loss: 0.00015 | Regression loss: 0.01796 | Running loss: 0.05434\n",
            "Epoch: 8 | Iteration: 2090 | Classification loss: 0.00070 | Regression loss: 0.01780 | Running loss: 0.05415\n",
            "Epoch: 8 | Iteration: 2091 | Classification loss: 0.00214 | Regression loss: 0.03038 | Running loss: 0.05415\n",
            "Epoch: 8 | Iteration: 2092 | Classification loss: 0.00047 | Regression loss: 0.01482 | Running loss: 0.05413\n",
            "Epoch: 8 | Iteration: 2093 | Classification loss: 0.00026 | Regression loss: 0.01158 | Running loss: 0.05410\n",
            "Epoch: 8 | Iteration: 2094 | Classification loss: 0.00021 | Regression loss: 0.01849 | Running loss: 0.05409\n",
            "Epoch: 8 | Iteration: 2095 | Classification loss: 0.00035 | Regression loss: 0.02200 | Running loss: 0.05410\n",
            "Epoch: 8 | Iteration: 2096 | Classification loss: 0.00006 | Regression loss: 0.01111 | Running loss: 0.05377\n",
            "Epoch: 8 | Iteration: 2097 | Classification loss: 0.00018 | Regression loss: 0.00932 | Running loss: 0.05373\n",
            "Epoch: 8 | Iteration: 2098 | Classification loss: 0.00164 | Regression loss: 0.03632 | Running loss: 0.05370\n",
            "Epoch: 8 | Iteration: 2099 | Classification loss: 0.00013 | Regression loss: 0.01764 | Running loss: 0.05369\n",
            "Epoch: 8 | Iteration: 2100 | Classification loss: 0.00048 | Regression loss: 0.02718 | Running loss: 0.05364\n",
            "Epoch: 8 | Iteration: 2101 | Classification loss: 0.00060 | Regression loss: 0.02424 | Running loss: 0.05365\n",
            "Epoch: 8 | Iteration: 2102 | Classification loss: 0.00025 | Regression loss: 0.01775 | Running loss: 0.05366\n",
            "Epoch: 8 | Iteration: 2103 | Classification loss: 0.00013 | Regression loss: 0.01579 | Running loss: 0.05366\n",
            "Epoch: 8 | Iteration: 2104 | Classification loss: 0.00015 | Regression loss: 0.03448 | Running loss: 0.05362\n",
            "Epoch: 8 | Iteration: 2105 | Classification loss: 0.00026 | Regression loss: 0.01612 | Running loss: 0.05357\n",
            "Epoch: 8 | Iteration: 2106 | Classification loss: 0.00017 | Regression loss: 0.01665 | Running loss: 0.05356\n",
            "Epoch: 8 | Iteration: 2107 | Classification loss: 0.00035 | Regression loss: 0.02113 | Running loss: 0.05352\n",
            "Epoch: 8 | Iteration: 2108 | Classification loss: 0.00021 | Regression loss: 0.03749 | Running loss: 0.05357\n",
            "Epoch: 8 | Iteration: 2109 | Classification loss: 0.00174 | Regression loss: 0.03892 | Running loss: 0.05353\n",
            "Epoch: 8 | Iteration: 2110 | Classification loss: 0.00013 | Regression loss: 0.04118 | Running loss: 0.05357\n",
            "Epoch: 8 | Iteration: 2111 | Classification loss: 0.00008 | Regression loss: 0.03136 | Running loss: 0.05356\n",
            "Epoch: 8 | Iteration: 2112 | Classification loss: 0.00009 | Regression loss: 0.01117 | Running loss: 0.05355\n",
            "Epoch: 8 | Iteration: 2113 | Classification loss: 0.00030 | Regression loss: 0.03300 | Running loss: 0.04940\n",
            "Epoch: 8 | Iteration: 2114 | Classification loss: 0.00007 | Regression loss: 0.05690 | Running loss: 0.04947\n",
            "Epoch: 8 | Iteration: 2115 | Classification loss: 0.00020 | Regression loss: 0.02235 | Running loss: 0.04949\n",
            "Epoch: 8 | Iteration: 2116 | Classification loss: 0.00153 | Regression loss: 0.04169 | Running loss: 0.04953\n",
            "Epoch: 8 | Iteration: 2117 | Classification loss: 0.00035 | Regression loss: 0.04624 | Running loss: 0.04953\n",
            "Epoch: 8 | Iteration: 2118 | Classification loss: 0.00047 | Regression loss: 0.03734 | Running loss: 0.04956\n",
            "Epoch: 8 | Iteration: 2119 | Classification loss: 0.04103 | Regression loss: 0.05554 | Running loss: 0.04967\n",
            "Epoch: 8 | Iteration: 2120 | Classification loss: 0.00006 | Regression loss: 0.02461 | Running loss: 0.04959\n",
            "Epoch: 8 | Iteration: 2121 | Classification loss: 0.00022 | Regression loss: 0.03183 | Running loss: 0.04952\n",
            "Epoch: 8 | Iteration: 2122 | Classification loss: 0.00059 | Regression loss: 0.01842 | Running loss: 0.04947\n",
            "Epoch: 8 | Iteration: 2123 | Classification loss: 0.00008 | Regression loss: 0.01150 | Running loss: 0.04944\n",
            "Epoch: 8 | Iteration: 2124 | Classification loss: 0.00026 | Regression loss: 0.01804 | Running loss: 0.04929\n",
            "Epoch: 8 | Iteration: 2125 | Classification loss: 0.00034 | Regression loss: 0.02721 | Running loss: 0.04928\n",
            "Epoch: 8 | Iteration: 2126 | Classification loss: 0.00024 | Regression loss: 0.04097 | Running loss: 0.04933\n",
            "Epoch: 8 | Iteration: 2127 | Classification loss: 0.00054 | Regression loss: 0.04468 | Running loss: 0.04937\n",
            "Epoch: 8 | Iteration: 2128 | Classification loss: 0.00214 | Regression loss: 0.05298 | Running loss: 0.04936\n",
            "Epoch: 8 | Iteration: 2129 | Classification loss: 0.00018 | Regression loss: 0.03087 | Running loss: 0.04933\n",
            "Epoch: 8 | Iteration: 2130 | Classification loss: 0.00020 | Regression loss: 0.04415 | Running loss: 0.04935\n",
            "Epoch: 8 | Iteration: 2131 | Classification loss: 0.00028 | Regression loss: 0.04198 | Running loss: 0.04938\n",
            "Epoch: 8 | Iteration: 2132 | Classification loss: 0.00028 | Regression loss: 0.03851 | Running loss: 0.04940\n",
            "Epoch: 8 | Iteration: 2133 | Classification loss: 0.00003 | Regression loss: 0.01201 | Running loss: 0.04936\n",
            "Epoch: 8 | Iteration: 2134 | Classification loss: 0.00051 | Regression loss: 0.05699 | Running loss: 0.04941\n",
            "Epoch: 8 | Iteration: 2135 | Classification loss: 0.00022 | Regression loss: 0.01995 | Running loss: 0.04935\n",
            "Epoch: 8 | Iteration: 2136 | Classification loss: 0.00021 | Regression loss: 0.02243 | Running loss: 0.04927\n",
            "Epoch: 8 | Iteration: 2137 | Classification loss: 0.00006 | Regression loss: 0.02585 | Running loss: 0.04929\n",
            "Epoch: 8 | Iteration: 2138 | Classification loss: 0.00082 | Regression loss: 0.01709 | Running loss: 0.04930\n",
            "Epoch: 8 | Iteration: 2139 | Classification loss: 0.00056 | Regression loss: 0.03153 | Running loss: 0.04934\n",
            "Epoch: 8 | Iteration: 2140 | Classification loss: 0.00014 | Regression loss: 0.02244 | Running loss: 0.04809\n",
            "Epoch: 8 | Iteration: 2141 | Classification loss: 0.00009 | Regression loss: 0.01808 | Running loss: 0.04804\n",
            "Epoch: 8 | Iteration: 2142 | Classification loss: 0.00055 | Regression loss: 0.02492 | Running loss: 0.04802\n",
            "Epoch: 8 | Iteration: 2143 | Classification loss: 0.00019 | Regression loss: 0.01374 | Running loss: 0.04794\n",
            "Epoch: 8 | Iteration: 2144 | Classification loss: 0.00012 | Regression loss: 0.00777 | Running loss: 0.04789\n",
            "Epoch: 8 | Iteration: 2145 | Classification loss: 0.00014 | Regression loss: 0.03375 | Running loss: 0.04783\n",
            "Epoch: 8 | Iteration: 2146 | Classification loss: 0.00021 | Regression loss: 0.01921 | Running loss: 0.04769\n",
            "Epoch: 8 | Iteration: 2147 | Classification loss: 0.00009 | Regression loss: 0.02075 | Running loss: 0.04765\n",
            "Epoch: 8 | Iteration: 2148 | Classification loss: 0.00079 | Regression loss: 0.02944 | Running loss: 0.04764\n",
            "Epoch: 8 | Iteration: 2149 | Classification loss: 0.00016 | Regression loss: 0.02590 | Running loss: 0.04764\n",
            "Epoch: 8 | Iteration: 2150 | Classification loss: 0.00019 | Regression loss: 0.04392 | Running loss: 0.04768\n",
            "Epoch: 8 | Iteration: 2151 | Classification loss: 0.00036 | Regression loss: 0.01244 | Running loss: 0.04762\n",
            "Epoch: 8 | Iteration: 2152 | Classification loss: 0.00022 | Regression loss: 0.01590 | Running loss: 0.04759\n",
            "Epoch: 8 | Iteration: 2153 | Classification loss: 0.00018 | Regression loss: 0.02970 | Running loss: 0.04757\n",
            "Epoch: 8 | Iteration: 2154 | Classification loss: 0.00130 | Regression loss: 0.02485 | Running loss: 0.04757\n",
            "Epoch: 8 | Iteration: 2155 | Classification loss: 0.00012 | Regression loss: 0.02967 | Running loss: 0.04745\n",
            "Epoch: 8 | Iteration: 2156 | Classification loss: 0.00042 | Regression loss: 0.02110 | Running loss: 0.04745\n",
            "Epoch: 8 | Iteration: 2157 | Classification loss: 0.00031 | Regression loss: 0.03052 | Running loss: 0.04746\n",
            "Epoch: 8 | Iteration: 2158 | Classification loss: 0.01554 | Regression loss: 0.03622 | Running loss: 0.04746\n",
            "Epoch: 8 | Iteration: 2159 | Classification loss: 0.01200 | Regression loss: 0.04051 | Running loss: 0.04725\n",
            "Epoch: 8 | Iteration: 2160 | Classification loss: 0.00258 | Regression loss: 0.04282 | Running loss: 0.04725\n",
            "Epoch: 8 | Iteration: 2161 | Classification loss: 0.00002 | Regression loss: 0.02479 | Running loss: 0.04721\n",
            "Epoch: 8 | Iteration: 2162 | Classification loss: 0.00028 | Regression loss: 0.02094 | Running loss: 0.04714\n",
            "Epoch: 8 | Iteration: 2163 | Classification loss: 0.00143 | Regression loss: 0.02746 | Running loss: 0.04717\n",
            "Epoch: 8 | Iteration: 2164 | Classification loss: 0.00012 | Regression loss: 0.01331 | Running loss: 0.04713\n",
            "Epoch: 8 | Iteration: 2165 | Classification loss: 0.00011 | Regression loss: 0.02204 | Running loss: 0.04710\n",
            "Epoch: 8 | Iteration: 2166 | Classification loss: 0.00026 | Regression loss: 0.01329 | Running loss: 0.04705\n",
            "Epoch: 8 | Iteration: 2167 | Classification loss: 0.00030 | Regression loss: 0.01832 | Running loss: 0.04705\n",
            "Epoch: 8 | Iteration: 2168 | Classification loss: 0.00008 | Regression loss: 0.04114 | Running loss: 0.04709\n",
            "Epoch: 8 | Iteration: 2169 | Classification loss: 0.00002 | Regression loss: 0.02801 | Running loss: 0.04710\n",
            "Epoch: 8 | Iteration: 2170 | Classification loss: 0.00024 | Regression loss: 0.04999 | Running loss: 0.04715\n",
            "Epoch: 8 | Iteration: 2171 | Classification loss: 0.00001 | Regression loss: 0.02228 | Running loss: 0.04713\n",
            "Epoch: 8 | Iteration: 2172 | Classification loss: 0.00070 | Regression loss: 0.04442 | Running loss: 0.04716\n",
            "Epoch: 8 | Iteration: 2173 | Classification loss: 0.00015 | Regression loss: 0.04967 | Running loss: 0.04721\n",
            "Epoch: 8 | Iteration: 2174 | Classification loss: 0.01274 | Regression loss: 0.06914 | Running loss: 0.04727\n",
            "Epoch: 8 | Iteration: 2175 | Classification loss: 0.00248 | Regression loss: 0.01758 | Running loss: 0.04722\n",
            "Epoch: 8 | Iteration: 2176 | Classification loss: 0.01278 | Regression loss: 0.06692 | Running loss: 0.04693\n",
            "Epoch: 8 | Iteration: 2177 | Classification loss: 0.00026 | Regression loss: 0.03060 | Running loss: 0.04688\n",
            "Epoch: 8 | Iteration: 2178 | Classification loss: 0.00033 | Regression loss: 0.03590 | Running loss: 0.04686\n",
            "Epoch: 8 | Iteration: 2179 | Classification loss: 0.00702 | Regression loss: 0.03219 | Running loss: 0.04683\n",
            "Epoch: 8 | Iteration: 2180 | Classification loss: 0.00566 | Regression loss: 0.05810 | Running loss: 0.04690\n",
            "Epoch: 8 | Iteration: 2181 | Classification loss: 0.00004 | Regression loss: 0.01983 | Running loss: 0.04687\n",
            "Epoch: 8 | Iteration: 2182 | Classification loss: 0.00017 | Regression loss: 0.01771 | Running loss: 0.04684\n",
            "Epoch: 8 | Iteration: 2183 | Classification loss: 0.00079 | Regression loss: 0.02420 | Running loss: 0.04684\n",
            "Epoch: 8 | Iteration: 2184 | Classification loss: 0.00003 | Regression loss: 0.02209 | Running loss: 0.04682\n",
            "Epoch: 8 | Iteration: 2185 | Classification loss: 0.00008 | Regression loss: 0.03771 | Running loss: 0.04685\n",
            "Epoch: 8 | Iteration: 2186 | Classification loss: 0.00009 | Regression loss: 0.02301 | Running loss: 0.04684\n",
            "Epoch: 8 | Iteration: 2187 | Classification loss: 0.00026 | Regression loss: 0.04712 | Running loss: 0.04673\n",
            "Epoch: 8 | Iteration: 2188 | Classification loss: 0.00037 | Regression loss: 0.03535 | Running loss: 0.04675\n",
            "Epoch: 8 | Iteration: 2189 | Classification loss: 0.00005 | Regression loss: 0.02112 | Running loss: 0.04676\n",
            "Epoch: 8 | Iteration: 2190 | Classification loss: 0.00062 | Regression loss: 0.02553 | Running loss: 0.04673\n",
            "Epoch: 8 | Iteration: 2191 | Classification loss: 0.00010 | Regression loss: 0.01311 | Running loss: 0.04667\n",
            "Epoch: 8 | Iteration: 2192 | Classification loss: 0.00002 | Regression loss: 0.03368 | Running loss: 0.04665\n",
            "Epoch: 8 | Iteration: 2193 | Classification loss: 0.00490 | Regression loss: 0.17015 | Running loss: 0.04481\n",
            "Epoch: 8 | Iteration: 2194 | Classification loss: 0.00015 | Regression loss: 0.00733 | Running loss: 0.04465\n",
            "Epoch: 8 | Iteration: 2195 | Classification loss: 0.00028 | Regression loss: 0.03472 | Running loss: 0.04460\n",
            "Epoch: 8 | Iteration: 2196 | Classification loss: 0.00039 | Regression loss: 0.03764 | Running loss: 0.04453\n",
            "Epoch: 8 | Iteration: 2197 | Classification loss: 0.00008 | Regression loss: 0.01880 | Running loss: 0.04436\n",
            "Epoch: 8 | Iteration: 2198 | Classification loss: 0.00424 | Regression loss: 0.04690 | Running loss: 0.04349\n",
            "Epoch: 8 | Iteration: 2199 | Classification loss: 0.00037 | Regression loss: 0.03552 | Running loss: 0.04351\n",
            "Epoch: 8 | Iteration: 2200 | Classification loss: 0.00017 | Regression loss: 0.01839 | Running loss: 0.04348\n",
            "Epoch: 8 | Iteration: 2201 | Classification loss: 0.00053 | Regression loss: 0.02260 | Running loss: 0.04346\n",
            "Epoch: 8 | Iteration: 2202 | Classification loss: 0.00017 | Regression loss: 0.01724 | Running loss: 0.04346\n",
            "Epoch: 8 | Iteration: 2203 | Classification loss: 0.00031 | Regression loss: 0.02643 | Running loss: 0.04332\n",
            "Epoch: 8 | Iteration: 2204 | Classification loss: 0.00006 | Regression loss: 0.03042 | Running loss: 0.04319\n",
            "Epoch: 8 | Iteration: 2205 | Classification loss: 0.00062 | Regression loss: 0.02161 | Running loss: 0.04320\n",
            "Epoch: 8 | Iteration: 2206 | Classification loss: 0.00221 | Regression loss: 0.01752 | Running loss: 0.04303\n",
            "Epoch: 8 | Iteration: 2207 | Classification loss: 0.00054 | Regression loss: 0.07682 | Running loss: 0.04313\n",
            "Epoch: 8 | Iteration: 2208 | Classification loss: 0.00003 | Regression loss: 0.01548 | Running loss: 0.04309\n",
            "Epoch: 8 | Iteration: 2209 | Classification loss: 0.00004 | Regression loss: 0.01357 | Running loss: 0.04308\n",
            "Epoch: 8 | Iteration: 2210 | Classification loss: 0.00047 | Regression loss: 0.01811 | Running loss: 0.04299\n",
            "Epoch: 8 | Iteration: 2211 | Classification loss: 0.00011 | Regression loss: 0.02046 | Running loss: 0.04299\n",
            "Epoch: 8 | Iteration: 2212 | Classification loss: 0.00014 | Regression loss: 0.03164 | Running loss: 0.04303\n",
            "Epoch: 8 | Iteration: 2213 | Classification loss: 0.00005 | Regression loss: 0.02575 | Running loss: 0.04303\n",
            "Epoch: 8 | Iteration: 2214 | Classification loss: 0.00004 | Regression loss: 0.02109 | Running loss: 0.04304\n",
            "Epoch: 8 | Iteration: 2215 | Classification loss: 0.00022 | Regression loss: 0.01231 | Running loss: 0.04302\n",
            "Epoch: 8 | Iteration: 2216 | Classification loss: 0.00055 | Regression loss: 0.02854 | Running loss: 0.04293\n",
            "Epoch: 8 | Iteration: 2217 | Classification loss: 0.00042 | Regression loss: 0.03705 | Running loss: 0.04294\n",
            "Epoch: 8 | Iteration: 2218 | Classification loss: 0.00010 | Regression loss: 0.02974 | Running loss: 0.04284\n",
            "Epoch: 8 | Iteration: 2219 | Classification loss: 0.00024 | Regression loss: 0.02580 | Running loss: 0.04284\n",
            "Epoch: 8 | Iteration: 2220 | Classification loss: 0.00020 | Regression loss: 0.01887 | Running loss: 0.04284\n",
            "Epoch: 8 | Iteration: 2221 | Classification loss: 0.00075 | Regression loss: 0.04667 | Running loss: 0.04291\n",
            "Epoch: 8 | Iteration: 2222 | Classification loss: 0.00012 | Regression loss: 0.02319 | Running loss: 0.04286\n",
            "Epoch: 8 | Iteration: 2223 | Classification loss: 0.00006 | Regression loss: 0.02188 | Running loss: 0.04285\n",
            "Epoch: 8 | Iteration: 2224 | Classification loss: 0.00001 | Regression loss: 0.01977 | Running loss: 0.04221\n",
            "Epoch: 8 | Iteration: 2225 | Classification loss: 0.00020 | Regression loss: 0.01368 | Running loss: 0.04221\n",
            "Epoch: 8 | Iteration: 2226 | Classification loss: 0.00024 | Regression loss: 0.02277 | Running loss: 0.04219\n",
            "Epoch: 8 | Iteration: 2227 | Classification loss: 0.00273 | Regression loss: 0.04656 | Running loss: 0.04226\n",
            "Epoch: 8 | Iteration: 2228 | Classification loss: 0.00026 | Regression loss: 0.02292 | Running loss: 0.04220\n",
            "Epoch: 8 | Iteration: 2229 | Classification loss: 0.00012 | Regression loss: 0.03609 | Running loss: 0.04214\n",
            "Epoch: 8 | Iteration: 2230 | Classification loss: 0.00154 | Regression loss: 0.08133 | Running loss: 0.04225\n",
            "Epoch: 8 | Iteration: 2231 | Classification loss: 0.00023 | Regression loss: 0.04262 | Running loss: 0.04226\n",
            "Epoch: 8 | Iteration: 2232 | Classification loss: 0.00132 | Regression loss: 0.08054 | Running loss: 0.04237\n",
            "Epoch: 8 | Iteration: 2233 | Classification loss: 0.00004 | Regression loss: 0.02723 | Running loss: 0.04237\n",
            "Epoch: 8 | Iteration: 2234 | Classification loss: 0.00004 | Regression loss: 0.02807 | Running loss: 0.04233\n",
            "Epoch: 8 | Iteration: 2235 | Classification loss: 0.00056 | Regression loss: 0.04113 | Running loss: 0.04236\n",
            "Epoch: 8 | Iteration: 2236 | Classification loss: 0.00000 | Regression loss: 0.02372 | Running loss: 0.04233\n",
            "Epoch: 8 | Iteration: 2237 | Classification loss: 0.00001 | Regression loss: 0.01816 | Running loss: 0.04234\n",
            "Epoch: 8 | Iteration: 2238 | Classification loss: 0.00006 | Regression loss: 0.04020 | Running loss: 0.04241\n",
            "Epoch: 8 | Iteration: 2239 | Classification loss: 0.00015 | Regression loss: 0.01800 | Running loss: 0.04226\n",
            "Epoch: 8 | Iteration: 2240 | Classification loss: 0.00009 | Regression loss: 0.02276 | Running loss: 0.04223\n",
            "Epoch: 8 | Iteration: 2241 | Classification loss: 0.00008 | Regression loss: 0.02149 | Running loss: 0.04221\n",
            "Epoch: 8 | Iteration: 2242 | Classification loss: 0.00003 | Regression loss: 0.02022 | Running loss: 0.04165\n",
            "Epoch: 8 | Iteration: 2243 | Classification loss: 0.00003 | Regression loss: 0.01478 | Running loss: 0.04157\n",
            "Epoch: 8 | Iteration: 2244 | Classification loss: 0.00079 | Regression loss: 0.02611 | Running loss: 0.04157\n",
            "Epoch: 8 | Iteration: 2245 | Classification loss: 0.00425 | Regression loss: 0.05451 | Running loss: 0.04153\n",
            "Epoch: 8 | Iteration: 2246 | Classification loss: 0.00004 | Regression loss: 0.01215 | Running loss: 0.04148\n",
            "Epoch: 8 | Iteration: 2247 | Classification loss: 0.00048 | Regression loss: 0.02147 | Running loss: 0.04146\n",
            "Epoch: 8 | Iteration: 2248 | Classification loss: 0.00003 | Regression loss: 0.02217 | Running loss: 0.04145\n",
            "Epoch: 8 | Iteration: 2249 | Classification loss: 0.00029 | Regression loss: 0.03604 | Running loss: 0.04149\n",
            "Epoch: 8 | Iteration: 2250 | Classification loss: 0.00002 | Regression loss: 0.01678 | Running loss: 0.04147\n",
            "Epoch: 8 | Iteration: 2251 | Classification loss: 0.00028 | Regression loss: 0.02056 | Running loss: 0.04145\n",
            "Epoch: 8 | Iteration: 2252 | Classification loss: 0.00002 | Regression loss: 0.04145 | Running loss: 0.04147\n",
            "Epoch: 8 | Iteration: 2253 | Classification loss: 0.00092 | Regression loss: 0.05842 | Running loss: 0.04155\n",
            "Epoch: 8 | Iteration: 2254 | Classification loss: 0.00067 | Regression loss: 0.03835 | Running loss: 0.04155\n",
            "Epoch: 8 | Iteration: 2255 | Classification loss: 0.00008 | Regression loss: 0.03041 | Running loss: 0.04141\n",
            "Epoch: 8 | Iteration: 2256 | Classification loss: 0.00002 | Regression loss: 0.02069 | Running loss: 0.04142\n",
            "Epoch: 8 | Iteration: 2257 | Classification loss: 0.00001 | Regression loss: 0.02175 | Running loss: 0.04138\n",
            "Epoch: 8 | Iteration: 2258 | Classification loss: 0.00044 | Regression loss: 0.03721 | Running loss: 0.04140\n",
            "Epoch: 8 | Iteration: 2259 | Classification loss: 0.00021 | Regression loss: 0.01964 | Running loss: 0.04135\n",
            "Epoch: 8 | Iteration: 2260 | Classification loss: 0.00008 | Regression loss: 0.02162 | Running loss: 0.04130\n",
            "Epoch: 8 | Iteration: 2261 | Classification loss: 0.00004 | Regression loss: 0.01132 | Running loss: 0.04072\n",
            "Epoch: 8 | Iteration: 2262 | Classification loss: 0.00002 | Regression loss: 0.02955 | Running loss: 0.04072\n",
            "Epoch: 8 | Iteration: 2263 | Classification loss: 0.00005 | Regression loss: 0.01974 | Running loss: 0.04070\n",
            "Epoch: 8 | Iteration: 2264 | Classification loss: 0.00008 | Regression loss: 0.02506 | Running loss: 0.04053\n",
            "Epoch: 8 | Iteration: 2265 | Classification loss: 0.00048 | Regression loss: 0.02349 | Running loss: 0.04049\n",
            "Epoch: 8 | Iteration: 2266 | Classification loss: 0.00009 | Regression loss: 0.04223 | Running loss: 0.04050\n",
            "Epoch: 8 | Iteration: 2267 | Classification loss: 0.00004 | Regression loss: 0.02434 | Running loss: 0.04048\n",
            "Epoch: 8 | Iteration: 2268 | Classification loss: 0.01912 | Regression loss: 0.02992 | Running loss: 0.04055\n",
            "Epoch: 8 | Iteration: 2269 | Classification loss: 0.00006 | Regression loss: 0.02171 | Running loss: 0.04056\n",
            "Epoch: 8 | Iteration: 2270 | Classification loss: 0.00005 | Regression loss: 0.03140 | Running loss: 0.04053\n",
            "Epoch: 8 | Iteration: 2271 | Classification loss: 0.57199 | Regression loss: 0.28256 | Running loss: 0.04215\n",
            "Epoch: 8 | Iteration: 2272 | Classification loss: 0.00059 | Regression loss: 0.03004 | Running loss: 0.04214\n",
            "Epoch: 8 | Iteration: 2273 | Classification loss: 0.00059 | Regression loss: 0.03569 | Running loss: 0.04006\n",
            "Epoch: 8 | Iteration: 2274 | Classification loss: 0.00043 | Regression loss: 0.04250 | Running loss: 0.04012\n",
            "Epoch: 8 | Iteration: 2275 | Classification loss: 0.00015 | Regression loss: 0.01867 | Running loss: 0.04006\n",
            "Epoch: 8 | Iteration: 2276 | Classification loss: 0.00009 | Regression loss: 0.03440 | Running loss: 0.04008\n",
            "Epoch: 8 | Iteration: 2277 | Classification loss: 0.00215 | Regression loss: 0.05288 | Running loss: 0.04015\n",
            "Epoch: 8 | Iteration: 2278 | Classification loss: 0.00046 | Regression loss: 0.02965 | Running loss: 0.04018\n",
            "Epoch: 8 | Iteration: 2279 | Classification loss: 0.00026 | Regression loss: 0.02249 | Running loss: 0.03873\n",
            "Epoch: 8 | Iteration: 2280 | Classification loss: 0.00017 | Regression loss: 0.03051 | Running loss: 0.03871\n",
            "Epoch: 8 | Iteration: 2281 | Classification loss: 0.00029 | Regression loss: 0.02079 | Running loss: 0.03866\n",
            "Epoch: 8 | Iteration: 2282 | Classification loss: 0.03077 | Regression loss: 0.07505 | Running loss: 0.03880\n",
            "Epoch: 8 | Iteration: 2283 | Classification loss: 1.05679 | Regression loss: 0.01363 | Running loss: 0.04078\n",
            "Epoch: 8 | Iteration: 2284 | Classification loss: 0.00079 | Regression loss: 0.06168 | Running loss: 0.04083\n",
            "Epoch: 8 | Iteration: 2285 | Classification loss: 0.01409 | Regression loss: 0.03167 | Running loss: 0.04086\n",
            "Epoch: 8 | Iteration: 2286 | Classification loss: 0.00010 | Regression loss: 0.03780 | Running loss: 0.04067\n",
            "Epoch: 8 | Iteration: 2287 | Classification loss: 0.00001 | Regression loss: 0.02071 | Running loss: 0.04067\n",
            "Epoch: 8 | Iteration: 2288 | Classification loss: 0.00009 | Regression loss: 0.02022 | Running loss: 0.04062\n",
            "Epoch: 8 | Iteration: 2289 | Classification loss: 0.00011 | Regression loss: 0.01411 | Running loss: 0.04056\n",
            "Epoch: 8 | Iteration: 2290 | Classification loss: 0.00022 | Regression loss: 0.02050 | Running loss: 0.04052\n",
            "Epoch: 8 | Iteration: 2291 | Classification loss: 0.00118 | Regression loss: 0.01840 | Running loss: 0.04049\n",
            "Epoch: 8 | Iteration: 2292 | Classification loss: 0.00021 | Regression loss: 0.04554 | Running loss: 0.04052\n",
            "Epoch: 8 | Iteration: 2293 | Classification loss: 0.00012 | Regression loss: 0.02810 | Running loss: 0.04053\n",
            "Epoch: 8 | Iteration: 2294 | Classification loss: 0.00424 | Regression loss: 0.02678 | Running loss: 0.04055\n",
            "Epoch: 8 | Iteration: 2295 | Classification loss: 0.00069 | Regression loss: 0.02547 | Running loss: 0.04056\n",
            "Epoch: 8 | Iteration: 2296 | Classification loss: 0.00506 | Regression loss: 0.05565 | Running loss: 0.04064\n",
            "Epoch: 8 | Iteration: 2297 | Classification loss: 0.01506 | Regression loss: 0.02377 | Running loss: 0.04069\n",
            "Epoch: 8 | Iteration: 2298 | Classification loss: 0.00351 | Regression loss: 0.01439 | Running loss: 0.04021\n",
            "Epoch: 8 | Iteration: 2299 | Classification loss: 0.00086 | Regression loss: 0.01398 | Running loss: 0.04020\n",
            "Epoch: 8 | Iteration: 2300 | Classification loss: 0.00022 | Regression loss: 0.04223 | Running loss: 0.04019\n",
            "Epoch: 8 | Iteration: 2301 | Classification loss: 0.00024 | Regression loss: 0.02436 | Running loss: 0.04020\n",
            "Epoch: 8 | Iteration: 2302 | Classification loss: 0.00041 | Regression loss: 0.03980 | Running loss: 0.04025\n",
            "Epoch: 8 | Iteration: 2303 | Classification loss: 0.00031 | Regression loss: 0.01757 | Running loss: 0.04023\n",
            "Epoch: 8 | Iteration: 2304 | Classification loss: 0.00093 | Regression loss: 0.04000 | Running loss: 0.04028\n",
            "Epoch: 8 | Iteration: 2305 | Classification loss: 0.00091 | Regression loss: 0.03048 | Running loss: 0.04031\n",
            "Epoch: 8 | Iteration: 2306 | Classification loss: 0.02390 | Regression loss: 0.05655 | Running loss: 0.04037\n",
            "Epoch: 8 | Iteration: 2307 | Classification loss: 0.00370 | Regression loss: 0.05704 | Running loss: 0.04045\n",
            "Epoch: 8 | Iteration: 2308 | Classification loss: 0.00131 | Regression loss: 0.04691 | Running loss: 0.04050\n",
            "Epoch: 8 | Iteration: 2309 | Classification loss: 0.00035 | Regression loss: 0.00805 | Running loss: 0.04048\n",
            "Epoch: 8 | Iteration: 2310 | Classification loss: 0.00008 | Regression loss: 0.01028 | Running loss: 0.04045\n",
            "Epoch: 8 | Iteration: 2311 | Classification loss: 0.13571 | Regression loss: 0.22820 | Running loss: 0.04114\n",
            "Epoch: 8 | Iteration: 2312 | Classification loss: 0.00024 | Regression loss: 0.02881 | Running loss: 0.04114\n",
            "Epoch: 8 | Iteration: 2313 | Classification loss: 0.03980 | Regression loss: 0.08387 | Running loss: 0.04135\n",
            "Epoch: 8 | Iteration: 2314 | Classification loss: 0.00081 | Regression loss: 0.02157 | Running loss: 0.04133\n",
            "Epoch: 8 | Iteration: 2315 | Classification loss: 0.00019 | Regression loss: 0.01911 | Running loss: 0.04123\n",
            "Epoch: 8 | Iteration: 2316 | Classification loss: 0.00041 | Regression loss: 0.02208 | Running loss: 0.04117\n",
            "Epoch: 8 | Iteration: 2317 | Classification loss: 0.00013 | Regression loss: 0.01585 | Running loss: 0.04114\n",
            "Epoch: 8 | Iteration: 2318 | Classification loss: 0.00007 | Regression loss: 0.01860 | Running loss: 0.04116\n",
            "Epoch: 8 | Iteration: 2319 | Classification loss: 0.00002 | Regression loss: 0.03793 | Running loss: 0.04120\n",
            "Epoch: 8 | Iteration: 2320 | Classification loss: 0.00039 | Regression loss: 0.03166 | Running loss: 0.04116\n",
            "Epoch: 8 | Iteration: 2321 | Classification loss: 0.00037 | Regression loss: 0.04393 | Running loss: 0.04121\n",
            "Epoch: 8 | Iteration: 2322 | Classification loss: 0.00044 | Regression loss: 0.01723 | Running loss: 0.04118\n",
            "Epoch: 8 | Iteration: 2323 | Classification loss: 0.00038 | Regression loss: 0.03551 | Running loss: 0.04122\n",
            "Epoch: 8 | Iteration: 2324 | Classification loss: 0.00099 | Regression loss: 0.02655 | Running loss: 0.04121\n",
            "Epoch: 8 | Iteration: 2325 | Classification loss: 0.00020 | Regression loss: 0.03599 | Running loss: 0.04123\n",
            "Epoch: 8 | Iteration: 2326 | Classification loss: 0.00033 | Regression loss: 0.02462 | Running loss: 0.04123\n",
            "Epoch: 8 | Iteration: 2327 | Classification loss: 0.00072 | Regression loss: 0.03746 | Running loss: 0.04122\n",
            "Epoch: 8 | Iteration: 2328 | Classification loss: 0.00035 | Regression loss: 0.01605 | Running loss: 0.04119\n",
            "Epoch: 8 | Iteration: 2329 | Classification loss: 0.00003 | Regression loss: 0.02339 | Running loss: 0.04119\n",
            "Epoch: 8 | Iteration: 2330 | Classification loss: 0.00070 | Regression loss: 0.08874 | Running loss: 0.04132\n",
            "Epoch: 8 | Iteration: 2331 | Classification loss: 0.00029 | Regression loss: 0.01995 | Running loss: 0.04130\n",
            "Epoch: 8 | Iteration: 2332 | Classification loss: 0.00011 | Regression loss: 0.01210 | Running loss: 0.04129\n",
            "Epoch: 8 | Iteration: 2333 | Classification loss: 0.00464 | Regression loss: 0.04220 | Running loss: 0.04129\n",
            "Epoch: 8 | Iteration: 2334 | Classification loss: 0.00392 | Regression loss: 0.02567 | Running loss: 0.04130\n",
            "Epoch: 8 | Iteration: 2335 | Classification loss: 0.00021 | Regression loss: 0.04486 | Running loss: 0.04133\n",
            "Epoch: 8 | Iteration: 2336 | Classification loss: 0.00492 | Regression loss: 0.04724 | Running loss: 0.04129\n",
            "Epoch: 8 | Iteration: 2337 | Classification loss: 0.00554 | Regression loss: 0.03409 | Running loss: 0.04126\n",
            "Epoch: 8 | Iteration: 2338 | Classification loss: 0.00014 | Regression loss: 0.02422 | Running loss: 0.04125\n",
            "Epoch: 8 | Iteration: 2339 | Classification loss: 0.01384 | Regression loss: 0.08001 | Running loss: 0.04137\n",
            "Epoch: 8 | Iteration: 2340 | Classification loss: 0.00147 | Regression loss: 0.05169 | Running loss: 0.04135\n",
            "Epoch: 8 | Iteration: 2341 | Classification loss: 0.00047 | Regression loss: 0.02192 | Running loss: 0.04131\n",
            "Epoch: 8 | Iteration: 2342 | Classification loss: 0.00004 | Regression loss: 0.01875 | Running loss: 0.04129\n",
            "Epoch: 8 | Iteration: 2343 | Classification loss: 0.00066 | Regression loss: 0.03297 | Running loss: 0.04116\n",
            "Epoch: 8 | Iteration: 2344 | Classification loss: 0.00023 | Regression loss: 0.01544 | Running loss: 0.04114\n",
            "Epoch: 8 | Iteration: 2345 | Classification loss: 0.00003 | Regression loss: 0.01984 | Running loss: 0.04114\n",
            "Epoch: 8 | Iteration: 2346 | Classification loss: 0.00005 | Regression loss: 0.02724 | Running loss: 0.04112\n",
            "Epoch: 8 | Iteration: 2347 | Classification loss: 0.02450 | Regression loss: 0.05809 | Running loss: 0.04112\n",
            "Epoch: 8 | Iteration: 2348 | Classification loss: 0.00019 | Regression loss: 0.02867 | Running loss: 0.04108\n",
            "Epoch: 8 | Iteration: 2349 | Classification loss: 0.00025 | Regression loss: 0.01987 | Running loss: 0.04101\n",
            "Epoch: 8 | Iteration: 2350 | Classification loss: 0.00027 | Regression loss: 0.03079 | Running loss: 0.04102\n",
            "Epoch: 8 | Iteration: 2351 | Classification loss: 0.00214 | Regression loss: 0.05621 | Running loss: 0.04104\n",
            "Epoch: 8 | Iteration: 2352 | Classification loss: 0.00092 | Regression loss: 0.01661 | Running loss: 0.04102\n",
            "Epoch: 8 | Iteration: 2353 | Classification loss: 0.02561 | Regression loss: 0.18850 | Running loss: 0.04141\n",
            "Epoch: 8 | Iteration: 2354 | Classification loss: 0.00390 | Regression loss: 0.02687 | Running loss: 0.04143\n",
            "Epoch: 8 | Iteration: 2355 | Classification loss: 0.00120 | Regression loss: 0.01837 | Running loss: 0.04140\n",
            "Epoch: 8 | Iteration: 2356 | Classification loss: 0.00750 | Regression loss: 0.01422 | Running loss: 0.04140\n",
            "Epoch: 8 | Iteration: 2357 | Classification loss: 0.00019 | Regression loss: 0.01290 | Running loss: 0.04138\n",
            "Epoch: 8 | Iteration: 2358 | Classification loss: 0.00004 | Regression loss: 0.03363 | Running loss: 0.04141\n",
            "Epoch: 8 | Iteration: 2359 | Classification loss: 0.00175 | Regression loss: 0.04788 | Running loss: 0.04132\n",
            "Epoch: 8 | Iteration: 2360 | Classification loss: 0.00017 | Regression loss: 0.07737 | Running loss: 0.04142\n",
            "Epoch: 8 | Iteration: 2361 | Classification loss: 0.00027 | Regression loss: 0.02549 | Running loss: 0.04144\n",
            "Epoch: 8 | Iteration: 2362 | Classification loss: 0.00135 | Regression loss: 0.03261 | Running loss: 0.04147\n",
            "Epoch: 8 | Iteration: 2363 | Classification loss: 0.00011 | Regression loss: 0.01744 | Running loss: 0.04146\n",
            "Epoch: 8 | Iteration: 2364 | Classification loss: 0.00014 | Regression loss: 0.04652 | Running loss: 0.04152\n",
            "Epoch: 8 | Iteration: 2365 | Classification loss: 0.00039 | Regression loss: 0.02302 | Running loss: 0.04154\n",
            "Epoch: 8 | Iteration: 2366 | Classification loss: 0.00517 | Regression loss: 0.01829 | Running loss: 0.04154\n",
            "Epoch: 8 | Iteration: 2367 | Classification loss: 0.00073 | Regression loss: 0.03040 | Running loss: 0.04154\n",
            "Epoch: 8 | Iteration: 2368 | Classification loss: 0.00024 | Regression loss: 0.05997 | Running loss: 0.04160\n",
            "Epoch: 8 | Iteration: 2369 | Classification loss: 0.00113 | Regression loss: 0.04957 | Running loss: 0.04166\n",
            "Epoch: 8 | Iteration: 2370 | Classification loss: 0.01122 | Regression loss: 0.03111 | Running loss: 0.04166\n",
            "Epoch: 8 | Iteration: 2371 | Classification loss: 0.00045 | Regression loss: 0.02182 | Running loss: 0.04003\n",
            "Epoch: 8 | Iteration: 2372 | Classification loss: 0.00005 | Regression loss: 0.04231 | Running loss: 0.04006\n",
            "Epoch: 8 | Iteration: 2373 | Classification loss: 0.00009 | Regression loss: 0.05050 | Running loss: 0.04007\n",
            "Epoch: 8 | Iteration: 2374 | Classification loss: 0.00009 | Regression loss: 0.02496 | Running loss: 0.04003\n",
            "Epoch: 8 | Iteration: 2375 | Classification loss: 0.00109 | Regression loss: 0.02100 | Running loss: 0.04003\n",
            "Epoch: 8 | Iteration: 2376 | Classification loss: 0.00010 | Regression loss: 0.00994 | Running loss: 0.03992\n",
            "Epoch: 8 | Iteration: 2377 | Classification loss: 0.00007 | Regression loss: 0.05308 | Running loss: 0.03995\n",
            "Epoch: 8 | Iteration: 2378 | Classification loss: 0.00279 | Regression loss: 0.04498 | Running loss: 0.03999\n",
            "Epoch: 8 | Iteration: 2379 | Classification loss: 0.01457 | Regression loss: 0.03417 | Running loss: 0.03996\n",
            "Epoch: 8 | Iteration: 2380 | Classification loss: 0.00017 | Regression loss: 0.02536 | Running loss: 0.03996\n",
            "Epoch: 8 | Iteration: 2381 | Classification loss: 0.00051 | Regression loss: 0.03832 | Running loss: 0.04000\n",
            "Epoch: 8 | Iteration: 2382 | Classification loss: 0.00073 | Regression loss: 0.01642 | Running loss: 0.03999\n",
            "Epoch: 8 | Iteration: 2383 | Classification loss: 0.00085 | Regression loss: 0.02783 | Running loss: 0.03996\n",
            "Epoch: 8 | Iteration: 2384 | Classification loss: 0.00079 | Regression loss: 0.01477 | Running loss: 0.03995\n",
            "Epoch: 8 | Iteration: 2385 | Classification loss: 0.00008 | Regression loss: 0.02749 | Running loss: 0.03994\n",
            "Epoch: 8 | Iteration: 2386 | Classification loss: 0.00017 | Regression loss: 0.01900 | Running loss: 0.03985\n",
            "Epoch: 8 | Iteration: 2387 | Classification loss: 0.00049 | Regression loss: 0.03788 | Running loss: 0.03978\n",
            "Epoch: 8 | Iteration: 2388 | Classification loss: 0.00068 | Regression loss: 0.06278 | Running loss: 0.03978\n",
            "Epoch: 8 | Iteration: 2389 | Classification loss: 0.00014 | Regression loss: 0.01941 | Running loss: 0.03889\n",
            "Epoch: 8 | Iteration: 2390 | Classification loss: 0.00120 | Regression loss: 0.02496 | Running loss: 0.03891\n",
            "Epoch: 8 | Iteration: 2391 | Classification loss: 0.00004 | Regression loss: 0.02802 | Running loss: 0.03889\n",
            "Epoch: 8 | Iteration: 2392 | Classification loss: 0.00030 | Regression loss: 0.04094 | Running loss: 0.03892\n",
            "Epoch: 8 | Iteration: 2393 | Classification loss: 0.00613 | Regression loss: 0.03259 | Running loss: 0.03896\n",
            "Epoch: 8 | Iteration: 2394 | Classification loss: 0.01529 | Regression loss: 0.02239 | Running loss: 0.03883\n",
            "Epoch: 8 | Iteration: 2395 | Classification loss: 0.01373 | Regression loss: 0.02799 | Running loss: 0.03888\n",
            "Epoch: 8 | Iteration: 2396 | Classification loss: 0.01133 | Regression loss: 0.04425 | Running loss: 0.03897\n",
            "Epoch: 8 | Iteration: 2397 | Classification loss: 0.00041 | Regression loss: 0.05532 | Running loss: 0.03905\n",
            "Epoch: 8 | Iteration: 2398 | Classification loss: 0.00004 | Regression loss: 0.02500 | Running loss: 0.03908\n",
            "Epoch: 8 | Iteration: 2399 | Classification loss: 0.00005 | Regression loss: 0.02458 | Running loss: 0.03912\n",
            "Epoch: 8 | Iteration: 2400 | Classification loss: 0.00316 | Regression loss: 0.02354 | Running loss: 0.03883\n",
            "Epoch: 8 | Iteration: 2401 | Classification loss: 0.00056 | Regression loss: 0.01376 | Running loss: 0.03880\n",
            "Epoch: 8 | Iteration: 2402 | Classification loss: 0.00085 | Regression loss: 0.01120 | Running loss: 0.03876\n",
            "Epoch: 8 | Iteration: 2403 | Classification loss: 0.00005 | Regression loss: 0.01888 | Running loss: 0.03876\n",
            "Epoch: 8 | Iteration: 2404 | Classification loss: 0.00103 | Regression loss: 0.04658 | Running loss: 0.03879\n",
            "Epoch: 8 | Iteration: 2405 | Classification loss: 0.00008 | Regression loss: 0.02318 | Running loss: 0.03881\n",
            "Epoch: 8 | Iteration: 2406 | Classification loss: 0.00015 | Regression loss: 0.02709 | Running loss: 0.03883\n",
            "Epoch: 8 | Iteration: 2407 | Classification loss: 0.00056 | Regression loss: 0.02607 | Running loss: 0.03884\n",
            "Epoch: 8 | Iteration: 2408 | Classification loss: 0.00030 | Regression loss: 0.03413 | Running loss: 0.03888\n",
            "Epoch: 8 | Iteration: 2409 | Classification loss: 0.00085 | Regression loss: 0.02597 | Running loss: 0.03884\n",
            "Epoch: 8 | Iteration: 2410 | Classification loss: 0.00044 | Regression loss: 0.05114 | Running loss: 0.03885\n",
            "Epoch: 8 | Iteration: 2411 | Classification loss: 0.00076 | Regression loss: 0.01094 | Running loss: 0.03883\n",
            "Epoch: 8 | Iteration: 2412 | Classification loss: 0.00005 | Regression loss: 0.01335 | Running loss: 0.03877\n",
            "Epoch: 8 | Iteration: 2413 | Classification loss: 0.00015 | Regression loss: 0.01310 | Running loss: 0.03870\n",
            "Epoch: 8 | Iteration: 2414 | Classification loss: 0.06091 | Regression loss: 0.20888 | Running loss: 0.03909\n",
            "Epoch: 8 | Iteration: 2415 | Classification loss: 0.00042 | Regression loss: 0.02070 | Running loss: 0.03911\n",
            "Epoch: 8 | Iteration: 2416 | Classification loss: 0.00324 | Regression loss: 0.01058 | Running loss: 0.03909\n",
            "Epoch: 8 | Iteration: 2417 | Classification loss: 0.00060 | Regression loss: 0.01962 | Running loss: 0.03910\n",
            "Epoch: 8 | Iteration: 2418 | Classification loss: 0.00060 | Regression loss: 0.01660 | Running loss: 0.03908\n",
            "Epoch: 8 | Iteration: 2419 | Classification loss: 0.00285 | Regression loss: 0.03542 | Running loss: 0.03910\n",
            "Epoch: 8 | Iteration: 2420 | Classification loss: 0.00009 | Regression loss: 0.00912 | Running loss: 0.03906\n",
            "Epoch: 8 | Iteration: 2421 | Classification loss: 0.00007 | Regression loss: 0.01790 | Running loss: 0.03903\n",
            "Epoch: 8 | Iteration: 2422 | Classification loss: 0.00005 | Regression loss: 0.01384 | Running loss: 0.03900\n",
            "Epoch: 8 | Iteration: 2423 | Classification loss: 0.00026 | Regression loss: 0.01319 | Running loss: 0.03897\n",
            "Epoch: 8 | Iteration: 2424 | Classification loss: 0.00003 | Regression loss: 0.03002 | Running loss: 0.03899\n",
            "Epoch: 8 | Iteration: 2425 | Classification loss: 0.00010 | Regression loss: 0.01702 | Running loss: 0.03895\n",
            "Epoch: 8 | Iteration: 2426 | Classification loss: 0.00001 | Regression loss: 0.01597 | Running loss: 0.03890\n",
            "Epoch: 8 | Iteration: 2427 | Classification loss: 0.00048 | Regression loss: 0.03590 | Running loss: 0.03887\n",
            "Epoch: 8 | Iteration: 2428 | Classification loss: 0.00039 | Regression loss: 0.01513 | Running loss: 0.03874\n",
            "Epoch: 8 | Iteration: 2429 | Classification loss: 0.00005 | Regression loss: 0.03493 | Running loss: 0.03877\n",
            "Epoch: 8 | Iteration: 2430 | Classification loss: 0.00009 | Regression loss: 0.01399 | Running loss: 0.03878\n",
            "Epoch: 8 | Iteration: 2431 | Classification loss: 0.00180 | Regression loss: 0.02647 | Running loss: 0.03878\n",
            "Epoch: 8 | Iteration: 2432 | Classification loss: 0.00018 | Regression loss: 0.02219 | Running loss: 0.03866\n",
            "Epoch: 8 | Iteration: 2433 | Classification loss: 0.00088 | Regression loss: 0.02312 | Running loss: 0.03865\n",
            "Epoch: 8 | Iteration: 2434 | Classification loss: 0.00087 | Regression loss: 0.02479 | Running loss: 0.03858\n",
            "Epoch: 8 | Iteration: 2435 | Classification loss: 0.00949 | Regression loss: 0.01293 | Running loss: 0.03851\n",
            "Epoch: 8 | Iteration: 2436 | Classification loss: 0.00004 | Regression loss: 0.03961 | Running loss: 0.03855\n",
            "Epoch: 8 | Iteration: 2437 | Classification loss: 0.00016 | Regression loss: 0.01902 | Running loss: 0.03850\n",
            "Epoch: 8 | Iteration: 2438 | Classification loss: 0.00081 | Regression loss: 0.01507 | Running loss: 0.03847\n",
            "Epoch: 8 | Iteration: 2439 | Classification loss: 0.00021 | Regression loss: 0.01314 | Running loss: 0.03843\n",
            "Epoch: 8 | Iteration: 2440 | Classification loss: 0.00093 | Regression loss: 0.12309 | Running loss: 0.03866\n",
            "Epoch: 8 | Iteration: 2441 | Classification loss: 0.00009 | Regression loss: 0.03179 | Running loss: 0.03864\n",
            "Epoch: 8 | Iteration: 2442 | Classification loss: 0.00024 | Regression loss: 0.01722 | Running loss: 0.03865\n",
            "Epoch: 8 | Iteration: 2443 | Classification loss: 0.00076 | Regression loss: 0.03432 | Running loss: 0.03863\n",
            "Epoch: 8 | Iteration: 2444 | Classification loss: 0.00050 | Regression loss: 0.01775 | Running loss: 0.03858\n",
            "Epoch: 8 | Iteration: 2445 | Classification loss: 0.00215 | Regression loss: 0.07483 | Running loss: 0.03866\n",
            "Epoch: 8 | Iteration: 2446 | Classification loss: 0.00088 | Regression loss: 0.02209 | Running loss: 0.03865\n",
            "Epoch: 8 | Iteration: 2447 | Classification loss: 0.00044 | Regression loss: 0.03966 | Running loss: 0.03870\n",
            "Epoch: 8 | Iteration: 2448 | Classification loss: 0.00026 | Regression loss: 0.02577 | Running loss: 0.03868\n",
            "Epoch: 8 | Iteration: 2449 | Classification loss: 0.00022 | Regression loss: 0.05305 | Running loss: 0.03875\n",
            "Epoch: 8 | Iteration: 2450 | Classification loss: 0.00011 | Regression loss: 0.02630 | Running loss: 0.03876\n",
            "Epoch: 8 | Iteration: 2451 | Classification loss: 0.00019 | Regression loss: 0.02883 | Running loss: 0.03878\n",
            "Epoch: 8 | Iteration: 2452 | Classification loss: 0.00377 | Regression loss: 0.03563 | Running loss: 0.03882\n",
            "Epoch: 8 | Iteration: 2453 | Classification loss: 0.00017 | Regression loss: 0.01817 | Running loss: 0.03877\n",
            "Epoch: 8 | Iteration: 2454 | Classification loss: 0.00061 | Regression loss: 0.01515 | Running loss: 0.03870\n",
            "Epoch: 8 | Iteration: 2455 | Classification loss: 0.00021 | Regression loss: 0.03966 | Running loss: 0.03811\n",
            "Epoch: 8 | Iteration: 2456 | Classification loss: 0.00020 | Regression loss: 0.02270 | Running loss: 0.03808\n",
            "Epoch: 8 | Iteration: 2457 | Classification loss: 0.00024 | Regression loss: 0.02326 | Running loss: 0.03804\n",
            "Epoch: 8 | Iteration: 2458 | Classification loss: 0.00034 | Regression loss: 0.05386 | Running loss: 0.03812\n",
            "Epoch: 8 | Iteration: 2459 | Classification loss: 0.00028 | Regression loss: 0.02051 | Running loss: 0.03814\n",
            "Epoch: 8 | Iteration: 2460 | Classification loss: 0.00003 | Regression loss: 0.02386 | Running loss: 0.03790\n",
            "Epoch: 8 | Iteration: 2461 | Classification loss: 0.00013 | Regression loss: 0.02395 | Running loss: 0.03789\n",
            "Epoch: 8 | Iteration: 2462 | Classification loss: 0.00013 | Regression loss: 0.00802 | Running loss: 0.03787\n",
            "Epoch: 8 | Iteration: 2463 | Classification loss: 0.00050 | Regression loss: 0.02498 | Running loss: 0.03784\n",
            "Epoch: 8 | Iteration: 2464 | Classification loss: 0.02050 | Regression loss: 0.02310 | Running loss: 0.03790\n",
            "Epoch: 8 | Iteration: 2465 | Classification loss: 0.00059 | Regression loss: 0.02739 | Running loss: 0.03792\n",
            "Epoch: 8 | Iteration: 2466 | Classification loss: 0.00054 | Regression loss: 0.02024 | Running loss: 0.03787\n",
            "Epoch: 8 | Iteration: 2467 | Classification loss: 0.00007 | Regression loss: 0.02852 | Running loss: 0.03790\n",
            "Epoch: 8 | Iteration: 2468 | Classification loss: 0.00120 | Regression loss: 0.02822 | Running loss: 0.03790\n",
            "Epoch: 8 | Iteration: 2469 | Classification loss: 0.00011 | Regression loss: 0.03916 | Running loss: 0.03786\n",
            "Epoch: 8 | Iteration: 2470 | Classification loss: 0.00025 | Regression loss: 0.04302 | Running loss: 0.03788\n",
            "Epoch: 8 | Iteration: 2471 | Classification loss: 0.00004 | Regression loss: 0.01486 | Running loss: 0.03788\n",
            "Epoch: 8 | Iteration: 2472 | Classification loss: 0.00004 | Regression loss: 0.03573 | Running loss: 0.03788\n",
            "Epoch: 8 | Iteration: 2473 | Classification loss: 0.00069 | Regression loss: 0.01272 | Running loss: 0.03788\n",
            "Epoch: 8 | Iteration: 2474 | Classification loss: 0.00072 | Regression loss: 0.03651 | Running loss: 0.03792\n",
            "Epoch: 8 | Iteration: 2475 | Classification loss: 0.00072 | Regression loss: 0.02020 | Running loss: 0.03793\n",
            "Epoch: 8 | Iteration: 2476 | Classification loss: 0.00146 | Regression loss: 0.02923 | Running loss: 0.03798\n",
            "Epoch: 8 | Iteration: 2477 | Classification loss: 0.00125 | Regression loss: 0.02837 | Running loss: 0.03799\n",
            "Epoch: 8 | Iteration: 2478 | Classification loss: 0.03478 | Regression loss: 0.17493 | Running loss: 0.03840\n",
            "Epoch: 8 | Iteration: 2479 | Classification loss: 0.00009 | Regression loss: 0.04923 | Running loss: 0.03842\n",
            "Epoch: 8 | Iteration: 2480 | Classification loss: 0.00361 | Regression loss: 0.07068 | Running loss: 0.03835\n",
            "Epoch: 8 | Iteration: 2481 | Classification loss: 0.00033 | Regression loss: 0.03661 | Running loss: 0.03830\n",
            "Epoch: 8 | Iteration: 2482 | Classification loss: 0.00016 | Regression loss: 0.03431 | Running loss: 0.03834\n",
            "Epoch: 8 | Iteration: 2483 | Classification loss: 0.00006 | Regression loss: 0.01909 | Running loss: 0.03833\n",
            "Epoch: 8 | Iteration: 2484 | Classification loss: 0.00004 | Regression loss: 0.02004 | Running loss: 0.03832\n",
            "Epoch: 8 | Iteration: 2485 | Classification loss: 0.00019 | Regression loss: 0.03044 | Running loss: 0.03824\n",
            "Epoch: 8 | Iteration: 2486 | Classification loss: 0.00008 | Regression loss: 0.00784 | Running loss: 0.03801\n",
            "Epoch: 8 | Iteration: 2487 | Classification loss: 0.00010 | Regression loss: 0.02238 | Running loss: 0.03798\n",
            "Epoch: 8 | Iteration: 2488 | Classification loss: 0.00190 | Regression loss: 0.04622 | Running loss: 0.03802\n",
            "Epoch: 8 | Iteration: 2489 | Classification loss: 0.00026 | Regression loss: 0.01685 | Running loss: 0.03801\n",
            "Epoch: 8 | Iteration: 2490 | Classification loss: 0.00982 | Regression loss: 0.04824 | Running loss: 0.03810\n",
            "Epoch: 8 | Iteration: 2491 | Classification loss: 0.01080 | Regression loss: 0.03170 | Running loss: 0.03814\n",
            "Epoch: 8 | Iteration: 2492 | Classification loss: 0.00031 | Regression loss: 0.00984 | Running loss: 0.03813\n",
            "Epoch: 8 | Iteration: 2493 | Classification loss: 0.00006 | Regression loss: 0.01234 | Running loss: 0.03811\n",
            "Epoch: 8 | Iteration: 2494 | Classification loss: 0.00057 | Regression loss: 0.02607 | Running loss: 0.03798\n",
            "Epoch: 8 | Iteration: 2495 | Classification loss: 0.00051 | Regression loss: 0.02396 | Running loss: 0.03791\n",
            "Epoch: 8 | Iteration: 2496 | Classification loss: 0.00042 | Regression loss: 0.02195 | Running loss: 0.03791\n",
            "Epoch: 8 | Iteration: 2497 | Classification loss: 0.00114 | Regression loss: 0.03474 | Running loss: 0.03794\n",
            "Epoch: 8 | Iteration: 2498 | Classification loss: 0.00043 | Regression loss: 0.02308 | Running loss: 0.03793\n",
            "Epoch: 8 | Iteration: 2499 | Classification loss: 0.00196 | Regression loss: 0.02761 | Running loss: 0.03795\n",
            "Epoch: 8 | Iteration: 2500 | Classification loss: 0.00034 | Regression loss: 0.02383 | Running loss: 0.03791\n",
            "Epoch: 8 | Iteration: 2501 | Classification loss: 0.00350 | Regression loss: 0.02408 | Running loss: 0.03793\n",
            "Epoch: 8 | Iteration: 2502 | Classification loss: 0.00008 | Regression loss: 0.02071 | Running loss: 0.03792\n",
            "Epoch: 8 | Iteration: 2503 | Classification loss: 0.00002 | Regression loss: 0.02896 | Running loss: 0.03789\n",
            "Epoch: 8 | Iteration: 2504 | Classification loss: 0.00008 | Regression loss: 0.00986 | Running loss: 0.03783\n",
            "Epoch: 8 | Iteration: 2505 | Classification loss: 0.00011 | Regression loss: 0.00794 | Running loss: 0.03781\n",
            "Epoch: 8 | Iteration: 2506 | Classification loss: 0.00067 | Regression loss: 0.03183 | Running loss: 0.03781\n",
            "Epoch: 8 | Iteration: 2507 | Classification loss: 0.05520 | Regression loss: 0.08969 | Running loss: 0.03808\n",
            "Epoch: 8 | Iteration: 2508 | Classification loss: 0.00008 | Regression loss: 0.02607 | Running loss: 0.03806\n",
            "Epoch: 8 | Iteration: 2509 | Classification loss: 0.03112 | Regression loss: 0.27355 | Running loss: 0.03863\n",
            "Epoch: 8 | Iteration: 2510 | Classification loss: 0.00011 | Regression loss: 0.02379 | Running loss: 0.03859\n",
            "Epoch: 8 | Iteration: 2511 | Classification loss: 0.00004 | Regression loss: 0.03070 | Running loss: 0.03861\n",
            "Epoch: 8 | Iteration: 2512 | Classification loss: 0.00016 | Regression loss: 0.02784 | Running loss: 0.03863\n",
            "Epoch: 8 | Iteration: 2513 | Classification loss: 0.00008 | Regression loss: 0.01561 | Running loss: 0.03860\n",
            "Epoch: 8 | Iteration: 2514 | Classification loss: 0.00003 | Regression loss: 0.01477 | Running loss: 0.03858\n",
            "Epoch: 8 | Iteration: 2515 | Classification loss: 0.00074 | Regression loss: 0.02552 | Running loss: 0.03851\n",
            "Epoch: 8 | Iteration: 2516 | Classification loss: 0.00054 | Regression loss: 0.03185 | Running loss: 0.03853\n",
            "Epoch: 8 | Iteration: 2517 | Classification loss: 0.00016 | Regression loss: 0.02578 | Running loss: 0.03852\n",
            "Epoch: 8 | Iteration: 2518 | Classification loss: 0.00007 | Regression loss: 0.02525 | Running loss: 0.03852\n",
            "Epoch: 8 | Iteration: 2519 | Classification loss: 0.00022 | Regression loss: 0.01294 | Running loss: 0.03846\n",
            "Epoch: 8 | Iteration: 2520 | Classification loss: 0.00003 | Regression loss: 0.02317 | Running loss: 0.03843\n",
            "Epoch: 8 | Iteration: 2521 | Classification loss: 0.00081 | Regression loss: 0.05080 | Running loss: 0.03847\n",
            "Epoch: 8 | Iteration: 2522 | Classification loss: 0.02628 | Regression loss: 0.03215 | Running loss: 0.03855\n",
            "Epoch: 8 | Iteration: 2523 | Classification loss: 0.00025 | Regression loss: 0.02000 | Running loss: 0.03852\n",
            "Epoch: 8 | Iteration: 2524 | Classification loss: 0.00016 | Regression loss: 0.02408 | Running loss: 0.03845\n",
            "Epoch: 8 | Iteration: 2525 | Classification loss: 0.00008 | Regression loss: 0.01509 | Running loss: 0.03841\n",
            "Epoch: 8 | Iteration: 2526 | Classification loss: 0.00071 | Regression loss: 0.02135 | Running loss: 0.03841\n",
            "Epoch: 8 | Iteration: 2527 | Classification loss: 0.00191 | Regression loss: 0.03634 | Running loss: 0.03841\n",
            "Epoch: 8 | Iteration: 2528 | Classification loss: 0.00028 | Regression loss: 0.02623 | Running loss: 0.03841\n",
            "Epoch: 8 | Iteration: 2529 | Classification loss: 0.00053 | Regression loss: 0.04806 | Running loss: 0.03841\n",
            "Epoch: 8 | Iteration: 2530 | Classification loss: 0.00006 | Regression loss: 0.02574 | Running loss: 0.03841\n",
            "Epoch: 8 | Iteration: 2531 | Classification loss: 0.00050 | Regression loss: 0.01561 | Running loss: 0.03842\n",
            "Epoch: 8 | Iteration: 2532 | Classification loss: 0.00076 | Regression loss: 0.03688 | Running loss: 0.03831\n",
            "Epoch: 8 | Iteration: 2533 | Classification loss: 0.00016 | Regression loss: 0.02424 | Running loss: 0.03833\n",
            "Epoch: 8 | Iteration: 2534 | Classification loss: 0.00685 | Regression loss: 0.07664 | Running loss: 0.03843\n",
            "Epoch: 8 | Iteration: 2535 | Classification loss: 0.00040 | Regression loss: 0.02433 | Running loss: 0.03843\n",
            "Epoch: 8 | Iteration: 2536 | Classification loss: 0.00006 | Regression loss: 0.04967 | Running loss: 0.03846\n",
            "Epoch: 8 | Iteration: 2537 | Classification loss: 0.00020 | Regression loss: 0.01476 | Running loss: 0.03843\n",
            "Epoch: 8 | Iteration: 2538 | Classification loss: 0.00177 | Regression loss: 0.02972 | Running loss: 0.03845\n",
            "Epoch: 8 | Iteration: 2539 | Classification loss: 0.00057 | Regression loss: 0.03802 | Running loss: 0.03846\n",
            "Epoch: 8 | Iteration: 2540 | Classification loss: 0.00070 | Regression loss: 0.00947 | Running loss: 0.03845\n",
            "Epoch: 8 | Iteration: 2541 | Classification loss: 0.23456 | Regression loss: 0.35400 | Running loss: 0.03958\n",
            "Epoch: 8 | Iteration: 2542 | Classification loss: 0.00019 | Regression loss: 0.02346 | Running loss: 0.03959\n",
            "Epoch: 8 | Iteration: 2543 | Classification loss: 0.00015 | Regression loss: 0.01774 | Running loss: 0.03958\n",
            "Epoch: 8 | Iteration: 2544 | Classification loss: 0.00197 | Regression loss: 0.10612 | Running loss: 0.03972\n",
            "Epoch: 8 | Iteration: 2545 | Classification loss: 0.00096 | Regression loss: 0.04943 | Running loss: 0.03973\n",
            "Epoch: 8 | Iteration: 2546 | Classification loss: 0.00136 | Regression loss: 0.04513 | Running loss: 0.03975\n",
            "Epoch: 8 | Iteration: 2547 | Classification loss: 0.00017 | Regression loss: 0.01859 | Running loss: 0.03969\n",
            "Epoch: 8 | Iteration: 2548 | Classification loss: 0.00387 | Regression loss: 0.09116 | Running loss: 0.03985\n",
            "Epoch: 8 | Iteration: 2549 | Classification loss: 0.00054 | Regression loss: 0.02348 | Running loss: 0.03988\n",
            "Epoch: 8 | Iteration: 2550 | Classification loss: 0.00264 | Regression loss: 0.02757 | Running loss: 0.03989\n",
            "Epoch: 8 | Iteration: 2551 | Classification loss: 0.00049 | Regression loss: 0.02275 | Running loss: 0.03990\n",
            "Epoch: 8 | Iteration: 2552 | Classification loss: 0.00167 | Regression loss: 0.02825 | Running loss: 0.03993\n",
            "Epoch: 8 | Iteration: 2553 | Classification loss: 0.00062 | Regression loss: 0.02343 | Running loss: 0.03995\n",
            "Epoch: 8 | Iteration: 2554 | Classification loss: 0.10304 | Regression loss: 0.07973 | Running loss: 0.04029\n",
            "Epoch: 8 | Iteration: 2555 | Classification loss: 0.00025 | Regression loss: 0.00778 | Running loss: 0.04024\n",
            "Epoch: 8 | Iteration: 2556 | Classification loss: 0.00002 | Regression loss: 0.00769 | Running loss: 0.04023\n",
            "Epoch: 8 | Iteration: 2557 | Classification loss: 0.00011 | Regression loss: 0.01063 | Running loss: 0.04017\n",
            "Epoch: 8 | Iteration: 2558 | Classification loss: 0.00134 | Regression loss: 0.02131 | Running loss: 0.04019\n",
            "Epoch: 8 | Iteration: 2559 | Classification loss: 0.00130 | Regression loss: 0.01537 | Running loss: 0.04016\n",
            "Epoch: 8 | Iteration: 2560 | Classification loss: 0.00150 | Regression loss: 0.01516 | Running loss: 0.04014\n",
            "Epoch: 8 | Iteration: 2561 | Classification loss: 0.00105 | Regression loss: 0.01174 | Running loss: 0.04012\n",
            "Epoch: 8 | Iteration: 2562 | Classification loss: 0.00020 | Regression loss: 0.01921 | Running loss: 0.04005\n",
            "Epoch: 8 | Iteration: 2563 | Classification loss: 0.00097 | Regression loss: 0.03012 | Running loss: 0.04007\n",
            "Epoch: 8 | Iteration: 2564 | Classification loss: 0.00019 | Regression loss: 0.01174 | Running loss: 0.03989\n",
            "Epoch: 8 | Iteration: 2565 | Classification loss: 0.00346 | Regression loss: 0.02321 | Running loss: 0.03984\n",
            "Epoch: 8 | Iteration: 2566 | Classification loss: 0.00168 | Regression loss: 0.02264 | Running loss: 0.03982\n",
            "Epoch: 8 | Iteration: 2567 | Classification loss: 0.00049 | Regression loss: 0.02939 | Running loss: 0.03982\n",
            "Epoch: 8 | Iteration: 2568 | Classification loss: 0.00046 | Regression loss: 0.01678 | Running loss: 0.03983\n",
            "Epoch: 8 | Iteration: 2569 | Classification loss: 0.00116 | Regression loss: 0.02910 | Running loss: 0.03984\n",
            "Epoch: 8 | Iteration: 2570 | Classification loss: 0.00004 | Regression loss: 0.01694 | Running loss: 0.03986\n",
            "Epoch: 8 | Iteration: 2571 | Classification loss: 0.00236 | Regression loss: 0.03356 | Running loss: 0.03988\n",
            "Epoch: 8 | Iteration: 2572 | Classification loss: 0.00023 | Regression loss: 0.02905 | Running loss: 0.03990\n",
            "Epoch: 8 | Iteration: 2573 | Classification loss: 0.00024 | Regression loss: 0.04288 | Running loss: 0.03979\n",
            "Epoch: 8 | Iteration: 2574 | Classification loss: 0.00003 | Regression loss: 0.01299 | Running loss: 0.03861\n",
            "Epoch: 8 | Iteration: 2575 | Classification loss: 0.00040 | Regression loss: 0.01734 | Running loss: 0.03858\n",
            "Epoch: 8 | Iteration: 2576 | Classification loss: 0.54724 | Regression loss: 0.38270 | Running loss: 0.04040\n",
            "Epoch: 8 | Iteration: 2577 | Classification loss: 0.00037 | Regression loss: 0.03700 | Running loss: 0.04041\n",
            "Epoch: 8 | Iteration: 2578 | Classification loss: 0.00046 | Regression loss: 0.07395 | Running loss: 0.04050\n",
            "Epoch: 8 | Iteration: 2579 | Classification loss: 0.00120 | Regression loss: 0.09601 | Running loss: 0.04066\n",
            "Epoch: 8 | Iteration: 2580 | Classification loss: 0.00017 | Regression loss: 0.06021 | Running loss: 0.04074\n",
            "Epoch: 8 | Iteration: 2581 | Classification loss: 0.00466 | Regression loss: 0.02994 | Running loss: 0.04072\n",
            "Epoch: 8 | Iteration: 2582 | Classification loss: 0.00163 | Regression loss: 0.02641 | Running loss: 0.04074\n",
            "Epoch: 8 | Iteration: 2583 | Classification loss: 0.07278 | Regression loss: 0.17607 | Running loss: 0.04115\n",
            "Epoch: 8 | Iteration: 2584 | Classification loss: 0.00030 | Regression loss: 0.02063 | Running loss: 0.04116\n",
            "Epoch: 8 | Iteration: 2585 | Classification loss: 0.00104 | Regression loss: 0.03664 | Running loss: 0.04119\n",
            "Epoch: 8 | Iteration: 2586 | Classification loss: 0.00107 | Regression loss: 0.02833 | Running loss: 0.04121\n",
            "Epoch: 8 | Iteration: 2587 | Classification loss: 0.00130 | Regression loss: 0.02858 | Running loss: 0.04124\n",
            "Epoch: 8 | Iteration: 2588 | Classification loss: 0.00038 | Regression loss: 0.03203 | Running loss: 0.04127\n",
            "Epoch: 8 | Iteration: 2589 | Classification loss: 0.00146 | Regression loss: 0.02519 | Running loss: 0.04129\n",
            "Epoch: 8 | Iteration: 2590 | Classification loss: 0.00021 | Regression loss: 0.02003 | Running loss: 0.04129\n",
            "Epoch: 8 | Iteration: 2591 | Classification loss: 0.00040 | Regression loss: 0.01441 | Running loss: 0.04125\n",
            "Epoch: 8 | Iteration: 2592 | Classification loss: 0.00061 | Regression loss: 0.03794 | Running loss: 0.04130\n",
            "Epoch: 8 | Iteration: 2593 | Classification loss: 0.00119 | Regression loss: 0.01632 | Running loss: 0.04131\n",
            "Epoch: 8 | Iteration: 2594 | Classification loss: 0.00158 | Regression loss: 0.01999 | Running loss: 0.04132\n",
            "Epoch: 8 | Iteration: 2595 | Classification loss: 0.00026 | Regression loss: 0.02156 | Running loss: 0.04132\n",
            "Epoch: 8 | Iteration: 2596 | Classification loss: 0.00044 | Regression loss: 0.01128 | Running loss: 0.04132\n",
            "Epoch: 8 | Iteration: 2597 | Classification loss: 0.00006 | Regression loss: 0.02084 | Running loss: 0.04134\n",
            "Epoch: 8 | Iteration: 2598 | Classification loss: 0.00113 | Regression loss: 0.01858 | Running loss: 0.04130\n",
            "Epoch: 8 | Iteration: 2599 | Classification loss: 0.00007 | Regression loss: 0.03501 | Running loss: 0.04134\n",
            "Epoch: 8 | Iteration: 2600 | Classification loss: 0.00067 | Regression loss: 0.02438 | Running loss: 0.04133\n",
            "Epoch: 8 | Iteration: 2601 | Classification loss: 0.00050 | Regression loss: 0.02996 | Running loss: 0.04134\n",
            "Epoch: 8 | Iteration: 2602 | Classification loss: 0.00098 | Regression loss: 0.03590 | Running loss: 0.04138\n",
            "Epoch: 8 | Iteration: 2603 | Classification loss: 0.00068 | Regression loss: 0.02374 | Running loss: 0.04140\n",
            "Epoch: 8 | Iteration: 2604 | Classification loss: 0.03584 | Regression loss: 0.08378 | Running loss: 0.04157\n",
            "Epoch: 8 | Iteration: 2605 | Classification loss: 0.00104 | Regression loss: 0.03732 | Running loss: 0.04161\n",
            "Epoch: 8 | Iteration: 2606 | Classification loss: 0.00076 | Regression loss: 0.03593 | Running loss: 0.04165\n",
            "Epoch: 8 | Iteration: 2607 | Classification loss: 0.00103 | Regression loss: 0.01801 | Running loss: 0.04165\n",
            "Epoch: 8 | Iteration: 2608 | Classification loss: 0.00069 | Regression loss: 0.03960 | Running loss: 0.04165\n",
            "Epoch: 8 | Iteration: 2609 | Classification loss: 0.00117 | Regression loss: 0.01428 | Running loss: 0.04160\n",
            "Epoch: 8 | Iteration: 2610 | Classification loss: 0.00032 | Regression loss: 0.02467 | Running loss: 0.04157\n",
            "Epoch: 8 | Iteration: 2611 | Classification loss: 0.00036 | Regression loss: 0.02275 | Running loss: 0.04155\n",
            "Epoch: 8 | Iteration: 2612 | Classification loss: 0.01363 | Regression loss: 0.11039 | Running loss: 0.04178\n",
            "Epoch: 8 | Iteration: 2613 | Classification loss: 0.00036 | Regression loss: 0.02461 | Running loss: 0.04176\n",
            "Epoch: 8 | Iteration: 2614 | Classification loss: 0.00022 | Regression loss: 0.03493 | Running loss: 0.04172\n",
            "Epoch: 8 | Iteration: 2615 | Classification loss: 0.00012 | Regression loss: 0.02042 | Running loss: 0.04171\n",
            "Epoch: 8 | Iteration: 2616 | Classification loss: 0.00062 | Regression loss: 0.02797 | Running loss: 0.04169\n",
            "Epoch: 8 | Iteration: 2617 | Classification loss: 0.00210 | Regression loss: 0.02557 | Running loss: 0.04165\n",
            "Epoch: 8 | Iteration: 2618 | Classification loss: 0.00162 | Regression loss: 0.01762 | Running loss: 0.04161\n",
            "Epoch: 8 | Iteration: 2619 | Classification loss: 0.00032 | Regression loss: 0.01270 | Running loss: 0.04144\n",
            "Epoch: 8 | Iteration: 2620 | Classification loss: 0.00032 | Regression loss: 0.02295 | Running loss: 0.04144\n",
            "Epoch: 8 | Iteration: 2621 | Classification loss: 0.00249 | Regression loss: 0.03035 | Running loss: 0.04144\n",
            "Epoch: 8 | Iteration: 2622 | Classification loss: 0.00022 | Regression loss: 0.01260 | Running loss: 0.04143\n",
            "Epoch: 8 | Iteration: 2623 | Classification loss: 0.00032 | Regression loss: 0.03773 | Running loss: 0.04148\n",
            "Epoch: 8 | Iteration: 2624 | Classification loss: 0.00031 | Regression loss: 0.02002 | Running loss: 0.04149\n",
            "Epoch: 8 | Iteration: 2625 | Classification loss: 0.00037 | Regression loss: 0.01158 | Running loss: 0.04146\n",
            "Epoch: 8 | Iteration: 2626 | Classification loss: 0.00027 | Regression loss: 0.03733 | Running loss: 0.04145\n",
            "Epoch: 8 | Iteration: 2627 | Classification loss: 0.00017 | Regression loss: 0.00362 | Running loss: 0.04137\n",
            "Epoch: 8 | Iteration: 2628 | Classification loss: 0.00019 | Regression loss: 0.02465 | Running loss: 0.04130\n",
            "Epoch: 8 | Iteration: 2629 | Classification loss: 0.00005 | Regression loss: 0.01797 | Running loss: 0.04128\n",
            "Epoch: 8 | Iteration: 2630 | Classification loss: 0.00008 | Regression loss: 0.01689 | Running loss: 0.04122\n",
            "Epoch: 8 | Iteration: 2631 | Classification loss: 0.00028 | Regression loss: 0.02201 | Running loss: 0.04118\n",
            "Epoch: 8 | Iteration: 2632 | Classification loss: 0.00006 | Regression loss: 0.01961 | Running loss: 0.04115\n",
            "Epoch: 8 | Iteration: 2633 | Classification loss: 0.00141 | Regression loss: 0.02335 | Running loss: 0.04117\n",
            "Epoch: 8 | Iteration: 2634 | Classification loss: 0.00007 | Regression loss: 0.02328 | Running loss: 0.04110\n",
            "Epoch: 8 | Iteration: 2635 | Classification loss: 0.00049 | Regression loss: 0.01963 | Running loss: 0.04110\n",
            "Epoch: 8 | Iteration: 2636 | Classification loss: 0.00030 | Regression loss: 0.02524 | Running loss: 0.04111\n",
            "Epoch: 8 | Iteration: 2637 | Classification loss: 0.00017 | Regression loss: 0.01076 | Running loss: 0.04108\n",
            "Epoch: 8 | Iteration: 2638 | Classification loss: 0.00008 | Regression loss: 0.02798 | Running loss: 0.04110\n",
            "Epoch: 8 | Iteration: 2639 | Classification loss: 0.00020 | Regression loss: 0.03027 | Running loss: 0.04110\n",
            "Epoch: 8 | Iteration: 2640 | Classification loss: 0.00007 | Regression loss: 0.02877 | Running loss: 0.04111\n",
            "Epoch: 8 | Iteration: 2641 | Classification loss: 0.00063 | Regression loss: 0.05050 | Running loss: 0.04117\n",
            "Epoch: 8 | Iteration: 2642 | Classification loss: 0.00002 | Regression loss: 0.01560 | Running loss: 0.04115\n",
            "Epoch: 8 | Iteration: 2643 | Classification loss: 0.00028 | Regression loss: 0.02150 | Running loss: 0.04117\n",
            "Epoch: 8 | Iteration: 2644 | Classification loss: 0.00008 | Regression loss: 0.03095 | Running loss: 0.04122\n",
            "Epoch: 8 | Iteration: 2645 | Classification loss: 0.00005 | Regression loss: 0.01572 | Running loss: 0.04118\n",
            "Epoch: 8 | Iteration: 2646 | Classification loss: 0.00010 | Regression loss: 0.03314 | Running loss: 0.04121\n",
            "Epoch: 8 | Iteration: 2647 | Classification loss: 0.00004 | Regression loss: 0.04120 | Running loss: 0.04125\n",
            "Epoch: 8 | Iteration: 2648 | Classification loss: 0.00006 | Regression loss: 0.01266 | Running loss: 0.04121\n",
            "Epoch: 8 | Iteration: 2649 | Classification loss: 0.00051 | Regression loss: 0.05461 | Running loss: 0.04127\n",
            "Epoch: 8 | Iteration: 2650 | Classification loss: 0.00014 | Regression loss: 0.02614 | Running loss: 0.04124\n",
            "Epoch: 8 | Iteration: 2651 | Classification loss: 0.00076 | Regression loss: 0.02166 | Running loss: 0.04126\n",
            "Epoch: 8 | Iteration: 2652 | Classification loss: 0.00320 | Regression loss: 0.03761 | Running loss: 0.04130\n",
            "Epoch: 8 | Iteration: 2653 | Classification loss: 0.00148 | Regression loss: 0.04451 | Running loss: 0.04134\n",
            "Epoch: 8 | Iteration: 2654 | Classification loss: 0.00015 | Regression loss: 0.01881 | Running loss: 0.04132\n",
            "Epoch: 8 | Iteration: 2655 | Classification loss: 0.00420 | Regression loss: 0.02540 | Running loss: 0.04132\n",
            "Epoch: 8 | Iteration: 2656 | Classification loss: 0.00032 | Regression loss: 0.01741 | Running loss: 0.04131\n",
            "Epoch: 8 | Iteration: 2657 | Classification loss: 0.00056 | Regression loss: 0.04420 | Running loss: 0.04134\n",
            "Epoch: 8 | Iteration: 2658 | Classification loss: 0.00004 | Regression loss: 0.02599 | Running loss: 0.04129\n",
            "Epoch: 8 | Iteration: 2659 | Classification loss: 0.00124 | Regression loss: 0.02517 | Running loss: 0.04124\n",
            "Epoch: 8 | Iteration: 2660 | Classification loss: 0.00073 | Regression loss: 0.06332 | Running loss: 0.04128\n",
            "Epoch: 8 | Iteration: 2661 | Classification loss: 0.00009 | Regression loss: 0.01293 | Running loss: 0.04125\n",
            "Epoch: 8 | Iteration: 2662 | Classification loss: 0.00102 | Regression loss: 0.03242 | Running loss: 0.04128\n",
            "Epoch: 8 | Iteration: 2663 | Classification loss: 0.00013 | Regression loss: 0.01708 | Running loss: 0.04125\n",
            "Epoch: 8 | Iteration: 2664 | Classification loss: 0.00024 | Regression loss: 0.02086 | Running loss: 0.04127\n",
            "Epoch: 8 | Iteration: 2665 | Classification loss: 0.00043 | Regression loss: 0.01719 | Running loss: 0.04126\n",
            "Epoch: 8 | Iteration: 2666 | Classification loss: 0.00023 | Regression loss: 0.02371 | Running loss: 0.04128\n",
            "Epoch: 8 | Iteration: 2667 | Classification loss: 0.00048 | Regression loss: 0.03326 | Running loss: 0.04131\n",
            "Epoch: 8 | Iteration: 2668 | Classification loss: 0.00023 | Regression loss: 0.01897 | Running loss: 0.04127\n",
            "Epoch: 8 | Iteration: 2669 | Classification loss: 0.00020 | Regression loss: 0.01308 | Running loss: 0.04124\n",
            "Epoch: 8 | Iteration: 2670 | Classification loss: 0.00013 | Regression loss: 0.02466 | Running loss: 0.04119\n",
            "Epoch: 8 | Iteration: 2671 | Classification loss: 0.00009 | Regression loss: 0.02184 | Running loss: 0.04119\n",
            "Epoch: 8 | Iteration: 2672 | Classification loss: 0.00064 | Regression loss: 0.02514 | Running loss: 0.04115\n",
            "Epoch: 8 | Iteration: 2673 | Classification loss: 0.00006 | Regression loss: 0.02159 | Running loss: 0.04109\n",
            "Evaluating dataset\n",
            "254/254\n",
            "mAP:\n",
            "fatigued: 0.9979730097497703\n",
            "Precision:  0.6477987421383647\n",
            "Recall:  1.0\n",
            "awake: 0.9999066467513069\n",
            "Precision:  0.6477987421383647\n",
            "Recall:  1.0\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch: 9 | Iteration: 0 | Classification loss: 0.00004 | Regression loss: 0.01401 | Running loss: 0.04096\n",
            "Epoch: 9 | Iteration: 1 | Classification loss: 0.00065 | Regression loss: 0.04499 | Running loss: 0.04101\n",
            "Epoch: 9 | Iteration: 2 | Classification loss: 0.00169 | Regression loss: 0.04319 | Running loss: 0.04094\n",
            "Epoch: 9 | Iteration: 3 | Classification loss: 0.00071 | Regression loss: 0.02097 | Running loss: 0.04092\n",
            "Epoch: 9 | Iteration: 4 | Classification loss: 0.00095 | Regression loss: 0.03079 | Running loss: 0.04091\n",
            "Epoch: 9 | Iteration: 5 | Classification loss: 0.00048 | Regression loss: 0.06829 | Running loss: 0.04097\n",
            "Epoch: 9 | Iteration: 6 | Classification loss: 0.01491 | Regression loss: 0.11054 | Running loss: 0.04109\n",
            "Epoch: 9 | Iteration: 7 | Classification loss: 0.00031 | Regression loss: 0.04194 | Running loss: 0.04114\n",
            "Epoch: 9 | Iteration: 8 | Classification loss: 0.00014 | Regression loss: 0.03641 | Running loss: 0.04117\n",
            "Epoch: 9 | Iteration: 9 | Classification loss: 0.00075 | Regression loss: 0.05059 | Running loss: 0.04123\n",
            "Epoch: 9 | Iteration: 10 | Classification loss: 0.02587 | Regression loss: 0.13443 | Running loss: 0.04150\n",
            "Epoch: 9 | Iteration: 11 | Classification loss: 0.00005 | Regression loss: 0.02244 | Running loss: 0.04147\n",
            "Epoch: 9 | Iteration: 12 | Classification loss: 0.00089 | Regression loss: 0.02788 | Running loss: 0.04148\n",
            "Epoch: 9 | Iteration: 13 | Classification loss: 0.00847 | Regression loss: 0.05038 | Running loss: 0.04151\n",
            "Epoch: 9 | Iteration: 14 | Classification loss: 0.00059 | Regression loss: 0.02780 | Running loss: 0.04149\n",
            "Epoch: 9 | Iteration: 15 | Classification loss: 0.00049 | Regression loss: 0.02370 | Running loss: 0.04150\n",
            "Epoch: 9 | Iteration: 16 | Classification loss: 0.00046 | Regression loss: 0.03951 | Running loss: 0.04153\n",
            "Epoch: 9 | Iteration: 17 | Classification loss: 0.00020 | Regression loss: 0.02995 | Running loss: 0.04156\n",
            "Epoch: 9 | Iteration: 18 | Classification loss: 0.00010 | Regression loss: 0.02218 | Running loss: 0.04154\n",
            "Epoch: 9 | Iteration: 19 | Classification loss: 0.00009 | Regression loss: 0.01043 | Running loss: 0.04121\n",
            "Epoch: 9 | Iteration: 20 | Classification loss: 0.00026 | Regression loss: 0.01155 | Running loss: 0.04122\n",
            "Epoch: 9 | Iteration: 21 | Classification loss: 0.00008 | Regression loss: 0.02110 | Running loss: 0.04119\n",
            "Epoch: 9 | Iteration: 22 | Classification loss: 0.00002 | Regression loss: 0.00904 | Running loss: 0.04113\n",
            "Epoch: 9 | Iteration: 23 | Classification loss: 0.00003 | Regression loss: 0.01266 | Running loss: 0.04112\n",
            "Epoch: 9 | Iteration: 24 | Classification loss: 0.00023 | Regression loss: 0.00955 | Running loss: 0.04104\n",
            "Epoch: 9 | Iteration: 25 | Classification loss: 0.00009 | Regression loss: 0.02892 | Running loss: 0.04102\n",
            "Epoch: 9 | Iteration: 26 | Classification loss: 0.00120 | Regression loss: 0.04781 | Running loss: 0.04108\n",
            "Epoch: 9 | Iteration: 27 | Classification loss: 0.37394 | Regression loss: 0.28634 | Running loss: 0.04236\n",
            "Epoch: 9 | Iteration: 28 | Classification loss: 0.00006 | Regression loss: 0.02798 | Running loss: 0.04238\n",
            "Epoch: 9 | Iteration: 29 | Classification loss: 0.00154 | Regression loss: 0.02525 | Running loss: 0.04238\n",
            "Epoch: 9 | Iteration: 30 | Classification loss: 0.00035 | Regression loss: 0.03711 | Running loss: 0.04239\n",
            "Epoch: 9 | Iteration: 31 | Classification loss: 0.00026 | Regression loss: 0.02508 | Running loss: 0.04240\n",
            "Epoch: 9 | Iteration: 32 | Classification loss: 0.00005 | Regression loss: 0.03089 | Running loss: 0.04242\n",
            "Epoch: 9 | Iteration: 33 | Classification loss: 0.00003 | Regression loss: 0.01452 | Running loss: 0.04230\n",
            "Epoch: 9 | Iteration: 34 | Classification loss: 0.00062 | Regression loss: 0.02144 | Running loss: 0.04231\n",
            "Epoch: 9 | Iteration: 35 | Classification loss: 0.00053 | Regression loss: 0.04821 | Running loss: 0.04238\n",
            "Epoch: 9 | Iteration: 36 | Classification loss: 0.00163 | Regression loss: 0.01285 | Running loss: 0.04237\n",
            "Epoch: 9 | Iteration: 37 | Classification loss: 0.00011 | Regression loss: 0.04725 | Running loss: 0.04242\n",
            "Epoch: 9 | Iteration: 38 | Classification loss: 0.00071 | Regression loss: 0.02189 | Running loss: 0.04241\n",
            "Epoch: 9 | Iteration: 39 | Classification loss: 0.00040 | Regression loss: 0.04728 | Running loss: 0.04245\n",
            "Epoch: 9 | Iteration: 40 | Classification loss: 0.00034 | Regression loss: 0.03355 | Running loss: 0.04248\n",
            "Epoch: 9 | Iteration: 41 | Classification loss: 0.00083 | Regression loss: 0.01941 | Running loss: 0.04249\n",
            "Epoch: 9 | Iteration: 42 | Classification loss: 0.05918 | Regression loss: 0.02986 | Running loss: 0.04261\n",
            "Epoch: 9 | Iteration: 43 | Classification loss: 0.00038 | Regression loss: 0.01462 | Running loss: 0.04257\n",
            "Epoch: 9 | Iteration: 44 | Classification loss: 0.00002 | Regression loss: 0.02128 | Running loss: 0.04255\n",
            "Epoch: 9 | Iteration: 45 | Classification loss: 0.00016 | Regression loss: 0.01816 | Running loss: 0.04253\n",
            "Epoch: 9 | Iteration: 46 | Classification loss: 0.00008 | Regression loss: 0.02532 | Running loss: 0.04255\n",
            "Epoch: 9 | Iteration: 47 | Classification loss: 0.00037 | Regression loss: 0.02486 | Running loss: 0.04250\n",
            "Epoch: 9 | Iteration: 48 | Classification loss: 0.00010 | Regression loss: 0.02714 | Running loss: 0.04251\n",
            "Epoch: 9 | Iteration: 49 | Classification loss: 0.00024 | Regression loss: 0.02646 | Running loss: 0.04252\n",
            "Epoch: 9 | Iteration: 50 | Classification loss: 0.00031 | Regression loss: 0.03672 | Running loss: 0.04255\n",
            "Epoch: 9 | Iteration: 51 | Classification loss: 0.00029 | Regression loss: 0.01741 | Running loss: 0.04256\n",
            "Epoch: 9 | Iteration: 52 | Classification loss: 0.00068 | Regression loss: 0.04217 | Running loss: 0.04260\n",
            "Epoch: 9 | Iteration: 53 | Classification loss: 0.00255 | Regression loss: 0.02964 | Running loss: 0.04257\n",
            "Epoch: 9 | Iteration: 54 | Classification loss: 0.00074 | Regression loss: 0.03431 | Running loss: 0.04259\n",
            "Epoch: 9 | Iteration: 55 | Classification loss: 0.00020 | Regression loss: 0.01422 | Running loss: 0.04255\n",
            "Epoch: 9 | Iteration: 56 | Classification loss: 0.00015 | Regression loss: 0.01998 | Running loss: 0.04242\n",
            "Epoch: 9 | Iteration: 57 | Classification loss: 0.00006 | Regression loss: 0.05054 | Running loss: 0.04244\n",
            "Epoch: 9 | Iteration: 58 | Classification loss: 0.00069 | Regression loss: 0.01628 | Running loss: 0.04231\n",
            "Epoch: 9 | Iteration: 59 | Classification loss: 0.00034 | Regression loss: 0.02194 | Running loss: 0.04230\n",
            "Epoch: 9 | Iteration: 60 | Classification loss: 0.00078 | Regression loss: 0.04821 | Running loss: 0.04234\n",
            "Epoch: 9 | Iteration: 61 | Classification loss: 0.16469 | Regression loss: 0.26314 | Running loss: 0.04311\n",
            "Epoch: 9 | Iteration: 62 | Classification loss: 0.00051 | Regression loss: 0.02165 | Running loss: 0.04311\n",
            "Epoch: 9 | Iteration: 63 | Classification loss: 0.00008 | Regression loss: 0.01751 | Running loss: 0.04311\n",
            "Epoch: 9 | Iteration: 64 | Classification loss: 0.00103 | Regression loss: 0.03865 | Running loss: 0.04311\n",
            "Epoch: 9 | Iteration: 65 | Classification loss: 0.00042 | Regression loss: 0.03327 | Running loss: 0.04314\n",
            "Epoch: 9 | Iteration: 66 | Classification loss: 0.00239 | Regression loss: 0.03700 | Running loss: 0.04317\n",
            "Epoch: 9 | Iteration: 67 | Classification loss: 0.00129 | Regression loss: 0.01267 | Running loss: 0.04315\n",
            "Epoch: 9 | Iteration: 68 | Classification loss: 0.04365 | Regression loss: 0.05703 | Running loss: 0.04332\n",
            "Epoch: 9 | Iteration: 69 | Classification loss: 0.00146 | Regression loss: 0.07366 | Running loss: 0.04344\n",
            "Epoch: 9 | Iteration: 70 | Classification loss: 0.00008 | Regression loss: 0.03438 | Running loss: 0.04345\n",
            "Epoch: 9 | Iteration: 71 | Classification loss: 0.00018 | Regression loss: 0.02881 | Running loss: 0.04339\n",
            "Epoch: 9 | Iteration: 72 | Classification loss: 0.00009 | Regression loss: 0.02200 | Running loss: 0.04341\n",
            "Epoch: 9 | Iteration: 73 | Classification loss: 0.00020 | Regression loss: 0.03730 | Running loss: 0.04344\n",
            "Epoch: 9 | Iteration: 74 | Classification loss: 0.00011 | Regression loss: 0.03493 | Running loss: 0.04347\n",
            "Epoch: 9 | Iteration: 75 | Classification loss: 0.00025 | Regression loss: 0.10461 | Running loss: 0.04360\n",
            "Epoch: 9 | Iteration: 76 | Classification loss: 0.01521 | Regression loss: 0.08768 | Running loss: 0.04378\n",
            "Epoch: 9 | Iteration: 77 | Classification loss: 0.00176 | Regression loss: 0.06388 | Running loss: 0.04387\n",
            "Epoch: 9 | Iteration: 78 | Classification loss: 0.01106 | Regression loss: 0.13896 | Running loss: 0.04408\n",
            "Epoch: 9 | Iteration: 79 | Classification loss: 0.00088 | Regression loss: 0.02165 | Running loss: 0.04401\n",
            "Epoch: 9 | Iteration: 80 | Classification loss: 0.00092 | Regression loss: 0.04921 | Running loss: 0.04403\n",
            "Epoch: 9 | Iteration: 81 | Classification loss: 0.00086 | Regression loss: 0.02471 | Running loss: 0.04402\n",
            "Epoch: 9 | Iteration: 82 | Classification loss: 0.07689 | Regression loss: 0.15419 | Running loss: 0.04444\n",
            "Epoch: 9 | Iteration: 83 | Classification loss: 0.00030 | Regression loss: 0.02552 | Running loss: 0.04445\n",
            "Epoch: 9 | Iteration: 84 | Classification loss: 0.00006 | Regression loss: 0.03665 | Running loss: 0.04445\n",
            "Epoch: 9 | Iteration: 85 | Classification loss: 0.00006 | Regression loss: 0.01267 | Running loss: 0.04444\n",
            "Epoch: 9 | Iteration: 86 | Classification loss: 0.00021 | Regression loss: 0.02502 | Running loss: 0.04444\n",
            "Epoch: 9 | Iteration: 87 | Classification loss: 0.00034 | Regression loss: 0.02781 | Running loss: 0.04448\n",
            "Epoch: 9 | Iteration: 88 | Classification loss: 0.00045 | Regression loss: 0.01031 | Running loss: 0.04444\n",
            "Epoch: 9 | Iteration: 89 | Classification loss: 0.00343 | Regression loss: 0.05896 | Running loss: 0.04452\n",
            "Epoch: 9 | Iteration: 90 | Classification loss: 0.00003 | Regression loss: 0.01300 | Running loss: 0.04450\n",
            "Epoch: 9 | Iteration: 91 | Classification loss: 0.00022 | Regression loss: 0.02739 | Running loss: 0.04451\n",
            "Epoch: 9 | Iteration: 92 | Classification loss: 0.00002 | Regression loss: 0.02272 | Running loss: 0.04447\n",
            "Epoch: 9 | Iteration: 93 | Classification loss: 0.00004 | Regression loss: 0.01174 | Running loss: 0.04444\n",
            "Epoch: 9 | Iteration: 94 | Classification loss: 0.00005 | Regression loss: 0.01430 | Running loss: 0.04437\n",
            "Epoch: 9 | Iteration: 95 | Classification loss: 0.00037 | Regression loss: 0.02625 | Running loss: 0.04438\n",
            "Epoch: 9 | Iteration: 96 | Classification loss: 0.00027 | Regression loss: 0.02193 | Running loss: 0.04436\n",
            "Epoch: 9 | Iteration: 97 | Classification loss: 0.00002 | Regression loss: 0.02249 | Running loss: 0.04270\n",
            "Epoch: 9 | Iteration: 98 | Classification loss: 0.00049 | Regression loss: 0.02048 | Running loss: 0.04268\n",
            "Epoch: 9 | Iteration: 99 | Classification loss: 0.00007 | Regression loss: 0.02307 | Running loss: 0.04265\n",
            "Epoch: 9 | Iteration: 100 | Classification loss: 0.00070 | Regression loss: 0.02299 | Running loss: 0.04262\n",
            "Epoch: 9 | Iteration: 101 | Classification loss: 0.00005 | Regression loss: 0.01125 | Running loss: 0.04260\n",
            "Epoch: 9 | Iteration: 102 | Classification loss: 0.00092 | Regression loss: 0.02386 | Running loss: 0.04258\n",
            "Epoch: 9 | Iteration: 103 | Classification loss: 0.00144 | Regression loss: 0.01185 | Running loss: 0.04250\n",
            "Epoch: 9 | Iteration: 104 | Classification loss: 0.00013 | Regression loss: 0.02106 | Running loss: 0.04248\n",
            "Epoch: 9 | Iteration: 105 | Classification loss: 0.00017 | Regression loss: 0.01928 | Running loss: 0.04247\n",
            "Epoch: 9 | Iteration: 106 | Classification loss: 0.00055 | Regression loss: 0.03934 | Running loss: 0.04249\n",
            "Epoch: 9 | Iteration: 107 | Classification loss: 0.00022 | Regression loss: 0.01035 | Running loss: 0.04247\n",
            "Epoch: 9 | Iteration: 108 | Classification loss: 0.00161 | Regression loss: 0.03915 | Running loss: 0.04234\n",
            "Epoch: 9 | Iteration: 109 | Classification loss: 0.00088 | Regression loss: 0.03606 | Running loss: 0.04027\n",
            "Epoch: 9 | Iteration: 110 | Classification loss: 0.00472 | Regression loss: 0.03570 | Running loss: 0.04023\n",
            "Epoch: 9 | Iteration: 111 | Classification loss: 0.00005 | Regression loss: 0.02043 | Running loss: 0.04018\n",
            "Epoch: 9 | Iteration: 112 | Classification loss: 0.00030 | Regression loss: 0.02959 | Running loss: 0.04016\n",
            "Epoch: 9 | Iteration: 113 | Classification loss: 0.00013 | Regression loss: 0.01066 | Running loss: 0.04014\n",
            "Epoch: 9 | Iteration: 114 | Classification loss: 0.00003 | Regression loss: 0.01191 | Running loss: 0.04013\n",
            "Epoch: 9 | Iteration: 115 | Classification loss: 0.00047 | Regression loss: 0.01376 | Running loss: 0.04013\n",
            "Epoch: 9 | Iteration: 116 | Classification loss: 0.00070 | Regression loss: 0.01997 | Running loss: 0.04013\n",
            "Epoch: 9 | Iteration: 117 | Classification loss: 0.00005 | Regression loss: 0.02125 | Running loss: 0.04013\n",
            "Epoch: 9 | Iteration: 118 | Classification loss: 0.00032 | Regression loss: 0.02704 | Running loss: 0.04009\n",
            "Epoch: 9 | Iteration: 119 | Classification loss: 0.00003 | Regression loss: 0.02601 | Running loss: 0.04009\n",
            "Epoch: 9 | Iteration: 120 | Classification loss: 0.00098 | Regression loss: 0.06597 | Running loss: 0.04016\n",
            "Epoch: 9 | Iteration: 121 | Classification loss: 0.00027 | Regression loss: 0.08383 | Running loss: 0.04028\n",
            "Epoch: 9 | Iteration: 122 | Classification loss: 0.00005 | Regression loss: 0.01724 | Running loss: 0.04019\n",
            "Epoch: 9 | Iteration: 123 | Classification loss: 0.00045 | Regression loss: 0.01046 | Running loss: 0.04013\n",
            "Epoch: 9 | Iteration: 124 | Classification loss: 0.00018 | Regression loss: 0.01503 | Running loss: 0.04013\n",
            "Epoch: 9 | Iteration: 125 | Classification loss: 0.00068 | Regression loss: 0.02396 | Running loss: 0.04015\n",
            "Epoch: 9 | Iteration: 126 | Classification loss: 0.00011 | Regression loss: 0.04691 | Running loss: 0.04016\n",
            "Epoch: 9 | Iteration: 127 | Classification loss: 0.01844 | Regression loss: 0.04258 | Running loss: 0.04023\n",
            "Epoch: 9 | Iteration: 128 | Classification loss: 0.00030 | Regression loss: 0.01376 | Running loss: 0.04018\n",
            "Epoch: 9 | Iteration: 129 | Classification loss: 0.00012 | Regression loss: 0.02513 | Running loss: 0.04019\n",
            "Epoch: 9 | Iteration: 130 | Classification loss: 0.00020 | Regression loss: 0.02192 | Running loss: 0.04015\n",
            "Epoch: 9 | Iteration: 131 | Classification loss: 0.00006 | Regression loss: 0.02143 | Running loss: 0.04014\n",
            "Epoch: 9 | Iteration: 132 | Classification loss: 0.00007 | Regression loss: 0.02842 | Running loss: 0.04003\n",
            "Epoch: 9 | Iteration: 133 | Classification loss: 0.00529 | Regression loss: 0.02984 | Running loss: 0.03998\n",
            "Epoch: 9 | Iteration: 134 | Classification loss: 0.00008 | Regression loss: 0.02106 | Running loss: 0.03993\n",
            "Epoch: 9 | Iteration: 135 | Classification loss: 0.00236 | Regression loss: 0.04283 | Running loss: 0.04000\n",
            "Epoch: 9 | Iteration: 136 | Classification loss: 0.00032 | Regression loss: 0.02203 | Running loss: 0.04002\n",
            "Epoch: 9 | Iteration: 137 | Classification loss: 0.00011 | Regression loss: 0.01910 | Running loss: 0.03933\n",
            "Epoch: 9 | Iteration: 138 | Classification loss: 0.00027 | Regression loss: 0.03057 | Running loss: 0.03934\n",
            "Epoch: 9 | Iteration: 139 | Classification loss: 0.00016 | Regression loss: 0.05243 | Running loss: 0.03920\n",
            "Epoch: 9 | Iteration: 140 | Classification loss: 0.00005 | Regression loss: 0.01299 | Running loss: 0.03918\n",
            "Epoch: 9 | Iteration: 141 | Classification loss: 0.00051 | Regression loss: 0.03472 | Running loss: 0.03921\n",
            "Epoch: 9 | Iteration: 142 | Classification loss: 0.00008 | Regression loss: 0.02268 | Running loss: 0.03921\n",
            "Epoch: 9 | Iteration: 143 | Classification loss: 0.00121 | Regression loss: 0.01817 | Running loss: 0.03922\n",
            "Epoch: 9 | Iteration: 144 | Classification loss: 0.00029 | Regression loss: 0.05111 | Running loss: 0.03928\n",
            "Epoch: 9 | Iteration: 145 | Classification loss: 0.00014 | Regression loss: 0.02640 | Running loss: 0.03926\n",
            "Epoch: 9 | Iteration: 146 | Classification loss: 0.00008 | Regression loss: 0.02841 | Running loss: 0.03925\n",
            "Epoch: 9 | Iteration: 147 | Classification loss: 0.00005 | Regression loss: 0.02900 | Running loss: 0.03922\n",
            "Epoch: 9 | Iteration: 148 | Classification loss: 0.00051 | Regression loss: 0.04297 | Running loss: 0.03927\n",
            "Epoch: 9 | Iteration: 149 | Classification loss: 0.00971 | Regression loss: 0.05234 | Running loss: 0.03932\n",
            "Epoch: 9 | Iteration: 150 | Classification loss: 0.00012 | Regression loss: 0.02941 | Running loss: 0.03933\n",
            "Epoch: 9 | Iteration: 151 | Classification loss: 0.00040 | Regression loss: 0.03703 | Running loss: 0.03933\n",
            "Epoch: 9 | Iteration: 152 | Classification loss: 0.00015 | Regression loss: 0.03512 | Running loss: 0.03935\n",
            "Epoch: 9 | Iteration: 153 | Classification loss: 0.00190 | Regression loss: 0.02709 | Running loss: 0.03933\n",
            "Epoch: 9 | Iteration: 154 | Classification loss: 0.00212 | Regression loss: 0.02054 | Running loss: 0.03935\n",
            "Epoch: 9 | Iteration: 155 | Classification loss: 0.00020 | Regression loss: 0.00964 | Running loss: 0.03932\n",
            "Epoch: 9 | Iteration: 156 | Classification loss: 0.00008 | Regression loss: 0.01241 | Running loss: 0.03916\n",
            "Epoch: 9 | Iteration: 157 | Classification loss: 0.00007 | Regression loss: 0.02825 | Running loss: 0.03918\n",
            "Epoch: 9 | Iteration: 158 | Classification loss: 0.00007 | Regression loss: 0.03956 | Running loss: 0.03924\n",
            "Epoch: 9 | Iteration: 159 | Classification loss: 0.00012 | Regression loss: 0.01344 | Running loss: 0.03917\n",
            "Epoch: 9 | Iteration: 160 | Classification loss: 0.00006 | Regression loss: 0.01043 | Running loss: 0.03913\n",
            "Epoch: 9 | Iteration: 161 | Classification loss: 0.00011 | Regression loss: 0.05232 | Running loss: 0.03915\n",
            "Epoch: 9 | Iteration: 162 | Classification loss: 0.00082 | Regression loss: 0.01166 | Running loss: 0.03907\n",
            "Epoch: 9 | Iteration: 163 | Classification loss: 0.00020 | Regression loss: 0.03576 | Running loss: 0.03906\n",
            "Epoch: 9 | Iteration: 164 | Classification loss: 0.00007 | Regression loss: 0.00787 | Running loss: 0.03903\n",
            "Epoch: 9 | Iteration: 165 | Classification loss: 0.00026 | Regression loss: 0.00920 | Running loss: 0.03886\n",
            "Epoch: 9 | Iteration: 166 | Classification loss: 0.00017 | Regression loss: 0.01230 | Running loss: 0.03878\n",
            "Epoch: 9 | Iteration: 167 | Classification loss: 0.00067 | Regression loss: 0.05153 | Running loss: 0.03884\n",
            "Epoch: 9 | Iteration: 168 | Classification loss: 0.00011 | Regression loss: 0.01085 | Running loss: 0.03882\n",
            "Epoch: 9 | Iteration: 169 | Classification loss: 0.00007 | Regression loss: 0.01988 | Running loss: 0.03879\n",
            "Epoch: 9 | Iteration: 170 | Classification loss: 0.00012 | Regression loss: 0.03804 | Running loss: 0.03884\n",
            "Epoch: 9 | Iteration: 171 | Classification loss: 0.00006 | Regression loss: 0.03398 | Running loss: 0.03887\n",
            "Epoch: 9 | Iteration: 172 | Classification loss: 0.00025 | Regression loss: 0.02034 | Running loss: 0.03885\n",
            "Epoch: 9 | Iteration: 173 | Classification loss: 0.00027 | Regression loss: 0.02941 | Running loss: 0.03875\n",
            "Epoch: 9 | Iteration: 174 | Classification loss: 0.00011 | Regression loss: 0.03408 | Running loss: 0.03876\n",
            "Epoch: 9 | Iteration: 175 | Classification loss: 0.00022 | Regression loss: 0.01935 | Running loss: 0.03876\n",
            "Epoch: 9 | Iteration: 176 | Classification loss: 0.00054 | Regression loss: 0.03012 | Running loss: 0.03876\n",
            "Epoch: 9 | Iteration: 177 | Classification loss: 0.00074 | Regression loss: 0.02357 | Running loss: 0.03869\n",
            "Epoch: 9 | Iteration: 178 | Classification loss: 0.00020 | Regression loss: 0.01303 | Running loss: 0.03868\n",
            "Epoch: 9 | Iteration: 179 | Classification loss: 0.00040 | Regression loss: 0.02098 | Running loss: 0.03829\n",
            "Epoch: 9 | Iteration: 180 | Classification loss: 0.00025 | Regression loss: 0.03037 | Running loss: 0.03829\n",
            "Epoch: 9 | Iteration: 181 | Classification loss: 0.00001 | Regression loss: 0.01206 | Running loss: 0.03828\n",
            "Epoch: 9 | Iteration: 182 | Classification loss: 0.00003 | Regression loss: 0.02323 | Running loss: 0.03828\n",
            "Epoch: 9 | Iteration: 183 | Classification loss: 0.00017 | Regression loss: 0.01285 | Running loss: 0.03828\n",
            "Epoch: 9 | Iteration: 184 | Classification loss: 0.00003 | Regression loss: 0.02347 | Running loss: 0.03826\n",
            "Epoch: 9 | Iteration: 185 | Classification loss: 0.00023 | Regression loss: 0.03320 | Running loss: 0.03823\n",
            "Epoch: 9 | Iteration: 186 | Classification loss: 0.00002 | Regression loss: 0.01329 | Running loss: 0.03810\n",
            "Epoch: 9 | Iteration: 187 | Classification loss: 0.00009 | Regression loss: 0.01894 | Running loss: 0.03809\n",
            "Epoch: 9 | Iteration: 188 | Classification loss: 0.01602 | Regression loss: 0.03140 | Running loss: 0.03811\n",
            "Epoch: 9 | Iteration: 189 | Classification loss: 0.00011 | Regression loss: 0.01456 | Running loss: 0.03811\n",
            "Epoch: 9 | Iteration: 190 | Classification loss: 0.00016 | Regression loss: 0.01043 | Running loss: 0.03804\n",
            "Epoch: 9 | Iteration: 191 | Classification loss: 0.00066 | Regression loss: 0.02235 | Running loss: 0.03803\n",
            "Epoch: 9 | Iteration: 192 | Classification loss: 0.00004 | Regression loss: 0.01910 | Running loss: 0.03803\n",
            "Epoch: 9 | Iteration: 193 | Classification loss: 0.00010 | Regression loss: 0.05277 | Running loss: 0.03807\n",
            "Epoch: 9 | Iteration: 194 | Classification loss: 0.00007 | Regression loss: 0.01761 | Running loss: 0.03798\n",
            "Epoch: 9 | Iteration: 195 | Classification loss: 0.00004 | Regression loss: 0.02263 | Running loss: 0.03793\n",
            "Epoch: 9 | Iteration: 196 | Classification loss: 0.00019 | Regression loss: 0.00906 | Running loss: 0.03786\n",
            "Epoch: 9 | Iteration: 197 | Classification loss: 0.00005 | Regression loss: 0.01599 | Running loss: 0.03785\n",
            "Epoch: 9 | Iteration: 198 | Classification loss: 0.00035 | Regression loss: 0.01184 | Running loss: 0.03779\n",
            "Epoch: 9 | Iteration: 199 | Classification loss: 0.00013 | Regression loss: 0.00981 | Running loss: 0.03771\n",
            "Epoch: 9 | Iteration: 200 | Classification loss: 0.00183 | Regression loss: 0.06358 | Running loss: 0.03779\n",
            "Epoch: 9 | Iteration: 201 | Classification loss: 0.00006 | Regression loss: 0.02534 | Running loss: 0.03780\n",
            "Epoch: 9 | Iteration: 202 | Classification loss: 0.00033 | Regression loss: 0.02066 | Running loss: 0.03782\n",
            "Epoch: 9 | Iteration: 203 | Classification loss: 0.00036 | Regression loss: 0.03395 | Running loss: 0.03778\n",
            "Epoch: 9 | Iteration: 204 | Classification loss: 0.00407 | Regression loss: 0.05655 | Running loss: 0.03781\n",
            "Epoch: 9 | Iteration: 205 | Classification loss: 0.00077 | Regression loss: 0.02291 | Running loss: 0.03776\n",
            "Epoch: 9 | Iteration: 206 | Classification loss: 0.00039 | Regression loss: 0.02662 | Running loss: 0.03776\n",
            "Epoch: 9 | Iteration: 207 | Classification loss: 0.00030 | Regression loss: 0.02386 | Running loss: 0.03773\n",
            "Epoch: 9 | Iteration: 208 | Classification loss: 0.00021 | Regression loss: 0.02683 | Running loss: 0.03775\n",
            "Epoch: 9 | Iteration: 209 | Classification loss: 0.00009 | Regression loss: 0.01941 | Running loss: 0.03773\n",
            "Epoch: 9 | Iteration: 210 | Classification loss: 0.00033 | Regression loss: 0.02372 | Running loss: 0.03775\n",
            "Epoch: 9 | Iteration: 211 | Classification loss: 0.13141 | Regression loss: 0.20770 | Running loss: 0.03837\n",
            "Epoch: 9 | Iteration: 212 | Classification loss: 0.00006 | Regression loss: 0.02732 | Running loss: 0.03839\n",
            "Epoch: 9 | Iteration: 213 | Classification loss: 0.00017 | Regression loss: 0.03069 | Running loss: 0.03837\n",
            "Epoch: 9 | Iteration: 214 | Classification loss: 0.00036 | Regression loss: 0.02200 | Running loss: 0.03829\n",
            "Epoch: 9 | Iteration: 215 | Classification loss: 0.00010 | Regression loss: 0.01718 | Running loss: 0.03829\n",
            "Epoch: 9 | Iteration: 216 | Classification loss: 0.00015 | Regression loss: 0.01269 | Running loss: 0.03826\n",
            "Epoch: 9 | Iteration: 217 | Classification loss: 0.00352 | Regression loss: 0.04044 | Running loss: 0.03829\n",
            "Epoch: 9 | Iteration: 218 | Classification loss: 0.02283 | Regression loss: 0.04248 | Running loss: 0.03834\n",
            "Epoch: 9 | Iteration: 219 | Classification loss: 0.00030 | Regression loss: 0.03098 | Running loss: 0.03832\n",
            "Epoch: 9 | Iteration: 220 | Classification loss: 0.00017 | Regression loss: 0.03336 | Running loss: 0.03832\n",
            "Epoch: 9 | Iteration: 221 | Classification loss: 0.00046 | Regression loss: 0.01262 | Running loss: 0.03826\n",
            "Epoch: 9 | Iteration: 222 | Classification loss: 0.00024 | Regression loss: 0.03118 | Running loss: 0.03821\n",
            "Epoch: 9 | Iteration: 223 | Classification loss: 0.00009 | Regression loss: 0.02003 | Running loss: 0.03814\n",
            "Epoch: 9 | Iteration: 224 | Classification loss: 0.00051 | Regression loss: 0.02340 | Running loss: 0.03814\n",
            "Epoch: 9 | Iteration: 225 | Classification loss: 0.00005 | Regression loss: 0.02814 | Running loss: 0.03814\n",
            "Epoch: 9 | Iteration: 226 | Classification loss: 0.00005 | Regression loss: 0.00638 | Running loss: 0.03810\n",
            "Epoch: 9 | Iteration: 227 | Classification loss: 0.00077 | Regression loss: 0.01623 | Running loss: 0.03811\n",
            "Epoch: 9 | Iteration: 228 | Classification loss: 0.00029 | Regression loss: 0.02778 | Running loss: 0.03814\n",
            "Epoch: 9 | Iteration: 229 | Classification loss: 0.00003 | Regression loss: 0.02474 | Running loss: 0.03815\n",
            "Epoch: 9 | Iteration: 230 | Classification loss: 0.00027 | Regression loss: 0.03595 | Running loss: 0.03813\n",
            "Epoch: 9 | Iteration: 231 | Classification loss: 0.00028 | Regression loss: 0.02584 | Running loss: 0.03813\n",
            "Epoch: 9 | Iteration: 232 | Classification loss: 0.00014 | Regression loss: 0.01616 | Running loss: 0.03811\n",
            "Epoch: 9 | Iteration: 233 | Classification loss: 0.00009 | Regression loss: 0.01744 | Running loss: 0.03809\n",
            "Epoch: 9 | Iteration: 234 | Classification loss: 0.00011 | Regression loss: 0.01262 | Running loss: 0.03805\n",
            "Epoch: 9 | Iteration: 235 | Classification loss: 0.00016 | Regression loss: 0.01312 | Running loss: 0.03802\n",
            "Epoch: 9 | Iteration: 236 | Classification loss: 0.00042 | Regression loss: 0.05543 | Running loss: 0.03803\n",
            "Epoch: 9 | Iteration: 237 | Classification loss: 0.05698 | Regression loss: 0.05306 | Running loss: 0.03823\n",
            "Epoch: 9 | Iteration: 238 | Classification loss: 0.00033 | Regression loss: 0.05748 | Running loss: 0.03832\n",
            "Epoch: 9 | Iteration: 239 | Classification loss: 0.00022 | Regression loss: 0.04464 | Running loss: 0.03838\n",
            "Epoch: 9 | Iteration: 240 | Classification loss: 0.00013 | Regression loss: 0.04244 | Running loss: 0.03793\n",
            "Epoch: 9 | Iteration: 241 | Classification loss: 0.00005 | Regression loss: 0.01417 | Running loss: 0.03791\n",
            "Epoch: 9 | Iteration: 242 | Classification loss: 0.00021 | Regression loss: 0.04230 | Running loss: 0.03797\n",
            "Epoch: 9 | Iteration: 243 | Classification loss: 0.00037 | Regression loss: 0.02920 | Running loss: 0.03799\n",
            "Epoch: 9 | Iteration: 244 | Classification loss: 0.00015 | Regression loss: 0.03411 | Running loss: 0.03802\n",
            "Epoch: 9 | Iteration: 245 | Classification loss: 0.00013 | Regression loss: 0.03068 | Running loss: 0.03801\n",
            "Epoch: 9 | Iteration: 246 | Classification loss: 0.00004 | Regression loss: 0.01686 | Running loss: 0.03802\n",
            "Epoch: 9 | Iteration: 247 | Classification loss: 0.00006 | Regression loss: 0.01522 | Running loss: 0.03802\n",
            "Epoch: 9 | Iteration: 248 | Classification loss: 0.00817 | Regression loss: 0.04213 | Running loss: 0.03809\n",
            "Epoch: 9 | Iteration: 249 | Classification loss: 0.00032 | Regression loss: 0.01402 | Running loss: 0.03809\n",
            "Epoch: 9 | Iteration: 250 | Classification loss: 0.00990 | Regression loss: 0.02958 | Running loss: 0.03811\n",
            "Epoch: 9 | Iteration: 251 | Classification loss: 0.00001 | Regression loss: 0.02250 | Running loss: 0.03812\n",
            "Epoch: 9 | Iteration: 252 | Classification loss: 0.00001 | Regression loss: 0.02132 | Running loss: 0.03813\n",
            "Epoch: 9 | Iteration: 253 | Classification loss: 0.00203 | Regression loss: 0.07919 | Running loss: 0.03822\n",
            "Epoch: 9 | Iteration: 254 | Classification loss: 0.00021 | Regression loss: 0.02223 | Running loss: 0.03824\n",
            "Epoch: 9 | Iteration: 255 | Classification loss: 0.00007 | Regression loss: 0.01530 | Running loss: 0.03820\n",
            "Epoch: 9 | Iteration: 256 | Classification loss: 0.00035 | Regression loss: 0.02046 | Running loss: 0.03821\n",
            "Epoch: 9 | Iteration: 257 | Classification loss: 0.00020 | Regression loss: 0.01475 | Running loss: 0.03818\n",
            "Epoch: 9 | Iteration: 258 | Classification loss: 0.00053 | Regression loss: 0.03552 | Running loss: 0.03821\n",
            "Epoch: 9 | Iteration: 259 | Classification loss: 0.00013 | Regression loss: 0.01858 | Running loss: 0.03820\n",
            "Epoch: 9 | Iteration: 260 | Classification loss: 0.00020 | Regression loss: 0.00866 | Running loss: 0.03817\n",
            "Epoch: 9 | Iteration: 261 | Classification loss: 0.00014 | Regression loss: 0.09597 | Running loss: 0.03832\n",
            "Epoch: 9 | Iteration: 262 | Classification loss: 0.00012 | Regression loss: 0.01907 | Running loss: 0.03827\n",
            "Epoch: 9 | Iteration: 263 | Classification loss: 0.00019 | Regression loss: 0.01761 | Running loss: 0.03827\n",
            "Epoch: 9 | Iteration: 264 | Classification loss: 0.00018 | Regression loss: 0.01736 | Running loss: 0.03827\n",
            "Epoch: 9 | Iteration: 265 | Classification loss: 0.00013 | Regression loss: 0.01758 | Running loss: 0.03828\n",
            "Epoch: 9 | Iteration: 266 | Classification loss: 0.00009 | Regression loss: 0.01404 | Running loss: 0.03806\n",
            "Epoch: 9 | Iteration: 267 | Classification loss: 0.00334 | Regression loss: 0.06389 | Running loss: 0.03813\n",
            "Epoch: 9 | Iteration: 268 | Classification loss: 0.00005 | Regression loss: 0.02038 | Running loss: 0.03814\n",
            "Epoch: 9 | Iteration: 269 | Classification loss: 0.00027 | Regression loss: 0.03690 | Running loss: 0.03814\n",
            "Epoch: 9 | Iteration: 270 | Classification loss: 0.00004 | Regression loss: 0.01978 | Running loss: 0.03815\n",
            "Epoch: 9 | Iteration: 271 | Classification loss: 0.00035 | Regression loss: 0.01500 | Running loss: 0.03802\n",
            "Epoch: 9 | Iteration: 272 | Classification loss: 0.00024 | Regression loss: 0.08318 | Running loss: 0.03815\n",
            "Epoch: 9 | Iteration: 273 | Classification loss: 0.00037 | Regression loss: 0.02345 | Running loss: 0.03811\n",
            "Epoch: 9 | Iteration: 274 | Classification loss: 0.00085 | Regression loss: 0.02324 | Running loss: 0.03811\n",
            "Epoch: 9 | Iteration: 275 | Classification loss: 0.19518 | Regression loss: 0.21352 | Running loss: 0.03882\n",
            "Epoch: 9 | Iteration: 276 | Classification loss: 0.00003 | Regression loss: 0.02485 | Running loss: 0.03882\n",
            "Epoch: 9 | Iteration: 277 | Classification loss: 0.00009 | Regression loss: 0.01477 | Running loss: 0.03879\n",
            "Epoch: 9 | Iteration: 278 | Classification loss: 0.00008 | Regression loss: 0.03262 | Running loss: 0.03877\n",
            "Epoch: 9 | Iteration: 279 | Classification loss: 0.13384 | Regression loss: 0.33853 | Running loss: 0.03968\n",
            "Epoch: 9 | Iteration: 280 | Classification loss: 0.00049 | Regression loss: 0.01486 | Running loss: 0.03968\n",
            "Epoch: 9 | Iteration: 281 | Classification loss: 0.00033 | Regression loss: 0.03473 | Running loss: 0.03967\n",
            "Epoch: 9 | Iteration: 282 | Classification loss: 0.00017 | Regression loss: 0.01449 | Running loss: 0.03966\n",
            "Epoch: 9 | Iteration: 283 | Classification loss: 0.00020 | Regression loss: 0.02121 | Running loss: 0.03965\n",
            "Epoch: 9 | Iteration: 284 | Classification loss: 0.00006 | Regression loss: 0.01635 | Running loss: 0.03958\n",
            "Epoch: 9 | Iteration: 285 | Classification loss: 0.00032 | Regression loss: 0.01592 | Running loss: 0.03957\n",
            "Epoch: 9 | Iteration: 286 | Classification loss: 0.00023 | Regression loss: 0.02177 | Running loss: 0.03956\n",
            "Epoch: 9 | Iteration: 287 | Classification loss: 0.00030 | Regression loss: 0.01774 | Running loss: 0.03955\n",
            "Epoch: 9 | Iteration: 288 | Classification loss: 0.00093 | Regression loss: 0.04344 | Running loss: 0.03962\n",
            "Epoch: 9 | Iteration: 289 | Classification loss: 0.00583 | Regression loss: 0.02801 | Running loss: 0.03964\n",
            "Epoch: 9 | Iteration: 290 | Classification loss: 0.00009 | Regression loss: 0.03964 | Running loss: 0.03963\n",
            "Epoch: 9 | Iteration: 291 | Classification loss: 0.00081 | Regression loss: 0.03389 | Running loss: 0.03965\n",
            "Epoch: 9 | Iteration: 292 | Classification loss: 0.00021 | Regression loss: 0.01891 | Running loss: 0.03964\n",
            "Epoch: 9 | Iteration: 293 | Classification loss: 0.00168 | Regression loss: 0.03266 | Running loss: 0.03965\n",
            "Epoch: 9 | Iteration: 294 | Classification loss: 0.00007 | Regression loss: 0.00447 | Running loss: 0.03960\n",
            "Epoch: 9 | Iteration: 295 | Classification loss: 0.00034 | Regression loss: 0.03083 | Running loss: 0.03959\n",
            "Epoch: 9 | Iteration: 296 | Classification loss: 0.30336 | Regression loss: 0.34004 | Running loss: 0.04079\n",
            "Epoch: 9 | Iteration: 297 | Classification loss: 0.00027 | Regression loss: 0.01524 | Running loss: 0.04079\n",
            "Epoch: 9 | Iteration: 298 | Classification loss: 0.00059 | Regression loss: 0.01802 | Running loss: 0.04076\n",
            "Epoch: 9 | Iteration: 299 | Classification loss: 0.00046 | Regression loss: 0.02180 | Running loss: 0.04077\n",
            "Epoch: 9 | Iteration: 300 | Classification loss: 0.00023 | Regression loss: 0.03466 | Running loss: 0.04077\n",
            "Epoch: 9 | Iteration: 301 | Classification loss: 0.00259 | Regression loss: 0.02256 | Running loss: 0.04078\n",
            "Epoch: 9 | Iteration: 302 | Classification loss: 0.00017 | Regression loss: 0.02523 | Running loss: 0.04077\n",
            "Epoch: 9 | Iteration: 303 | Classification loss: 0.06026 | Regression loss: 0.10196 | Running loss: 0.04103\n",
            "Epoch: 9 | Iteration: 304 | Classification loss: 0.00006 | Regression loss: 0.01804 | Running loss: 0.04065\n",
            "Epoch: 9 | Iteration: 305 | Classification loss: 0.00025 | Regression loss: 0.04622 | Running loss: 0.04064\n",
            "Epoch: 9 | Iteration: 306 | Classification loss: 0.00051 | Regression loss: 0.02471 | Running loss: 0.04054\n",
            "Epoch: 9 | Iteration: 307 | Classification loss: 0.00028 | Regression loss: 0.02159 | Running loss: 0.04051\n",
            "Epoch: 9 | Iteration: 308 | Classification loss: 0.00044 | Regression loss: 0.01533 | Running loss: 0.04048\n",
            "Epoch: 9 | Iteration: 309 | Classification loss: 0.00028 | Regression loss: 0.01245 | Running loss: 0.04046\n",
            "Epoch: 9 | Iteration: 310 | Classification loss: 0.00036 | Regression loss: 0.02579 | Running loss: 0.04048\n",
            "Epoch: 9 | Iteration: 311 | Classification loss: 0.00305 | Regression loss: 0.01385 | Running loss: 0.04045\n",
            "Epoch: 9 | Iteration: 312 | Classification loss: 0.00053 | Regression loss: 0.02816 | Running loss: 0.04049\n",
            "Epoch: 9 | Iteration: 313 | Classification loss: 0.00003 | Regression loss: 0.02540 | Running loss: 0.04050\n",
            "Epoch: 9 | Iteration: 314 | Classification loss: 0.00008 | Regression loss: 0.01247 | Running loss: 0.04043\n",
            "Epoch: 9 | Iteration: 315 | Classification loss: 0.00069 | Regression loss: 0.04091 | Running loss: 0.04047\n",
            "Epoch: 9 | Iteration: 316 | Classification loss: 0.00065 | Regression loss: 0.01397 | Running loss: 0.04039\n",
            "Epoch: 9 | Iteration: 317 | Classification loss: 0.00423 | Regression loss: 0.06921 | Running loss: 0.04045\n",
            "Epoch: 9 | Iteration: 318 | Classification loss: 0.00004 | Regression loss: 0.02538 | Running loss: 0.04048\n",
            "Epoch: 9 | Iteration: 319 | Classification loss: 0.00011 | Regression loss: 0.03665 | Running loss: 0.04053\n",
            "Epoch: 9 | Iteration: 320 | Classification loss: 0.00114 | Regression loss: 0.01375 | Running loss: 0.04050\n",
            "Epoch: 9 | Iteration: 321 | Classification loss: 0.00040 | Regression loss: 0.02679 | Running loss: 0.04051\n",
            "Epoch: 9 | Iteration: 322 | Classification loss: 0.00425 | Regression loss: 0.01902 | Running loss: 0.04051\n",
            "Epoch: 9 | Iteration: 323 | Classification loss: 0.00075 | Regression loss: 0.03128 | Running loss: 0.04050\n",
            "Epoch: 9 | Iteration: 324 | Classification loss: 0.00017 | Regression loss: 0.04615 | Running loss: 0.04055\n",
            "Epoch: 9 | Iteration: 325 | Classification loss: 0.00027 | Regression loss: 0.04548 | Running loss: 0.04058\n",
            "Epoch: 9 | Iteration: 326 | Classification loss: 0.00011 | Regression loss: 0.01874 | Running loss: 0.04057\n",
            "Epoch: 9 | Iteration: 327 | Classification loss: 0.00023 | Regression loss: 0.02045 | Running loss: 0.04056\n",
            "Epoch: 9 | Iteration: 328 | Classification loss: 0.00023 | Regression loss: 0.03791 | Running loss: 0.04059\n",
            "Epoch: 9 | Iteration: 329 | Classification loss: 0.00036 | Regression loss: 0.09035 | Running loss: 0.04072\n",
            "Epoch: 9 | Iteration: 330 | Classification loss: 0.00018 | Regression loss: 0.02517 | Running loss: 0.04075\n",
            "Epoch: 9 | Iteration: 331 | Classification loss: 0.08523 | Regression loss: 0.06742 | Running loss: 0.04104\n",
            "Epoch: 9 | Iteration: 332 | Classification loss: 0.00013 | Regression loss: 0.03259 | Running loss: 0.04104\n",
            "Epoch: 9 | Iteration: 333 | Classification loss: 0.00022 | Regression loss: 0.02435 | Running loss: 0.04080\n",
            "Epoch: 9 | Iteration: 334 | Classification loss: 0.00036 | Regression loss: 0.02010 | Running loss: 0.04078\n",
            "Epoch: 9 | Iteration: 335 | Classification loss: 0.00010 | Regression loss: 0.01891 | Running loss: 0.04021\n",
            "Epoch: 9 | Iteration: 336 | Classification loss: 0.00010 | Regression loss: 0.01815 | Running loss: 0.04020\n",
            "Epoch: 9 | Iteration: 337 | Classification loss: 0.00204 | Regression loss: 0.03480 | Running loss: 0.04021\n",
            "Epoch: 9 | Iteration: 338 | Classification loss: 0.00069 | Regression loss: 0.04234 | Running loss: 0.04024\n",
            "Epoch: 9 | Iteration: 339 | Classification loss: 0.11472 | Regression loss: 0.21772 | Running loss: 0.04088\n",
            "Epoch: 9 | Iteration: 340 | Classification loss: 0.00101 | Regression loss: 0.03742 | Running loss: 0.04092\n",
            "Epoch: 9 | Iteration: 341 | Classification loss: 0.00006 | Regression loss: 0.04274 | Running loss: 0.04096\n",
            "Epoch: 9 | Iteration: 342 | Classification loss: 0.00009 | Regression loss: 0.03358 | Running loss: 0.04096\n",
            "Epoch: 9 | Iteration: 343 | Classification loss: 0.00031 | Regression loss: 0.02198 | Running loss: 0.04095\n",
            "Epoch: 9 | Iteration: 344 | Classification loss: 0.00004 | Regression loss: 0.01538 | Running loss: 0.04093\n",
            "Epoch: 9 | Iteration: 345 | Classification loss: 0.00004 | Regression loss: 0.02384 | Running loss: 0.04095\n",
            "Epoch: 9 | Iteration: 346 | Classification loss: 0.00008 | Regression loss: 0.01370 | Running loss: 0.04094\n",
            "Epoch: 9 | Iteration: 347 | Classification loss: 0.01727 | Regression loss: 0.05915 | Running loss: 0.04099\n",
            "Epoch: 9 | Iteration: 348 | Classification loss: 0.00018 | Regression loss: 0.01602 | Running loss: 0.04090\n",
            "Epoch: 9 | Iteration: 349 | Classification loss: 0.00037 | Regression loss: 0.03844 | Running loss: 0.04094\n",
            "Epoch: 9 | Iteration: 350 | Classification loss: 0.00362 | Regression loss: 0.12090 | Running loss: 0.04114\n",
            "Epoch: 9 | Iteration: 351 | Classification loss: 0.00019 | Regression loss: 0.01724 | Running loss: 0.04114\n",
            "Epoch: 9 | Iteration: 352 | Classification loss: 0.00015 | Regression loss: 0.01783 | Running loss: 0.04114\n",
            "Epoch: 9 | Iteration: 353 | Classification loss: 0.00014 | Regression loss: 0.01536 | Running loss: 0.04109\n",
            "Epoch: 9 | Iteration: 354 | Classification loss: 0.00009 | Regression loss: 0.01897 | Running loss: 0.04107\n",
            "Epoch: 9 | Iteration: 355 | Classification loss: 0.00050 | Regression loss: 0.01800 | Running loss: 0.04101\n",
            "Epoch: 9 | Iteration: 356 | Classification loss: 0.00005 | Regression loss: 0.03567 | Running loss: 0.04103\n",
            "Epoch: 9 | Iteration: 357 | Classification loss: 0.00005 | Regression loss: 0.03041 | Running loss: 0.04106\n",
            "Epoch: 9 | Iteration: 358 | Classification loss: 0.00032 | Regression loss: 0.02407 | Running loss: 0.04104\n",
            "Epoch: 9 | Iteration: 359 | Classification loss: 0.00012 | Regression loss: 0.01455 | Running loss: 0.04102\n",
            "Epoch: 9 | Iteration: 360 | Classification loss: 0.00025 | Regression loss: 0.04312 | Running loss: 0.04094\n",
            "Epoch: 9 | Iteration: 361 | Classification loss: 0.00089 | Regression loss: 0.01403 | Running loss: 0.04092\n",
            "Epoch: 9 | Iteration: 362 | Classification loss: 0.00021 | Regression loss: 0.02135 | Running loss: 0.04086\n",
            "Epoch: 9 | Iteration: 363 | Classification loss: 0.25682 | Regression loss: 0.24763 | Running loss: 0.04184\n",
            "Epoch: 9 | Iteration: 364 | Classification loss: 0.00009 | Regression loss: 0.02368 | Running loss: 0.04182\n",
            "Epoch: 9 | Iteration: 365 | Classification loss: 0.00010 | Regression loss: 0.01008 | Running loss: 0.04177\n",
            "Epoch: 9 | Iteration: 366 | Classification loss: 0.02064 | Regression loss: 0.05834 | Running loss: 0.04191\n",
            "Epoch: 9 | Iteration: 367 | Classification loss: 0.00026 | Regression loss: 0.01643 | Running loss: 0.04076\n",
            "Epoch: 9 | Iteration: 368 | Classification loss: 0.00580 | Regression loss: 0.02521 | Running loss: 0.04078\n",
            "Epoch: 9 | Iteration: 369 | Classification loss: 0.00025 | Regression loss: 0.01058 | Running loss: 0.04076\n",
            "Epoch: 9 | Iteration: 370 | Classification loss: 0.00007 | Regression loss: 0.02714 | Running loss: 0.04060\n",
            "Epoch: 9 | Iteration: 371 | Classification loss: 0.00029 | Regression loss: 0.02029 | Running loss: 0.04054\n",
            "Epoch: 9 | Iteration: 372 | Classification loss: 0.00011 | Regression loss: 0.02784 | Running loss: 0.04050\n",
            "Epoch: 9 | Iteration: 373 | Classification loss: 0.00216 | Regression loss: 0.06817 | Running loss: 0.04061\n",
            "Epoch: 9 | Iteration: 374 | Classification loss: 0.00221 | Regression loss: 0.03356 | Running loss: 0.04049\n",
            "Epoch: 9 | Iteration: 375 | Classification loss: 0.00027 | Regression loss: 0.01205 | Running loss: 0.04046\n",
            "Epoch: 9 | Iteration: 376 | Classification loss: 0.00010 | Regression loss: 0.03157 | Running loss: 0.04047\n",
            "Epoch: 9 | Iteration: 377 | Classification loss: 0.00021 | Regression loss: 0.01538 | Running loss: 0.04045\n",
            "Epoch: 9 | Iteration: 378 | Classification loss: 0.00009 | Regression loss: 0.01229 | Running loss: 0.04042\n",
            "Epoch: 9 | Iteration: 379 | Classification loss: 0.00061 | Regression loss: 0.01840 | Running loss: 0.04041\n",
            "Epoch: 9 | Iteration: 380 | Classification loss: 0.00017 | Regression loss: 0.02201 | Running loss: 0.04009\n",
            "Epoch: 9 | Iteration: 381 | Classification loss: 0.00041 | Regression loss: 0.02317 | Running loss: 0.04012\n",
            "Epoch: 9 | Iteration: 382 | Classification loss: 0.00018 | Regression loss: 0.02890 | Running loss: 0.04016\n",
            "Epoch: 9 | Iteration: 383 | Classification loss: 0.00033 | Regression loss: 0.04058 | Running loss: 0.04022\n",
            "Epoch: 9 | Iteration: 384 | Classification loss: 0.00033 | Regression loss: 0.02599 | Running loss: 0.04023\n",
            "Epoch: 9 | Iteration: 385 | Classification loss: 0.00035 | Regression loss: 0.03445 | Running loss: 0.04026\n",
            "Epoch: 9 | Iteration: 386 | Classification loss: 0.00231 | Regression loss: 0.04275 | Running loss: 0.04032\n",
            "Epoch: 9 | Iteration: 387 | Classification loss: 0.00258 | Regression loss: 0.03632 | Running loss: 0.04037\n",
            "Epoch: 9 | Iteration: 388 | Classification loss: 0.00020 | Regression loss: 0.02056 | Running loss: 0.04038\n",
            "Epoch: 9 | Iteration: 389 | Classification loss: 0.00018 | Regression loss: 0.01194 | Running loss: 0.04034\n",
            "Epoch: 9 | Iteration: 390 | Classification loss: 0.00008 | Regression loss: 0.02501 | Running loss: 0.04036\n",
            "Epoch: 9 | Iteration: 391 | Classification loss: 0.00041 | Regression loss: 0.01803 | Running loss: 0.04035\n",
            "Epoch: 9 | Iteration: 392 | Classification loss: 0.00004 | Regression loss: 0.02678 | Running loss: 0.04035\n",
            "Epoch: 9 | Iteration: 393 | Classification loss: 0.14715 | Regression loss: 0.31416 | Running loss: 0.04122\n",
            "Epoch: 9 | Iteration: 394 | Classification loss: 0.00071 | Regression loss: 0.01889 | Running loss: 0.04122\n",
            "Epoch: 9 | Iteration: 395 | Classification loss: 0.00066 | Regression loss: 0.04294 | Running loss: 0.04125\n",
            "Epoch: 9 | Iteration: 396 | Classification loss: 0.00015 | Regression loss: 0.03990 | Running loss: 0.04129\n",
            "Epoch: 9 | Iteration: 397 | Classification loss: 0.00004 | Regression loss: 0.01423 | Running loss: 0.04125\n",
            "Epoch: 9 | Iteration: 398 | Classification loss: 0.00077 | Regression loss: 0.01635 | Running loss: 0.04123\n",
            "Epoch: 9 | Iteration: 399 | Classification loss: 0.00007 | Regression loss: 0.01346 | Running loss: 0.04117\n",
            "Epoch: 9 | Iteration: 400 | Classification loss: 0.00130 | Regression loss: 0.02763 | Running loss: 0.04120\n",
            "Epoch: 9 | Iteration: 401 | Classification loss: 0.00024 | Regression loss: 0.05311 | Running loss: 0.04127\n",
            "Epoch: 9 | Iteration: 402 | Classification loss: 0.00011 | Regression loss: 0.00943 | Running loss: 0.03943\n",
            "Epoch: 9 | Iteration: 403 | Classification loss: 0.00004 | Regression loss: 0.00904 | Running loss: 0.03937\n",
            "Epoch: 9 | Iteration: 404 | Classification loss: 0.00006 | Regression loss: 0.02222 | Running loss: 0.03927\n",
            "Epoch: 9 | Iteration: 405 | Classification loss: 0.00020 | Regression loss: 0.02663 | Running loss: 0.03913\n",
            "Epoch: 9 | Iteration: 406 | Classification loss: 0.00237 | Regression loss: 0.05306 | Running loss: 0.03912\n",
            "Epoch: 9 | Iteration: 407 | Classification loss: 0.00118 | Regression loss: 0.02731 | Running loss: 0.03910\n",
            "Epoch: 9 | Iteration: 408 | Classification loss: 0.00072 | Regression loss: 0.02848 | Running loss: 0.03911\n",
            "Epoch: 9 | Iteration: 409 | Classification loss: 0.00015 | Regression loss: 0.01089 | Running loss: 0.03863\n",
            "Epoch: 9 | Iteration: 410 | Classification loss: 0.00006 | Regression loss: 0.02257 | Running loss: 0.03863\n",
            "Epoch: 9 | Iteration: 411 | Classification loss: 0.00011 | Regression loss: 0.02005 | Running loss: 0.03860\n",
            "Epoch: 9 | Iteration: 412 | Classification loss: 0.00008 | Regression loss: 0.02448 | Running loss: 0.03859\n",
            "Epoch: 9 | Iteration: 413 | Classification loss: 0.00036 | Regression loss: 0.04012 | Running loss: 0.03861\n",
            "Epoch: 9 | Iteration: 414 | Classification loss: 0.00004 | Regression loss: 0.01129 | Running loss: 0.03857\n",
            "Epoch: 9 | Iteration: 415 | Classification loss: 0.00231 | Regression loss: 0.07748 | Running loss: 0.03868\n",
            "Epoch: 9 | Iteration: 416 | Classification loss: 0.00034 | Regression loss: 0.05385 | Running loss: 0.03874\n",
            "Epoch: 9 | Iteration: 417 | Classification loss: 0.00005 | Regression loss: 0.01774 | Running loss: 0.03875\n",
            "Epoch: 9 | Iteration: 418 | Classification loss: 0.00011 | Regression loss: 0.03287 | Running loss: 0.03874\n",
            "Epoch: 9 | Iteration: 419 | Classification loss: 0.00095 | Regression loss: 0.05370 | Running loss: 0.03881\n",
            "Epoch: 9 | Iteration: 420 | Classification loss: 0.00027 | Regression loss: 0.03638 | Running loss: 0.03884\n",
            "Epoch: 9 | Iteration: 421 | Classification loss: 0.00005 | Regression loss: 0.04307 | Running loss: 0.03889\n",
            "Epoch: 9 | Iteration: 422 | Classification loss: 0.00005 | Regression loss: 0.01863 | Running loss: 0.03890\n",
            "Epoch: 9 | Iteration: 423 | Classification loss: 0.00022 | Regression loss: 0.03614 | Running loss: 0.03893\n",
            "Epoch: 9 | Iteration: 424 | Classification loss: 0.00029 | Regression loss: 0.02093 | Running loss: 0.03893\n",
            "Epoch: 9 | Iteration: 425 | Classification loss: 0.00009 | Regression loss: 0.01302 | Running loss: 0.03889\n",
            "Epoch: 9 | Iteration: 426 | Classification loss: 0.00006 | Regression loss: 0.03819 | Running loss: 0.03892\n",
            "Epoch: 9 | Iteration: 427 | Classification loss: 0.00038 | Regression loss: 0.04820 | Running loss: 0.03895\n",
            "Epoch: 9 | Iteration: 428 | Classification loss: 0.00473 | Regression loss: 0.04867 | Running loss: 0.03898\n",
            "Epoch: 9 | Iteration: 429 | Classification loss: 0.00107 | Regression loss: 0.03660 | Running loss: 0.03901\n",
            "Epoch: 9 | Iteration: 430 | Classification loss: 0.00078 | Regression loss: 0.02362 | Running loss: 0.03882\n",
            "Epoch: 9 | Iteration: 431 | Classification loss: 0.00005 | Regression loss: 0.03372 | Running loss: 0.03881\n",
            "Epoch: 9 | Iteration: 432 | Classification loss: 0.00008 | Regression loss: 0.02685 | Running loss: 0.03879\n",
            "Epoch: 9 | Iteration: 433 | Classification loss: 0.00088 | Regression loss: 0.09365 | Running loss: 0.03894\n",
            "Epoch: 9 | Iteration: 434 | Classification loss: 0.00016 | Regression loss: 0.02450 | Running loss: 0.03891\n",
            "Epoch: 9 | Iteration: 435 | Classification loss: 0.00026 | Regression loss: 0.02110 | Running loss: 0.03892\n",
            "Epoch: 9 | Iteration: 436 | Classification loss: 0.00002 | Regression loss: 0.02331 | Running loss: 0.03892\n",
            "Epoch: 9 | Iteration: 437 | Classification loss: 0.00048 | Regression loss: 0.02542 | Running loss: 0.03893\n",
            "Epoch: 9 | Iteration: 438 | Classification loss: 0.00017 | Regression loss: 0.02601 | Running loss: 0.03873\n",
            "Epoch: 9 | Iteration: 439 | Classification loss: 0.00003 | Regression loss: 0.02127 | Running loss: 0.03872\n",
            "Epoch: 9 | Iteration: 440 | Classification loss: 0.04596 | Regression loss: 0.04709 | Running loss: 0.03884\n",
            "Epoch: 9 | Iteration: 441 | Classification loss: 0.00033 | Regression loss: 0.07088 | Running loss: 0.03894\n",
            "Epoch: 9 | Iteration: 442 | Classification loss: 0.00118 | Regression loss: 0.02531 | Running loss: 0.03894\n",
            "Epoch: 9 | Iteration: 443 | Classification loss: 0.00031 | Regression loss: 0.02545 | Running loss: 0.03893\n",
            "Epoch: 9 | Iteration: 444 | Classification loss: 0.00006 | Regression loss: 0.01067 | Running loss: 0.03891\n",
            "Epoch: 9 | Iteration: 445 | Classification loss: 0.00002 | Regression loss: 0.02139 | Running loss: 0.03893\n",
            "Epoch: 9 | Iteration: 446 | Classification loss: 0.00018 | Regression loss: 0.01785 | Running loss: 0.03892\n",
            "Epoch: 9 | Iteration: 447 | Classification loss: 0.00005 | Regression loss: 0.01037 | Running loss: 0.03888\n",
            "Epoch: 9 | Iteration: 448 | Classification loss: 0.00007 | Regression loss: 0.03432 | Running loss: 0.03892\n",
            "Epoch: 9 | Iteration: 449 | Classification loss: 0.00005 | Regression loss: 0.02797 | Running loss: 0.03890\n",
            "Epoch: 9 | Iteration: 450 | Classification loss: 0.00003 | Regression loss: 0.02785 | Running loss: 0.03891\n",
            "Epoch: 9 | Iteration: 451 | Classification loss: 0.00005 | Regression loss: 0.02948 | Running loss: 0.03895\n",
            "Epoch: 9 | Iteration: 452 | Classification loss: 0.00018 | Regression loss: 0.02732 | Running loss: 0.03893\n",
            "Epoch: 9 | Iteration: 453 | Classification loss: 0.00065 | Regression loss: 0.03434 | Running loss: 0.03899\n",
            "Epoch: 9 | Iteration: 454 | Classification loss: 0.00014 | Regression loss: 0.01953 | Running loss: 0.03898\n",
            "Epoch: 9 | Iteration: 455 | Classification loss: 0.00004 | Regression loss: 0.01472 | Running loss: 0.03898\n",
            "Epoch: 9 | Iteration: 456 | Classification loss: 0.00007 | Regression loss: 0.03915 | Running loss: 0.03902\n",
            "Epoch: 9 | Iteration: 457 | Classification loss: 0.00024 | Regression loss: 0.03012 | Running loss: 0.03904\n",
            "Epoch: 9 | Iteration: 458 | Classification loss: 0.00504 | Regression loss: 0.01957 | Running loss: 0.03905\n",
            "Epoch: 9 | Iteration: 459 | Classification loss: 0.00025 | Regression loss: 0.04985 | Running loss: 0.03910\n",
            "Epoch: 9 | Iteration: 460 | Classification loss: 0.00011 | Regression loss: 0.02039 | Running loss: 0.03909\n",
            "Epoch: 9 | Iteration: 461 | Classification loss: 0.00008 | Regression loss: 0.02709 | Running loss: 0.03910\n",
            "Epoch: 9 | Iteration: 462 | Classification loss: 0.09211 | Regression loss: 0.07271 | Running loss: 0.03938\n",
            "Epoch: 9 | Iteration: 463 | Classification loss: 0.00003 | Regression loss: 0.03329 | Running loss: 0.03943\n",
            "Epoch: 9 | Iteration: 464 | Classification loss: 0.03867 | Regression loss: 0.05561 | Running loss: 0.03956\n",
            "Epoch: 9 | Iteration: 465 | Classification loss: 0.00005 | Regression loss: 0.03597 | Running loss: 0.03957\n",
            "Epoch: 9 | Iteration: 466 | Classification loss: 0.00003 | Regression loss: 0.01890 | Running loss: 0.03955\n",
            "Epoch: 9 | Iteration: 467 | Classification loss: 0.00036 | Regression loss: 0.04283 | Running loss: 0.03954\n",
            "Epoch: 9 | Iteration: 468 | Classification loss: 0.00010 | Regression loss: 0.02771 | Running loss: 0.03956\n",
            "Epoch: 9 | Iteration: 469 | Classification loss: 0.00008 | Regression loss: 0.01103 | Running loss: 0.03954\n",
            "Epoch: 9 | Iteration: 470 | Classification loss: 0.00006 | Regression loss: 0.03665 | Running loss: 0.03955\n",
            "Epoch: 9 | Iteration: 471 | Classification loss: 0.05058 | Regression loss: 0.01997 | Running loss: 0.03966\n",
            "Epoch: 9 | Iteration: 472 | Classification loss: 0.00178 | Regression loss: 0.01474 | Running loss: 0.03963\n",
            "Epoch: 9 | Iteration: 473 | Classification loss: 0.00007 | Regression loss: 0.02180 | Running loss: 0.03959\n",
            "Epoch: 9 | Iteration: 474 | Classification loss: 0.00010 | Regression loss: 0.01400 | Running loss: 0.03959\n",
            "Epoch: 9 | Iteration: 475 | Classification loss: 0.00049 | Regression loss: 0.03929 | Running loss: 0.03956\n",
            "Epoch: 9 | Iteration: 476 | Classification loss: 0.02578 | Regression loss: 0.10552 | Running loss: 0.03977\n",
            "Epoch: 9 | Iteration: 477 | Classification loss: 0.00044 | Regression loss: 0.01086 | Running loss: 0.03975\n",
            "Epoch: 9 | Iteration: 478 | Classification loss: 0.00180 | Regression loss: 0.02161 | Running loss: 0.03971\n",
            "Epoch: 9 | Iteration: 479 | Classification loss: 0.00005 | Regression loss: 0.01364 | Running loss: 0.03965\n",
            "Epoch: 9 | Iteration: 480 | Classification loss: 0.00006 | Regression loss: 0.01179 | Running loss: 0.03963\n",
            "Epoch: 9 | Iteration: 481 | Classification loss: 0.00057 | Regression loss: 0.04621 | Running loss: 0.03967\n",
            "Epoch: 9 | Iteration: 482 | Classification loss: 0.00006 | Regression loss: 0.01607 | Running loss: 0.03967\n",
            "Epoch: 9 | Iteration: 483 | Classification loss: 0.01956 | Regression loss: 0.05968 | Running loss: 0.03973\n",
            "Epoch: 9 | Iteration: 484 | Classification loss: 0.22392 | Regression loss: 0.06502 | Running loss: 0.04026\n",
            "Epoch: 9 | Iteration: 485 | Classification loss: 0.00017 | Regression loss: 0.01955 | Running loss: 0.04025\n",
            "Epoch: 9 | Iteration: 486 | Classification loss: 0.00081 | Regression loss: 0.02704 | Running loss: 0.04017\n",
            "Epoch: 9 | Iteration: 487 | Classification loss: 0.00002 | Regression loss: 0.02801 | Running loss: 0.04020\n",
            "Epoch: 9 | Iteration: 488 | Classification loss: 0.00036 | Regression loss: 0.02507 | Running loss: 0.04019\n",
            "Epoch: 9 | Iteration: 489 | Classification loss: 0.00011 | Regression loss: 0.02580 | Running loss: 0.04021\n",
            "Epoch: 9 | Iteration: 490 | Classification loss: 0.02453 | Regression loss: 0.03919 | Running loss: 0.04029\n",
            "Epoch: 9 | Iteration: 491 | Classification loss: 0.00240 | Regression loss: 0.05040 | Running loss: 0.04036\n",
            "Epoch: 9 | Iteration: 492 | Classification loss: 0.00009 | Regression loss: 0.01750 | Running loss: 0.04035\n",
            "Epoch: 9 | Iteration: 493 | Classification loss: 0.00058 | Regression loss: 0.03959 | Running loss: 0.04036\n",
            "Epoch: 9 | Iteration: 494 | Classification loss: 0.00028 | Regression loss: 0.00971 | Running loss: 0.04034\n",
            "Epoch: 9 | Iteration: 495 | Classification loss: 0.00010 | Regression loss: 0.02620 | Running loss: 0.04037\n",
            "Epoch: 9 | Iteration: 496 | Classification loss: 0.00815 | Regression loss: 0.02790 | Running loss: 0.04039\n",
            "Epoch: 9 | Iteration: 497 | Classification loss: 0.00023 | Regression loss: 0.01755 | Running loss: 0.04038\n",
            "Epoch: 9 | Iteration: 498 | Classification loss: 0.00133 | Regression loss: 0.03137 | Running loss: 0.04040\n",
            "Epoch: 9 | Iteration: 499 | Classification loss: 0.00002 | Regression loss: 0.01000 | Running loss: 0.04037\n",
            "Epoch: 9 | Iteration: 500 | Classification loss: 0.00046 | Regression loss: 0.03991 | Running loss: 0.04043\n",
            "Epoch: 9 | Iteration: 501 | Classification loss: 0.00848 | Regression loss: 0.04693 | Running loss: 0.04045\n",
            "Epoch: 9 | Iteration: 502 | Classification loss: 0.00023 | Regression loss: 0.03448 | Running loss: 0.04043\n",
            "Epoch: 9 | Iteration: 503 | Classification loss: 0.00003 | Regression loss: 0.04587 | Running loss: 0.04047\n",
            "Epoch: 9 | Iteration: 504 | Classification loss: 0.00415 | Regression loss: 0.05970 | Running loss: 0.04054\n",
            "Epoch: 9 | Iteration: 505 | Classification loss: 0.01687 | Regression loss: 0.02859 | Running loss: 0.04049\n",
            "Epoch: 9 | Iteration: 506 | Classification loss: 0.00016 | Regression loss: 0.04714 | Running loss: 0.04034\n",
            "Epoch: 9 | Iteration: 507 | Classification loss: 0.00008 | Regression loss: 0.02136 | Running loss: 0.04029\n",
            "Epoch: 9 | Iteration: 508 | Classification loss: 0.00010 | Regression loss: 0.00827 | Running loss: 0.04024\n",
            "Epoch: 9 | Iteration: 509 | Classification loss: 0.00004 | Regression loss: 0.02093 | Running loss: 0.04018\n",
            "Epoch: 9 | Iteration: 510 | Classification loss: 0.00780 | Regression loss: 0.04032 | Running loss: 0.03995\n",
            "Epoch: 9 | Iteration: 511 | Classification loss: 0.00011 | Regression loss: 0.02132 | Running loss: 0.03995\n",
            "Epoch: 9 | Iteration: 512 | Classification loss: 0.00022 | Regression loss: 0.02632 | Running loss: 0.03995\n",
            "Epoch: 9 | Iteration: 513 | Classification loss: 0.00033 | Regression loss: 0.03760 | Running loss: 0.03990\n",
            "Epoch: 9 | Iteration: 514 | Classification loss: 0.00075 | Regression loss: 0.02131 | Running loss: 0.03989\n",
            "Epoch: 9 | Iteration: 515 | Classification loss: 0.00040 | Regression loss: 0.04106 | Running loss: 0.03993\n",
            "Epoch: 9 | Iteration: 516 | Classification loss: 0.00107 | Regression loss: 0.03097 | Running loss: 0.03991\n",
            "Epoch: 9 | Iteration: 517 | Classification loss: 0.00095 | Regression loss: 0.04358 | Running loss: 0.03994\n",
            "Epoch: 9 | Iteration: 518 | Classification loss: 0.00069 | Regression loss: 0.02481 | Running loss: 0.03994\n",
            "Epoch: 9 | Iteration: 519 | Classification loss: 0.00054 | Regression loss: 0.02628 | Running loss: 0.03998\n",
            "Epoch: 9 | Iteration: 520 | Classification loss: 0.00065 | Regression loss: 0.03197 | Running loss: 0.04002\n",
            "Epoch: 9 | Iteration: 521 | Classification loss: 0.00094 | Regression loss: 0.07375 | Running loss: 0.04013\n",
            "Epoch: 9 | Iteration: 522 | Classification loss: 0.00044 | Regression loss: 0.02548 | Running loss: 0.04016\n",
            "Epoch: 9 | Iteration: 523 | Classification loss: 0.00021 | Regression loss: 0.01435 | Running loss: 0.04016\n",
            "Epoch: 9 | Iteration: 524 | Classification loss: 0.00134 | Regression loss: 0.02493 | Running loss: 0.04020\n",
            "Epoch: 9 | Iteration: 525 | Classification loss: 0.00002 | Regression loss: 0.02792 | Running loss: 0.04019\n",
            "Epoch: 9 | Iteration: 526 | Classification loss: 0.00012 | Regression loss: 0.02492 | Running loss: 0.04015\n",
            "Epoch: 9 | Iteration: 527 | Classification loss: 0.00193 | Regression loss: 0.05069 | Running loss: 0.03893\n",
            "Epoch: 9 | Iteration: 528 | Classification loss: 0.00022 | Regression loss: 0.01442 | Running loss: 0.03890\n",
            "Epoch: 9 | Iteration: 529 | Classification loss: 0.01225 | Regression loss: 0.01663 | Running loss: 0.03891\n",
            "Epoch: 9 | Iteration: 530 | Classification loss: 0.00614 | Regression loss: 0.01353 | Running loss: 0.03887\n",
            "Epoch: 9 | Iteration: 531 | Classification loss: 1.65493 | Regression loss: 0.03192 | Running loss: 0.04220\n",
            "Epoch: 9 | Iteration: 532 | Classification loss: 0.00023 | Regression loss: 0.01731 | Running loss: 0.04217\n",
            "Epoch: 9 | Iteration: 533 | Classification loss: 0.00043 | Regression loss: 0.01479 | Running loss: 0.04217\n",
            "Epoch: 9 | Iteration: 534 | Classification loss: 0.00018 | Regression loss: 0.02328 | Running loss: 0.04217\n",
            "Epoch: 9 | Iteration: 535 | Classification loss: 0.00053 | Regression loss: 0.01906 | Running loss: 0.04212\n",
            "Epoch: 9 | Iteration: 536 | Classification loss: 0.00012 | Regression loss: 0.02111 | Running loss: 0.04213\n",
            "Epoch: 9 | Iteration: 537 | Classification loss: 0.00009 | Regression loss: 0.02110 | Running loss: 0.04208\n",
            "Epoch: 9 | Iteration: 538 | Classification loss: 0.12746 | Regression loss: 0.03966 | Running loss: 0.04237\n",
            "Epoch: 9 | Iteration: 539 | Classification loss: 0.00102 | Regression loss: 0.07096 | Running loss: 0.04241\n",
            "Epoch: 9 | Iteration: 540 | Classification loss: 0.00066 | Regression loss: 0.02142 | Running loss: 0.04239\n",
            "Epoch: 9 | Iteration: 541 | Classification loss: 0.00845 | Regression loss: 0.07434 | Running loss: 0.04252\n",
            "Epoch: 9 | Iteration: 542 | Classification loss: 0.00008 | Regression loss: 0.03723 | Running loss: 0.04241\n",
            "Epoch: 9 | Iteration: 543 | Classification loss: 0.00067 | Regression loss: 0.02240 | Running loss: 0.04243\n",
            "Epoch: 9 | Iteration: 544 | Classification loss: 0.00026 | Regression loss: 0.03098 | Running loss: 0.04245\n",
            "Epoch: 9 | Iteration: 545 | Classification loss: 0.00018 | Regression loss: 0.02359 | Running loss: 0.04246\n",
            "Epoch: 9 | Iteration: 546 | Classification loss: 0.00009 | Regression loss: 0.02072 | Running loss: 0.04245\n",
            "Epoch: 9 | Iteration: 547 | Classification loss: 0.00111 | Regression loss: 0.05912 | Running loss: 0.04252\n",
            "Epoch: 9 | Iteration: 548 | Classification loss: 0.24959 | Regression loss: 0.03190 | Running loss: 0.04303\n",
            "Epoch: 9 | Iteration: 549 | Classification loss: 0.02450 | Regression loss: 0.02870 | Running loss: 0.04308\n",
            "Epoch: 9 | Iteration: 550 | Classification loss: 0.08525 | Regression loss: 0.02601 | Running loss: 0.04323\n",
            "Epoch: 9 | Iteration: 551 | Classification loss: 0.00146 | Regression loss: 0.04396 | Running loss: 0.04328\n",
            "Epoch: 9 | Iteration: 552 | Classification loss: 0.84157 | Regression loss: 0.01456 | Running loss: 0.04491\n",
            "Epoch: 9 | Iteration: 553 | Classification loss: 0.00065 | Regression loss: 0.02845 | Running loss: 0.04491\n",
            "Epoch: 9 | Iteration: 554 | Classification loss: 0.00175 | Regression loss: 0.02142 | Running loss: 0.04488\n",
            "Epoch: 9 | Iteration: 555 | Classification loss: 0.00022 | Regression loss: 0.01254 | Running loss: 0.04488\n",
            "Epoch: 9 | Iteration: 556 | Classification loss: 0.00247 | Regression loss: 0.04311 | Running loss: 0.04493\n",
            "Epoch: 9 | Iteration: 557 | Classification loss: 0.00099 | Regression loss: 0.02964 | Running loss: 0.04489\n",
            "Epoch: 9 | Iteration: 558 | Classification loss: 0.00090 | Regression loss: 0.03056 | Running loss: 0.04492\n",
            "Epoch: 9 | Iteration: 559 | Classification loss: 0.04010 | Regression loss: 0.02065 | Running loss: 0.04500\n",
            "Epoch: 9 | Iteration: 560 | Classification loss: 0.00191 | Regression loss: 0.01147 | Running loss: 0.04492\n",
            "Epoch: 9 | Iteration: 561 | Classification loss: 0.00176 | Regression loss: 0.02574 | Running loss: 0.04412\n",
            "Epoch: 9 | Iteration: 562 | Classification loss: 0.00230 | Regression loss: 0.01958 | Running loss: 0.04412\n",
            "Epoch: 9 | Iteration: 563 | Classification loss: 0.00025 | Regression loss: 0.02159 | Running loss: 0.04413\n",
            "Epoch: 9 | Iteration: 564 | Classification loss: 0.00622 | Regression loss: 0.03555 | Running loss: 0.04414\n",
            "Epoch: 9 | Iteration: 565 | Classification loss: 0.16503 | Regression loss: 0.01640 | Running loss: 0.04443\n",
            "Epoch: 9 | Iteration: 566 | Classification loss: 0.00715 | Regression loss: 0.02338 | Running loss: 0.04441\n",
            "Epoch: 9 | Iteration: 567 | Classification loss: 0.00036 | Regression loss: 0.04874 | Running loss: 0.04448\n",
            "Epoch: 9 | Iteration: 568 | Classification loss: 0.00082 | Regression loss: 0.03294 | Running loss: 0.04435\n",
            "Epoch: 9 | Iteration: 569 | Classification loss: 0.13326 | Regression loss: 0.03465 | Running loss: 0.04454\n",
            "Epoch: 9 | Iteration: 570 | Classification loss: 0.00357 | Regression loss: 0.03530 | Running loss: 0.04454\n",
            "Epoch: 9 | Iteration: 571 | Classification loss: 0.00202 | Regression loss: 0.02113 | Running loss: 0.04453\n",
            "Epoch: 9 | Iteration: 572 | Classification loss: 0.00086 | Regression loss: 0.01926 | Running loss: 0.04453\n",
            "Epoch: 9 | Iteration: 573 | Classification loss: 0.00111 | Regression loss: 0.02415 | Running loss: 0.04450\n",
            "Epoch: 9 | Iteration: 574 | Classification loss: 0.00350 | Regression loss: 0.03275 | Running loss: 0.04451\n",
            "Epoch: 9 | Iteration: 575 | Classification loss: 0.00790 | Regression loss: 0.02034 | Running loss: 0.04435\n",
            "Epoch: 9 | Iteration: 576 | Classification loss: 0.00014 | Regression loss: 0.02593 | Running loss: 0.04420\n",
            "Epoch: 9 | Iteration: 577 | Classification loss: 0.00553 | Regression loss: 0.05092 | Running loss: 0.04418\n",
            "Epoch: 9 | Iteration: 578 | Classification loss: 0.01081 | Regression loss: 0.03665 | Running loss: 0.04398\n",
            "Epoch: 9 | Iteration: 579 | Classification loss: 0.02148 | Regression loss: 0.02545 | Running loss: 0.04402\n",
            "Epoch: 9 | Iteration: 580 | Classification loss: 0.00008 | Regression loss: 0.02944 | Running loss: 0.04398\n",
            "Epoch: 9 | Iteration: 581 | Classification loss: 0.00189 | Regression loss: 0.06163 | Running loss: 0.04406\n",
            "Epoch: 9 | Iteration: 582 | Classification loss: 0.00067 | Regression loss: 0.04864 | Running loss: 0.04370\n",
            "Epoch: 9 | Iteration: 583 | Classification loss: 0.00217 | Regression loss: 0.03262 | Running loss: 0.04371\n",
            "Epoch: 9 | Iteration: 584 | Classification loss: 0.00033 | Regression loss: 0.02667 | Running loss: 0.04369\n",
            "Epoch: 9 | Iteration: 585 | Classification loss: 0.00052 | Regression loss: 0.02306 | Running loss: 0.04372\n",
            "Epoch: 9 | Iteration: 586 | Classification loss: 0.00093 | Regression loss: 0.02996 | Running loss: 0.04373\n",
            "Epoch: 9 | Iteration: 587 | Classification loss: 0.02211 | Regression loss: 0.05982 | Running loss: 0.04384\n",
            "Epoch: 9 | Iteration: 588 | Classification loss: 0.20248 | Regression loss: 0.26429 | Running loss: 0.04475\n",
            "Epoch: 9 | Iteration: 589 | Classification loss: 0.00164 | Regression loss: 0.03626 | Running loss: 0.04470\n",
            "Epoch: 9 | Iteration: 590 | Classification loss: 0.00043 | Regression loss: 0.02628 | Running loss: 0.04473\n",
            "Epoch: 9 | Iteration: 591 | Classification loss: 0.00595 | Regression loss: 0.03933 | Running loss: 0.04476\n",
            "Epoch: 9 | Iteration: 592 | Classification loss: 0.01386 | Regression loss: 0.05671 | Running loss: 0.04486\n",
            "Epoch: 9 | Iteration: 593 | Classification loss: 0.00234 | Regression loss: 0.01720 | Running loss: 0.04487\n",
            "Epoch: 9 | Iteration: 594 | Classification loss: 0.00531 | Regression loss: 0.01956 | Running loss: 0.04489\n",
            "Epoch: 9 | Iteration: 595 | Classification loss: 0.02399 | Regression loss: 0.03034 | Running loss: 0.04495\n",
            "Epoch: 9 | Iteration: 596 | Classification loss: 0.01573 | Regression loss: 0.03336 | Running loss: 0.04500\n",
            "Epoch: 9 | Iteration: 597 | Classification loss: 0.00119 | Regression loss: 0.02068 | Running loss: 0.04500\n",
            "Epoch: 9 | Iteration: 598 | Classification loss: 0.00200 | Regression loss: 0.02910 | Running loss: 0.04502\n",
            "Epoch: 9 | Iteration: 599 | Classification loss: 0.00079 | Regression loss: 0.02121 | Running loss: 0.04502\n",
            "Epoch: 9 | Iteration: 600 | Classification loss: 0.00039 | Regression loss: 0.03551 | Running loss: 0.04504\n",
            "Epoch: 9 | Iteration: 601 | Classification loss: 0.01034 | Regression loss: 0.02238 | Running loss: 0.04509\n",
            "Epoch: 9 | Iteration: 602 | Classification loss: 0.00780 | Regression loss: 0.03073 | Running loss: 0.04511\n",
            "Epoch: 9 | Iteration: 603 | Classification loss: 0.00035 | Regression loss: 0.02081 | Running loss: 0.04513\n",
            "Epoch: 9 | Iteration: 604 | Classification loss: 0.00019 | Regression loss: 0.00668 | Running loss: 0.04510\n",
            "Epoch: 9 | Iteration: 605 | Classification loss: 0.00126 | Regression loss: 0.01633 | Running loss: 0.04510\n",
            "Epoch: 9 | Iteration: 606 | Classification loss: 0.03678 | Regression loss: 0.06612 | Running loss: 0.04522\n",
            "Epoch: 9 | Iteration: 607 | Classification loss: 0.00129 | Regression loss: 0.02880 | Running loss: 0.04526\n",
            "Epoch: 9 | Iteration: 608 | Classification loss: 0.00051 | Regression loss: 0.01484 | Running loss: 0.04521\n",
            "Epoch: 9 | Iteration: 609 | Classification loss: 0.00145 | Regression loss: 0.03604 | Running loss: 0.04521\n",
            "Epoch: 9 | Iteration: 610 | Classification loss: 0.00179 | Regression loss: 0.02777 | Running loss: 0.04519\n",
            "Epoch: 9 | Iteration: 611 | Classification loss: 0.00158 | Regression loss: 0.03578 | Running loss: 0.04522\n",
            "Epoch: 9 | Iteration: 612 | Classification loss: 0.20614 | Regression loss: 0.02878 | Running loss: 0.04563\n",
            "Epoch: 9 | Iteration: 613 | Classification loss: 0.00375 | Regression loss: 0.03174 | Running loss: 0.04568\n",
            "Epoch: 9 | Iteration: 614 | Classification loss: 0.01866 | Regression loss: 0.03593 | Running loss: 0.04577\n",
            "Epoch: 9 | Iteration: 615 | Classification loss: 0.00055 | Regression loss: 0.01768 | Running loss: 0.04578\n",
            "Epoch: 9 | Iteration: 616 | Classification loss: 0.02364 | Regression loss: 0.03092 | Running loss: 0.04584\n",
            "Epoch: 9 | Iteration: 617 | Classification loss: 0.00026 | Regression loss: 0.02084 | Running loss: 0.04584\n",
            "Epoch: 9 | Iteration: 618 | Classification loss: 0.00010 | Regression loss: 0.04111 | Running loss: 0.04587\n",
            "Epoch: 9 | Iteration: 619 | Classification loss: 0.00135 | Regression loss: 0.01541 | Running loss: 0.04585\n",
            "Epoch: 9 | Iteration: 620 | Classification loss: 0.00085 | Regression loss: 0.02228 | Running loss: 0.04577\n",
            "Epoch: 9 | Iteration: 621 | Classification loss: 0.00067 | Regression loss: 0.03386 | Running loss: 0.04567\n",
            "Epoch: 9 | Iteration: 622 | Classification loss: 0.01809 | Regression loss: 0.02972 | Running loss: 0.04573\n",
            "Epoch: 9 | Iteration: 623 | Classification loss: 0.00048 | Regression loss: 0.01766 | Running loss: 0.04574\n",
            "Epoch: 9 | Iteration: 624 | Classification loss: 0.53093 | Regression loss: 0.02879 | Running loss: 0.04683\n",
            "Epoch: 9 | Iteration: 625 | Classification loss: 0.01609 | Regression loss: 0.09783 | Running loss: 0.04701\n",
            "Epoch: 9 | Iteration: 626 | Classification loss: 0.00269 | Regression loss: 0.01377 | Running loss: 0.04695\n",
            "Epoch: 9 | Iteration: 627 | Classification loss: 0.03364 | Regression loss: 0.05717 | Running loss: 0.04701\n",
            "Epoch: 9 | Iteration: 628 | Classification loss: 0.02863 | Regression loss: 0.02486 | Running loss: 0.04709\n",
            "Epoch: 9 | Iteration: 629 | Classification loss: 0.25319 | Regression loss: 0.03852 | Running loss: 0.04762\n",
            "Epoch: 9 | Iteration: 630 | Classification loss: 0.00302 | Regression loss: 0.03085 | Running loss: 0.04764\n",
            "Epoch: 9 | Iteration: 631 | Classification loss: 0.00041 | Regression loss: 0.02451 | Running loss: 0.04765\n",
            "Epoch: 9 | Iteration: 632 | Classification loss: 0.00126 | Regression loss: 0.02707 | Running loss: 0.04765\n",
            "Epoch: 9 | Iteration: 633 | Classification loss: 0.00360 | Regression loss: 0.02006 | Running loss: 0.04763\n",
            "Epoch: 9 | Iteration: 634 | Classification loss: 0.00363 | Regression loss: 0.20451 | Running loss: 0.04800\n",
            "Epoch: 9 | Iteration: 635 | Classification loss: 0.00763 | Regression loss: 0.01709 | Running loss: 0.04796\n",
            "Epoch: 9 | Iteration: 636 | Classification loss: 0.00049 | Regression loss: 0.02010 | Running loss: 0.04796\n",
            "Epoch: 9 | Iteration: 637 | Classification loss: 0.00053 | Regression loss: 0.01841 | Running loss: 0.04796\n",
            "Epoch: 9 | Iteration: 638 | Classification loss: 0.00837 | Regression loss: 0.03801 | Running loss: 0.04799\n",
            "Epoch: 9 | Iteration: 639 | Classification loss: 0.00860 | Regression loss: 0.05701 | Running loss: 0.04801\n",
            "Epoch: 9 | Iteration: 640 | Classification loss: 0.03208 | Regression loss: 0.06086 | Running loss: 0.04817\n",
            "Epoch: 9 | Iteration: 641 | Classification loss: 0.00127 | Regression loss: 0.04640 | Running loss: 0.04820\n",
            "Epoch: 9 | Iteration: 642 | Classification loss: 0.00264 | Regression loss: 0.02168 | Running loss: 0.04820\n",
            "Epoch: 9 | Iteration: 643 | Classification loss: 0.00752 | Regression loss: 0.03098 | Running loss: 0.04824\n",
            "Epoch: 9 | Iteration: 644 | Classification loss: 0.00252 | Regression loss: 0.01203 | Running loss: 0.04817\n",
            "Epoch: 9 | Iteration: 645 | Classification loss: 0.03222 | Regression loss: 0.03623 | Running loss: 0.04825\n",
            "Epoch: 9 | Iteration: 646 | Classification loss: 0.00033 | Regression loss: 0.01501 | Running loss: 0.04822\n",
            "Epoch: 9 | Iteration: 647 | Classification loss: 0.00161 | Regression loss: 0.02226 | Running loss: 0.04821\n",
            "Epoch: 9 | Iteration: 648 | Classification loss: 0.00009 | Regression loss: 0.01799 | Running loss: 0.04816\n",
            "Epoch: 9 | Iteration: 649 | Classification loss: 0.11948 | Regression loss: 0.03430 | Running loss: 0.04835\n",
            "Epoch: 9 | Iteration: 650 | Classification loss: 0.00144 | Regression loss: 0.02808 | Running loss: 0.04835\n",
            "Epoch: 9 | Iteration: 651 | Classification loss: 0.00658 | Regression loss: 0.03567 | Running loss: 0.04836\n",
            "Epoch: 9 | Iteration: 652 | Classification loss: 0.00009 | Regression loss: 0.00766 | Running loss: 0.04830\n",
            "Epoch: 9 | Iteration: 653 | Classification loss: 0.14480 | Regression loss: 0.02578 | Running loss: 0.04858\n",
            "Epoch: 9 | Iteration: 654 | Classification loss: 0.00098 | Regression loss: 0.04398 | Running loss: 0.04863\n",
            "Epoch: 9 | Iteration: 655 | Classification loss: 0.00067 | Regression loss: 0.05132 | Running loss: 0.04871\n",
            "Epoch: 9 | Iteration: 656 | Classification loss: 0.00030 | Regression loss: 0.04052 | Running loss: 0.04877\n",
            "Epoch: 9 | Iteration: 657 | Classification loss: 0.00412 | Regression loss: 0.02421 | Running loss: 0.04877\n",
            "Epoch: 9 | Iteration: 658 | Classification loss: 0.00641 | Regression loss: 0.01490 | Running loss: 0.04873\n",
            "Epoch: 9 | Iteration: 659 | Classification loss: 0.00218 | Regression loss: 0.01644 | Running loss: 0.04874\n",
            "Epoch: 9 | Iteration: 660 | Classification loss: 0.01098 | Regression loss: 0.01903 | Running loss: 0.04878\n",
            "Epoch: 9 | Iteration: 661 | Classification loss: 0.00020 | Regression loss: 0.03408 | Running loss: 0.04875\n",
            "Epoch: 9 | Iteration: 662 | Classification loss: 0.00006 | Regression loss: 0.02445 | Running loss: 0.04877\n",
            "Epoch: 9 | Iteration: 663 | Classification loss: 0.00634 | Regression loss: 0.09517 | Running loss: 0.04890\n",
            "Epoch: 9 | Iteration: 664 | Classification loss: 0.00112 | Regression loss: 0.00902 | Running loss: 0.04890\n",
            "Epoch: 9 | Iteration: 665 | Classification loss: 0.00199 | Regression loss: 0.06924 | Running loss: 0.04903\n",
            "Epoch: 9 | Iteration: 666 | Classification loss: 0.00186 | Regression loss: 0.02447 | Running loss: 0.04906\n",
            "Epoch: 9 | Iteration: 667 | Classification loss: 0.00006 | Regression loss: 0.02608 | Running loss: 0.04900\n",
            "Epoch: 9 | Iteration: 668 | Classification loss: 0.00316 | Regression loss: 0.02089 | Running loss: 0.04903\n",
            "Epoch: 9 | Iteration: 669 | Classification loss: 0.00028 | Regression loss: 0.01373 | Running loss: 0.04902\n",
            "Epoch: 9 | Iteration: 670 | Classification loss: 0.00027 | Regression loss: 0.04050 | Running loss: 0.04902\n",
            "Epoch: 9 | Iteration: 671 | Classification loss: 1.02247 | Regression loss: 0.03477 | Running loss: 0.05107\n",
            "Epoch: 9 | Iteration: 672 | Classification loss: 0.00244 | Regression loss: 0.02341 | Running loss: 0.05108\n",
            "Epoch: 9 | Iteration: 673 | Classification loss: 0.00021 | Regression loss: 0.02569 | Running loss: 0.05107\n",
            "Epoch: 9 | Iteration: 674 | Classification loss: 0.00019 | Regression loss: 0.02274 | Running loss: 0.05105\n",
            "Epoch: 9 | Iteration: 675 | Classification loss: 0.00344 | Regression loss: 0.07430 | Running loss: 0.05117\n",
            "Epoch: 9 | Iteration: 676 | Classification loss: 0.00042 | Regression loss: 0.02801 | Running loss: 0.05116\n",
            "Epoch: 9 | Iteration: 677 | Classification loss: 0.00578 | Regression loss: 0.01457 | Running loss: 0.05115\n",
            "Epoch: 9 | Iteration: 678 | Classification loss: 0.00149 | Regression loss: 0.01056 | Running loss: 0.05115\n",
            "Epoch: 9 | Iteration: 679 | Classification loss: 0.00715 | Regression loss: 0.02248 | Running loss: 0.05117\n",
            "Epoch: 9 | Iteration: 680 | Classification loss: 0.00108 | Regression loss: 0.04079 | Running loss: 0.05119\n",
            "Epoch: 9 | Iteration: 681 | Classification loss: 0.00028 | Regression loss: 0.03043 | Running loss: 0.05123\n",
            "Epoch: 9 | Iteration: 682 | Classification loss: 0.00063 | Regression loss: 0.01263 | Running loss: 0.05121\n",
            "Epoch: 9 | Iteration: 683 | Classification loss: 0.00061 | Regression loss: 0.02132 | Running loss: 0.05123\n",
            "Epoch: 9 | Iteration: 684 | Classification loss: 0.00072 | Regression loss: 0.02190 | Running loss: 0.05122\n",
            "Epoch: 9 | Iteration: 685 | Classification loss: 0.00226 | Regression loss: 0.02304 | Running loss: 0.05121\n",
            "Epoch: 9 | Iteration: 686 | Classification loss: 0.00174 | Regression loss: 0.06923 | Running loss: 0.05132\n",
            "Epoch: 9 | Iteration: 687 | Classification loss: 0.00039 | Regression loss: 0.03019 | Running loss: 0.05135\n",
            "Epoch: 9 | Iteration: 688 | Classification loss: 0.00204 | Regression loss: 0.01916 | Running loss: 0.05129\n",
            "Epoch: 9 | Iteration: 689 | Classification loss: 0.00697 | Regression loss: 0.02895 | Running loss: 0.05134\n",
            "Epoch: 9 | Iteration: 690 | Classification loss: 0.01653 | Regression loss: 0.05768 | Running loss: 0.05146\n",
            "Epoch: 9 | Iteration: 691 | Classification loss: 0.00296 | Regression loss: 0.07168 | Running loss: 0.05157\n",
            "Epoch: 9 | Iteration: 692 | Classification loss: 0.00849 | Regression loss: 0.08700 | Running loss: 0.05172\n",
            "Epoch: 9 | Iteration: 693 | Classification loss: 0.00176 | Regression loss: 0.03711 | Running loss: 0.05169\n",
            "Epoch: 9 | Iteration: 694 | Classification loss: 0.00310 | Regression loss: 0.03324 | Running loss: 0.05173\n",
            "Epoch: 9 | Iteration: 695 | Classification loss: 0.00041 | Regression loss: 0.04017 | Running loss: 0.05176\n",
            "Epoch: 9 | Iteration: 696 | Classification loss: 0.00014 | Regression loss: 0.03608 | Running loss: 0.05182\n",
            "Epoch: 9 | Iteration: 697 | Classification loss: 0.00029 | Regression loss: 0.03237 | Running loss: 0.05185\n",
            "Epoch: 9 | Iteration: 698 | Classification loss: 0.00251 | Regression loss: 0.07280 | Running loss: 0.05198\n",
            "Epoch: 9 | Iteration: 699 | Classification loss: 0.00154 | Regression loss: 0.04311 | Running loss: 0.05205\n",
            "Epoch: 9 | Iteration: 700 | Classification loss: 0.00573 | Regression loss: 0.07248 | Running loss: 0.05207\n",
            "Epoch: 9 | Iteration: 701 | Classification loss: 0.00047 | Regression loss: 0.01102 | Running loss: 0.05205\n",
            "Epoch: 9 | Iteration: 702 | Classification loss: 0.00126 | Regression loss: 0.03770 | Running loss: 0.05208\n",
            "Epoch: 9 | Iteration: 703 | Classification loss: 0.00052 | Regression loss: 0.02734 | Running loss: 0.05207\n",
            "Epoch: 9 | Iteration: 704 | Classification loss: 0.00023 | Regression loss: 0.01588 | Running loss: 0.05198\n",
            "Epoch: 9 | Iteration: 705 | Classification loss: 0.00019 | Regression loss: 0.03011 | Running loss: 0.05199\n",
            "Epoch: 9 | Iteration: 706 | Classification loss: 0.00005 | Regression loss: 0.02037 | Running loss: 0.05198\n",
            "Epoch: 9 | Iteration: 707 | Classification loss: 0.00024 | Regression loss: 0.01729 | Running loss: 0.05197\n",
            "Epoch: 9 | Iteration: 708 | Classification loss: 0.02038 | Regression loss: 0.04448 | Running loss: 0.05204\n",
            "Epoch: 9 | Iteration: 709 | Classification loss: 0.00558 | Regression loss: 0.04456 | Running loss: 0.05210\n",
            "Epoch: 9 | Iteration: 710 | Classification loss: 0.00028 | Regression loss: 0.02149 | Running loss: 0.05210\n",
            "Epoch: 9 | Iteration: 711 | Classification loss: 0.00011 | Regression loss: 0.01373 | Running loss: 0.05145\n",
            "Epoch: 9 | Iteration: 712 | Classification loss: 0.00067 | Regression loss: 0.02101 | Running loss: 0.05144\n",
            "Epoch: 9 | Iteration: 713 | Classification loss: 0.00023 | Regression loss: 0.01856 | Running loss: 0.05141\n",
            "Epoch: 9 | Iteration: 714 | Classification loss: 0.00048 | Regression loss: 0.03416 | Running loss: 0.05144\n",
            "Epoch: 9 | Iteration: 715 | Classification loss: 0.00055 | Regression loss: 0.03666 | Running loss: 0.05148\n",
            "Epoch: 9 | Iteration: 716 | Classification loss: 0.00092 | Regression loss: 0.03167 | Running loss: 0.05152\n",
            "Epoch: 9 | Iteration: 717 | Classification loss: 0.00033 | Regression loss: 0.01882 | Running loss: 0.05147\n",
            "Epoch: 9 | Iteration: 718 | Classification loss: 0.01423 | Regression loss: 0.08900 | Running loss: 0.05154\n",
            "Epoch: 9 | Iteration: 719 | Classification loss: 0.00013 | Regression loss: 0.02551 | Running loss: 0.05153\n",
            "Epoch: 9 | Iteration: 720 | Classification loss: 0.01082 | Regression loss: 0.06444 | Running loss: 0.05161\n",
            "Epoch: 9 | Iteration: 721 | Classification loss: 0.00025 | Regression loss: 0.01481 | Running loss: 0.05162\n",
            "Epoch: 9 | Iteration: 722 | Classification loss: 0.00013 | Regression loss: 0.01959 | Running loss: 0.05160\n",
            "Epoch: 9 | Iteration: 723 | Classification loss: 0.00107 | Regression loss: 0.03400 | Running loss: 0.05163\n",
            "Epoch: 9 | Iteration: 724 | Classification loss: 0.00040 | Regression loss: 0.03350 | Running loss: 0.05165\n",
            "Epoch: 9 | Iteration: 725 | Classification loss: 0.00151 | Regression loss: 0.02271 | Running loss: 0.05164\n",
            "Epoch: 9 | Iteration: 726 | Classification loss: 0.00799 | Regression loss: 0.02478 | Running loss: 0.05169\n",
            "Epoch: 9 | Iteration: 727 | Classification loss: 0.00044 | Regression loss: 0.01845 | Running loss: 0.05169\n",
            "Epoch: 9 | Iteration: 728 | Classification loss: 0.00225 | Regression loss: 0.05149 | Running loss: 0.05175\n",
            "Epoch: 9 | Iteration: 729 | Classification loss: 0.00007 | Regression loss: 0.02385 | Running loss: 0.05174\n",
            "Epoch: 9 | Iteration: 730 | Classification loss: 0.00021 | Regression loss: 0.02101 | Running loss: 0.05171\n",
            "Epoch: 9 | Iteration: 731 | Classification loss: 0.00057 | Regression loss: 0.02802 | Running loss: 0.05172\n",
            "Epoch: 9 | Iteration: 732 | Classification loss: 0.00433 | Regression loss: 0.05724 | Running loss: 0.05181\n",
            "Epoch: 9 | Iteration: 733 | Classification loss: 0.00100 | Regression loss: 0.03600 | Running loss: 0.05185\n",
            "Epoch: 9 | Iteration: 734 | Classification loss: 0.00082 | Regression loss: 0.05387 | Running loss: 0.05193\n",
            "Epoch: 9 | Iteration: 735 | Classification loss: 0.00015 | Regression loss: 0.01984 | Running loss: 0.05195\n",
            "Epoch: 9 | Iteration: 736 | Classification loss: 0.00016 | Regression loss: 0.02353 | Running loss: 0.05188\n",
            "Epoch: 9 | Iteration: 737 | Classification loss: 0.00161 | Regression loss: 0.02079 | Running loss: 0.05171\n",
            "Epoch: 9 | Iteration: 738 | Classification loss: 0.00025 | Regression loss: 0.02258 | Running loss: 0.05164\n",
            "Epoch: 9 | Iteration: 739 | Classification loss: 0.00032 | Regression loss: 0.01946 | Running loss: 0.05159\n",
            "Epoch: 9 | Iteration: 740 | Classification loss: 0.00006 | Regression loss: 0.02669 | Running loss: 0.05155\n",
            "Epoch: 9 | Iteration: 741 | Classification loss: 0.00049 | Regression loss: 0.03068 | Running loss: 0.05159\n",
            "Epoch: 9 | Iteration: 742 | Classification loss: 0.00007 | Regression loss: 0.01155 | Running loss: 0.05153\n",
            "Epoch: 9 | Iteration: 743 | Classification loss: 0.00462 | Regression loss: 0.04552 | Running loss: 0.05157\n",
            "Epoch: 9 | Iteration: 744 | Classification loss: 0.00084 | Regression loss: 0.04810 | Running loss: 0.05160\n",
            "Epoch: 9 | Iteration: 745 | Classification loss: 0.01619 | Regression loss: 0.02079 | Running loss: 0.05161\n",
            "Epoch: 9 | Iteration: 746 | Classification loss: 0.00013 | Regression loss: 0.03842 | Running loss: 0.05165\n",
            "Epoch: 9 | Iteration: 747 | Classification loss: 0.00006 | Regression loss: 0.03819 | Running loss: 0.05170\n",
            "Epoch: 9 | Iteration: 748 | Classification loss: 0.00031 | Regression loss: 0.01121 | Running loss: 0.05162\n",
            "Epoch: 9 | Iteration: 749 | Classification loss: 0.00035 | Regression loss: 0.01274 | Running loss: 0.05162\n",
            "Epoch: 9 | Iteration: 750 | Classification loss: 0.01084 | Regression loss: 0.02147 | Running loss: 0.05160\n",
            "Epoch: 9 | Iteration: 751 | Classification loss: 0.00030 | Regression loss: 0.02565 | Running loss: 0.05161\n",
            "Epoch: 9 | Iteration: 752 | Classification loss: 0.01195 | Regression loss: 0.06405 | Running loss: 0.05172\n",
            "Epoch: 9 | Iteration: 753 | Classification loss: 0.01262 | Regression loss: 0.04185 | Running loss: 0.05167\n",
            "Epoch: 9 | Iteration: 754 | Classification loss: 0.00028 | Regression loss: 0.02172 | Running loss: 0.05167\n",
            "Epoch: 9 | Iteration: 755 | Classification loss: 0.00249 | Regression loss: 0.02795 | Running loss: 0.05170\n",
            "Epoch: 9 | Iteration: 756 | Classification loss: 0.00022 | Regression loss: 0.01659 | Running loss: 0.05169\n",
            "Epoch: 9 | Iteration: 757 | Classification loss: 0.00038 | Regression loss: 0.01445 | Running loss: 0.05169\n",
            "Epoch: 9 | Iteration: 758 | Classification loss: 0.01149 | Regression loss: 0.06738 | Running loss: 0.05177\n",
            "Epoch: 9 | Iteration: 759 | Classification loss: 0.00030 | Regression loss: 0.02347 | Running loss: 0.05178\n",
            "Epoch: 9 | Iteration: 760 | Classification loss: 0.00013 | Regression loss: 0.01275 | Running loss: 0.05179\n",
            "Epoch: 9 | Iteration: 761 | Classification loss: 0.00175 | Regression loss: 0.05523 | Running loss: 0.05171\n",
            "Epoch: 9 | Iteration: 762 | Classification loss: 0.00004 | Regression loss: 0.02399 | Running loss: 0.05172\n",
            "Epoch: 9 | Iteration: 763 | Classification loss: 0.00023 | Regression loss: 0.02946 | Running loss: 0.05175\n",
            "Epoch: 9 | Iteration: 764 | Classification loss: 0.00020 | Regression loss: 0.01842 | Running loss: 0.05175\n",
            "Epoch: 9 | Iteration: 765 | Classification loss: 0.00041 | Regression loss: 0.02136 | Running loss: 0.05176\n",
            "Epoch: 9 | Iteration: 766 | Classification loss: 0.00017 | Regression loss: 0.02020 | Running loss: 0.05177\n",
            "Epoch: 9 | Iteration: 767 | Classification loss: 0.00949 | Regression loss: 0.02257 | Running loss: 0.05170\n",
            "Epoch: 9 | Iteration: 768 | Classification loss: 0.00048 | Regression loss: 0.02224 | Running loss: 0.05170\n",
            "Epoch: 9 | Iteration: 769 | Classification loss: 0.00006 | Regression loss: 0.03399 | Running loss: 0.05170\n",
            "Epoch: 9 | Iteration: 770 | Classification loss: 0.00008 | Regression loss: 0.02510 | Running loss: 0.05171\n",
            "Epoch: 9 | Iteration: 771 | Classification loss: 0.00062 | Regression loss: 0.02329 | Running loss: 0.05173\n",
            "Epoch: 9 | Iteration: 772 | Classification loss: 0.00028 | Regression loss: 0.02655 | Running loss: 0.05161\n",
            "Epoch: 9 | Iteration: 773 | Classification loss: 0.00087 | Regression loss: 0.04602 | Running loss: 0.05166\n",
            "Epoch: 9 | Iteration: 774 | Classification loss: 0.00033 | Regression loss: 0.02729 | Running loss: 0.05167\n",
            "Epoch: 9 | Iteration: 775 | Classification loss: 0.00618 | Regression loss: 0.02312 | Running loss: 0.05091\n",
            "Epoch: 9 | Iteration: 776 | Classification loss: 0.00009 | Regression loss: 0.02226 | Running loss: 0.05090\n",
            "Epoch: 9 | Iteration: 777 | Classification loss: 0.00006 | Regression loss: 0.03118 | Running loss: 0.05093\n",
            "Epoch: 9 | Iteration: 778 | Classification loss: 0.83503 | Regression loss: 0.45632 | Running loss: 0.05345\n",
            "Epoch: 9 | Iteration: 779 | Classification loss: 0.00023 | Regression loss: 0.02939 | Running loss: 0.05257\n",
            "Epoch: 9 | Iteration: 780 | Classification loss: 0.00028 | Regression loss: 0.03196 | Running loss: 0.05260\n",
            "Epoch: 9 | Iteration: 781 | Classification loss: 0.00026 | Regression loss: 0.01596 | Running loss: 0.05256\n",
            "Epoch: 9 | Iteration: 782 | Classification loss: 0.00040 | Regression loss: 0.01791 | Running loss: 0.05257\n",
            "Epoch: 9 | Iteration: 783 | Classification loss: 0.00062 | Regression loss: 0.02511 | Running loss: 0.05258\n",
            "Epoch: 9 | Iteration: 784 | Classification loss: 0.00408 | Regression loss: 0.01461 | Running loss: 0.05258\n",
            "Epoch: 9 | Iteration: 785 | Classification loss: 0.00042 | Regression loss: 0.06117 | Running loss: 0.05267\n",
            "Epoch: 9 | Iteration: 786 | Classification loss: 0.00036 | Regression loss: 0.02761 | Running loss: 0.05268\n",
            "Epoch: 9 | Iteration: 787 | Classification loss: 0.00290 | Regression loss: 0.03046 | Running loss: 0.05272\n",
            "Epoch: 9 | Iteration: 788 | Classification loss: 0.00511 | Regression loss: 0.02645 | Running loss: 0.05269\n",
            "Epoch: 9 | Iteration: 789 | Classification loss: 0.00230 | Regression loss: 0.03498 | Running loss: 0.05270\n",
            "Epoch: 9 | Iteration: 790 | Classification loss: 0.00262 | Regression loss: 0.01894 | Running loss: 0.05266\n",
            "Epoch: 9 | Iteration: 791 | Classification loss: 0.00016 | Regression loss: 0.01330 | Running loss: 0.05262\n",
            "Epoch: 9 | Iteration: 792 | Classification loss: 0.00192 | Regression loss: 0.01269 | Running loss: 0.05261\n",
            "Epoch: 9 | Iteration: 793 | Classification loss: 0.17995 | Regression loss: 0.25114 | Running loss: 0.05340\n",
            "Epoch: 9 | Iteration: 794 | Classification loss: 0.00148 | Regression loss: 0.02807 | Running loss: 0.05345\n",
            "Epoch: 9 | Iteration: 795 | Classification loss: 0.00003 | Regression loss: 0.02648 | Running loss: 0.05344\n",
            "Epoch: 9 | Iteration: 796 | Classification loss: 0.00011 | Regression loss: 0.02140 | Running loss: 0.05220\n",
            "Epoch: 9 | Iteration: 797 | Classification loss: 0.00048 | Regression loss: 0.02559 | Running loss: 0.05222\n",
            "Epoch: 9 | Iteration: 798 | Classification loss: 0.00042 | Regression loss: 0.01644 | Running loss: 0.05222\n",
            "Epoch: 9 | Iteration: 799 | Classification loss: 0.00078 | Regression loss: 0.01471 | Running loss: 0.05220\n",
            "Epoch: 9 | Iteration: 800 | Classification loss: 0.00019 | Regression loss: 0.02560 | Running loss: 0.05219\n",
            "Epoch: 9 | Iteration: 801 | Classification loss: 0.00079 | Regression loss: 0.02047 | Running loss: 0.05218\n",
            "Epoch: 9 | Iteration: 802 | Classification loss: 0.00074 | Regression loss: 0.01033 | Running loss: 0.05215\n",
            "Epoch: 9 | Iteration: 803 | Classification loss: 0.00007 | Regression loss: 0.03556 | Running loss: 0.05190\n",
            "Epoch: 9 | Iteration: 804 | Classification loss: 0.02658 | Regression loss: 0.04430 | Running loss: 0.05200\n",
            "Epoch: 9 | Iteration: 805 | Classification loss: 0.00015 | Regression loss: 0.03954 | Running loss: 0.05199\n",
            "Epoch: 9 | Iteration: 806 | Classification loss: 0.00034 | Regression loss: 0.03764 | Running loss: 0.05201\n",
            "Epoch: 9 | Iteration: 807 | Classification loss: 0.00131 | Regression loss: 0.03711 | Running loss: 0.05205\n",
            "Epoch: 9 | Iteration: 808 | Classification loss: 0.00009 | Regression loss: 0.02843 | Running loss: 0.05207\n",
            "Epoch: 9 | Iteration: 809 | Classification loss: 0.00065 | Regression loss: 0.01616 | Running loss: 0.05208\n",
            "Epoch: 9 | Iteration: 810 | Classification loss: 0.00131 | Regression loss: 0.02824 | Running loss: 0.05209\n",
            "Epoch: 9 | Iteration: 811 | Classification loss: 0.00016 | Regression loss: 0.01131 | Running loss: 0.05208\n",
            "Epoch: 9 | Iteration: 812 | Classification loss: 0.00809 | Regression loss: 0.05368 | Running loss: 0.05214\n",
            "Epoch: 9 | Iteration: 813 | Classification loss: 0.00018 | Regression loss: 0.03567 | Running loss: 0.05216\n",
            "Epoch: 9 | Iteration: 814 | Classification loss: 0.00013 | Regression loss: 0.01956 | Running loss: 0.05218\n",
            "Epoch: 9 | Iteration: 815 | Classification loss: 0.00087 | Regression loss: 0.03434 | Running loss: 0.05216\n",
            "Epoch: 9 | Iteration: 816 | Classification loss: 0.00044 | Regression loss: 0.04381 | Running loss: 0.05222\n",
            "Epoch: 9 | Iteration: 817 | Classification loss: 0.00716 | Regression loss: 0.04173 | Running loss: 0.05217\n",
            "Epoch: 9 | Iteration: 818 | Classification loss: 0.00113 | Regression loss: 0.03290 | Running loss: 0.05219\n",
            "Epoch: 9 | Iteration: 819 | Classification loss: 0.00026 | Regression loss: 0.02048 | Running loss: 0.05216\n",
            "Epoch: 9 | Iteration: 820 | Classification loss: 0.00011 | Regression loss: 0.01767 | Running loss: 0.05217\n",
            "Epoch: 9 | Iteration: 821 | Classification loss: 0.00066 | Regression loss: 0.01844 | Running loss: 0.05215\n",
            "Epoch: 9 | Iteration: 822 | Classification loss: 0.00219 | Regression loss: 0.03493 | Running loss: 0.05218\n",
            "Epoch: 9 | Iteration: 823 | Classification loss: 0.00065 | Regression loss: 0.02699 | Running loss: 0.05217\n",
            "Epoch: 9 | Iteration: 824 | Classification loss: 0.00013 | Regression loss: 0.01525 | Running loss: 0.05211\n",
            "Epoch: 9 | Iteration: 825 | Classification loss: 0.00006 | Regression loss: 0.01532 | Running loss: 0.05205\n",
            "Epoch: 9 | Iteration: 826 | Classification loss: 0.00041 | Regression loss: 0.06427 | Running loss: 0.05214\n",
            "Epoch: 9 | Iteration: 827 | Classification loss: 0.00051 | Regression loss: 0.01636 | Running loss: 0.05213\n",
            "Epoch: 9 | Iteration: 828 | Classification loss: 0.00138 | Regression loss: 0.01329 | Running loss: 0.05208\n",
            "Epoch: 9 | Iteration: 829 | Classification loss: 0.00053 | Regression loss: 0.01260 | Running loss: 0.05193\n",
            "Epoch: 9 | Iteration: 830 | Classification loss: 0.00019 | Regression loss: 0.02174 | Running loss: 0.05192\n",
            "Epoch: 9 | Iteration: 831 | Classification loss: 0.00071 | Regression loss: 0.01779 | Running loss: 0.05165\n",
            "Epoch: 9 | Iteration: 832 | Classification loss: 0.00947 | Regression loss: 0.07175 | Running loss: 0.05175\n",
            "Epoch: 9 | Iteration: 833 | Classification loss: 0.00011 | Regression loss: 0.01677 | Running loss: 0.05173\n",
            "Epoch: 9 | Iteration: 834 | Classification loss: 0.00002 | Regression loss: 0.01874 | Running loss: 0.05173\n",
            "Epoch: 9 | Iteration: 835 | Classification loss: 0.00005 | Regression loss: 0.02273 | Running loss: 0.05174\n",
            "Epoch: 9 | Iteration: 836 | Classification loss: 0.00225 | Regression loss: 0.02284 | Running loss: 0.05175\n",
            "Epoch: 9 | Iteration: 837 | Classification loss: 0.00028 | Regression loss: 0.01508 | Running loss: 0.05171\n",
            "Epoch: 9 | Iteration: 838 | Classification loss: 0.00065 | Regression loss: 0.01418 | Running loss: 0.05165\n",
            "Epoch: 9 | Iteration: 839 | Classification loss: 0.00022 | Regression loss: 0.01322 | Running loss: 0.05101\n",
            "Epoch: 9 | Iteration: 840 | Classification loss: 0.00969 | Regression loss: 0.04398 | Running loss: 0.05104\n",
            "Epoch: 9 | Iteration: 841 | Classification loss: 0.00051 | Regression loss: 0.02968 | Running loss: 0.05102\n",
            "Epoch: 9 | Iteration: 842 | Classification loss: 0.00005 | Regression loss: 0.03798 | Running loss: 0.05103\n",
            "Epoch: 9 | Iteration: 843 | Classification loss: 0.00021 | Regression loss: 0.02693 | Running loss: 0.05104\n",
            "Epoch: 9 | Iteration: 844 | Classification loss: 0.00024 | Regression loss: 0.00737 | Running loss: 0.05102\n",
            "Epoch: 9 | Iteration: 845 | Classification loss: 0.00020 | Regression loss: 0.00999 | Running loss: 0.05100\n",
            "Epoch: 9 | Iteration: 846 | Classification loss: 0.00016 | Regression loss: 0.01495 | Running loss: 0.05100\n",
            "Epoch: 9 | Iteration: 847 | Classification loss: 0.00010 | Regression loss: 0.01496 | Running loss: 0.05088\n",
            "Epoch: 9 | Iteration: 848 | Classification loss: 0.00008 | Regression loss: 0.01632 | Running loss: 0.05088\n",
            "Epoch: 9 | Iteration: 849 | Classification loss: 0.00092 | Regression loss: 0.01406 | Running loss: 0.05083\n",
            "Epoch: 9 | Iteration: 850 | Classification loss: 0.00080 | Regression loss: 0.03087 | Running loss: 0.05064\n",
            "Epoch: 9 | Iteration: 851 | Classification loss: 0.00009 | Regression loss: 0.02795 | Running loss: 0.05066\n",
            "Epoch: 9 | Iteration: 852 | Classification loss: 0.00006 | Regression loss: 0.02136 | Running loss: 0.05067\n",
            "Epoch: 9 | Iteration: 853 | Classification loss: 0.00149 | Regression loss: 0.02048 | Running loss: 0.05068\n",
            "Epoch: 9 | Iteration: 854 | Classification loss: 0.00064 | Regression loss: 0.01719 | Running loss: 0.05068\n",
            "Epoch: 9 | Iteration: 855 | Classification loss: 0.00009 | Regression loss: 0.03232 | Running loss: 0.05071\n",
            "Epoch: 9 | Iteration: 856 | Classification loss: 0.00060 | Regression loss: 0.02520 | Running loss: 0.05069\n",
            "Epoch: 9 | Iteration: 857 | Classification loss: 0.00010 | Regression loss: 0.02766 | Running loss: 0.05068\n",
            "Epoch: 9 | Iteration: 858 | Classification loss: 0.00103 | Regression loss: 0.02161 | Running loss: 0.05068\n",
            "Epoch: 9 | Iteration: 859 | Classification loss: 0.00031 | Regression loss: 0.02205 | Running loss: 0.05070\n",
            "Epoch: 9 | Iteration: 860 | Classification loss: 0.00008 | Regression loss: 0.02790 | Running loss: 0.05066\n",
            "Epoch: 9 | Iteration: 861 | Classification loss: 0.00084 | Regression loss: 0.01955 | Running loss: 0.05068\n",
            "Epoch: 9 | Iteration: 862 | Classification loss: 0.00031 | Regression loss: 0.01706 | Running loss: 0.05067\n",
            "Epoch: 9 | Iteration: 863 | Classification loss: 0.00028 | Regression loss: 0.03655 | Running loss: 0.04973\n",
            "Epoch: 9 | Iteration: 864 | Classification loss: 0.00001 | Regression loss: 0.02151 | Running loss: 0.04973\n",
            "Epoch: 9 | Iteration: 865 | Classification loss: 0.00132 | Regression loss: 0.04147 | Running loss: 0.04979\n",
            "Epoch: 9 | Iteration: 866 | Classification loss: 0.00145 | Regression loss: 0.03743 | Running loss: 0.04971\n",
            "Epoch: 9 | Iteration: 867 | Classification loss: 0.00040 | Regression loss: 0.01994 | Running loss: 0.04972\n",
            "Epoch: 9 | Iteration: 868 | Classification loss: 0.00010 | Regression loss: 0.01979 | Running loss: 0.04970\n",
            "Epoch: 9 | Iteration: 869 | Classification loss: 0.00007 | Regression loss: 0.03238 | Running loss: 0.04974\n",
            "Epoch: 9 | Iteration: 870 | Classification loss: 0.00009 | Regression loss: 0.01555 | Running loss: 0.04972\n",
            "Epoch: 9 | Iteration: 871 | Classification loss: 0.00018 | Regression loss: 0.00586 | Running loss: 0.04969\n",
            "Epoch: 9 | Iteration: 872 | Classification loss: 0.00010 | Regression loss: 0.03632 | Running loss: 0.04971\n",
            "Epoch: 9 | Iteration: 873 | Classification loss: 0.00814 | Regression loss: 0.04914 | Running loss: 0.04968\n",
            "Epoch: 9 | Iteration: 874 | Classification loss: 0.00048 | Regression loss: 0.03034 | Running loss: 0.04967\n",
            "Epoch: 9 | Iteration: 875 | Classification loss: 0.00001 | Regression loss: 0.03582 | Running loss: 0.04972\n",
            "Epoch: 9 | Iteration: 876 | Classification loss: 0.00012 | Regression loss: 0.03368 | Running loss: 0.04972\n",
            "Epoch: 9 | Iteration: 877 | Classification loss: 0.00035 | Regression loss: 0.05347 | Running loss: 0.04980\n",
            "Epoch: 9 | Iteration: 878 | Classification loss: 0.00020 | Regression loss: 0.01435 | Running loss: 0.04980\n",
            "Epoch: 9 | Iteration: 879 | Classification loss: 0.00577 | Regression loss: 0.04696 | Running loss: 0.04987\n",
            "Epoch: 9 | Iteration: 880 | Classification loss: 0.00031 | Regression loss: 0.02595 | Running loss: 0.04988\n",
            "Epoch: 9 | Iteration: 881 | Classification loss: 0.00003 | Regression loss: 0.02280 | Running loss: 0.04988\n",
            "Epoch: 9 | Iteration: 882 | Classification loss: 0.00111 | Regression loss: 0.03293 | Running loss: 0.04989\n",
            "Epoch: 9 | Iteration: 883 | Classification loss: 0.00082 | Regression loss: 0.04018 | Running loss: 0.04989\n",
            "Epoch: 9 | Iteration: 884 | Classification loss: 0.00014 | Regression loss: 0.03710 | Running loss: 0.04991\n",
            "Epoch: 9 | Iteration: 885 | Classification loss: 0.00160 | Regression loss: 0.02536 | Running loss: 0.04989\n",
            "Epoch: 9 | Iteration: 886 | Classification loss: 0.00052 | Regression loss: 0.02734 | Running loss: 0.04986\n",
            "Epoch: 9 | Iteration: 887 | Classification loss: 0.00007 | Regression loss: 0.02449 | Running loss: 0.04983\n",
            "Epoch: 9 | Iteration: 888 | Classification loss: 0.00021 | Regression loss: 0.02167 | Running loss: 0.04983\n",
            "Epoch: 9 | Iteration: 889 | Classification loss: 0.00088 | Regression loss: 0.04440 | Running loss: 0.04990\n",
            "Epoch: 9 | Iteration: 890 | Classification loss: 0.00061 | Regression loss: 0.03352 | Running loss: 0.04992\n",
            "Epoch: 9 | Iteration: 891 | Classification loss: 0.00229 | Regression loss: 0.06827 | Running loss: 0.05002\n",
            "Epoch: 9 | Iteration: 892 | Classification loss: 0.00011 | Regression loss: 0.02424 | Running loss: 0.05001\n",
            "Epoch: 9 | Iteration: 893 | Classification loss: 0.00051 | Regression loss: 0.04461 | Running loss: 0.04918\n",
            "Epoch: 9 | Iteration: 894 | Classification loss: 0.00014 | Regression loss: 0.02146 | Running loss: 0.04919\n",
            "Epoch: 9 | Iteration: 895 | Classification loss: 0.00362 | Regression loss: 0.07937 | Running loss: 0.04927\n",
            "Epoch: 9 | Iteration: 896 | Classification loss: 0.00285 | Regression loss: 0.05402 | Running loss: 0.04930\n",
            "Epoch: 9 | Iteration: 897 | Classification loss: 0.00044 | Regression loss: 0.07182 | Running loss: 0.04941\n",
            "Epoch: 9 | Iteration: 898 | Classification loss: 0.00110 | Regression loss: 0.03722 | Running loss: 0.04946\n",
            "Epoch: 9 | Iteration: 899 | Classification loss: 0.00506 | Regression loss: 0.05290 | Running loss: 0.04955\n",
            "Epoch: 9 | Iteration: 900 | Classification loss: 0.00782 | Regression loss: 0.08628 | Running loss: 0.04968\n",
            "Epoch: 9 | Iteration: 901 | Classification loss: 0.00030 | Regression loss: 0.02484 | Running loss: 0.04962\n",
            "Epoch: 9 | Iteration: 902 | Classification loss: 0.00002 | Regression loss: 0.01238 | Running loss: 0.04963\n",
            "Epoch: 9 | Iteration: 903 | Classification loss: 0.00026 | Regression loss: 0.02462 | Running loss: 0.04966\n",
            "Epoch: 9 | Iteration: 904 | Classification loss: 0.00094 | Regression loss: 0.01960 | Running loss: 0.04965\n",
            "Epoch: 9 | Iteration: 905 | Classification loss: 0.00076 | Regression loss: 0.02278 | Running loss: 0.04965\n",
            "Epoch: 9 | Iteration: 906 | Classification loss: 0.00012 | Regression loss: 0.01571 | Running loss: 0.04957\n",
            "Epoch: 9 | Iteration: 907 | Classification loss: 0.00117 | Regression loss: 0.10995 | Running loss: 0.04973\n",
            "Epoch: 9 | Iteration: 908 | Classification loss: 0.00075 | Regression loss: 0.01853 | Running loss: 0.04971\n",
            "Epoch: 9 | Iteration: 909 | Classification loss: 0.00023 | Regression loss: 0.03793 | Running loss: 0.04977\n",
            "Epoch: 9 | Iteration: 910 | Classification loss: 0.00019 | Regression loss: 0.01045 | Running loss: 0.04974\n",
            "Epoch: 9 | Iteration: 911 | Classification loss: 0.00013 | Regression loss: 0.03596 | Running loss: 0.04978\n",
            "Epoch: 9 | Iteration: 912 | Classification loss: 0.00047 | Regression loss: 0.05662 | Running loss: 0.04984\n",
            "Epoch: 9 | Iteration: 913 | Classification loss: 0.01147 | Regression loss: 0.04746 | Running loss: 0.04988\n",
            "Epoch: 9 | Iteration: 914 | Classification loss: 0.00165 | Regression loss: 0.03174 | Running loss: 0.04992\n",
            "Epoch: 9 | Iteration: 915 | Classification loss: 0.00017 | Regression loss: 0.03634 | Running loss: 0.04984\n",
            "Epoch: 9 | Iteration: 916 | Classification loss: 0.00102 | Regression loss: 0.07617 | Running loss: 0.04988\n",
            "Epoch: 9 | Iteration: 917 | Classification loss: 0.00012 | Regression loss: 0.02901 | Running loss: 0.04990\n",
            "Epoch: 9 | Iteration: 918 | Classification loss: 0.00016 | Regression loss: 0.06279 | Running loss: 0.04996\n",
            "Epoch: 9 | Iteration: 919 | Classification loss: 0.00742 | Regression loss: 0.05619 | Running loss: 0.04998\n",
            "Epoch: 9 | Iteration: 920 | Classification loss: 0.00014 | Regression loss: 0.02103 | Running loss: 0.04995\n",
            "Epoch: 9 | Iteration: 921 | Classification loss: 0.00051 | Regression loss: 0.08031 | Running loss: 0.05003\n",
            "Epoch: 9 | Iteration: 922 | Classification loss: 0.00155 | Regression loss: 0.03384 | Running loss: 0.05006\n",
            "Epoch: 9 | Iteration: 923 | Classification loss: 0.00056 | Regression loss: 0.01235 | Running loss: 0.05001\n",
            "Epoch: 9 | Iteration: 924 | Classification loss: 0.34686 | Regression loss: 0.28736 | Running loss: 0.05124\n",
            "Epoch: 9 | Iteration: 925 | Classification loss: 0.00016 | Regression loss: 0.02874 | Running loss: 0.05127\n",
            "Epoch: 9 | Iteration: 926 | Classification loss: 0.00004 | Regression loss: 0.04767 | Running loss: 0.05129\n",
            "Epoch: 9 | Iteration: 927 | Classification loss: 0.00004 | Regression loss: 0.01855 | Running loss: 0.05123\n",
            "Epoch: 9 | Iteration: 928 | Classification loss: 0.00069 | Regression loss: 0.03826 | Running loss: 0.05120\n",
            "Epoch: 9 | Iteration: 929 | Classification loss: 0.00070 | Regression loss: 0.04104 | Running loss: 0.05121\n",
            "Epoch: 9 | Iteration: 930 | Classification loss: 0.01585 | Regression loss: 0.07836 | Running loss: 0.05135\n",
            "Epoch: 9 | Iteration: 931 | Classification loss: 0.00131 | Regression loss: 0.01531 | Running loss: 0.05131\n",
            "Epoch: 9 | Iteration: 932 | Classification loss: 0.00024 | Regression loss: 0.02846 | Running loss: 0.05132\n",
            "Epoch: 9 | Iteration: 933 | Classification loss: 0.00276 | Regression loss: 0.03641 | Running loss: 0.05121\n",
            "Epoch: 9 | Iteration: 934 | Classification loss: 0.00007 | Regression loss: 0.02287 | Running loss: 0.05120\n",
            "Epoch: 9 | Iteration: 935 | Classification loss: 0.00020 | Regression loss: 0.01409 | Running loss: 0.05119\n",
            "Epoch: 9 | Iteration: 936 | Classification loss: 0.00019 | Regression loss: 0.01892 | Running loss: 0.05118\n",
            "Epoch: 9 | Iteration: 937 | Classification loss: 0.00042 | Regression loss: 0.01491 | Running loss: 0.05116\n",
            "Epoch: 9 | Iteration: 938 | Classification loss: 0.00030 | Regression loss: 0.03677 | Running loss: 0.05118\n",
            "Epoch: 9 | Iteration: 939 | Classification loss: 0.00007 | Regression loss: 0.03310 | Running loss: 0.05120\n",
            "Epoch: 9 | Iteration: 940 | Classification loss: 0.00028 | Regression loss: 0.01623 | Running loss: 0.05105\n",
            "Epoch: 9 | Iteration: 941 | Classification loss: 0.00022 | Regression loss: 0.04233 | Running loss: 0.05099\n",
            "Epoch: 9 | Iteration: 942 | Classification loss: 0.00053 | Regression loss: 0.03404 | Running loss: 0.05101\n",
            "Epoch: 9 | Iteration: 943 | Classification loss: 0.00112 | Regression loss: 0.01577 | Running loss: 0.05099\n",
            "Epoch: 9 | Iteration: 944 | Classification loss: 0.00395 | Regression loss: 0.02280 | Running loss: 0.05102\n",
            "Epoch: 9 | Iteration: 945 | Classification loss: 0.00139 | Regression loss: 0.09358 | Running loss: 0.05117\n",
            "Epoch: 9 | Iteration: 946 | Classification loss: 0.00017 | Regression loss: 0.00761 | Running loss: 0.05115\n",
            "Epoch: 9 | Iteration: 947 | Classification loss: 0.00011 | Regression loss: 0.01405 | Running loss: 0.05116\n",
            "Epoch: 9 | Iteration: 948 | Classification loss: 0.00053 | Regression loss: 0.01901 | Running loss: 0.05113\n",
            "Epoch: 9 | Iteration: 949 | Classification loss: 0.00020 | Regression loss: 0.02076 | Running loss: 0.05112\n",
            "Epoch: 9 | Iteration: 950 | Classification loss: 0.00007 | Regression loss: 0.02389 | Running loss: 0.05111\n",
            "Epoch: 9 | Iteration: 951 | Classification loss: 0.00018 | Regression loss: 0.03679 | Running loss: 0.05112\n",
            "Epoch: 9 | Iteration: 952 | Classification loss: 0.00146 | Regression loss: 0.07177 | Running loss: 0.05121\n",
            "Epoch: 9 | Iteration: 953 | Classification loss: 0.00013 | Regression loss: 0.01248 | Running loss: 0.05117\n",
            "Epoch: 9 | Iteration: 954 | Classification loss: 0.00002 | Regression loss: 0.00887 | Running loss: 0.05115\n",
            "Epoch: 9 | Iteration: 955 | Classification loss: 0.00048 | Regression loss: 0.03236 | Running loss: 0.05118\n",
            "Epoch: 9 | Iteration: 956 | Classification loss: 0.00018 | Regression loss: 0.03127 | Running loss: 0.05117\n",
            "Epoch: 9 | Iteration: 957 | Classification loss: 0.00029 | Regression loss: 0.01214 | Running loss: 0.05113\n",
            "Epoch: 9 | Iteration: 958 | Classification loss: 0.00006 | Regression loss: 0.00713 | Running loss: 0.05110\n",
            "Epoch: 9 | Iteration: 959 | Classification loss: 0.00016 | Regression loss: 0.03662 | Running loss: 0.05107\n",
            "Epoch: 9 | Iteration: 960 | Classification loss: 0.00028 | Regression loss: 0.03129 | Running loss: 0.05109\n",
            "Epoch: 9 | Iteration: 961 | Classification loss: 0.00025 | Regression loss: 0.02392 | Running loss: 0.05109\n",
            "Epoch: 9 | Iteration: 962 | Classification loss: 0.00040 | Regression loss: 0.01765 | Running loss: 0.05079\n",
            "Epoch: 9 | Iteration: 963 | Classification loss: 0.00021 | Regression loss: 0.04161 | Running loss: 0.05081\n",
            "Epoch: 9 | Iteration: 964 | Classification loss: 0.00007 | Regression loss: 0.01018 | Running loss: 0.05064\n",
            "Epoch: 9 | Iteration: 965 | Classification loss: 0.00039 | Regression loss: 0.02117 | Running loss: 0.05061\n",
            "Epoch: 9 | Iteration: 966 | Classification loss: 0.00064 | Regression loss: 0.02967 | Running loss: 0.05064\n",
            "Epoch: 9 | Iteration: 967 | Classification loss: 0.00006 | Regression loss: 0.03151 | Running loss: 0.05061\n",
            "Epoch: 9 | Iteration: 968 | Classification loss: 0.00012 | Regression loss: 0.03981 | Running loss: 0.05064\n",
            "Epoch: 9 | Iteration: 969 | Classification loss: 0.00458 | Regression loss: 0.05291 | Running loss: 0.05073\n",
            "Epoch: 9 | Iteration: 970 | Classification loss: 0.00068 | Regression loss: 0.04701 | Running loss: 0.05075\n",
            "Epoch: 9 | Iteration: 971 | Classification loss: 0.00023 | Regression loss: 0.02391 | Running loss: 0.05066\n",
            "Epoch: 9 | Iteration: 972 | Classification loss: 0.00007 | Regression loss: 0.03407 | Running loss: 0.05069\n",
            "Epoch: 9 | Iteration: 973 | Classification loss: 0.00084 | Regression loss: 0.02608 | Running loss: 0.05070\n",
            "Epoch: 9 | Iteration: 974 | Classification loss: 0.00048 | Regression loss: 0.04271 | Running loss: 0.05076\n",
            "Epoch: 9 | Iteration: 975 | Classification loss: 0.00100 | Regression loss: 0.08005 | Running loss: 0.05084\n",
            "Epoch: 9 | Iteration: 976 | Classification loss: 0.00004 | Regression loss: 0.00982 | Running loss: 0.05060\n",
            "Epoch: 9 | Iteration: 977 | Classification loss: 0.00027 | Regression loss: 0.01396 | Running loss: 0.05061\n",
            "Epoch: 9 | Iteration: 978 | Classification loss: 0.00023 | Regression loss: 0.00900 | Running loss: 0.05058\n",
            "Epoch: 9 | Iteration: 979 | Classification loss: 0.02558 | Regression loss: 0.18966 | Running loss: 0.05098\n",
            "Epoch: 9 | Iteration: 980 | Classification loss: 0.04493 | Regression loss: 0.03660 | Running loss: 0.05112\n",
            "Epoch: 9 | Iteration: 981 | Classification loss: 0.00091 | Regression loss: 0.02789 | Running loss: 0.05109\n",
            "Epoch: 9 | Iteration: 982 | Classification loss: 0.00014 | Regression loss: 0.03296 | Running loss: 0.05112\n",
            "Epoch: 9 | Iteration: 983 | Classification loss: 0.00018 | Regression loss: 0.00948 | Running loss: 0.05098\n",
            "Epoch: 9 | Iteration: 984 | Classification loss: 0.00133 | Regression loss: 0.03653 | Running loss: 0.05048\n",
            "Epoch: 9 | Iteration: 985 | Classification loss: 0.00059 | Regression loss: 0.03540 | Running loss: 0.05051\n",
            "Epoch: 9 | Iteration: 986 | Classification loss: 0.00005 | Regression loss: 0.02376 | Running loss: 0.05050\n",
            "Epoch: 9 | Iteration: 987 | Classification loss: 0.00041 | Regression loss: 0.01966 | Running loss: 0.05049\n",
            "Epoch: 9 | Iteration: 988 | Classification loss: 0.00013 | Regression loss: 0.02072 | Running loss: 0.05048\n",
            "Epoch: 9 | Iteration: 989 | Classification loss: 0.00005 | Regression loss: 0.01779 | Running loss: 0.05046\n",
            "Epoch: 9 | Iteration: 990 | Classification loss: 0.00017 | Regression loss: 0.01666 | Running loss: 0.05037\n",
            "Epoch: 9 | Iteration: 991 | Classification loss: 0.00007 | Regression loss: 0.01925 | Running loss: 0.05030\n",
            "Epoch: 9 | Iteration: 992 | Classification loss: 0.00017 | Regression loss: 0.03467 | Running loss: 0.05034\n",
            "Epoch: 9 | Iteration: 993 | Classification loss: 0.00087 | Regression loss: 0.01831 | Running loss: 0.05029\n",
            "Epoch: 9 | Iteration: 994 | Classification loss: 0.00359 | Regression loss: 0.01791 | Running loss: 0.05032\n",
            "Epoch: 9 | Iteration: 995 | Classification loss: 0.00279 | Regression loss: 0.02212 | Running loss: 0.05031\n",
            "Epoch: 9 | Iteration: 996 | Classification loss: 0.00095 | Regression loss: 0.05000 | Running loss: 0.05034\n",
            "Epoch: 9 | Iteration: 997 | Classification loss: 0.00019 | Regression loss: 0.07099 | Running loss: 0.05045\n",
            "Epoch: 9 | Iteration: 998 | Classification loss: 0.00021 | Regression loss: 0.01392 | Running loss: 0.05041\n",
            "Epoch: 9 | Iteration: 999 | Classification loss: 0.00876 | Regression loss: 0.03444 | Running loss: 0.05048\n",
            "Epoch: 9 | Iteration: 1000 | Classification loss: 0.00010 | Regression loss: 0.02133 | Running loss: 0.05044\n",
            "Epoch: 9 | Iteration: 1001 | Classification loss: 0.00010 | Regression loss: 0.02877 | Running loss: 0.05039\n",
            "Epoch: 9 | Iteration: 1002 | Classification loss: 0.00005 | Regression loss: 0.03689 | Running loss: 0.05039\n",
            "Epoch: 9 | Iteration: 1003 | Classification loss: 0.00135 | Regression loss: 0.05006 | Running loss: 0.05040\n",
            "Epoch: 9 | Iteration: 1004 | Classification loss: 0.00058 | Regression loss: 0.03497 | Running loss: 0.05035\n",
            "Epoch: 9 | Iteration: 1005 | Classification loss: 0.00012 | Regression loss: 0.03305 | Running loss: 0.05032\n",
            "Epoch: 9 | Iteration: 1006 | Classification loss: 0.00013 | Regression loss: 0.04348 | Running loss: 0.05032\n",
            "Epoch: 9 | Iteration: 1007 | Classification loss: 0.00204 | Regression loss: 0.04944 | Running loss: 0.05038\n",
            "Epoch: 9 | Iteration: 1008 | Classification loss: 0.00027 | Regression loss: 0.02678 | Running loss: 0.05041\n",
            "Epoch: 9 | Iteration: 1009 | Classification loss: 0.00006 | Regression loss: 0.01518 | Running loss: 0.05040\n",
            "Epoch: 9 | Iteration: 1010 | Classification loss: 0.00005 | Regression loss: 0.01119 | Running loss: 0.05033\n",
            "Epoch: 9 | Iteration: 1011 | Classification loss: 0.00165 | Regression loss: 0.02917 | Running loss: 0.05035\n",
            "Epoch: 9 | Iteration: 1012 | Classification loss: 0.00007 | Regression loss: 0.02786 | Running loss: 0.05035\n",
            "Epoch: 9 | Iteration: 1013 | Classification loss: 0.00007 | Regression loss: 0.02430 | Running loss: 0.05032\n",
            "Epoch: 9 | Iteration: 1014 | Classification loss: 0.00855 | Regression loss: 0.06960 | Running loss: 0.05043\n",
            "Epoch: 9 | Iteration: 1015 | Classification loss: 0.00440 | Regression loss: 0.03583 | Running loss: 0.05043\n",
            "Epoch: 9 | Iteration: 1016 | Classification loss: 0.00483 | Regression loss: 0.03551 | Running loss: 0.05045\n",
            "Epoch: 9 | Iteration: 1017 | Classification loss: 0.09753 | Regression loss: 0.25777 | Running loss: 0.05107\n",
            "Epoch: 9 | Iteration: 1018 | Classification loss: 0.00227 | Regression loss: 0.02034 | Running loss: 0.05106\n",
            "Epoch: 9 | Iteration: 1019 | Classification loss: 0.00034 | Regression loss: 0.01962 | Running loss: 0.05105\n",
            "Epoch: 9 | Iteration: 1020 | Classification loss: 0.00005 | Regression loss: 0.01766 | Running loss: 0.05102\n",
            "Epoch: 9 | Iteration: 1021 | Classification loss: 0.00031 | Regression loss: 0.01841 | Running loss: 0.05091\n",
            "Epoch: 9 | Iteration: 1022 | Classification loss: 0.00013 | Regression loss: 0.02686 | Running loss: 0.05091\n",
            "Epoch: 9 | Iteration: 1023 | Classification loss: 0.01028 | Regression loss: 0.05682 | Running loss: 0.05102\n",
            "Epoch: 9 | Iteration: 1024 | Classification loss: 0.00011 | Regression loss: 0.01484 | Running loss: 0.05099\n",
            "Epoch: 9 | Iteration: 1025 | Classification loss: 0.00035 | Regression loss: 0.02376 | Running loss: 0.05099\n",
            "Epoch: 9 | Iteration: 1026 | Classification loss: 0.00004 | Regression loss: 0.01529 | Running loss: 0.05097\n",
            "Epoch: 9 | Iteration: 1027 | Classification loss: 0.00004 | Regression loss: 0.02137 | Running loss: 0.05090\n",
            "Epoch: 9 | Iteration: 1028 | Classification loss: 0.00005 | Regression loss: 0.01138 | Running loss: 0.05090\n",
            "Epoch: 9 | Iteration: 1029 | Classification loss: 0.00099 | Regression loss: 0.01886 | Running loss: 0.05088\n",
            "Epoch: 9 | Iteration: 1030 | Classification loss: 0.00007 | Regression loss: 0.04925 | Running loss: 0.05094\n",
            "Epoch: 9 | Iteration: 1031 | Classification loss: 0.00008 | Regression loss: 0.01805 | Running loss: 0.04760\n",
            "Epoch: 9 | Iteration: 1032 | Classification loss: 0.00011 | Regression loss: 0.04312 | Running loss: 0.04765\n",
            "Epoch: 9 | Iteration: 1033 | Classification loss: 0.00027 | Regression loss: 0.02026 | Running loss: 0.04766\n",
            "Epoch: 9 | Iteration: 1034 | Classification loss: 0.00003 | Regression loss: 0.02501 | Running loss: 0.04767\n",
            "Epoch: 9 | Iteration: 1035 | Classification loss: 0.00054 | Regression loss: 0.03894 | Running loss: 0.04771\n",
            "Epoch: 9 | Iteration: 1036 | Classification loss: 0.00073 | Regression loss: 0.02767 | Running loss: 0.04772\n",
            "Epoch: 9 | Iteration: 1037 | Classification loss: 0.00012 | Regression loss: 0.01674 | Running loss: 0.04771\n",
            "Epoch: 9 | Iteration: 1038 | Classification loss: 0.01480 | Regression loss: 0.06847 | Running loss: 0.04754\n",
            "Epoch: 9 | Iteration: 1039 | Classification loss: 0.01364 | Regression loss: 0.05727 | Running loss: 0.04754\n",
            "Epoch: 9 | Iteration: 1040 | Classification loss: 0.00047 | Regression loss: 0.02392 | Running loss: 0.04755\n",
            "Epoch: 9 | Iteration: 1041 | Classification loss: 0.00051 | Regression loss: 0.03251 | Running loss: 0.04745\n",
            "Epoch: 9 | Iteration: 1042 | Classification loss: 0.00017 | Regression loss: 0.02342 | Running loss: 0.04742\n",
            "Epoch: 9 | Iteration: 1043 | Classification loss: 0.00676 | Regression loss: 0.05486 | Running loss: 0.04750\n",
            "Epoch: 9 | Iteration: 1044 | Classification loss: 0.00036 | Regression loss: 0.02514 | Running loss: 0.04749\n",
            "Epoch: 9 | Iteration: 1045 | Classification loss: 0.00064 | Regression loss: 0.02920 | Running loss: 0.04750\n",
            "Epoch: 9 | Iteration: 1046 | Classification loss: 0.00447 | Regression loss: 0.08924 | Running loss: 0.04764\n",
            "Epoch: 9 | Iteration: 1047 | Classification loss: 0.00018 | Regression loss: 0.02185 | Running loss: 0.04757\n",
            "Epoch: 9 | Iteration: 1048 | Classification loss: 0.00038 | Regression loss: 0.02511 | Running loss: 0.04706\n",
            "Epoch: 9 | Iteration: 1049 | Classification loss: 0.00027 | Regression loss: 0.03932 | Running loss: 0.04703\n",
            "Epoch: 9 | Iteration: 1050 | Classification loss: 0.00002 | Regression loss: 0.02497 | Running loss: 0.04686\n",
            "Epoch: 9 | Iteration: 1051 | Classification loss: 0.02771 | Regression loss: 0.05266 | Running loss: 0.04693\n",
            "Epoch: 9 | Iteration: 1052 | Classification loss: 0.00022 | Regression loss: 0.03686 | Running loss: 0.04529\n",
            "Epoch: 9 | Iteration: 1053 | Classification loss: 0.00021 | Regression loss: 0.03383 | Running loss: 0.04530\n",
            "Epoch: 9 | Iteration: 1054 | Classification loss: 0.00009 | Regression loss: 0.01631 | Running loss: 0.04528\n",
            "Epoch: 9 | Iteration: 1055 | Classification loss: 0.00007 | Regression loss: 0.01380 | Running loss: 0.04529\n",
            "Epoch: 9 | Iteration: 1056 | Classification loss: 0.00020 | Regression loss: 0.04433 | Running loss: 0.04528\n",
            "Epoch: 9 | Iteration: 1057 | Classification loss: 0.00045 | Regression loss: 0.02282 | Running loss: 0.04527\n",
            "Epoch: 9 | Iteration: 1058 | Classification loss: 0.00008 | Regression loss: 0.01133 | Running loss: 0.04523\n",
            "Epoch: 9 | Iteration: 1059 | Classification loss: 0.08401 | Regression loss: 0.18037 | Running loss: 0.04564\n",
            "Epoch: 9 | Iteration: 1060 | Classification loss: 0.00023 | Regression loss: 0.02421 | Running loss: 0.04566\n",
            "Epoch: 9 | Iteration: 1061 | Classification loss: 0.00104 | Regression loss: 0.04618 | Running loss: 0.04570\n",
            "Epoch: 9 | Iteration: 1062 | Classification loss: 0.00019 | Regression loss: 0.01576 | Running loss: 0.04569\n",
            "Epoch: 9 | Iteration: 1063 | Classification loss: 0.00064 | Regression loss: 0.01563 | Running loss: 0.04567\n",
            "Epoch: 9 | Iteration: 1064 | Classification loss: 0.00009 | Regression loss: 0.01865 | Running loss: 0.04563\n",
            "Epoch: 9 | Iteration: 1065 | Classification loss: 0.00002 | Regression loss: 0.02640 | Running loss: 0.04532\n",
            "Epoch: 9 | Iteration: 1066 | Classification loss: 0.00031 | Regression loss: 0.02464 | Running loss: 0.04531\n",
            "Epoch: 9 | Iteration: 1067 | Classification loss: 0.00009 | Regression loss: 0.01306 | Running loss: 0.04524\n",
            "Epoch: 9 | Iteration: 1068 | Classification loss: 0.00016 | Regression loss: 0.02113 | Running loss: 0.04521\n",
            "Epoch: 9 | Iteration: 1069 | Classification loss: 0.00412 | Regression loss: 0.03683 | Running loss: 0.04496\n",
            "Epoch: 9 | Iteration: 1070 | Classification loss: 0.00057 | Regression loss: 0.02534 | Running loss: 0.04493\n",
            "Epoch: 9 | Iteration: 1071 | Classification loss: 0.00072 | Regression loss: 0.02063 | Running loss: 0.04493\n",
            "Epoch: 9 | Iteration: 1072 | Classification loss: 0.00012 | Regression loss: 0.01442 | Running loss: 0.04492\n",
            "Epoch: 9 | Iteration: 1073 | Classification loss: 0.00005 | Regression loss: 0.02648 | Running loss: 0.04492\n",
            "Epoch: 9 | Iteration: 1074 | Classification loss: 0.00032 | Regression loss: 0.01809 | Running loss: 0.04488\n",
            "Epoch: 9 | Iteration: 1075 | Classification loss: 0.00017 | Regression loss: 0.01851 | Running loss: 0.04486\n",
            "Epoch: 9 | Iteration: 1076 | Classification loss: 0.00022 | Regression loss: 0.02007 | Running loss: 0.04485\n",
            "Epoch: 9 | Iteration: 1077 | Classification loss: 0.00049 | Regression loss: 0.03518 | Running loss: 0.04481\n",
            "Epoch: 9 | Iteration: 1078 | Classification loss: 0.00040 | Regression loss: 0.02020 | Running loss: 0.04476\n",
            "Epoch: 9 | Iteration: 1079 | Classification loss: 0.00141 | Regression loss: 0.05591 | Running loss: 0.04478\n",
            "Epoch: 9 | Iteration: 1080 | Classification loss: 0.00025 | Regression loss: 0.03200 | Running loss: 0.04478\n",
            "Epoch: 9 | Iteration: 1081 | Classification loss: 0.00022 | Regression loss: 0.02974 | Running loss: 0.04472\n",
            "Epoch: 9 | Iteration: 1082 | Classification loss: 0.00013 | Regression loss: 0.00909 | Running loss: 0.04464\n",
            "Epoch: 9 | Iteration: 1083 | Classification loss: 0.00103 | Regression loss: 0.05980 | Running loss: 0.04469\n",
            "Epoch: 9 | Iteration: 1084 | Classification loss: 0.00010 | Regression loss: 0.01312 | Running loss: 0.04466\n",
            "Epoch: 9 | Iteration: 1085 | Classification loss: 0.00077 | Regression loss: 0.04479 | Running loss: 0.04470\n",
            "Epoch: 9 | Iteration: 1086 | Classification loss: 0.00053 | Regression loss: 0.03734 | Running loss: 0.04472\n",
            "Epoch: 9 | Iteration: 1087 | Classification loss: 0.00020 | Regression loss: 0.04104 | Running loss: 0.04464\n",
            "Epoch: 9 | Iteration: 1088 | Classification loss: 0.00109 | Regression loss: 0.03708 | Running loss: 0.04378\n",
            "Epoch: 9 | Iteration: 1089 | Classification loss: 0.00016 | Regression loss: 0.01158 | Running loss: 0.04373\n",
            "Epoch: 9 | Iteration: 1090 | Classification loss: 0.00043 | Regression loss: 0.03286 | Running loss: 0.04374\n",
            "Epoch: 9 | Iteration: 1091 | Classification loss: 0.00024 | Regression loss: 0.02587 | Running loss: 0.04370\n",
            "Epoch: 9 | Iteration: 1092 | Classification loss: 0.00015 | Regression loss: 0.01241 | Running loss: 0.04359\n",
            "Epoch: 9 | Iteration: 1093 | Classification loss: 0.00029 | Regression loss: 0.02992 | Running loss: 0.04361\n",
            "Epoch: 9 | Iteration: 1094 | Classification loss: 0.00003 | Regression loss: 0.03156 | Running loss: 0.04362\n",
            "Epoch: 9 | Iteration: 1095 | Classification loss: 0.00245 | Regression loss: 0.04237 | Running loss: 0.04360\n",
            "Epoch: 9 | Iteration: 1096 | Classification loss: 0.00433 | Regression loss: 0.13790 | Running loss: 0.04379\n",
            "Epoch: 9 | Iteration: 1097 | Classification loss: 0.00076 | Regression loss: 0.02793 | Running loss: 0.04380\n",
            "Epoch: 9 | Iteration: 1098 | Classification loss: 0.00010 | Regression loss: 0.02873 | Running loss: 0.04380\n",
            "Epoch: 9 | Iteration: 1099 | Classification loss: 0.00011 | Regression loss: 0.02576 | Running loss: 0.04380\n",
            "Epoch: 9 | Iteration: 1100 | Classification loss: 0.00015 | Regression loss: 0.03292 | Running loss: 0.04380\n",
            "Epoch: 9 | Iteration: 1101 | Classification loss: 0.10447 | Regression loss: 0.08751 | Running loss: 0.04412\n",
            "Epoch: 9 | Iteration: 1102 | Classification loss: 0.00026 | Regression loss: 0.03214 | Running loss: 0.04411\n",
            "Epoch: 9 | Iteration: 1103 | Classification loss: 0.00009 | Regression loss: 0.01713 | Running loss: 0.04410\n",
            "Epoch: 9 | Iteration: 1104 | Classification loss: 0.00161 | Regression loss: 0.02387 | Running loss: 0.04413\n",
            "Epoch: 9 | Iteration: 1105 | Classification loss: 0.00044 | Regression loss: 0.02098 | Running loss: 0.04414\n",
            "Epoch: 9 | Iteration: 1106 | Classification loss: 0.00053 | Regression loss: 0.02259 | Running loss: 0.04398\n",
            "Epoch: 9 | Iteration: 1107 | Classification loss: 0.00004 | Regression loss: 0.01915 | Running loss: 0.04396\n",
            "Epoch: 9 | Iteration: 1108 | Classification loss: 0.00011 | Regression loss: 0.02776 | Running loss: 0.04399\n",
            "Epoch: 9 | Iteration: 1109 | Classification loss: 0.00006 | Regression loss: 0.03483 | Running loss: 0.04398\n",
            "Epoch: 9 | Iteration: 1110 | Classification loss: 0.00030 | Regression loss: 0.02635 | Running loss: 0.04398\n",
            "Epoch: 9 | Iteration: 1111 | Classification loss: 0.00005 | Regression loss: 0.01257 | Running loss: 0.04393\n",
            "Epoch: 9 | Iteration: 1112 | Classification loss: 0.00051 | Regression loss: 0.04611 | Running loss: 0.04355\n",
            "Epoch: 9 | Iteration: 1113 | Classification loss: 0.00011 | Regression loss: 0.02555 | Running loss: 0.04353\n",
            "Epoch: 9 | Iteration: 1114 | Classification loss: 0.00002 | Regression loss: 0.02129 | Running loss: 0.04346\n",
            "Epoch: 9 | Iteration: 1115 | Classification loss: 0.00002 | Regression loss: 0.02433 | Running loss: 0.04348\n",
            "Epoch: 9 | Iteration: 1116 | Classification loss: 0.00004 | Regression loss: 0.02100 | Running loss: 0.04341\n",
            "Epoch: 9 | Iteration: 1117 | Classification loss: 0.09161 | Regression loss: 0.42483 | Running loss: 0.04440\n",
            "Epoch: 9 | Iteration: 1118 | Classification loss: 0.00009 | Regression loss: 0.02549 | Running loss: 0.04437\n",
            "Epoch: 9 | Iteration: 1119 | Classification loss: 0.00045 | Regression loss: 0.01851 | Running loss: 0.04437\n",
            "Epoch: 9 | Iteration: 1120 | Classification loss: 0.00004 | Regression loss: 0.02778 | Running loss: 0.04438\n",
            "Epoch: 9 | Iteration: 1121 | Classification loss: 0.00060 | Regression loss: 0.03676 | Running loss: 0.04439\n",
            "Epoch: 9 | Iteration: 1122 | Classification loss: 0.00065 | Regression loss: 0.03277 | Running loss: 0.04436\n",
            "Epoch: 9 | Iteration: 1123 | Classification loss: 0.00101 | Regression loss: 0.00822 | Running loss: 0.04434\n",
            "Epoch: 9 | Iteration: 1124 | Classification loss: 0.00005 | Regression loss: 0.04196 | Running loss: 0.04330\n",
            "Epoch: 9 | Iteration: 1125 | Classification loss: 0.00069 | Regression loss: 0.02262 | Running loss: 0.04312\n",
            "Epoch: 9 | Iteration: 1126 | Classification loss: 0.00053 | Regression loss: 0.03972 | Running loss: 0.04317\n",
            "Epoch: 9 | Iteration: 1127 | Classification loss: 0.00013 | Regression loss: 0.03270 | Running loss: 0.04306\n",
            "Epoch: 9 | Iteration: 1128 | Classification loss: 0.01610 | Regression loss: 0.03838 | Running loss: 0.04306\n",
            "Epoch: 9 | Iteration: 1129 | Classification loss: 0.00026 | Regression loss: 0.04121 | Running loss: 0.04256\n",
            "Epoch: 9 | Iteration: 1130 | Classification loss: 0.00053 | Regression loss: 0.02344 | Running loss: 0.04254\n",
            "Epoch: 9 | Iteration: 1131 | Classification loss: 0.00005 | Regression loss: 0.02198 | Running loss: 0.04253\n",
            "Epoch: 9 | Iteration: 1132 | Classification loss: 0.00019 | Regression loss: 0.04286 | Running loss: 0.04256\n",
            "Epoch: 9 | Iteration: 1133 | Classification loss: 0.00011 | Regression loss: 0.03003 | Running loss: 0.04257\n",
            "Epoch: 9 | Iteration: 1134 | Classification loss: 0.00014 | Regression loss: 0.01388 | Running loss: 0.04219\n",
            "Epoch: 9 | Iteration: 1135 | Classification loss: 0.00018 | Regression loss: 0.03305 | Running loss: 0.04220\n",
            "Epoch: 9 | Iteration: 1136 | Classification loss: 0.00237 | Regression loss: 0.01069 | Running loss: 0.04219\n",
            "Epoch: 9 | Iteration: 1137 | Classification loss: 0.00041 | Regression loss: 0.05022 | Running loss: 0.04225\n",
            "Epoch: 9 | Iteration: 1138 | Classification loss: 0.00004 | Regression loss: 0.01177 | Running loss: 0.04218\n",
            "Epoch: 9 | Iteration: 1139 | Classification loss: 0.00681 | Regression loss: 0.04418 | Running loss: 0.04215\n",
            "Epoch: 9 | Iteration: 1140 | Classification loss: 0.00088 | Regression loss: 0.02140 | Running loss: 0.04201\n",
            "Epoch: 9 | Iteration: 1141 | Classification loss: 0.00013 | Regression loss: 0.03720 | Running loss: 0.04199\n",
            "Epoch: 9 | Iteration: 1142 | Classification loss: 0.00107 | Regression loss: 0.01304 | Running loss: 0.04197\n",
            "Epoch: 9 | Iteration: 1143 | Classification loss: 0.00013 | Regression loss: 0.02433 | Running loss: 0.04194\n",
            "Epoch: 9 | Iteration: 1144 | Classification loss: 0.00004 | Regression loss: 0.01914 | Running loss: 0.04195\n",
            "Epoch: 9 | Iteration: 1145 | Classification loss: 0.00002 | Regression loss: 0.00759 | Running loss: 0.04183\n",
            "Epoch: 9 | Iteration: 1146 | Classification loss: 0.00021 | Regression loss: 0.01649 | Running loss: 0.04183\n",
            "Epoch: 9 | Iteration: 1147 | Classification loss: 0.00028 | Regression loss: 0.04503 | Running loss: 0.04188\n",
            "Epoch: 9 | Iteration: 1148 | Classification loss: 0.04356 | Regression loss: 0.05139 | Running loss: 0.04203\n",
            "Epoch: 9 | Iteration: 1149 | Classification loss: 0.00014 | Regression loss: 0.01447 | Running loss: 0.04175\n",
            "Epoch: 9 | Iteration: 1150 | Classification loss: 0.00008 | Regression loss: 0.01329 | Running loss: 0.04172\n",
            "Epoch: 9 | Iteration: 1151 | Classification loss: 0.00010 | Regression loss: 0.01198 | Running loss: 0.04166\n",
            "Epoch: 9 | Iteration: 1152 | Classification loss: 0.00043 | Regression loss: 0.01707 | Running loss: 0.04168\n",
            "Epoch: 9 | Iteration: 1153 | Classification loss: 0.07046 | Regression loss: 0.30965 | Running loss: 0.04210\n",
            "Epoch: 9 | Iteration: 1154 | Classification loss: 0.00004 | Regression loss: 0.02236 | Running loss: 0.04205\n",
            "Epoch: 9 | Iteration: 1155 | Classification loss: 0.00037 | Regression loss: 0.03045 | Running loss: 0.04201\n",
            "Epoch: 9 | Iteration: 1156 | Classification loss: 0.00033 | Regression loss: 0.04502 | Running loss: 0.04202\n",
            "Epoch: 9 | Iteration: 1157 | Classification loss: 0.00010 | Regression loss: 0.02873 | Running loss: 0.04202\n",
            "Epoch: 9 | Iteration: 1158 | Classification loss: 0.00442 | Regression loss: 0.06923 | Running loss: 0.04212\n",
            "Epoch: 9 | Iteration: 1159 | Classification loss: 0.00013 | Regression loss: 0.02430 | Running loss: 0.04214\n",
            "Epoch: 9 | Iteration: 1160 | Classification loss: 0.01360 | Regression loss: 0.07388 | Running loss: 0.04225\n",
            "Epoch: 9 | Iteration: 1161 | Classification loss: 0.06457 | Regression loss: 0.07894 | Running loss: 0.04247\n",
            "Epoch: 9 | Iteration: 1162 | Classification loss: 0.00002 | Regression loss: 0.02804 | Running loss: 0.04248\n",
            "Epoch: 9 | Iteration: 1163 | Classification loss: 0.13687 | Regression loss: 0.07629 | Running loss: 0.04270\n",
            "Epoch: 9 | Iteration: 1164 | Classification loss: 0.00720 | Regression loss: 0.03064 | Running loss: 0.04275\n",
            "Epoch: 9 | Iteration: 1165 | Classification loss: 0.00018 | Regression loss: 0.00932 | Running loss: 0.04263\n",
            "Epoch: 9 | Iteration: 1166 | Classification loss: 0.00005 | Regression loss: 0.00811 | Running loss: 0.04259\n",
            "Epoch: 9 | Iteration: 1167 | Classification loss: 0.00146 | Regression loss: 0.02877 | Running loss: 0.04260\n",
            "Epoch: 9 | Iteration: 1168 | Classification loss: 0.00040 | Regression loss: 0.04373 | Running loss: 0.04264\n",
            "Epoch: 9 | Iteration: 1169 | Classification loss: 0.00047 | Regression loss: 0.01555 | Running loss: 0.04265\n",
            "Epoch: 9 | Iteration: 1170 | Classification loss: 0.00629 | Regression loss: 0.02154 | Running loss: 0.04262\n",
            "Epoch: 9 | Iteration: 1171 | Classification loss: 0.00129 | Regression loss: 0.03002 | Running loss: 0.04057\n",
            "Epoch: 9 | Iteration: 1172 | Classification loss: 0.01474 | Regression loss: 0.04529 | Running loss: 0.04064\n",
            "Epoch: 9 | Iteration: 1173 | Classification loss: 0.00019 | Regression loss: 0.02140 | Running loss: 0.04063\n",
            "Epoch: 9 | Iteration: 1174 | Classification loss: 0.00071 | Regression loss: 0.02962 | Running loss: 0.04064\n",
            "Epoch: 9 | Iteration: 1175 | Classification loss: 0.01009 | Regression loss: 0.02613 | Running loss: 0.04056\n",
            "Epoch: 9 | Iteration: 1176 | Classification loss: 0.00435 | Regression loss: 0.02787 | Running loss: 0.04057\n",
            "Epoch: 9 | Iteration: 1177 | Classification loss: 0.00018 | Regression loss: 0.02190 | Running loss: 0.04057\n",
            "Epoch: 9 | Iteration: 1178 | Classification loss: 0.00043 | Regression loss: 0.02846 | Running loss: 0.04061\n",
            "Epoch: 9 | Iteration: 1179 | Classification loss: 0.00331 | Regression loss: 0.02367 | Running loss: 0.04060\n",
            "Epoch: 9 | Iteration: 1180 | Classification loss: 0.00071 | Regression loss: 0.01261 | Running loss: 0.04054\n",
            "Epoch: 9 | Iteration: 1181 | Classification loss: 0.00019 | Regression loss: 0.01977 | Running loss: 0.04052\n",
            "Epoch: 9 | Iteration: 1182 | Classification loss: 1.86237 | Regression loss: 0.12636 | Running loss: 0.04447\n",
            "Epoch: 9 | Iteration: 1183 | Classification loss: 0.00010 | Regression loss: 0.01815 | Running loss: 0.04447\n",
            "Epoch: 9 | Iteration: 1184 | Classification loss: 0.00005 | Regression loss: 0.01935 | Running loss: 0.04446\n",
            "Epoch: 9 | Iteration: 1185 | Classification loss: 0.00029 | Regression loss: 0.02146 | Running loss: 0.04445\n",
            "Epoch: 9 | Iteration: 1186 | Classification loss: 0.00032 | Regression loss: 0.02841 | Running loss: 0.04437\n",
            "Epoch: 9 | Iteration: 1187 | Classification loss: 0.00030 | Regression loss: 0.01951 | Running loss: 0.04435\n",
            "Epoch: 9 | Iteration: 1188 | Classification loss: 0.00009 | Regression loss: 0.02824 | Running loss: 0.04436\n",
            "Epoch: 9 | Iteration: 1189 | Classification loss: 0.00120 | Regression loss: 0.03003 | Running loss: 0.04435\n",
            "Epoch: 9 | Iteration: 1190 | Classification loss: 0.00003 | Regression loss: 0.02795 | Running loss: 0.04426\n",
            "Epoch: 9 | Iteration: 1191 | Classification loss: 0.00044 | Regression loss: 0.02333 | Running loss: 0.04416\n",
            "Epoch: 9 | Iteration: 1192 | Classification loss: 0.03817 | Regression loss: 0.20176 | Running loss: 0.04445\n",
            "Epoch: 9 | Iteration: 1193 | Classification loss: 0.00020 | Regression loss: 0.02543 | Running loss: 0.04442\n",
            "Epoch: 9 | Iteration: 1194 | Classification loss: 0.00027 | Regression loss: 0.02517 | Running loss: 0.04440\n",
            "Epoch: 9 | Iteration: 1195 | Classification loss: 0.00132 | Regression loss: 0.01755 | Running loss: 0.04435\n",
            "Epoch: 9 | Iteration: 1196 | Classification loss: 0.00151 | Regression loss: 0.04922 | Running loss: 0.04438\n",
            "Epoch: 9 | Iteration: 1197 | Classification loss: 0.00035 | Regression loss: 0.02394 | Running loss: 0.04437\n",
            "Epoch: 9 | Iteration: 1198 | Classification loss: 0.00061 | Regression loss: 0.01243 | Running loss: 0.04424\n",
            "Epoch: 9 | Iteration: 1199 | Classification loss: 0.14700 | Regression loss: 0.23856 | Running loss: 0.04492\n",
            "Epoch: 9 | Iteration: 1200 | Classification loss: 0.00039 | Regression loss: 0.02601 | Running loss: 0.04482\n",
            "Epoch: 9 | Iteration: 1201 | Classification loss: 0.00023 | Regression loss: 0.02652 | Running loss: 0.04485\n",
            "Epoch: 9 | Iteration: 1202 | Classification loss: 0.00198 | Regression loss: 0.06589 | Running loss: 0.04491\n",
            "Epoch: 9 | Iteration: 1203 | Classification loss: 0.00014 | Regression loss: 0.02064 | Running loss: 0.04489\n",
            "Epoch: 9 | Iteration: 1204 | Classification loss: 0.00182 | Regression loss: 0.01806 | Running loss: 0.04490\n",
            "Epoch: 9 | Iteration: 1205 | Classification loss: 0.00019 | Regression loss: 0.01273 | Running loss: 0.04487\n",
            "Epoch: 9 | Iteration: 1206 | Classification loss: 0.00304 | Regression loss: 0.02753 | Running loss: 0.04489\n",
            "Epoch: 9 | Iteration: 1207 | Classification loss: 0.00886 | Regression loss: 0.02058 | Running loss: 0.04491\n",
            "Epoch: 9 | Iteration: 1208 | Classification loss: 0.00154 | Regression loss: 0.01140 | Running loss: 0.04481\n",
            "Epoch: 9 | Iteration: 1209 | Classification loss: 0.00015 | Regression loss: 0.01510 | Running loss: 0.04474\n",
            "Epoch: 9 | Iteration: 1210 | Classification loss: 0.00163 | Regression loss: 0.04616 | Running loss: 0.04479\n",
            "Epoch: 9 | Iteration: 1211 | Classification loss: 0.00180 | Regression loss: 0.02188 | Running loss: 0.04481\n",
            "Epoch: 9 | Iteration: 1212 | Classification loss: 0.00175 | Regression loss: 0.04713 | Running loss: 0.04486\n",
            "Epoch: 9 | Iteration: 1213 | Classification loss: 0.00051 | Regression loss: 0.01433 | Running loss: 0.04485\n",
            "Epoch: 9 | Iteration: 1214 | Classification loss: 0.00048 | Regression loss: 0.04326 | Running loss: 0.04487\n",
            "Epoch: 9 | Iteration: 1215 | Classification loss: 0.00019 | Regression loss: 0.04594 | Running loss: 0.04489\n",
            "Epoch: 9 | Iteration: 1216 | Classification loss: 0.00568 | Regression loss: 0.04196 | Running loss: 0.04492\n",
            "Epoch: 9 | Iteration: 1217 | Classification loss: 0.02912 | Regression loss: 0.01583 | Running loss: 0.04497\n",
            "Epoch: 9 | Iteration: 1218 | Classification loss: 0.00417 | Regression loss: 0.03496 | Running loss: 0.04484\n",
            "Epoch: 9 | Iteration: 1219 | Classification loss: 0.00135 | Regression loss: 0.03316 | Running loss: 0.04486\n",
            "Epoch: 9 | Iteration: 1220 | Classification loss: 0.00057 | Regression loss: 0.05628 | Running loss: 0.04483\n",
            "Epoch: 9 | Iteration: 1221 | Classification loss: 0.00009 | Regression loss: 0.02779 | Running loss: 0.04485\n",
            "Epoch: 9 | Iteration: 1222 | Classification loss: 0.00063 | Regression loss: 0.01768 | Running loss: 0.04485\n",
            "Epoch: 9 | Iteration: 1223 | Classification loss: 0.00032 | Regression loss: 0.01188 | Running loss: 0.04480\n",
            "Epoch: 9 | Iteration: 1224 | Classification loss: 0.00020 | Regression loss: 0.01122 | Running loss: 0.04476\n",
            "Epoch: 9 | Iteration: 1225 | Classification loss: 0.00513 | Regression loss: 0.04631 | Running loss: 0.04481\n",
            "Epoch: 9 | Iteration: 1226 | Classification loss: 0.02167 | Regression loss: 0.02302 | Running loss: 0.04484\n",
            "Epoch: 9 | Iteration: 1227 | Classification loss: 0.00007 | Regression loss: 0.03079 | Running loss: 0.04486\n",
            "Epoch: 9 | Iteration: 1228 | Classification loss: 0.00070 | Regression loss: 0.02557 | Running loss: 0.04480\n",
            "Epoch: 9 | Iteration: 1229 | Classification loss: 0.06178 | Regression loss: 0.06926 | Running loss: 0.04502\n",
            "Epoch: 9 | Iteration: 1230 | Classification loss: 0.01256 | Regression loss: 0.03845 | Running loss: 0.04508\n",
            "Epoch: 9 | Iteration: 1231 | Classification loss: 0.00011 | Regression loss: 0.01264 | Running loss: 0.04505\n",
            "Epoch: 9 | Iteration: 1232 | Classification loss: 0.05812 | Regression loss: 0.03346 | Running loss: 0.04511\n",
            "Epoch: 9 | Iteration: 1233 | Classification loss: 0.00009 | Regression loss: 0.01207 | Running loss: 0.04506\n",
            "Epoch: 9 | Iteration: 1234 | Classification loss: 0.00063 | Regression loss: 0.02106 | Running loss: 0.04499\n",
            "Epoch: 9 | Iteration: 1235 | Classification loss: 0.00322 | Regression loss: 0.01428 | Running loss: 0.04499\n",
            "Epoch: 9 | Iteration: 1236 | Classification loss: 0.01400 | Regression loss: 0.02570 | Running loss: 0.04502\n",
            "Epoch: 9 | Iteration: 1237 | Classification loss: 0.00245 | Regression loss: 0.03038 | Running loss: 0.04504\n",
            "Epoch: 9 | Iteration: 1238 | Classification loss: 0.00008 | Regression loss: 0.01639 | Running loss: 0.04503\n",
            "Epoch: 9 | Iteration: 1239 | Classification loss: 0.00244 | Regression loss: 0.06585 | Running loss: 0.04512\n",
            "Epoch: 9 | Iteration: 1240 | Classification loss: 0.00069 | Regression loss: 0.01131 | Running loss: 0.04509\n",
            "Epoch: 9 | Iteration: 1241 | Classification loss: 0.00369 | Regression loss: 0.01765 | Running loss: 0.04507\n",
            "Epoch: 9 | Iteration: 1242 | Classification loss: 0.00503 | Regression loss: 0.02416 | Running loss: 0.04511\n",
            "Epoch: 9 | Iteration: 1243 | Classification loss: 0.00238 | Regression loss: 0.02319 | Running loss: 0.04506\n",
            "Epoch: 9 | Iteration: 1244 | Classification loss: 0.00324 | Regression loss: 0.01916 | Running loss: 0.04501\n",
            "Epoch: 9 | Iteration: 1245 | Classification loss: 0.00051 | Regression loss: 0.02665 | Running loss: 0.04499\n",
            "Epoch: 9 | Iteration: 1246 | Classification loss: 0.00116 | Regression loss: 0.01846 | Running loss: 0.04495\n",
            "Epoch: 9 | Iteration: 1247 | Classification loss: 0.00054 | Regression loss: 0.01000 | Running loss: 0.04489\n",
            "Epoch: 9 | Iteration: 1248 | Classification loss: 0.00047 | Regression loss: 0.01485 | Running loss: 0.04490\n",
            "Epoch: 9 | Iteration: 1249 | Classification loss: 0.00074 | Regression loss: 0.02726 | Running loss: 0.04493\n",
            "Epoch: 9 | Iteration: 1250 | Classification loss: 0.02025 | Regression loss: 0.05027 | Running loss: 0.04501\n",
            "Epoch: 9 | Iteration: 1251 | Classification loss: 0.00058 | Regression loss: 0.01615 | Running loss: 0.04499\n",
            "Epoch: 9 | Iteration: 1252 | Classification loss: 0.00029 | Regression loss: 0.01821 | Running loss: 0.04487\n",
            "Epoch: 9 | Iteration: 1253 | Classification loss: 0.00022 | Regression loss: 0.01668 | Running loss: 0.04480\n",
            "Epoch: 9 | Iteration: 1254 | Classification loss: 0.00004 | Regression loss: 0.02002 | Running loss: 0.04480\n",
            "Epoch: 9 | Iteration: 1255 | Classification loss: 0.00132 | Regression loss: 0.03654 | Running loss: 0.04481\n",
            "Epoch: 9 | Iteration: 1256 | Classification loss: 0.00006 | Regression loss: 0.01743 | Running loss: 0.04481\n",
            "Epoch: 9 | Iteration: 1257 | Classification loss: 0.00006 | Regression loss: 0.01444 | Running loss: 0.04481\n",
            "Epoch: 9 | Iteration: 1258 | Classification loss: 0.00049 | Regression loss: 0.01499 | Running loss: 0.04468\n",
            "Epoch: 9 | Iteration: 1259 | Classification loss: 0.00191 | Regression loss: 0.05779 | Running loss: 0.04476\n",
            "Epoch: 9 | Iteration: 1260 | Classification loss: 0.00126 | Regression loss: 0.03602 | Running loss: 0.04481\n",
            "Epoch: 9 | Iteration: 1261 | Classification loss: 0.00286 | Regression loss: 0.05299 | Running loss: 0.04480\n",
            "Epoch: 9 | Iteration: 1262 | Classification loss: 0.00115 | Regression loss: 0.07146 | Running loss: 0.04490\n",
            "Epoch: 9 | Iteration: 1263 | Classification loss: 0.00725 | Regression loss: 0.02781 | Running loss: 0.04491\n",
            "Epoch: 9 | Iteration: 1264 | Classification loss: 0.00151 | Regression loss: 0.03360 | Running loss: 0.04494\n",
            "Epoch: 9 | Iteration: 1265 | Classification loss: 0.00016 | Regression loss: 0.02966 | Running loss: 0.04496\n",
            "Epoch: 9 | Iteration: 1266 | Classification loss: 0.00918 | Regression loss: 0.03935 | Running loss: 0.04502\n",
            "Epoch: 9 | Iteration: 1267 | Classification loss: 0.00019 | Regression loss: 0.01357 | Running loss: 0.04498\n",
            "Epoch: 9 | Iteration: 1268 | Classification loss: 0.00065 | Regression loss: 0.02872 | Running loss: 0.04499\n",
            "Epoch: 9 | Iteration: 1269 | Classification loss: 0.00390 | Regression loss: 0.02217 | Running loss: 0.04498\n",
            "Epoch: 9 | Iteration: 1270 | Classification loss: 0.00032 | Regression loss: 0.02544 | Running loss: 0.04498\n",
            "Epoch: 9 | Iteration: 1271 | Classification loss: 0.00080 | Regression loss: 0.01672 | Running loss: 0.04497\n",
            "Epoch: 9 | Iteration: 1272 | Classification loss: 0.00679 | Regression loss: 0.02324 | Running loss: 0.04497\n",
            "Epoch: 9 | Iteration: 1273 | Classification loss: 0.00008 | Regression loss: 0.00969 | Running loss: 0.04490\n",
            "Epoch: 9 | Iteration: 1274 | Classification loss: 0.00028 | Regression loss: 0.00948 | Running loss: 0.04486\n",
            "Epoch: 9 | Iteration: 1275 | Classification loss: 0.00012 | Regression loss: 0.02853 | Running loss: 0.04486\n",
            "Epoch: 9 | Iteration: 1276 | Classification loss: 0.00172 | Regression loss: 0.06019 | Running loss: 0.04494\n",
            "Epoch: 9 | Iteration: 1277 | Classification loss: 0.00300 | Regression loss: 0.01647 | Running loss: 0.04492\n",
            "Epoch: 9 | Iteration: 1278 | Classification loss: 0.00354 | Regression loss: 0.01470 | Running loss: 0.04237\n",
            "Epoch: 9 | Iteration: 1279 | Classification loss: 0.00017 | Regression loss: 0.01856 | Running loss: 0.04235\n",
            "Epoch: 9 | Iteration: 1280 | Classification loss: 0.00028 | Regression loss: 0.01635 | Running loss: 0.04232\n",
            "Epoch: 9 | Iteration: 1281 | Classification loss: 0.00010 | Regression loss: 0.02124 | Running loss: 0.04233\n",
            "Epoch: 9 | Iteration: 1282 | Classification loss: 0.00010 | Regression loss: 0.01335 | Running loss: 0.04232\n",
            "Epoch: 9 | Iteration: 1283 | Classification loss: 0.00021 | Regression loss: 0.01369 | Running loss: 0.04229\n",
            "Epoch: 9 | Iteration: 1284 | Classification loss: 0.00046 | Regression loss: 0.11019 | Running loss: 0.04248\n",
            "Epoch: 9 | Iteration: 1285 | Classification loss: 0.00017 | Regression loss: 0.01305 | Running loss: 0.04238\n",
            "Epoch: 9 | Iteration: 1286 | Classification loss: 0.00196 | Regression loss: 0.03742 | Running loss: 0.04240\n",
            "Epoch: 9 | Iteration: 1287 | Classification loss: 0.00006 | Regression loss: 0.01352 | Running loss: 0.04236\n",
            "Epoch: 9 | Iteration: 1288 | Classification loss: 0.00035 | Regression loss: 0.03151 | Running loss: 0.04236\n",
            "Epoch: 9 | Iteration: 1289 | Classification loss: 0.00035 | Regression loss: 0.01684 | Running loss: 0.04232\n",
            "Epoch: 9 | Iteration: 1290 | Classification loss: 0.00013 | Regression loss: 0.03664 | Running loss: 0.04235\n",
            "Epoch: 9 | Iteration: 1291 | Classification loss: 0.00006 | Regression loss: 0.03122 | Running loss: 0.04239\n",
            "Epoch: 9 | Iteration: 1292 | Classification loss: 0.00780 | Regression loss: 0.02758 | Running loss: 0.04243\n",
            "Epoch: 9 | Iteration: 1293 | Classification loss: 0.00002 | Regression loss: 0.01981 | Running loss: 0.04161\n",
            "Epoch: 9 | Iteration: 1294 | Classification loss: 0.00052 | Regression loss: 0.04130 | Running loss: 0.04163\n",
            "Epoch: 9 | Iteration: 1295 | Classification loss: 0.00004 | Regression loss: 0.01653 | Running loss: 0.04161\n",
            "Epoch: 9 | Iteration: 1296 | Classification loss: 0.00167 | Regression loss: 0.06643 | Running loss: 0.04171\n",
            "Epoch: 9 | Iteration: 1297 | Classification loss: 0.00008 | Regression loss: 0.01003 | Running loss: 0.04168\n",
            "Epoch: 9 | Iteration: 1298 | Classification loss: 0.00019 | Regression loss: 0.03316 | Running loss: 0.04171\n",
            "Epoch: 9 | Iteration: 1299 | Classification loss: 0.00004 | Regression loss: 0.02637 | Running loss: 0.04173\n",
            "Epoch: 9 | Iteration: 1300 | Classification loss: 0.00028 | Regression loss: 0.03066 | Running loss: 0.04174\n",
            "Epoch: 9 | Iteration: 1301 | Classification loss: 0.00003 | Regression loss: 0.01598 | Running loss: 0.04173\n",
            "Epoch: 9 | Iteration: 1302 | Classification loss: 0.00342 | Regression loss: 0.02796 | Running loss: 0.04177\n",
            "Epoch: 9 | Iteration: 1303 | Classification loss: 0.00015 | Regression loss: 0.01808 | Running loss: 0.04174\n",
            "Epoch: 9 | Iteration: 1304 | Classification loss: 0.00009 | Regression loss: 0.02041 | Running loss: 0.04164\n",
            "Epoch: 9 | Iteration: 1305 | Classification loss: 0.00006 | Regression loss: 0.03299 | Running loss: 0.04162\n",
            "Epoch: 9 | Iteration: 1306 | Classification loss: 0.00090 | Regression loss: 0.04853 | Running loss: 0.04164\n",
            "Epoch: 9 | Iteration: 1307 | Classification loss: 0.00026 | Regression loss: 0.02591 | Running loss: 0.04162\n",
            "Epoch: 9 | Iteration: 1308 | Classification loss: 0.00137 | Regression loss: 0.04796 | Running loss: 0.04166\n",
            "Epoch: 9 | Iteration: 1309 | Classification loss: 0.00047 | Regression loss: 0.05753 | Running loss: 0.04174\n",
            "Epoch: 9 | Iteration: 1310 | Classification loss: 0.00070 | Regression loss: 0.01177 | Running loss: 0.04171\n",
            "Epoch: 9 | Iteration: 1311 | Classification loss: 0.00052 | Regression loss: 0.01405 | Running loss: 0.04172\n",
            "Epoch: 9 | Iteration: 1312 | Classification loss: 0.00029 | Regression loss: 0.03445 | Running loss: 0.04166\n",
            "Epoch: 9 | Iteration: 1313 | Classification loss: 0.00018 | Regression loss: 0.03484 | Running loss: 0.04166\n",
            "Epoch: 9 | Iteration: 1314 | Classification loss: 0.00035 | Regression loss: 0.02034 | Running loss: 0.04166\n",
            "Epoch: 9 | Iteration: 1315 | Classification loss: 0.00015 | Regression loss: 0.02830 | Running loss: 0.04165\n",
            "Epoch: 9 | Iteration: 1316 | Classification loss: 0.00063 | Regression loss: 0.03976 | Running loss: 0.04164\n",
            "Epoch: 9 | Iteration: 1317 | Classification loss: 0.00017 | Regression loss: 0.01680 | Running loss: 0.04158\n",
            "Epoch: 9 | Iteration: 1318 | Classification loss: 0.00025 | Regression loss: 0.02212 | Running loss: 0.04155\n",
            "Epoch: 9 | Iteration: 1319 | Classification loss: 0.00044 | Regression loss: 0.02689 | Running loss: 0.04157\n",
            "Epoch: 9 | Iteration: 1320 | Classification loss: 0.00021 | Regression loss: 0.02199 | Running loss: 0.04158\n",
            "Epoch: 9 | Iteration: 1321 | Classification loss: 0.00024 | Regression loss: 0.03198 | Running loss: 0.04160\n",
            "Epoch: 9 | Iteration: 1322 | Classification loss: 0.00014 | Regression loss: 0.02090 | Running loss: 0.04157\n",
            "Epoch: 9 | Iteration: 1323 | Classification loss: 0.00048 | Regression loss: 0.01533 | Running loss: 0.04155\n",
            "Epoch: 9 | Iteration: 1324 | Classification loss: 0.00021 | Regression loss: 0.01867 | Running loss: 0.04155\n",
            "Epoch: 9 | Iteration: 1325 | Classification loss: 0.00114 | Regression loss: 0.03961 | Running loss: 0.04160\n",
            "Epoch: 9 | Iteration: 1326 | Classification loss: 0.00018 | Regression loss: 0.03185 | Running loss: 0.04154\n",
            "Epoch: 9 | Iteration: 1327 | Classification loss: 0.00019 | Regression loss: 0.02302 | Running loss: 0.04155\n",
            "Epoch: 9 | Iteration: 1328 | Classification loss: 0.00016 | Regression loss: 0.02242 | Running loss: 0.04157\n",
            "Epoch: 9 | Iteration: 1329 | Classification loss: 0.00034 | Regression loss: 0.03827 | Running loss: 0.04162\n",
            "Epoch: 9 | Iteration: 1330 | Classification loss: 0.00022 | Regression loss: 0.02216 | Running loss: 0.04162\n",
            "Epoch: 9 | Iteration: 1331 | Classification loss: 0.00004 | Regression loss: 0.02618 | Running loss: 0.04163\n",
            "Epoch: 9 | Iteration: 1332 | Classification loss: 0.00086 | Regression loss: 0.01463 | Running loss: 0.04150\n",
            "Epoch: 9 | Iteration: 1333 | Classification loss: 0.00018 | Regression loss: 0.02583 | Running loss: 0.04152\n",
            "Epoch: 9 | Iteration: 1334 | Classification loss: 0.00003 | Regression loss: 0.01521 | Running loss: 0.04151\n",
            "Epoch: 9 | Iteration: 1335 | Classification loss: 0.00016 | Regression loss: 0.00864 | Running loss: 0.04149\n",
            "Epoch: 9 | Iteration: 1336 | Classification loss: 0.00003 | Regression loss: 0.02357 | Running loss: 0.04148\n",
            "Epoch: 9 | Iteration: 1337 | Classification loss: 0.00003 | Regression loss: 0.00804 | Running loss: 0.04147\n",
            "Epoch: 9 | Iteration: 1338 | Classification loss: 0.00057 | Regression loss: 0.02473 | Running loss: 0.04149\n",
            "Epoch: 9 | Iteration: 1339 | Classification loss: 0.00034 | Regression loss: 0.01317 | Running loss: 0.04149\n",
            "Epoch: 9 | Iteration: 1340 | Classification loss: 0.00085 | Regression loss: 0.02510 | Running loss: 0.04143\n",
            "Epoch: 9 | Iteration: 1341 | Classification loss: 0.00002 | Regression loss: 0.01815 | Running loss: 0.04141\n",
            "Epoch: 9 | Iteration: 1342 | Classification loss: 0.00010 | Regression loss: 0.03053 | Running loss: 0.04140\n",
            "Epoch: 9 | Iteration: 1343 | Classification loss: 0.00429 | Regression loss: 0.06371 | Running loss: 0.04148\n",
            "Epoch: 9 | Iteration: 1344 | Classification loss: 0.00004 | Regression loss: 0.02856 | Running loss: 0.04152\n",
            "Epoch: 9 | Iteration: 1345 | Classification loss: 0.00017 | Regression loss: 0.06145 | Running loss: 0.04162\n",
            "Epoch: 9 | Iteration: 1346 | Classification loss: 0.00009 | Regression loss: 0.03059 | Running loss: 0.04165\n",
            "Epoch: 9 | Iteration: 1347 | Classification loss: 0.00009 | Regression loss: 0.02384 | Running loss: 0.04167\n",
            "Epoch: 9 | Iteration: 1348 | Classification loss: 0.00042 | Regression loss: 0.03094 | Running loss: 0.04170\n",
            "Epoch: 9 | Iteration: 1349 | Classification loss: 0.00089 | Regression loss: 0.01526 | Running loss: 0.04170\n",
            "Epoch: 9 | Iteration: 1350 | Classification loss: 0.00281 | Regression loss: 0.05307 | Running loss: 0.04175\n",
            "Epoch: 9 | Iteration: 1351 | Classification loss: 0.00008 | Regression loss: 0.03516 | Running loss: 0.04177\n",
            "Epoch: 9 | Iteration: 1352 | Classification loss: 0.00003 | Regression loss: 0.03454 | Running loss: 0.04179\n",
            "Epoch: 9 | Iteration: 1353 | Classification loss: 0.00020 | Regression loss: 0.02903 | Running loss: 0.04181\n",
            "Epoch: 9 | Iteration: 1354 | Classification loss: 0.00003 | Regression loss: 0.02315 | Running loss: 0.04182\n",
            "Epoch: 9 | Iteration: 1355 | Classification loss: 0.00054 | Regression loss: 0.03766 | Running loss: 0.04183\n",
            "Epoch: 9 | Iteration: 1356 | Classification loss: 0.00040 | Regression loss: 0.01798 | Running loss: 0.04181\n",
            "Epoch: 9 | Iteration: 1357 | Classification loss: 0.00020 | Regression loss: 0.01052 | Running loss: 0.04178\n",
            "Epoch: 9 | Iteration: 1358 | Classification loss: 0.00006 | Regression loss: 0.02164 | Running loss: 0.04178\n",
            "Epoch: 9 | Iteration: 1359 | Classification loss: 0.00014 | Regression loss: 0.03642 | Running loss: 0.04181\n",
            "Epoch: 9 | Iteration: 1360 | Classification loss: 0.00003 | Regression loss: 0.02855 | Running loss: 0.04181\n",
            "Epoch: 9 | Iteration: 1361 | Classification loss: 0.00360 | Regression loss: 0.05040 | Running loss: 0.04188\n",
            "Epoch: 9 | Iteration: 1362 | Classification loss: 0.00001 | Regression loss: 0.04208 | Running loss: 0.04192\n",
            "Epoch: 9 | Iteration: 1363 | Classification loss: 0.00003 | Regression loss: 0.03180 | Running loss: 0.04191\n",
            "Epoch: 9 | Iteration: 1364 | Classification loss: 0.00002 | Regression loss: 0.04515 | Running loss: 0.04196\n",
            "Epoch: 9 | Iteration: 1365 | Classification loss: 0.00008 | Regression loss: 0.03260 | Running loss: 0.04194\n",
            "Epoch: 9 | Iteration: 1366 | Classification loss: 0.00018 | Regression loss: 0.02828 | Running loss: 0.04192\n",
            "Epoch: 9 | Iteration: 1367 | Classification loss: 0.00009 | Regression loss: 0.03932 | Running loss: 0.04196\n",
            "Epoch: 9 | Iteration: 1368 | Classification loss: 0.00004 | Regression loss: 0.01079 | Running loss: 0.04194\n",
            "Epoch: 9 | Iteration: 1369 | Classification loss: 0.00183 | Regression loss: 0.02195 | Running loss: 0.04192\n",
            "Epoch: 9 | Iteration: 1370 | Classification loss: 0.00003 | Regression loss: 0.02739 | Running loss: 0.04195\n",
            "Epoch: 9 | Iteration: 1371 | Classification loss: 0.00012 | Regression loss: 0.02813 | Running loss: 0.04199\n",
            "Epoch: 9 | Iteration: 1372 | Classification loss: 0.00044 | Regression loss: 0.03119 | Running loss: 0.04198\n",
            "Epoch: 9 | Iteration: 1373 | Classification loss: 0.03044 | Regression loss: 0.05158 | Running loss: 0.04203\n",
            "Epoch: 9 | Iteration: 1374 | Classification loss: 0.00005 | Regression loss: 0.02140 | Running loss: 0.04201\n",
            "Epoch: 9 | Iteration: 1375 | Classification loss: 0.00043 | Regression loss: 0.02079 | Running loss: 0.04198\n",
            "Epoch: 9 | Iteration: 1376 | Classification loss: 0.00036 | Regression loss: 0.02177 | Running loss: 0.04196\n",
            "Epoch: 9 | Iteration: 1377 | Classification loss: 0.00943 | Regression loss: 0.05120 | Running loss: 0.04197\n",
            "Epoch: 9 | Iteration: 1378 | Classification loss: 0.00007 | Regression loss: 0.02000 | Running loss: 0.04199\n",
            "Epoch: 9 | Iteration: 1379 | Classification loss: 0.00006 | Regression loss: 0.02615 | Running loss: 0.04193\n",
            "Epoch: 9 | Iteration: 1380 | Classification loss: 0.00563 | Regression loss: 0.03560 | Running loss: 0.04196\n",
            "Epoch: 9 | Iteration: 1381 | Classification loss: 0.01506 | Regression loss: 0.07187 | Running loss: 0.04209\n",
            "Epoch: 9 | Iteration: 1382 | Classification loss: 0.00139 | Regression loss: 0.03027 | Running loss: 0.04209\n",
            "Epoch: 9 | Iteration: 1383 | Classification loss: 0.00008 | Regression loss: 0.00978 | Running loss: 0.04202\n",
            "Epoch: 9 | Iteration: 1384 | Classification loss: 0.00051 | Regression loss: 0.01701 | Running loss: 0.04198\n",
            "Epoch: 9 | Iteration: 1385 | Classification loss: 0.00011 | Regression loss: 0.01851 | Running loss: 0.04197\n",
            "Epoch: 9 | Iteration: 1386 | Classification loss: 0.54996 | Regression loss: 0.05665 | Running loss: 0.04312\n",
            "Epoch: 9 | Iteration: 1387 | Classification loss: 0.23507 | Regression loss: 0.22534 | Running loss: 0.04400\n",
            "Epoch: 9 | Iteration: 1388 | Classification loss: 0.01714 | Regression loss: 0.06018 | Running loss: 0.04411\n",
            "Epoch: 9 | Iteration: 1389 | Classification loss: 0.00042 | Regression loss: 0.03663 | Running loss: 0.04409\n",
            "Epoch: 9 | Iteration: 1390 | Classification loss: 0.00025 | Regression loss: 0.02046 | Running loss: 0.04406\n",
            "Epoch: 9 | Iteration: 1391 | Classification loss: 0.01413 | Regression loss: 0.07574 | Running loss: 0.04410\n",
            "Epoch: 9 | Iteration: 1392 | Classification loss: 0.00006 | Regression loss: 0.01488 | Running loss: 0.04408\n",
            "Epoch: 9 | Iteration: 1393 | Classification loss: 0.00005 | Regression loss: 0.02524 | Running loss: 0.04404\n",
            "Epoch: 9 | Iteration: 1394 | Classification loss: 0.00043 | Regression loss: 0.03838 | Running loss: 0.04408\n",
            "Epoch: 9 | Iteration: 1395 | Classification loss: 0.03712 | Regression loss: 0.05022 | Running loss: 0.04409\n",
            "Epoch: 9 | Iteration: 1396 | Classification loss: 0.00244 | Regression loss: 0.02400 | Running loss: 0.04403\n",
            "Epoch: 9 | Iteration: 1397 | Classification loss: 0.00012 | Regression loss: 0.05801 | Running loss: 0.04400\n",
            "Epoch: 9 | Iteration: 1398 | Classification loss: 0.00070 | Regression loss: 0.02820 | Running loss: 0.04398\n",
            "Epoch: 9 | Iteration: 1399 | Classification loss: 0.00077 | Regression loss: 0.07735 | Running loss: 0.04402\n",
            "Epoch: 9 | Iteration: 1400 | Classification loss: 0.00038 | Regression loss: 0.03472 | Running loss: 0.04390\n",
            "Epoch: 9 | Iteration: 1401 | Classification loss: 0.00029 | Regression loss: 0.03425 | Running loss: 0.04392\n",
            "Epoch: 9 | Iteration: 1402 | Classification loss: 0.00025 | Regression loss: 0.04988 | Running loss: 0.04400\n",
            "Epoch: 9 | Iteration: 1403 | Classification loss: 0.00112 | Regression loss: 0.00909 | Running loss: 0.04397\n",
            "Epoch: 9 | Iteration: 1404 | Classification loss: 0.00588 | Regression loss: 0.03325 | Running loss: 0.04400\n",
            "Epoch: 9 | Iteration: 1405 | Classification loss: 0.20664 | Regression loss: 0.01550 | Running loss: 0.04440\n",
            "Epoch: 9 | Iteration: 1406 | Classification loss: 0.00299 | Regression loss: 0.04059 | Running loss: 0.04446\n",
            "Epoch: 9 | Iteration: 1407 | Classification loss: 0.01765 | Regression loss: 0.01879 | Running loss: 0.04431\n",
            "Epoch: 9 | Iteration: 1408 | Classification loss: 0.00251 | Regression loss: 0.05693 | Running loss: 0.04439\n",
            "Epoch: 9 | Iteration: 1409 | Classification loss: 0.00033 | Regression loss: 0.01514 | Running loss: 0.04434\n",
            "Epoch: 9 | Iteration: 1410 | Classification loss: 0.01891 | Regression loss: 0.06066 | Running loss: 0.04448\n",
            "Epoch: 9 | Iteration: 1411 | Classification loss: 0.00076 | Regression loss: 0.01763 | Running loss: 0.04444\n",
            "Epoch: 9 | Iteration: 1412 | Classification loss: 0.00028 | Regression loss: 0.01260 | Running loss: 0.04436\n",
            "Epoch: 9 | Iteration: 1413 | Classification loss: 0.00028 | Regression loss: 0.04151 | Running loss: 0.04432\n",
            "Epoch: 9 | Iteration: 1414 | Classification loss: 0.00034 | Regression loss: 0.03109 | Running loss: 0.04432\n",
            "Epoch: 9 | Iteration: 1415 | Classification loss: 0.00027 | Regression loss: 0.02228 | Running loss: 0.04429\n",
            "Epoch: 9 | Iteration: 1416 | Classification loss: 0.00048 | Regression loss: 0.02114 | Running loss: 0.04418\n",
            "Epoch: 9 | Iteration: 1417 | Classification loss: 0.00847 | Regression loss: 0.09674 | Running loss: 0.04433\n",
            "Epoch: 9 | Iteration: 1418 | Classification loss: 0.00056 | Regression loss: 0.03899 | Running loss: 0.04428\n",
            "Epoch: 9 | Iteration: 1419 | Classification loss: 0.00012 | Regression loss: 0.01776 | Running loss: 0.04419\n",
            "Epoch: 9 | Iteration: 1420 | Classification loss: 0.00126 | Regression loss: 0.01887 | Running loss: 0.04419\n",
            "Epoch: 9 | Iteration: 1421 | Classification loss: 0.00088 | Regression loss: 0.02370 | Running loss: 0.04408\n",
            "Epoch: 9 | Iteration: 1422 | Classification loss: 0.00050 | Regression loss: 0.02587 | Running loss: 0.04406\n",
            "Epoch: 9 | Iteration: 1423 | Classification loss: 0.00030 | Regression loss: 0.01154 | Running loss: 0.04406\n",
            "Epoch: 9 | Iteration: 1424 | Classification loss: 0.00084 | Regression loss: 0.03221 | Running loss: 0.04286\n",
            "Epoch: 9 | Iteration: 1425 | Classification loss: 0.00157 | Regression loss: 0.03790 | Running loss: 0.04288\n",
            "Epoch: 9 | Iteration: 1426 | Classification loss: 0.00027 | Regression loss: 0.02304 | Running loss: 0.04283\n",
            "Epoch: 9 | Iteration: 1427 | Classification loss: 0.00034 | Regression loss: 0.01359 | Running loss: 0.04282\n",
            "Epoch: 9 | Iteration: 1428 | Classification loss: 0.00105 | Regression loss: 0.03422 | Running loss: 0.04281\n",
            "Epoch: 9 | Iteration: 1429 | Classification loss: 0.00019 | Regression loss: 0.01296 | Running loss: 0.04275\n",
            "Epoch: 9 | Iteration: 1430 | Classification loss: 0.00022 | Regression loss: 0.01615 | Running loss: 0.04260\n",
            "Epoch: 9 | Iteration: 1431 | Classification loss: 0.00018 | Regression loss: 0.00905 | Running loss: 0.04258\n",
            "Epoch: 9 | Iteration: 1432 | Classification loss: 0.00072 | Regression loss: 0.01306 | Running loss: 0.04255\n",
            "Epoch: 9 | Iteration: 1433 | Classification loss: 0.00026 | Regression loss: 0.01395 | Running loss: 0.04250\n",
            "Epoch: 9 | Iteration: 1434 | Classification loss: 0.00027 | Regression loss: 0.02116 | Running loss: 0.04250\n",
            "Epoch: 9 | Iteration: 1435 | Classification loss: 0.00015 | Regression loss: 0.01566 | Running loss: 0.04250\n",
            "Epoch: 9 | Iteration: 1436 | Classification loss: 0.00010 | Regression loss: 0.02051 | Running loss: 0.04251\n",
            "Epoch: 9 | Iteration: 1437 | Classification loss: 0.00098 | Regression loss: 0.02206 | Running loss: 0.04252\n",
            "Epoch: 9 | Iteration: 1438 | Classification loss: 0.00011 | Regression loss: 0.01366 | Running loss: 0.04248\n",
            "Epoch: 9 | Iteration: 1439 | Classification loss: 0.00011 | Regression loss: 0.04095 | Running loss: 0.04249\n",
            "Epoch: 9 | Iteration: 1440 | Classification loss: 0.00005 | Regression loss: 0.02634 | Running loss: 0.04251\n",
            "Epoch: 9 | Iteration: 1441 | Classification loss: 0.00004 | Regression loss: 0.01730 | Running loss: 0.04246\n",
            "Epoch: 9 | Iteration: 1442 | Classification loss: 0.00067 | Regression loss: 0.01462 | Running loss: 0.04242\n",
            "Epoch: 9 | Iteration: 1443 | Classification loss: 0.00010 | Regression loss: 0.02522 | Running loss: 0.04244\n",
            "Epoch: 9 | Iteration: 1444 | Classification loss: 0.00219 | Regression loss: 0.02611 | Running loss: 0.04244\n",
            "Epoch: 9 | Iteration: 1445 | Classification loss: 0.00021 | Regression loss: 0.01451 | Running loss: 0.04228\n",
            "Epoch: 9 | Iteration: 1446 | Classification loss: 0.00132 | Regression loss: 0.02544 | Running loss: 0.04232\n",
            "Epoch: 9 | Iteration: 1447 | Classification loss: 0.00394 | Regression loss: 0.02376 | Running loss: 0.04235\n",
            "Epoch: 9 | Iteration: 1448 | Classification loss: 0.00010 | Regression loss: 0.01167 | Running loss: 0.04233\n",
            "Epoch: 9 | Iteration: 1449 | Classification loss: 0.00005 | Regression loss: 0.01587 | Running loss: 0.04232\n",
            "Epoch: 9 | Iteration: 1450 | Classification loss: 0.00034 | Regression loss: 0.01042 | Running loss: 0.04229\n",
            "Epoch: 9 | Iteration: 1451 | Classification loss: 0.00037 | Regression loss: 0.01972 | Running loss: 0.04226\n",
            "Epoch: 9 | Iteration: 1452 | Classification loss: 0.00032 | Regression loss: 0.02164 | Running loss: 0.04216\n",
            "Epoch: 9 | Iteration: 1453 | Classification loss: 0.02486 | Regression loss: 0.05664 | Running loss: 0.04230\n",
            "Epoch: 9 | Iteration: 1454 | Classification loss: 0.00004 | Regression loss: 0.02095 | Running loss: 0.04232\n",
            "Epoch: 9 | Iteration: 1455 | Classification loss: 0.00007 | Regression loss: 0.03978 | Running loss: 0.04233\n",
            "Epoch: 9 | Iteration: 1456 | Classification loss: 0.00010 | Regression loss: 0.01827 | Running loss: 0.04231\n",
            "Epoch: 9 | Iteration: 1457 | Classification loss: 0.00350 | Regression loss: 0.06381 | Running loss: 0.04242\n",
            "Epoch: 9 | Iteration: 1458 | Classification loss: 0.01113 | Regression loss: 0.08656 | Running loss: 0.04260\n",
            "Epoch: 9 | Iteration: 1459 | Classification loss: 0.00890 | Regression loss: 0.03700 | Running loss: 0.04262\n",
            "Epoch: 9 | Iteration: 1460 | Classification loss: 0.00034 | Regression loss: 0.02393 | Running loss: 0.04260\n",
            "Epoch: 9 | Iteration: 1461 | Classification loss: 0.00187 | Regression loss: 0.02455 | Running loss: 0.04261\n",
            "Epoch: 9 | Iteration: 1462 | Classification loss: 0.00155 | Regression loss: 0.02999 | Running loss: 0.04263\n",
            "Epoch: 9 | Iteration: 1463 | Classification loss: 0.00036 | Regression loss: 0.02983 | Running loss: 0.04261\n",
            "Epoch: 9 | Iteration: 1464 | Classification loss: 0.00264 | Regression loss: 0.12901 | Running loss: 0.04285\n",
            "Epoch: 9 | Iteration: 1465 | Classification loss: 0.00100 | Regression loss: 0.02767 | Running loss: 0.04287\n",
            "Epoch: 9 | Iteration: 1466 | Classification loss: 0.00063 | Regression loss: 0.01819 | Running loss: 0.04284\n",
            "Epoch: 9 | Iteration: 1467 | Classification loss: 0.00006 | Regression loss: 0.03251 | Running loss: 0.04285\n",
            "Epoch: 9 | Iteration: 1468 | Classification loss: 0.00096 | Regression loss: 0.04049 | Running loss: 0.04285\n",
            "Epoch: 9 | Iteration: 1469 | Classification loss: 0.00050 | Regression loss: 0.02789 | Running loss: 0.04279\n",
            "Epoch: 9 | Iteration: 1470 | Classification loss: 0.00014 | Regression loss: 0.04812 | Running loss: 0.04279\n",
            "Epoch: 9 | Iteration: 1471 | Classification loss: 0.00139 | Regression loss: 0.01326 | Running loss: 0.04277\n",
            "Epoch: 9 | Iteration: 1472 | Classification loss: 0.00006 | Regression loss: 0.01975 | Running loss: 0.04275\n",
            "Epoch: 9 | Iteration: 1473 | Classification loss: 0.00381 | Regression loss: 0.02095 | Running loss: 0.04274\n",
            "Epoch: 9 | Iteration: 1474 | Classification loss: 0.00042 | Regression loss: 0.01646 | Running loss: 0.04269\n",
            "Epoch: 9 | Iteration: 1475 | Classification loss: 0.00153 | Regression loss: 0.02062 | Running loss: 0.04257\n",
            "Epoch: 9 | Iteration: 1476 | Classification loss: 0.00014 | Regression loss: 0.01590 | Running loss: 0.04258\n",
            "Epoch: 9 | Iteration: 1477 | Classification loss: 0.00110 | Regression loss: 0.08423 | Running loss: 0.04272\n",
            "Epoch: 9 | Iteration: 1478 | Classification loss: 0.00067 | Regression loss: 0.01836 | Running loss: 0.04274\n",
            "Epoch: 9 | Iteration: 1479 | Classification loss: 0.00027 | Regression loss: 0.02934 | Running loss: 0.04237\n",
            "Epoch: 9 | Iteration: 1480 | Classification loss: 0.35003 | Regression loss: 0.30482 | Running loss: 0.04352\n",
            "Epoch: 9 | Iteration: 1481 | Classification loss: 0.00105 | Regression loss: 0.02814 | Running loss: 0.04352\n",
            "Epoch: 9 | Iteration: 1482 | Classification loss: 0.00032 | Regression loss: 0.02455 | Running loss: 0.04350\n",
            "Epoch: 9 | Iteration: 1483 | Classification loss: 0.00118 | Regression loss: 0.06571 | Running loss: 0.04362\n",
            "Epoch: 9 | Iteration: 1484 | Classification loss: 0.00031 | Regression loss: 0.02270 | Running loss: 0.04359\n",
            "Epoch: 9 | Iteration: 1485 | Classification loss: 0.00047 | Regression loss: 0.01165 | Running loss: 0.04354\n",
            "Epoch: 9 | Iteration: 1486 | Classification loss: 0.00088 | Regression loss: 0.07983 | Running loss: 0.04366\n",
            "Epoch: 9 | Iteration: 1487 | Classification loss: 0.00004 | Regression loss: 0.01146 | Running loss: 0.04364\n",
            "Epoch: 9 | Iteration: 1488 | Classification loss: 0.00023 | Regression loss: 0.02515 | Running loss: 0.04365\n",
            "Epoch: 9 | Iteration: 1489 | Classification loss: 0.00060 | Regression loss: 0.02751 | Running loss: 0.04367\n",
            "Epoch: 9 | Iteration: 1490 | Classification loss: 0.00022 | Regression loss: 0.01811 | Running loss: 0.04367\n",
            "Epoch: 9 | Iteration: 1491 | Classification loss: 0.00014 | Regression loss: 0.02316 | Running loss: 0.04368\n",
            "Epoch: 9 | Iteration: 1492 | Classification loss: 0.00046 | Regression loss: 0.02131 | Running loss: 0.04365\n",
            "Epoch: 9 | Iteration: 1493 | Classification loss: 0.00038 | Regression loss: 0.01514 | Running loss: 0.04365\n",
            "Epoch: 9 | Iteration: 1494 | Classification loss: 0.00033 | Regression loss: 0.01836 | Running loss: 0.04364\n",
            "Epoch: 9 | Iteration: 1495 | Classification loss: 0.00051 | Regression loss: 0.02468 | Running loss: 0.04364\n",
            "Epoch: 9 | Iteration: 1496 | Classification loss: 0.00005 | Regression loss: 0.01741 | Running loss: 0.04357\n",
            "Epoch: 9 | Iteration: 1497 | Classification loss: 0.00088 | Regression loss: 0.04231 | Running loss: 0.04352\n",
            "Epoch: 9 | Iteration: 1498 | Classification loss: 0.00098 | Regression loss: 0.02163 | Running loss: 0.04353\n",
            "Epoch: 9 | Iteration: 1499 | Classification loss: 0.00027 | Regression loss: 0.01841 | Running loss: 0.04348\n",
            "Epoch: 9 | Iteration: 1500 | Classification loss: 0.00002 | Regression loss: 0.01923 | Running loss: 0.04348\n",
            "Epoch: 9 | Iteration: 1501 | Classification loss: 0.00039 | Regression loss: 0.01521 | Running loss: 0.04345\n",
            "Epoch: 9 | Iteration: 1502 | Classification loss: 0.00013 | Regression loss: 0.01562 | Running loss: 0.04341\n",
            "Epoch: 9 | Iteration: 1503 | Classification loss: 0.01072 | Regression loss: 0.06443 | Running loss: 0.04346\n",
            "Epoch: 9 | Iteration: 1504 | Classification loss: 0.00135 | Regression loss: 0.01890 | Running loss: 0.04343\n",
            "Epoch: 9 | Iteration: 1505 | Classification loss: 0.00167 | Regression loss: 0.02071 | Running loss: 0.04341\n",
            "Epoch: 9 | Iteration: 1506 | Classification loss: 0.00253 | Regression loss: 0.07112 | Running loss: 0.04347\n",
            "Epoch: 9 | Iteration: 1507 | Classification loss: 0.00070 | Regression loss: 0.03414 | Running loss: 0.04343\n",
            "Epoch: 9 | Iteration: 1508 | Classification loss: 0.00185 | Regression loss: 0.01948 | Running loss: 0.04342\n",
            "Epoch: 9 | Iteration: 1509 | Classification loss: 0.00086 | Regression loss: 0.05143 | Running loss: 0.04350\n",
            "Epoch: 9 | Iteration: 1510 | Classification loss: 0.00033 | Regression loss: 0.03387 | Running loss: 0.04354\n",
            "Epoch: 9 | Iteration: 1511 | Classification loss: 0.00011 | Regression loss: 0.02465 | Running loss: 0.04353\n",
            "Epoch: 9 | Iteration: 1512 | Classification loss: 0.01735 | Regression loss: 0.11582 | Running loss: 0.04374\n",
            "Epoch: 9 | Iteration: 1513 | Classification loss: 0.10239 | Regression loss: 0.11336 | Running loss: 0.04412\n",
            "Epoch: 9 | Iteration: 1514 | Classification loss: 0.00004 | Regression loss: 0.01795 | Running loss: 0.04400\n",
            "Epoch: 9 | Iteration: 1515 | Classification loss: 0.00013 | Regression loss: 0.03121 | Running loss: 0.04399\n",
            "Epoch: 9 | Iteration: 1516 | Classification loss: 0.00025 | Regression loss: 0.01099 | Running loss: 0.04393\n",
            "Epoch: 9 | Iteration: 1517 | Classification loss: 0.00016 | Regression loss: 0.01630 | Running loss: 0.04325\n",
            "Epoch: 9 | Iteration: 1518 | Classification loss: 0.00013 | Regression loss: 0.03191 | Running loss: 0.04327\n",
            "Epoch: 9 | Iteration: 1519 | Classification loss: 0.00100 | Regression loss: 0.01884 | Running loss: 0.04327\n",
            "Epoch: 9 | Iteration: 1520 | Classification loss: 0.00015 | Regression loss: 0.01981 | Running loss: 0.04327\n",
            "Epoch: 9 | Iteration: 1521 | Classification loss: 0.00046 | Regression loss: 0.02544 | Running loss: 0.04329\n",
            "Epoch: 9 | Iteration: 1522 | Classification loss: 0.00675 | Regression loss: 0.02715 | Running loss: 0.04330\n",
            "Epoch: 9 | Iteration: 1523 | Classification loss: 0.00024 | Regression loss: 0.01262 | Running loss: 0.04319\n",
            "Epoch: 9 | Iteration: 1524 | Classification loss: 0.00045 | Regression loss: 0.02124 | Running loss: 0.04321\n",
            "Epoch: 9 | Iteration: 1525 | Classification loss: 0.00006 | Regression loss: 0.02219 | Running loss: 0.04320\n",
            "Epoch: 9 | Iteration: 1526 | Classification loss: 0.00049 | Regression loss: 0.01357 | Running loss: 0.04320\n",
            "Epoch: 9 | Iteration: 1527 | Classification loss: 0.00002 | Regression loss: 0.01771 | Running loss: 0.04319\n",
            "Epoch: 9 | Iteration: 1528 | Classification loss: 0.00048 | Regression loss: 0.01546 | Running loss: 0.04320\n",
            "Epoch: 9 | Iteration: 1529 | Classification loss: 0.00012 | Regression loss: 0.01292 | Running loss: 0.04319\n",
            "Epoch: 9 | Iteration: 1530 | Classification loss: 0.00098 | Regression loss: 0.01407 | Running loss: 0.04312\n",
            "Epoch: 9 | Iteration: 1531 | Classification loss: 0.00012 | Regression loss: 0.02827 | Running loss: 0.04314\n",
            "Epoch: 9 | Iteration: 1532 | Classification loss: 0.00020 | Regression loss: 0.02172 | Running loss: 0.04310\n",
            "Epoch: 9 | Iteration: 1533 | Classification loss: 0.00008 | Regression loss: 0.02607 | Running loss: 0.04311\n",
            "Epoch: 9 | Iteration: 1534 | Classification loss: 0.00137 | Regression loss: 0.02864 | Running loss: 0.04312\n",
            "Epoch: 9 | Iteration: 1535 | Classification loss: 0.00020 | Regression loss: 0.01007 | Running loss: 0.04306\n",
            "Epoch: 9 | Iteration: 1536 | Classification loss: 0.00009 | Regression loss: 0.01895 | Running loss: 0.04304\n",
            "Epoch: 9 | Iteration: 1537 | Classification loss: 0.00059 | Regression loss: 0.03756 | Running loss: 0.04308\n",
            "Epoch: 9 | Iteration: 1538 | Classification loss: 0.00022 | Regression loss: 0.00981 | Running loss: 0.04294\n",
            "Epoch: 9 | Iteration: 1539 | Classification loss: 0.00203 | Regression loss: 0.04524 | Running loss: 0.04289\n",
            "Epoch: 9 | Iteration: 1540 | Classification loss: 0.00012 | Regression loss: 0.01504 | Running loss: 0.04287\n",
            "Epoch: 9 | Iteration: 1541 | Classification loss: 0.00006 | Regression loss: 0.02191 | Running loss: 0.04285\n",
            "Epoch: 9 | Iteration: 1542 | Classification loss: 0.00071 | Regression loss: 0.03905 | Running loss: 0.04288\n",
            "Epoch: 9 | Iteration: 1543 | Classification loss: 0.00126 | Regression loss: 0.06983 | Running loss: 0.04290\n",
            "Epoch: 9 | Iteration: 1544 | Classification loss: 0.00022 | Regression loss: 0.03466 | Running loss: 0.04292\n",
            "Epoch: 9 | Iteration: 1545 | Classification loss: 0.00037 | Regression loss: 0.01759 | Running loss: 0.04290\n",
            "Epoch: 9 | Iteration: 1546 | Classification loss: 0.00003 | Regression loss: 0.01777 | Running loss: 0.04274\n",
            "Epoch: 9 | Iteration: 1547 | Classification loss: 0.00010 | Regression loss: 0.02105 | Running loss: 0.04274\n",
            "Epoch: 9 | Iteration: 1548 | Classification loss: 0.00010 | Regression loss: 0.02012 | Running loss: 0.04273\n",
            "Epoch: 9 | Iteration: 1549 | Classification loss: 0.00012 | Regression loss: 0.01706 | Running loss: 0.04269\n",
            "Epoch: 9 | Iteration: 1550 | Classification loss: 0.00147 | Regression loss: 0.02570 | Running loss: 0.04269\n",
            "Epoch: 9 | Iteration: 1551 | Classification loss: 0.00013 | Regression loss: 0.08658 | Running loss: 0.04270\n",
            "Epoch: 9 | Iteration: 1552 | Classification loss: 0.00019 | Regression loss: 0.01742 | Running loss: 0.04266\n",
            "Epoch: 9 | Iteration: 1553 | Classification loss: 0.00085 | Regression loss: 0.02604 | Running loss: 0.04265\n",
            "Epoch: 9 | Iteration: 1554 | Classification loss: 0.00158 | Regression loss: 0.04966 | Running loss: 0.04272\n",
            "Epoch: 9 | Iteration: 1555 | Classification loss: 0.00033 | Regression loss: 0.02266 | Running loss: 0.04274\n",
            "Epoch: 9 | Iteration: 1556 | Classification loss: 0.00111 | Regression loss: 0.06038 | Running loss: 0.04277\n",
            "Epoch: 9 | Iteration: 1557 | Classification loss: 0.00007 | Regression loss: 0.01517 | Running loss: 0.04276\n",
            "Epoch: 9 | Iteration: 1558 | Classification loss: 0.00009 | Regression loss: 0.01685 | Running loss: 0.04277\n",
            "Epoch: 9 | Iteration: 1559 | Classification loss: 0.00146 | Regression loss: 0.04169 | Running loss: 0.04232\n",
            "Epoch: 9 | Iteration: 1560 | Classification loss: 0.00068 | Regression loss: 0.01427 | Running loss: 0.04231\n",
            "Epoch: 9 | Iteration: 1561 | Classification loss: 0.00045 | Regression loss: 0.05388 | Running loss: 0.04232\n",
            "Epoch: 9 | Iteration: 1562 | Classification loss: 0.00028 | Regression loss: 0.02573 | Running loss: 0.04234\n",
            "Epoch: 9 | Iteration: 1563 | Classification loss: 0.00050 | Regression loss: 0.03999 | Running loss: 0.04239\n",
            "Epoch: 9 | Iteration: 1564 | Classification loss: 0.00012 | Regression loss: 0.06194 | Running loss: 0.04248\n",
            "Epoch: 9 | Iteration: 1565 | Classification loss: 0.00011 | Regression loss: 0.01715 | Running loss: 0.04246\n",
            "Epoch: 9 | Iteration: 1566 | Classification loss: 0.00282 | Regression loss: 0.04535 | Running loss: 0.04250\n",
            "Epoch: 9 | Iteration: 1567 | Classification loss: 0.00003 | Regression loss: 0.01597 | Running loss: 0.04251\n",
            "Epoch: 9 | Iteration: 1568 | Classification loss: 0.00009 | Regression loss: 0.01814 | Running loss: 0.04250\n",
            "Epoch: 9 | Iteration: 1569 | Classification loss: 0.00015 | Regression loss: 0.01988 | Running loss: 0.04246\n",
            "Epoch: 9 | Iteration: 1570 | Classification loss: 0.00012 | Regression loss: 0.03493 | Running loss: 0.04248\n",
            "Epoch: 9 | Iteration: 1571 | Classification loss: 0.00025 | Regression loss: 0.04940 | Running loss: 0.04254\n",
            "Epoch: 9 | Iteration: 1572 | Classification loss: 0.00002 | Regression loss: 0.03841 | Running loss: 0.04258\n",
            "Epoch: 9 | Iteration: 1573 | Classification loss: 0.00014 | Regression loss: 0.03391 | Running loss: 0.04260\n",
            "Epoch: 9 | Iteration: 1574 | Classification loss: 0.00028 | Regression loss: 0.03086 | Running loss: 0.04262\n",
            "Epoch: 9 | Iteration: 1575 | Classification loss: 0.00010 | Regression loss: 0.01449 | Running loss: 0.04262\n",
            "Epoch: 9 | Iteration: 1576 | Classification loss: 0.00023 | Regression loss: 0.02422 | Running loss: 0.04262\n",
            "Epoch: 9 | Iteration: 1577 | Classification loss: 0.00002 | Regression loss: 0.02484 | Running loss: 0.04260\n",
            "Epoch: 9 | Iteration: 1578 | Classification loss: 0.00005 | Regression loss: 0.03059 | Running loss: 0.04262\n",
            "Epoch: 9 | Iteration: 1579 | Classification loss: 0.01996 | Regression loss: 0.06116 | Running loss: 0.04267\n",
            "Epoch: 9 | Iteration: 1580 | Classification loss: 0.00019 | Regression loss: 0.01474 | Running loss: 0.04264\n",
            "Epoch: 9 | Iteration: 1581 | Classification loss: 0.00014 | Regression loss: 0.01187 | Running loss: 0.04260\n",
            "Epoch: 9 | Iteration: 1582 | Classification loss: 0.00001 | Regression loss: 0.00531 | Running loss: 0.04259\n",
            "Epoch: 9 | Iteration: 1583 | Classification loss: 0.00008 | Regression loss: 0.01361 | Running loss: 0.04250\n",
            "Epoch: 9 | Iteration: 1584 | Classification loss: 0.00007 | Regression loss: 0.01946 | Running loss: 0.04251\n",
            "Epoch: 9 | Iteration: 1585 | Classification loss: 0.00003 | Regression loss: 0.01733 | Running loss: 0.04245\n",
            "Epoch: 9 | Iteration: 1586 | Classification loss: 0.00006 | Regression loss: 0.00600 | Running loss: 0.04239\n",
            "Epoch: 9 | Iteration: 1587 | Classification loss: 0.00075 | Regression loss: 0.03771 | Running loss: 0.04238\n",
            "Epoch: 9 | Iteration: 1588 | Classification loss: 0.00008 | Regression loss: 0.02705 | Running loss: 0.04236\n",
            "Epoch: 9 | Iteration: 1589 | Classification loss: 0.00011 | Regression loss: 0.02285 | Running loss: 0.04239\n",
            "Epoch: 9 | Iteration: 1590 | Classification loss: 0.00001 | Regression loss: 0.02221 | Running loss: 0.04236\n",
            "Epoch: 9 | Iteration: 1591 | Classification loss: 0.00058 | Regression loss: 0.01663 | Running loss: 0.04235\n",
            "Epoch: 9 | Iteration: 1592 | Classification loss: 0.00005 | Regression loss: 0.01674 | Running loss: 0.04235\n",
            "Epoch: 9 | Iteration: 1593 | Classification loss: 0.00016 | Regression loss: 0.01963 | Running loss: 0.04233\n",
            "Epoch: 9 | Iteration: 1594 | Classification loss: 0.00038 | Regression loss: 0.02950 | Running loss: 0.04233\n",
            "Epoch: 9 | Iteration: 1595 | Classification loss: 0.00040 | Regression loss: 0.01113 | Running loss: 0.04226\n",
            "Epoch: 9 | Iteration: 1596 | Classification loss: 0.00039 | Regression loss: 0.02491 | Running loss: 0.04203\n",
            "Epoch: 9 | Iteration: 1597 | Classification loss: 0.00068 | Regression loss: 0.03334 | Running loss: 0.04204\n",
            "Epoch: 9 | Iteration: 1598 | Classification loss: 0.00018 | Regression loss: 0.02189 | Running loss: 0.04203\n",
            "Epoch: 9 | Iteration: 1599 | Classification loss: 0.00954 | Regression loss: 0.07242 | Running loss: 0.04214\n",
            "Epoch: 9 | Iteration: 1600 | Classification loss: 0.00001 | Regression loss: 0.01916 | Running loss: 0.04211\n",
            "Epoch: 9 | Iteration: 1601 | Classification loss: 0.00005 | Regression loss: 0.01739 | Running loss: 0.04176\n",
            "Epoch: 9 | Iteration: 1602 | Classification loss: 0.00015 | Regression loss: 0.03054 | Running loss: 0.04176\n",
            "Epoch: 9 | Iteration: 1603 | Classification loss: 0.00009 | Regression loss: 0.02837 | Running loss: 0.04178\n",
            "Epoch: 9 | Iteration: 1604 | Classification loss: 0.00052 | Regression loss: 0.05714 | Running loss: 0.04184\n",
            "Epoch: 9 | Iteration: 1605 | Classification loss: 0.00030 | Regression loss: 0.02683 | Running loss: 0.04186\n",
            "Epoch: 9 | Iteration: 1606 | Classification loss: 0.00031 | Regression loss: 0.03298 | Running loss: 0.04188\n",
            "Epoch: 9 | Iteration: 1607 | Classification loss: 0.00023 | Regression loss: 0.02519 | Running loss: 0.04189\n",
            "Epoch: 9 | Iteration: 1608 | Classification loss: 0.00006 | Regression loss: 0.01778 | Running loss: 0.04187\n",
            "Epoch: 9 | Iteration: 1609 | Classification loss: 0.02623 | Regression loss: 0.16677 | Running loss: 0.04219\n",
            "Epoch: 9 | Iteration: 1610 | Classification loss: 0.00008 | Regression loss: 0.03112 | Running loss: 0.04219\n",
            "Epoch: 9 | Iteration: 1611 | Classification loss: 0.00107 | Regression loss: 0.03307 | Running loss: 0.04224\n",
            "Epoch: 9 | Iteration: 1612 | Classification loss: 0.00018 | Regression loss: 0.02430 | Running loss: 0.04219\n",
            "Epoch: 9 | Iteration: 1613 | Classification loss: 0.00125 | Regression loss: 0.02530 | Running loss: 0.04219\n",
            "Epoch: 9 | Iteration: 1614 | Classification loss: 0.00022 | Regression loss: 0.01467 | Running loss: 0.04218\n",
            "Epoch: 9 | Iteration: 1615 | Classification loss: 0.00024 | Regression loss: 0.01486 | Running loss: 0.04216\n",
            "Epoch: 9 | Iteration: 1616 | Classification loss: 0.00009 | Regression loss: 0.02668 | Running loss: 0.04218\n",
            "Epoch: 9 | Iteration: 1617 | Classification loss: 0.00060 | Regression loss: 0.01153 | Running loss: 0.04117\n",
            "Epoch: 9 | Iteration: 1618 | Classification loss: 0.00011 | Regression loss: 0.02113 | Running loss: 0.04116\n",
            "Epoch: 9 | Iteration: 1619 | Classification loss: 0.00002 | Regression loss: 0.03338 | Running loss: 0.04119\n",
            "Epoch: 9 | Iteration: 1620 | Classification loss: 0.00016 | Regression loss: 0.03232 | Running loss: 0.04120\n",
            "Epoch: 9 | Iteration: 1621 | Classification loss: 0.00001 | Regression loss: 0.01558 | Running loss: 0.04115\n",
            "Epoch: 9 | Iteration: 1622 | Classification loss: 0.00008 | Regression loss: 0.02180 | Running loss: 0.04113\n",
            "Epoch: 9 | Iteration: 1623 | Classification loss: 0.01833 | Regression loss: 0.05883 | Running loss: 0.04127\n",
            "Epoch: 9 | Iteration: 1624 | Classification loss: 0.00004 | Regression loss: 0.01268 | Running loss: 0.04121\n",
            "Epoch: 9 | Iteration: 1625 | Classification loss: 0.00174 | Regression loss: 0.03510 | Running loss: 0.04123\n",
            "Epoch: 9 | Iteration: 1626 | Classification loss: 0.00010 | Regression loss: 0.02811 | Running loss: 0.04121\n",
            "Epoch: 9 | Iteration: 1627 | Classification loss: 0.00010 | Regression loss: 0.01829 | Running loss: 0.04118\n",
            "Epoch: 9 | Iteration: 1628 | Classification loss: 0.00079 | Regression loss: 0.05967 | Running loss: 0.04119\n",
            "Epoch: 9 | Iteration: 1629 | Classification loss: 0.00110 | Regression loss: 0.05502 | Running loss: 0.04122\n",
            "Epoch: 9 | Iteration: 1630 | Classification loss: 0.00012 | Regression loss: 0.01254 | Running loss: 0.04120\n",
            "Epoch: 9 | Iteration: 1631 | Classification loss: 0.00009 | Regression loss: 0.01108 | Running loss: 0.04118\n",
            "Epoch: 9 | Iteration: 1632 | Classification loss: 0.00125 | Regression loss: 0.13664 | Running loss: 0.04137\n",
            "Epoch: 9 | Iteration: 1633 | Classification loss: 0.00013 | Regression loss: 0.02061 | Running loss: 0.04135\n",
            "Epoch: 9 | Iteration: 1634 | Classification loss: 0.00010 | Regression loss: 0.06686 | Running loss: 0.04145\n",
            "Epoch: 9 | Iteration: 1635 | Classification loss: 0.00019 | Regression loss: 0.03507 | Running loss: 0.04146\n",
            "Epoch: 9 | Iteration: 1636 | Classification loss: 0.00475 | Regression loss: 0.06978 | Running loss: 0.04158\n",
            "Epoch: 9 | Iteration: 1637 | Classification loss: 0.00042 | Regression loss: 0.02975 | Running loss: 0.04154\n",
            "Epoch: 9 | Iteration: 1638 | Classification loss: 0.00011 | Regression loss: 0.03230 | Running loss: 0.04158\n",
            "Epoch: 9 | Iteration: 1639 | Classification loss: 0.10331 | Regression loss: 0.26992 | Running loss: 0.04223\n",
            "Epoch: 9 | Iteration: 1640 | Classification loss: 0.00013 | Regression loss: 0.02991 | Running loss: 0.04224\n",
            "Epoch: 9 | Iteration: 1641 | Classification loss: 0.00202 | Regression loss: 0.07477 | Running loss: 0.04232\n",
            "Epoch: 9 | Iteration: 1642 | Classification loss: 0.00004 | Regression loss: 0.01043 | Running loss: 0.04231\n",
            "Epoch: 9 | Iteration: 1643 | Classification loss: 0.00035 | Regression loss: 0.03806 | Running loss: 0.04234\n",
            "Epoch: 9 | Iteration: 1644 | Classification loss: 0.00056 | Regression loss: 0.01616 | Running loss: 0.04234\n",
            "Epoch: 9 | Iteration: 1645 | Classification loss: 0.02121 | Regression loss: 0.03358 | Running loss: 0.04243\n",
            "Epoch: 9 | Iteration: 1646 | Classification loss: 0.00016 | Regression loss: 0.05658 | Running loss: 0.04251\n",
            "Epoch: 9 | Iteration: 1647 | Classification loss: 0.00014 | Regression loss: 0.03491 | Running loss: 0.04249\n",
            "Epoch: 9 | Iteration: 1648 | Classification loss: 0.00012 | Regression loss: 0.02871 | Running loss: 0.04236\n",
            "Epoch: 9 | Iteration: 1649 | Classification loss: 0.00067 | Regression loss: 0.03061 | Running loss: 0.04239\n",
            "Epoch: 9 | Iteration: 1650 | Classification loss: 0.00009 | Regression loss: 0.02137 | Running loss: 0.04241\n",
            "Epoch: 9 | Iteration: 1651 | Classification loss: 0.00012 | Regression loss: 0.02437 | Running loss: 0.04243\n",
            "Epoch: 9 | Iteration: 1652 | Classification loss: 0.00020 | Regression loss: 0.02815 | Running loss: 0.04245\n",
            "Epoch: 9 | Iteration: 1653 | Classification loss: 0.00150 | Regression loss: 0.03036 | Running loss: 0.04176\n",
            "Epoch: 9 | Iteration: 1654 | Classification loss: 0.02769 | Regression loss: 0.04747 | Running loss: 0.04186\n",
            "Epoch: 9 | Iteration: 1655 | Classification loss: 0.00001 | Regression loss: 0.01954 | Running loss: 0.04184\n",
            "Epoch: 9 | Iteration: 1656 | Classification loss: 0.01117 | Regression loss: 0.06232 | Running loss: 0.04190\n",
            "Epoch: 9 | Iteration: 1657 | Classification loss: 0.00020 | Regression loss: 0.01146 | Running loss: 0.04186\n",
            "Epoch: 9 | Iteration: 1658 | Classification loss: 0.00324 | Regression loss: 0.03344 | Running loss: 0.04179\n",
            "Epoch: 9 | Iteration: 1659 | Classification loss: 0.00004 | Regression loss: 0.02462 | Running loss: 0.04179\n",
            "Epoch: 9 | Iteration: 1660 | Classification loss: 0.00064 | Regression loss: 0.03574 | Running loss: 0.04169\n",
            "Epoch: 9 | Iteration: 1661 | Classification loss: 0.00003 | Regression loss: 0.05212 | Running loss: 0.04150\n",
            "Epoch: 9 | Iteration: 1662 | Classification loss: 0.00039 | Regression loss: 0.04864 | Running loss: 0.04155\n",
            "Epoch: 9 | Iteration: 1663 | Classification loss: 0.00004 | Regression loss: 0.02906 | Running loss: 0.04118\n",
            "Epoch: 9 | Iteration: 1664 | Classification loss: 0.00010 | Regression loss: 0.02659 | Running loss: 0.04116\n",
            "Epoch: 9 | Iteration: 1665 | Classification loss: 0.00042 | Regression loss: 0.01559 | Running loss: 0.04117\n",
            "Epoch: 9 | Iteration: 1666 | Classification loss: 0.00003 | Regression loss: 0.01461 | Running loss: 0.04118\n",
            "Epoch: 9 | Iteration: 1667 | Classification loss: 0.00131 | Regression loss: 0.06128 | Running loss: 0.04125\n",
            "Epoch: 9 | Iteration: 1668 | Classification loss: 0.00020 | Regression loss: 0.01136 | Running loss: 0.04118\n",
            "Epoch: 9 | Iteration: 1669 | Classification loss: 0.00018 | Regression loss: 0.01112 | Running loss: 0.04117\n",
            "Epoch: 9 | Iteration: 1670 | Classification loss: 0.00006 | Regression loss: 0.02686 | Running loss: 0.04117\n",
            "Epoch: 9 | Iteration: 1671 | Classification loss: 0.00012 | Regression loss: 0.03795 | Running loss: 0.04118\n",
            "Epoch: 9 | Iteration: 1672 | Classification loss: 0.00007 | Regression loss: 0.01671 | Running loss: 0.04110\n",
            "Epoch: 9 | Iteration: 1673 | Classification loss: 0.00031 | Regression loss: 0.02588 | Running loss: 0.04111\n",
            "Epoch: 9 | Iteration: 1674 | Classification loss: 0.00006 | Regression loss: 0.07305 | Running loss: 0.04119\n",
            "Epoch: 9 | Iteration: 1675 | Classification loss: 0.00004 | Regression loss: 0.02413 | Running loss: 0.04117\n",
            "Epoch: 9 | Iteration: 1676 | Classification loss: 0.00020 | Regression loss: 0.03495 | Running loss: 0.04117\n",
            "Epoch: 9 | Iteration: 1677 | Classification loss: 0.00004 | Regression loss: 0.01721 | Running loss: 0.04116\n",
            "Epoch: 9 | Iteration: 1678 | Classification loss: 0.00028 | Regression loss: 0.02203 | Running loss: 0.04115\n",
            "Epoch: 9 | Iteration: 1679 | Classification loss: 0.00012 | Regression loss: 0.01177 | Running loss: 0.04112\n",
            "Epoch: 9 | Iteration: 1680 | Classification loss: 0.00004 | Regression loss: 0.01077 | Running loss: 0.04112\n",
            "Epoch: 9 | Iteration: 1681 | Classification loss: 0.00034 | Regression loss: 0.04812 | Running loss: 0.04117\n",
            "Epoch: 9 | Iteration: 1682 | Classification loss: 0.00239 | Regression loss: 0.02915 | Running loss: 0.03726\n",
            "Epoch: 9 | Iteration: 1683 | Classification loss: 0.00010 | Regression loss: 0.02581 | Running loss: 0.03727\n",
            "Epoch: 9 | Iteration: 1684 | Classification loss: 0.00050 | Regression loss: 0.05933 | Running loss: 0.03735\n",
            "Epoch: 9 | Iteration: 1685 | Classification loss: 0.00010 | Regression loss: 0.02322 | Running loss: 0.03736\n",
            "Epoch: 9 | Iteration: 1686 | Classification loss: 0.00006 | Regression loss: 0.03100 | Running loss: 0.03736\n",
            "Epoch: 9 | Iteration: 1687 | Classification loss: 0.00114 | Regression loss: 0.03521 | Running loss: 0.03740\n",
            "Epoch: 9 | Iteration: 1688 | Classification loss: 0.00076 | Regression loss: 0.02594 | Running loss: 0.03739\n",
            "Epoch: 9 | Iteration: 1689 | Classification loss: 0.00007 | Regression loss: 0.02220 | Running loss: 0.03737\n",
            "Epoch: 9 | Iteration: 1690 | Classification loss: 0.00009 | Regression loss: 0.02841 | Running loss: 0.03737\n",
            "Epoch: 9 | Iteration: 1691 | Classification loss: 0.00026 | Regression loss: 0.01740 | Running loss: 0.03736\n",
            "Epoch: 9 | Iteration: 1692 | Classification loss: 0.00020 | Regression loss: 0.02172 | Running loss: 0.03693\n",
            "Epoch: 9 | Iteration: 1693 | Classification loss: 0.00015 | Regression loss: 0.01329 | Running loss: 0.03690\n",
            "Epoch: 9 | Iteration: 1694 | Classification loss: 0.00196 | Regression loss: 0.04833 | Running loss: 0.03695\n",
            "Epoch: 9 | Iteration: 1695 | Classification loss: 0.00270 | Regression loss: 0.01259 | Running loss: 0.03694\n",
            "Epoch: 9 | Iteration: 1696 | Classification loss: 0.00102 | Regression loss: 0.01554 | Running loss: 0.03688\n",
            "Epoch: 9 | Iteration: 1697 | Classification loss: 0.00003 | Regression loss: 0.00697 | Running loss: 0.03684\n",
            "Epoch: 9 | Iteration: 1698 | Classification loss: 0.00003 | Regression loss: 0.01748 | Running loss: 0.03685\n",
            "Epoch: 9 | Iteration: 1699 | Classification loss: 0.00013 | Regression loss: 0.04127 | Running loss: 0.03616\n",
            "Epoch: 9 | Iteration: 1700 | Classification loss: 0.00003 | Regression loss: 0.03171 | Running loss: 0.03617\n",
            "Epoch: 9 | Iteration: 1701 | Classification loss: 0.00021 | Regression loss: 0.02494 | Running loss: 0.03617\n",
            "Epoch: 9 | Iteration: 1702 | Classification loss: 0.00004 | Regression loss: 0.01252 | Running loss: 0.03606\n",
            "Epoch: 9 | Iteration: 1703 | Classification loss: 0.00008 | Regression loss: 0.01535 | Running loss: 0.03605\n",
            "Epoch: 9 | Iteration: 1704 | Classification loss: 0.01693 | Regression loss: 0.07098 | Running loss: 0.03618\n",
            "Epoch: 9 | Iteration: 1705 | Classification loss: 0.00003 | Regression loss: 0.02686 | Running loss: 0.03621\n",
            "Epoch: 9 | Iteration: 1706 | Classification loss: 0.00005 | Regression loss: 0.03507 | Running loss: 0.03622\n",
            "Epoch: 9 | Iteration: 1707 | Classification loss: 0.00043 | Regression loss: 0.03358 | Running loss: 0.03623\n",
            "Epoch: 9 | Iteration: 1708 | Classification loss: 0.00019 | Regression loss: 0.01842 | Running loss: 0.03624\n",
            "Epoch: 9 | Iteration: 1709 | Classification loss: 0.00022 | Regression loss: 0.05067 | Running loss: 0.03631\n",
            "Epoch: 9 | Iteration: 1710 | Classification loss: 0.00004 | Regression loss: 0.04626 | Running loss: 0.03631\n",
            "Epoch: 9 | Iteration: 1711 | Classification loss: 0.00033 | Regression loss: 0.02951 | Running loss: 0.03632\n",
            "Epoch: 9 | Iteration: 1712 | Classification loss: 0.00014 | Regression loss: 0.03024 | Running loss: 0.03629\n",
            "Epoch: 9 | Iteration: 1713 | Classification loss: 0.00014 | Regression loss: 0.03058 | Running loss: 0.03632\n",
            "Epoch: 9 | Iteration: 1714 | Classification loss: 0.00007 | Regression loss: 0.02777 | Running loss: 0.03629\n",
            "Epoch: 9 | Iteration: 1715 | Classification loss: 0.00025 | Regression loss: 0.03710 | Running loss: 0.03627\n",
            "Epoch: 9 | Iteration: 1716 | Classification loss: 0.00928 | Regression loss: 0.07824 | Running loss: 0.03635\n",
            "Epoch: 9 | Iteration: 1717 | Classification loss: 0.01464 | Regression loss: 0.05577 | Running loss: 0.03640\n",
            "Epoch: 9 | Iteration: 1718 | Classification loss: 0.00008 | Regression loss: 0.02211 | Running loss: 0.03637\n",
            "Epoch: 9 | Iteration: 1719 | Classification loss: 0.00052 | Regression loss: 0.04045 | Running loss: 0.03638\n",
            "Epoch: 9 | Iteration: 1720 | Classification loss: 0.00011 | Regression loss: 0.02609 | Running loss: 0.03632\n",
            "Epoch: 9 | Iteration: 1721 | Classification loss: 0.00001 | Regression loss: 0.01328 | Running loss: 0.03629\n",
            "Epoch: 9 | Iteration: 1722 | Classification loss: 0.00007 | Regression loss: 0.00811 | Running loss: 0.03627\n",
            "Epoch: 9 | Iteration: 1723 | Classification loss: 0.08999 | Regression loss: 0.28227 | Running loss: 0.03699\n",
            "Epoch: 9 | Iteration: 1724 | Classification loss: 0.00258 | Regression loss: 0.03860 | Running loss: 0.03705\n",
            "Epoch: 9 | Iteration: 1725 | Classification loss: 0.00006 | Regression loss: 0.02762 | Running loss: 0.03700\n",
            "Epoch: 9 | Iteration: 1726 | Classification loss: 0.00003 | Regression loss: 0.03765 | Running loss: 0.03699\n",
            "Epoch: 9 | Iteration: 1727 | Classification loss: 0.00010 | Regression loss: 0.02020 | Running loss: 0.03696\n",
            "Epoch: 9 | Iteration: 1728 | Classification loss: 0.00021 | Regression loss: 0.08529 | Running loss: 0.03708\n",
            "Epoch: 9 | Iteration: 1729 | Classification loss: 0.00102 | Regression loss: 0.01601 | Running loss: 0.03685\n",
            "Epoch: 9 | Iteration: 1730 | Classification loss: 0.02773 | Regression loss: 0.06665 | Running loss: 0.03694\n",
            "Epoch: 9 | Iteration: 1731 | Classification loss: 0.00031 | Regression loss: 0.03470 | Running loss: 0.03699\n",
            "Epoch: 9 | Iteration: 1732 | Classification loss: 0.00006 | Regression loss: 0.00824 | Running loss: 0.03682\n",
            "Epoch: 9 | Iteration: 1733 | Classification loss: 0.00182 | Regression loss: 0.05569 | Running loss: 0.03691\n",
            "Epoch: 9 | Iteration: 1734 | Classification loss: 0.00004 | Regression loss: 0.04042 | Running loss: 0.03695\n",
            "Epoch: 9 | Iteration: 1735 | Classification loss: 0.00008 | Regression loss: 0.04091 | Running loss: 0.03699\n",
            "Epoch: 9 | Iteration: 1736 | Classification loss: 0.00081 | Regression loss: 0.04082 | Running loss: 0.03700\n",
            "Epoch: 9 | Iteration: 1737 | Classification loss: 0.05810 | Regression loss: 0.07526 | Running loss: 0.03720\n",
            "Epoch: 9 | Iteration: 1738 | Classification loss: 0.00011 | Regression loss: 0.01551 | Running loss: 0.03720\n",
            "Epoch: 9 | Iteration: 1739 | Classification loss: 0.00025 | Regression loss: 0.02619 | Running loss: 0.03711\n",
            "Epoch: 9 | Iteration: 1740 | Classification loss: 0.00007 | Regression loss: 0.04468 | Running loss: 0.03718\n",
            "Epoch: 9 | Iteration: 1741 | Classification loss: 0.00064 | Regression loss: 0.02165 | Running loss: 0.03718\n",
            "Epoch: 9 | Iteration: 1742 | Classification loss: 0.00188 | Regression loss: 0.01877 | Running loss: 0.03716\n",
            "Epoch: 9 | Iteration: 1743 | Classification loss: 0.00007 | Regression loss: 0.01581 | Running loss: 0.03715\n",
            "Epoch: 9 | Iteration: 1744 | Classification loss: 0.00036 | Regression loss: 0.07230 | Running loss: 0.03725\n",
            "Epoch: 9 | Iteration: 1745 | Classification loss: 0.00043 | Regression loss: 0.03379 | Running loss: 0.03726\n",
            "Epoch: 9 | Iteration: 1746 | Classification loss: 0.00031 | Regression loss: 0.02162 | Running loss: 0.03726\n",
            "Epoch: 9 | Iteration: 1747 | Classification loss: 0.00238 | Regression loss: 0.05805 | Running loss: 0.03736\n",
            "Epoch: 9 | Iteration: 1748 | Classification loss: 0.01141 | Regression loss: 0.05275 | Running loss: 0.03746\n",
            "Epoch: 9 | Iteration: 1749 | Classification loss: 0.01475 | Regression loss: 0.04620 | Running loss: 0.03753\n",
            "Epoch: 9 | Iteration: 1750 | Classification loss: 0.03493 | Regression loss: 0.03683 | Running loss: 0.03753\n",
            "Epoch: 9 | Iteration: 1751 | Classification loss: 0.00024 | Regression loss: 0.06107 | Running loss: 0.03762\n",
            "Epoch: 9 | Iteration: 1752 | Classification loss: 0.00026 | Regression loss: 0.02950 | Running loss: 0.03764\n",
            "Epoch: 9 | Iteration: 1753 | Classification loss: 0.00005 | Regression loss: 0.06804 | Running loss: 0.03774\n",
            "Epoch: 9 | Iteration: 1754 | Classification loss: 0.00312 | Regression loss: 0.04649 | Running loss: 0.03780\n",
            "Epoch: 9 | Iteration: 1755 | Classification loss: 0.00017 | Regression loss: 0.02878 | Running loss: 0.03779\n",
            "Epoch: 9 | Iteration: 1756 | Classification loss: 0.00020 | Regression loss: 0.00978 | Running loss: 0.03777\n",
            "Epoch: 9 | Iteration: 1757 | Classification loss: 0.00009 | Regression loss: 0.03323 | Running loss: 0.03781\n",
            "Epoch: 9 | Iteration: 1758 | Classification loss: 0.00008 | Regression loss: 0.02125 | Running loss: 0.03782\n",
            "Epoch: 9 | Iteration: 1759 | Classification loss: 0.00114 | Regression loss: 0.04166 | Running loss: 0.03779\n",
            "Epoch: 9 | Iteration: 1760 | Classification loss: 0.00016 | Regression loss: 0.02615 | Running loss: 0.03776\n",
            "Epoch: 9 | Iteration: 1761 | Classification loss: 0.00013 | Regression loss: 0.01205 | Running loss: 0.03768\n",
            "Epoch: 9 | Iteration: 1762 | Classification loss: 0.00017 | Regression loss: 0.01162 | Running loss: 0.03756\n",
            "Epoch: 9 | Iteration: 1763 | Classification loss: 0.00026 | Regression loss: 0.01714 | Running loss: 0.03752\n",
            "Epoch: 9 | Iteration: 1764 | Classification loss: 0.00679 | Regression loss: 0.01178 | Running loss: 0.03749\n",
            "Epoch: 9 | Iteration: 1765 | Classification loss: 0.07398 | Regression loss: 0.02739 | Running loss: 0.03763\n",
            "Epoch: 9 | Iteration: 1766 | Classification loss: 0.00478 | Regression loss: 0.11323 | Running loss: 0.03777\n",
            "Epoch: 9 | Iteration: 1767 | Classification loss: 0.00018 | Regression loss: 0.01763 | Running loss: 0.03778\n",
            "Epoch: 9 | Iteration: 1768 | Classification loss: 0.01104 | Regression loss: 0.08134 | Running loss: 0.03790\n",
            "Epoch: 9 | Iteration: 1769 | Classification loss: 0.00039 | Regression loss: 0.02675 | Running loss: 0.03791\n",
            "Epoch: 9 | Iteration: 1770 | Classification loss: 0.01129 | Regression loss: 0.03873 | Running loss: 0.03795\n",
            "Epoch: 9 | Iteration: 1771 | Classification loss: 0.00307 | Regression loss: 0.05677 | Running loss: 0.03804\n",
            "Epoch: 9 | Iteration: 1772 | Classification loss: 0.00029 | Regression loss: 0.01724 | Running loss: 0.03801\n",
            "Epoch: 9 | Iteration: 1773 | Classification loss: 0.00009 | Regression loss: 0.00971 | Running loss: 0.03801\n",
            "Epoch: 9 | Iteration: 1774 | Classification loss: 0.00025 | Regression loss: 0.01990 | Running loss: 0.03803\n",
            "Epoch: 9 | Iteration: 1775 | Classification loss: 0.00006 | Regression loss: 0.00637 | Running loss: 0.03799\n",
            "Epoch: 9 | Iteration: 1776 | Classification loss: 0.00283 | Regression loss: 0.02507 | Running loss: 0.03792\n",
            "Epoch: 9 | Iteration: 1777 | Classification loss: 0.00674 | Regression loss: 0.04421 | Running loss: 0.03798\n",
            "Epoch: 9 | Iteration: 1778 | Classification loss: 0.00074 | Regression loss: 0.04125 | Running loss: 0.03803\n",
            "Epoch: 9 | Iteration: 1779 | Classification loss: 0.00002 | Regression loss: 0.02140 | Running loss: 0.03804\n",
            "Epoch: 9 | Iteration: 1780 | Classification loss: 0.07854 | Regression loss: 0.25411 | Running loss: 0.03867\n",
            "Epoch: 9 | Iteration: 1781 | Classification loss: 0.00302 | Regression loss: 0.02985 | Running loss: 0.03869\n",
            "Epoch: 9 | Iteration: 1782 | Classification loss: 0.00245 | Regression loss: 0.02811 | Running loss: 0.03873\n",
            "Epoch: 9 | Iteration: 1783 | Classification loss: 0.00045 | Regression loss: 0.05220 | Running loss: 0.03880\n",
            "Epoch: 9 | Iteration: 1784 | Classification loss: 0.00040 | Regression loss: 0.04443 | Running loss: 0.03867\n",
            "Epoch: 9 | Iteration: 1785 | Classification loss: 0.01209 | Regression loss: 0.03421 | Running loss: 0.03874\n",
            "Epoch: 9 | Iteration: 1786 | Classification loss: 0.00019 | Regression loss: 0.02128 | Running loss: 0.03870\n",
            "Epoch: 9 | Iteration: 1787 | Classification loss: 0.00023 | Regression loss: 0.02730 | Running loss: 0.03873\n",
            "Epoch: 9 | Iteration: 1788 | Classification loss: 0.00021 | Regression loss: 0.02523 | Running loss: 0.03872\n",
            "Epoch: 9 | Iteration: 1789 | Classification loss: 0.00072 | Regression loss: 0.01691 | Running loss: 0.03872\n",
            "Epoch: 9 | Iteration: 1790 | Classification loss: 0.01661 | Regression loss: 0.03517 | Running loss: 0.03875\n",
            "Epoch: 9 | Iteration: 1791 | Classification loss: 0.00015 | Regression loss: 0.01720 | Running loss: 0.03872\n",
            "Epoch: 9 | Iteration: 1792 | Classification loss: 0.00031 | Regression loss: 0.01463 | Running loss: 0.03868\n",
            "Epoch: 9 | Iteration: 1793 | Classification loss: 0.00007 | Regression loss: 0.00568 | Running loss: 0.03865\n",
            "Epoch: 9 | Iteration: 1794 | Classification loss: 0.00023 | Regression loss: 0.02809 | Running loss: 0.03863\n",
            "Epoch: 9 | Iteration: 1795 | Classification loss: 0.00059 | Regression loss: 0.01080 | Running loss: 0.03861\n",
            "Epoch: 9 | Iteration: 1796 | Classification loss: 0.00223 | Regression loss: 0.02111 | Running loss: 0.03853\n",
            "Epoch: 9 | Iteration: 1797 | Classification loss: 0.00017 | Regression loss: 0.02501 | Running loss: 0.03856\n",
            "Epoch: 9 | Iteration: 1798 | Classification loss: 0.00066 | Regression loss: 0.01587 | Running loss: 0.03852\n",
            "Epoch: 9 | Iteration: 1799 | Classification loss: 0.00024 | Regression loss: 0.00994 | Running loss: 0.03849\n",
            "Epoch: 9 | Iteration: 1800 | Classification loss: 0.00398 | Regression loss: 0.02156 | Running loss: 0.03848\n",
            "Epoch: 9 | Iteration: 1801 | Classification loss: 0.00020 | Regression loss: 0.00982 | Running loss: 0.03847\n",
            "Epoch: 9 | Iteration: 1802 | Classification loss: 0.00018 | Regression loss: 0.05449 | Running loss: 0.03851\n",
            "Epoch: 9 | Iteration: 1803 | Classification loss: 0.00009 | Regression loss: 0.01508 | Running loss: 0.03851\n",
            "Epoch: 9 | Iteration: 1804 | Classification loss: 0.00025 | Regression loss: 0.02236 | Running loss: 0.03851\n",
            "Epoch: 9 | Iteration: 1805 | Classification loss: 0.00255 | Regression loss: 0.04274 | Running loss: 0.03854\n",
            "Epoch: 9 | Iteration: 1806 | Classification loss: 0.00047 | Regression loss: 0.04414 | Running loss: 0.03853\n",
            "Epoch: 9 | Iteration: 1807 | Classification loss: 0.00056 | Regression loss: 0.03043 | Running loss: 0.03854\n",
            "Epoch: 9 | Iteration: 1808 | Classification loss: 0.00092 | Regression loss: 0.05447 | Running loss: 0.03855\n",
            "Epoch: 9 | Iteration: 1809 | Classification loss: 0.00008 | Regression loss: 0.02043 | Running loss: 0.03847\n",
            "Epoch: 9 | Iteration: 1810 | Classification loss: 0.00026 | Regression loss: 0.01556 | Running loss: 0.03848\n",
            "Epoch: 9 | Iteration: 1811 | Classification loss: 0.00008 | Regression loss: 0.01368 | Running loss: 0.03848\n",
            "Epoch: 9 | Iteration: 1812 | Classification loss: 0.00232 | Regression loss: 0.05066 | Running loss: 0.03851\n",
            "Epoch: 9 | Iteration: 1813 | Classification loss: 0.00027 | Regression loss: 0.02206 | Running loss: 0.03849\n",
            "Epoch: 9 | Iteration: 1814 | Classification loss: 0.00009 | Regression loss: 0.02280 | Running loss: 0.03849\n",
            "Epoch: 9 | Iteration: 1815 | Classification loss: 0.00006 | Regression loss: 0.01574 | Running loss: 0.03847\n",
            "Epoch: 9 | Iteration: 1816 | Classification loss: 0.00046 | Regression loss: 0.02846 | Running loss: 0.03845\n",
            "Epoch: 9 | Iteration: 1817 | Classification loss: 0.00010 | Regression loss: 0.01853 | Running loss: 0.03845\n",
            "Epoch: 9 | Iteration: 1818 | Classification loss: 0.00014 | Regression loss: 0.02319 | Running loss: 0.03845\n",
            "Epoch: 9 | Iteration: 1819 | Classification loss: 0.01017 | Regression loss: 0.03711 | Running loss: 0.03849\n",
            "Epoch: 9 | Iteration: 1820 | Classification loss: 0.00069 | Regression loss: 0.02910 | Running loss: 0.03851\n",
            "Epoch: 9 | Iteration: 1821 | Classification loss: 0.00064 | Regression loss: 0.02977 | Running loss: 0.03850\n",
            "Epoch: 9 | Iteration: 1822 | Classification loss: 0.00021 | Regression loss: 0.03262 | Running loss: 0.03853\n",
            "Epoch: 9 | Iteration: 1823 | Classification loss: 0.00038 | Regression loss: 0.02662 | Running loss: 0.03855\n",
            "Epoch: 9 | Iteration: 1824 | Classification loss: 0.00007 | Regression loss: 0.03286 | Running loss: 0.03858\n",
            "Epoch: 9 | Iteration: 1825 | Classification loss: 0.00058 | Regression loss: 0.04955 | Running loss: 0.03859\n",
            "Epoch: 9 | Iteration: 1826 | Classification loss: 0.00014 | Regression loss: 0.02032 | Running loss: 0.03857\n",
            "Epoch: 9 | Iteration: 1827 | Classification loss: 0.00016 | Regression loss: 0.01436 | Running loss: 0.03855\n",
            "Epoch: 9 | Iteration: 1828 | Classification loss: 0.00172 | Regression loss: 0.02972 | Running loss: 0.03857\n",
            "Epoch: 9 | Iteration: 1829 | Classification loss: 0.00046 | Regression loss: 0.01183 | Running loss: 0.03852\n",
            "Epoch: 9 | Iteration: 1830 | Classification loss: 0.00004 | Regression loss: 0.01613 | Running loss: 0.03851\n",
            "Epoch: 9 | Iteration: 1831 | Classification loss: 0.00009 | Regression loss: 0.01573 | Running loss: 0.03849\n",
            "Epoch: 9 | Iteration: 1832 | Classification loss: 0.00024 | Regression loss: 0.01504 | Running loss: 0.03849\n",
            "Epoch: 9 | Iteration: 1833 | Classification loss: 0.00018 | Regression loss: 0.01399 | Running loss: 0.03846\n",
            "Epoch: 9 | Iteration: 1834 | Classification loss: 0.00021 | Regression loss: 0.01872 | Running loss: 0.03847\n",
            "Epoch: 9 | Iteration: 1835 | Classification loss: 0.00077 | Regression loss: 0.02414 | Running loss: 0.03850\n",
            "Epoch: 9 | Iteration: 1836 | Classification loss: 0.00005 | Regression loss: 0.02826 | Running loss: 0.03851\n",
            "Epoch: 9 | Iteration: 1837 | Classification loss: 0.00057 | Regression loss: 0.01532 | Running loss: 0.03853\n",
            "Epoch: 9 | Iteration: 1838 | Classification loss: 0.00011 | Regression loss: 0.02030 | Running loss: 0.03852\n",
            "Epoch: 9 | Iteration: 1839 | Classification loss: 0.00002 | Regression loss: 0.02145 | Running loss: 0.03853\n",
            "Epoch: 9 | Iteration: 1840 | Classification loss: 0.00003 | Regression loss: 0.01099 | Running loss: 0.03850\n",
            "Epoch: 9 | Iteration: 1841 | Classification loss: 0.00010 | Regression loss: 0.01882 | Running loss: 0.03850\n",
            "Epoch: 9 | Iteration: 1842 | Classification loss: 0.00011 | Regression loss: 0.02519 | Running loss: 0.03849\n",
            "Epoch: 9 | Iteration: 1843 | Classification loss: 0.00035 | Regression loss: 0.00984 | Running loss: 0.03838\n",
            "Epoch: 9 | Iteration: 1844 | Classification loss: 0.00379 | Regression loss: 0.10048 | Running loss: 0.03853\n",
            "Epoch: 9 | Iteration: 1845 | Classification loss: 0.00060 | Regression loss: 0.02096 | Running loss: 0.03845\n",
            "Epoch: 9 | Iteration: 1846 | Classification loss: 0.00078 | Regression loss: 0.02030 | Running loss: 0.03843\n",
            "Epoch: 9 | Iteration: 1847 | Classification loss: 0.00039 | Regression loss: 0.02277 | Running loss: 0.03843\n",
            "Epoch: 9 | Iteration: 1848 | Classification loss: 0.00134 | Regression loss: 0.01883 | Running loss: 0.03841\n",
            "Epoch: 9 | Iteration: 1849 | Classification loss: 0.00015 | Regression loss: 0.03208 | Running loss: 0.03844\n",
            "Epoch: 9 | Iteration: 1850 | Classification loss: 0.00082 | Regression loss: 0.02904 | Running loss: 0.03839\n",
            "Epoch: 9 | Iteration: 1851 | Classification loss: 0.00057 | Regression loss: 0.05025 | Running loss: 0.03842\n",
            "Epoch: 9 | Iteration: 1852 | Classification loss: 0.00105 | Regression loss: 0.01590 | Running loss: 0.03838\n",
            "Epoch: 9 | Iteration: 1853 | Classification loss: 0.00011 | Regression loss: 0.01458 | Running loss: 0.03835\n",
            "Epoch: 9 | Iteration: 1854 | Classification loss: 0.00002 | Regression loss: 0.01429 | Running loss: 0.03834\n",
            "Epoch: 9 | Iteration: 1855 | Classification loss: 0.00120 | Regression loss: 0.01951 | Running loss: 0.03830\n",
            "Epoch: 9 | Iteration: 1856 | Classification loss: 0.00006 | Regression loss: 0.02158 | Running loss: 0.03831\n",
            "Epoch: 9 | Iteration: 1857 | Classification loss: 0.00012 | Regression loss: 0.01285 | Running loss: 0.03831\n",
            "Epoch: 9 | Iteration: 1858 | Classification loss: 0.00029 | Regression loss: 0.02189 | Running loss: 0.03831\n",
            "Epoch: 9 | Iteration: 1859 | Classification loss: 0.00024 | Regression loss: 0.02152 | Running loss: 0.03828\n",
            "Epoch: 9 | Iteration: 1860 | Classification loss: 0.00008 | Regression loss: 0.01589 | Running loss: 0.03826\n",
            "Epoch: 9 | Iteration: 1861 | Classification loss: 0.00005 | Regression loss: 0.02240 | Running loss: 0.03819\n",
            "Epoch: 9 | Iteration: 1862 | Classification loss: 0.00002 | Regression loss: 0.00951 | Running loss: 0.03813\n",
            "Epoch: 9 | Iteration: 1863 | Classification loss: 0.03364 | Regression loss: 0.05898 | Running loss: 0.03825\n",
            "Epoch: 9 | Iteration: 1864 | Classification loss: 0.00026 | Regression loss: 0.01896 | Running loss: 0.03820\n",
            "Epoch: 9 | Iteration: 1865 | Classification loss: 0.00008 | Regression loss: 0.01620 | Running loss: 0.03817\n",
            "Epoch: 9 | Iteration: 1866 | Classification loss: 0.00002 | Regression loss: 0.01280 | Running loss: 0.03814\n",
            "Epoch: 9 | Iteration: 1867 | Classification loss: 0.00048 | Regression loss: 0.01046 | Running loss: 0.03808\n",
            "Epoch: 9 | Iteration: 1868 | Classification loss: 0.00185 | Regression loss: 0.02456 | Running loss: 0.03811\n",
            "Epoch: 9 | Iteration: 1869 | Classification loss: 0.00005 | Regression loss: 0.02749 | Running loss: 0.03812\n",
            "Epoch: 9 | Iteration: 1870 | Classification loss: 0.00033 | Regression loss: 0.01749 | Running loss: 0.03810\n",
            "Epoch: 9 | Iteration: 1871 | Classification loss: 0.00028 | Regression loss: 0.06764 | Running loss: 0.03818\n",
            "Epoch: 9 | Iteration: 1872 | Classification loss: 0.00011 | Regression loss: 0.03503 | Running loss: 0.03818\n",
            "Epoch: 9 | Iteration: 1873 | Classification loss: 0.00007 | Regression loss: 0.01256 | Running loss: 0.03805\n",
            "Epoch: 9 | Iteration: 1874 | Classification loss: 0.00007 | Regression loss: 0.06332 | Running loss: 0.03813\n",
            "Epoch: 9 | Iteration: 1875 | Classification loss: 0.00059 | Regression loss: 0.03403 | Running loss: 0.03816\n",
            "Epoch: 9 | Iteration: 1876 | Classification loss: 0.00007 | Regression loss: 0.01270 | Running loss: 0.03814\n",
            "Epoch: 9 | Iteration: 1877 | Classification loss: 0.00075 | Regression loss: 0.04232 | Running loss: 0.03810\n",
            "Epoch: 9 | Iteration: 1878 | Classification loss: 0.00011 | Regression loss: 0.02168 | Running loss: 0.03811\n",
            "Epoch: 9 | Iteration: 1879 | Classification loss: 0.00013 | Regression loss: 0.02949 | Running loss: 0.03811\n",
            "Epoch: 9 | Iteration: 1880 | Classification loss: 0.00007 | Regression loss: 0.02007 | Running loss: 0.03807\n",
            "Epoch: 9 | Iteration: 1881 | Classification loss: 0.00067 | Regression loss: 0.02676 | Running loss: 0.03795\n",
            "Epoch: 9 | Iteration: 1882 | Classification loss: 0.00003 | Regression loss: 0.02406 | Running loss: 0.03794\n",
            "Epoch: 9 | Iteration: 1883 | Classification loss: 0.00025 | Regression loss: 0.02551 | Running loss: 0.03797\n",
            "Epoch: 9 | Iteration: 1884 | Classification loss: 0.00134 | Regression loss: 0.01959 | Running loss: 0.03797\n",
            "Epoch: 9 | Iteration: 1885 | Classification loss: 0.00002 | Regression loss: 0.02716 | Running loss: 0.03799\n",
            "Epoch: 9 | Iteration: 1886 | Classification loss: 0.00274 | Regression loss: 0.06858 | Running loss: 0.03692\n",
            "Epoch: 9 | Iteration: 1887 | Classification loss: 0.00076 | Regression loss: 0.03082 | Running loss: 0.03606\n",
            "Epoch: 9 | Iteration: 1888 | Classification loss: 0.00010 | Regression loss: 0.01013 | Running loss: 0.03593\n",
            "Epoch: 9 | Iteration: 1889 | Classification loss: 0.00022 | Regression loss: 0.02221 | Running loss: 0.03590\n",
            "Epoch: 9 | Iteration: 1890 | Classification loss: 0.00002 | Regression loss: 0.00856 | Running loss: 0.03588\n",
            "Epoch: 9 | Iteration: 1891 | Classification loss: 0.00007 | Regression loss: 0.02352 | Running loss: 0.03574\n",
            "Epoch: 9 | Iteration: 1892 | Classification loss: 0.00017 | Regression loss: 0.02626 | Running loss: 0.03577\n",
            "Epoch: 9 | Iteration: 1893 | Classification loss: 0.00030 | Regression loss: 0.02800 | Running loss: 0.03577\n",
            "Epoch: 9 | Iteration: 1894 | Classification loss: 0.00003 | Regression loss: 0.00983 | Running loss: 0.03571\n",
            "Epoch: 9 | Iteration: 1895 | Classification loss: 0.00056 | Regression loss: 0.02548 | Running loss: 0.03559\n",
            "Epoch: 9 | Iteration: 1896 | Classification loss: 0.00076 | Regression loss: 0.03841 | Running loss: 0.03562\n",
            "Epoch: 9 | Iteration: 1897 | Classification loss: 0.00009 | Regression loss: 0.02523 | Running loss: 0.03555\n",
            "Epoch: 9 | Iteration: 1898 | Classification loss: 0.00051 | Regression loss: 0.03274 | Running loss: 0.03556\n",
            "Epoch: 9 | Iteration: 1899 | Classification loss: 0.00006 | Regression loss: 0.02118 | Running loss: 0.03545\n",
            "Epoch: 9 | Iteration: 1900 | Classification loss: 0.00260 | Regression loss: 0.03492 | Running loss: 0.03545\n",
            "Epoch: 9 | Iteration: 1901 | Classification loss: 0.00015 | Regression loss: 0.01589 | Running loss: 0.03541\n",
            "Epoch: 9 | Iteration: 1902 | Classification loss: 0.00010 | Regression loss: 0.01488 | Running loss: 0.03534\n",
            "Epoch: 9 | Iteration: 1903 | Classification loss: 0.00023 | Regression loss: 0.02499 | Running loss: 0.03537\n",
            "Epoch: 9 | Iteration: 1904 | Classification loss: 0.00005 | Regression loss: 0.02634 | Running loss: 0.03535\n",
            "Epoch: 9 | Iteration: 1905 | Classification loss: 0.00021 | Regression loss: 0.02118 | Running loss: 0.03495\n",
            "Epoch: 9 | Iteration: 1906 | Classification loss: 0.00008 | Regression loss: 0.03910 | Running loss: 0.03494\n",
            "Epoch: 9 | Iteration: 1907 | Classification loss: 0.00006 | Regression loss: 0.01643 | Running loss: 0.03490\n",
            "Epoch: 9 | Iteration: 1908 | Classification loss: 0.00020 | Regression loss: 0.06978 | Running loss: 0.03492\n",
            "Epoch: 9 | Iteration: 1909 | Classification loss: 0.00068 | Regression loss: 0.04375 | Running loss: 0.03498\n",
            "Epoch: 9 | Iteration: 1910 | Classification loss: 0.00006 | Regression loss: 0.01437 | Running loss: 0.03485\n",
            "Epoch: 9 | Iteration: 1911 | Classification loss: 0.00004 | Regression loss: 0.01751 | Running loss: 0.03485\n",
            "Epoch: 9 | Iteration: 1912 | Classification loss: 0.00009 | Regression loss: 0.01918 | Running loss: 0.03486\n",
            "Epoch: 9 | Iteration: 1913 | Classification loss: 0.00022 | Regression loss: 0.02979 | Running loss: 0.03483\n",
            "Epoch: 9 | Iteration: 1914 | Classification loss: 0.00020 | Regression loss: 0.04515 | Running loss: 0.03486\n",
            "Epoch: 9 | Iteration: 1915 | Classification loss: 0.00007 | Regression loss: 0.02515 | Running loss: 0.03487\n",
            "Epoch: 9 | Iteration: 1916 | Classification loss: 0.00029 | Regression loss: 0.05240 | Running loss: 0.03493\n",
            "Epoch: 9 | Iteration: 1917 | Classification loss: 0.00001 | Regression loss: 0.01972 | Running loss: 0.03476\n",
            "Epoch: 9 | Iteration: 1918 | Classification loss: 0.00434 | Regression loss: 0.03281 | Running loss: 0.03475\n",
            "Epoch: 9 | Iteration: 1919 | Classification loss: 0.00001 | Regression loss: 0.01748 | Running loss: 0.03475\n",
            "Epoch: 9 | Iteration: 1920 | Classification loss: 0.00014 | Regression loss: 0.00802 | Running loss: 0.03473\n",
            "Epoch: 9 | Iteration: 1921 | Classification loss: 0.00007 | Regression loss: 0.03350 | Running loss: 0.03475\n",
            "Epoch: 9 | Iteration: 1922 | Classification loss: 0.00020 | Regression loss: 0.01499 | Running loss: 0.03473\n",
            "Epoch: 9 | Iteration: 1923 | Classification loss: 0.00007 | Regression loss: 0.03004 | Running loss: 0.03476\n",
            "Epoch: 9 | Iteration: 1924 | Classification loss: 0.00002 | Regression loss: 0.01715 | Running loss: 0.03473\n",
            "Epoch: 9 | Iteration: 1925 | Classification loss: 0.00113 | Regression loss: 0.02024 | Running loss: 0.03469\n",
            "Epoch: 9 | Iteration: 1926 | Classification loss: 0.00025 | Regression loss: 0.02105 | Running loss: 0.03469\n",
            "Epoch: 9 | Iteration: 1927 | Classification loss: 0.00013 | Regression loss: 0.01008 | Running loss: 0.03468\n",
            "Epoch: 9 | Iteration: 1928 | Classification loss: 0.00034 | Regression loss: 0.08120 | Running loss: 0.03477\n",
            "Epoch: 9 | Iteration: 1929 | Classification loss: 0.00010 | Regression loss: 0.01890 | Running loss: 0.03479\n",
            "Epoch: 9 | Iteration: 1930 | Classification loss: 0.00042 | Regression loss: 0.04277 | Running loss: 0.03484\n",
            "Epoch: 9 | Iteration: 1931 | Classification loss: 0.00002 | Regression loss: 0.01250 | Running loss: 0.03485\n",
            "Epoch: 9 | Iteration: 1932 | Classification loss: 0.00006 | Regression loss: 0.07084 | Running loss: 0.03496\n",
            "Epoch: 9 | Iteration: 1933 | Classification loss: 0.00049 | Regression loss: 0.06131 | Running loss: 0.03506\n",
            "Epoch: 9 | Iteration: 1934 | Classification loss: 0.00009 | Regression loss: 0.01307 | Running loss: 0.03504\n",
            "Epoch: 9 | Iteration: 1935 | Classification loss: 0.00087 | Regression loss: 0.02076 | Running loss: 0.03505\n",
            "Epoch: 9 | Iteration: 1936 | Classification loss: 0.00006 | Regression loss: 0.01514 | Running loss: 0.03504\n",
            "Epoch: 9 | Iteration: 1937 | Classification loss: 0.00024 | Regression loss: 0.02995 | Running loss: 0.03505\n",
            "Epoch: 9 | Iteration: 1938 | Classification loss: 0.00017 | Regression loss: 0.01027 | Running loss: 0.03505\n",
            "Epoch: 9 | Iteration: 1939 | Classification loss: 0.00007 | Regression loss: 0.02410 | Running loss: 0.03501\n",
            "Epoch: 9 | Iteration: 1940 | Classification loss: 0.00007 | Regression loss: 0.01250 | Running loss: 0.03499\n",
            "Epoch: 9 | Iteration: 1941 | Classification loss: 0.00009 | Regression loss: 0.03562 | Running loss: 0.03502\n",
            "Epoch: 9 | Iteration: 1942 | Classification loss: 0.00003 | Regression loss: 0.02468 | Running loss: 0.03504\n",
            "Epoch: 9 | Iteration: 1943 | Classification loss: 0.00003 | Regression loss: 0.01577 | Running loss: 0.03502\n",
            "Epoch: 9 | Iteration: 1944 | Classification loss: 0.00026 | Regression loss: 0.03170 | Running loss: 0.03503\n",
            "Epoch: 9 | Iteration: 1945 | Classification loss: 0.00013 | Regression loss: 0.01585 | Running loss: 0.03503\n",
            "Epoch: 9 | Iteration: 1946 | Classification loss: 0.00008 | Regression loss: 0.03420 | Running loss: 0.03505\n",
            "Epoch: 9 | Iteration: 1947 | Classification loss: 0.00041 | Regression loss: 0.01466 | Running loss: 0.03502\n",
            "Epoch: 9 | Iteration: 1948 | Classification loss: 0.00177 | Regression loss: 0.05439 | Running loss: 0.03511\n",
            "Epoch: 9 | Iteration: 1949 | Classification loss: 0.00002 | Regression loss: 0.01372 | Running loss: 0.03511\n",
            "Epoch: 9 | Iteration: 1950 | Classification loss: 0.00141 | Regression loss: 0.04032 | Running loss: 0.03517\n",
            "Epoch: 9 | Iteration: 1951 | Classification loss: 0.00009 | Regression loss: 0.01538 | Running loss: 0.03516\n",
            "Epoch: 9 | Iteration: 1952 | Classification loss: 0.00036 | Regression loss: 0.02967 | Running loss: 0.03518\n",
            "Epoch: 9 | Iteration: 1953 | Classification loss: 0.00031 | Regression loss: 0.03293 | Running loss: 0.03508\n",
            "Epoch: 9 | Iteration: 1954 | Classification loss: 0.00022 | Regression loss: 0.05722 | Running loss: 0.03515\n",
            "Epoch: 9 | Iteration: 1955 | Classification loss: 0.00134 | Regression loss: 0.05558 | Running loss: 0.03519\n",
            "Epoch: 9 | Iteration: 1956 | Classification loss: 0.00013 | Regression loss: 0.02676 | Running loss: 0.03520\n",
            "Epoch: 9 | Iteration: 1957 | Classification loss: 0.00028 | Regression loss: 0.03191 | Running loss: 0.03513\n",
            "Epoch: 9 | Iteration: 1958 | Classification loss: 0.00007 | Regression loss: 0.03375 | Running loss: 0.03501\n",
            "Epoch: 9 | Iteration: 1959 | Classification loss: 0.00005 | Regression loss: 0.01197 | Running loss: 0.03494\n",
            "Epoch: 9 | Iteration: 1960 | Classification loss: 0.00508 | Regression loss: 0.03500 | Running loss: 0.03497\n",
            "Epoch: 9 | Iteration: 1961 | Classification loss: 0.00003 | Regression loss: 0.01525 | Running loss: 0.03495\n",
            "Epoch: 9 | Iteration: 1962 | Classification loss: 0.00006 | Regression loss: 0.01384 | Running loss: 0.03491\n",
            "Epoch: 9 | Iteration: 1963 | Classification loss: 0.00007 | Regression loss: 0.01291 | Running loss: 0.03488\n",
            "Epoch: 9 | Iteration: 1964 | Classification loss: 0.00003 | Regression loss: 0.01332 | Running loss: 0.03464\n",
            "Epoch: 9 | Iteration: 1965 | Classification loss: 0.00015 | Regression loss: 0.02722 | Running loss: 0.03464\n",
            "Epoch: 9 | Iteration: 1966 | Classification loss: 0.00015 | Regression loss: 0.02282 | Running loss: 0.03465\n",
            "Epoch: 9 | Iteration: 1967 | Classification loss: 0.00026 | Regression loss: 0.01672 | Running loss: 0.03462\n",
            "Epoch: 9 | Iteration: 1968 | Classification loss: 0.00009 | Regression loss: 0.03109 | Running loss: 0.03459\n",
            "Epoch: 9 | Iteration: 1969 | Classification loss: 0.00168 | Regression loss: 0.06491 | Running loss: 0.03467\n",
            "Epoch: 9 | Iteration: 1970 | Classification loss: 0.00044 | Regression loss: 0.02225 | Running loss: 0.03462\n",
            "Epoch: 9 | Iteration: 1971 | Classification loss: 0.00002 | Regression loss: 0.03445 | Running loss: 0.03466\n",
            "Epoch: 9 | Iteration: 1972 | Classification loss: 0.00014 | Regression loss: 0.03065 | Running loss: 0.03468\n",
            "Epoch: 9 | Iteration: 1973 | Classification loss: 0.00018 | Regression loss: 0.02132 | Running loss: 0.03468\n",
            "Epoch: 9 | Iteration: 1974 | Classification loss: 0.00005 | Regression loss: 0.03127 | Running loss: 0.03470\n",
            "Epoch: 9 | Iteration: 1975 | Classification loss: 0.00003 | Regression loss: 0.03752 | Running loss: 0.03473\n",
            "Epoch: 9 | Iteration: 1976 | Classification loss: 0.00061 | Regression loss: 0.04160 | Running loss: 0.03479\n",
            "Epoch: 9 | Iteration: 1977 | Classification loss: 0.00220 | Regression loss: 0.06968 | Running loss: 0.03476\n",
            "Epoch: 9 | Iteration: 1978 | Classification loss: 0.00005 | Regression loss: 0.01465 | Running loss: 0.03475\n",
            "Epoch: 9 | Iteration: 1979 | Classification loss: 0.00003 | Regression loss: 0.01724 | Running loss: 0.03473\n",
            "Epoch: 9 | Iteration: 1980 | Classification loss: 0.00002 | Regression loss: 0.01265 | Running loss: 0.03344\n",
            "Epoch: 9 | Iteration: 1981 | Classification loss: 0.00141 | Regression loss: 0.02008 | Running loss: 0.03343\n",
            "Epoch: 9 | Iteration: 1982 | Classification loss: 0.00007 | Regression loss: 0.02985 | Running loss: 0.03344\n",
            "Epoch: 9 | Iteration: 1983 | Classification loss: 0.00003 | Regression loss: 0.02862 | Running loss: 0.03336\n",
            "Epoch: 9 | Iteration: 1984 | Classification loss: 0.00010 | Regression loss: 0.03345 | Running loss: 0.03338\n",
            "Epoch: 9 | Iteration: 1985 | Classification loss: 0.00113 | Regression loss: 0.06551 | Running loss: 0.03349\n",
            "Epoch: 9 | Iteration: 1986 | Classification loss: 0.00003 | Regression loss: 0.01600 | Running loss: 0.03336\n",
            "Epoch: 9 | Iteration: 1987 | Classification loss: 0.00038 | Regression loss: 0.05483 | Running loss: 0.03345\n",
            "Epoch: 9 | Iteration: 1988 | Classification loss: 0.00001 | Regression loss: 0.01103 | Running loss: 0.03342\n",
            "Epoch: 9 | Iteration: 1989 | Classification loss: 0.00349 | Regression loss: 0.05979 | Running loss: 0.03349\n",
            "Epoch: 9 | Iteration: 1990 | Classification loss: 0.00006 | Regression loss: 0.02905 | Running loss: 0.03351\n",
            "Epoch: 9 | Iteration: 1991 | Classification loss: 0.00002 | Regression loss: 0.02385 | Running loss: 0.03351\n",
            "Epoch: 9 | Iteration: 1992 | Classification loss: 0.00151 | Regression loss: 0.03280 | Running loss: 0.03354\n",
            "Epoch: 9 | Iteration: 1993 | Classification loss: 0.00002 | Regression loss: 0.01782 | Running loss: 0.03354\n",
            "Epoch: 9 | Iteration: 1994 | Classification loss: 0.00003 | Regression loss: 0.02316 | Running loss: 0.03355\n",
            "Epoch: 9 | Iteration: 1995 | Classification loss: 0.00156 | Regression loss: 0.02904 | Running loss: 0.03356\n",
            "Epoch: 9 | Iteration: 1996 | Classification loss: 0.00022 | Regression loss: 0.03475 | Running loss: 0.03360\n",
            "Epoch: 9 | Iteration: 1997 | Classification loss: 0.00016 | Regression loss: 0.01541 | Running loss: 0.03354\n",
            "Epoch: 9 | Iteration: 1998 | Classification loss: 0.00000 | Regression loss: 0.02100 | Running loss: 0.03354\n",
            "Epoch: 9 | Iteration: 1999 | Classification loss: 0.00272 | Regression loss: 0.06006 | Running loss: 0.03363\n",
            "Epoch: 9 | Iteration: 2000 | Classification loss: 0.00011 | Regression loss: 0.03447 | Running loss: 0.03366\n",
            "Epoch: 9 | Iteration: 2001 | Classification loss: 0.00004 | Regression loss: 0.02947 | Running loss: 0.03369\n",
            "Epoch: 9 | Iteration: 2002 | Classification loss: 0.00019 | Regression loss: 0.02101 | Running loss: 0.03370\n",
            "Epoch: 9 | Iteration: 2003 | Classification loss: 0.00001 | Regression loss: 0.03288 | Running loss: 0.03361\n",
            "Epoch: 9 | Iteration: 2004 | Classification loss: 0.00005 | Regression loss: 0.01831 | Running loss: 0.03361\n",
            "Epoch: 9 | Iteration: 2005 | Classification loss: 0.00018 | Regression loss: 0.08504 | Running loss: 0.03373\n",
            "Epoch: 9 | Iteration: 2006 | Classification loss: 0.00004 | Regression loss: 0.01803 | Running loss: 0.03362\n",
            "Epoch: 9 | Iteration: 2007 | Classification loss: 0.00007 | Regression loss: 0.05173 | Running loss: 0.03366\n",
            "Epoch: 9 | Iteration: 2008 | Classification loss: 0.00005 | Regression loss: 0.02449 | Running loss: 0.03366\n",
            "Epoch: 9 | Iteration: 2009 | Classification loss: 0.00150 | Regression loss: 0.04134 | Running loss: 0.03364\n",
            "Epoch: 9 | Iteration: 2010 | Classification loss: 0.00002 | Regression loss: 0.02319 | Running loss: 0.03362\n",
            "Epoch: 9 | Iteration: 2011 | Classification loss: 0.00025 | Regression loss: 0.03141 | Running loss: 0.03364\n",
            "Epoch: 9 | Iteration: 2012 | Classification loss: 0.00013 | Regression loss: 0.02155 | Running loss: 0.03341\n",
            "Epoch: 9 | Iteration: 2013 | Classification loss: 0.00002 | Regression loss: 0.02516 | Running loss: 0.03303\n",
            "Epoch: 9 | Iteration: 2014 | Classification loss: 0.00075 | Regression loss: 0.01560 | Running loss: 0.03303\n",
            "Epoch: 9 | Iteration: 2015 | Classification loss: 0.15215 | Regression loss: 0.25034 | Running loss: 0.03377\n",
            "Epoch: 9 | Iteration: 2016 | Classification loss: 0.00017 | Regression loss: 0.01179 | Running loss: 0.03377\n",
            "Epoch: 9 | Iteration: 2017 | Classification loss: 0.00001 | Regression loss: 0.02187 | Running loss: 0.03378\n",
            "Epoch: 9 | Iteration: 2018 | Classification loss: 0.00004 | Regression loss: 0.01085 | Running loss: 0.03374\n",
            "Epoch: 9 | Iteration: 2019 | Classification loss: 0.00002 | Regression loss: 0.01006 | Running loss: 0.03372\n",
            "Epoch: 9 | Iteration: 2020 | Classification loss: 0.01008 | Regression loss: 0.05394 | Running loss: 0.03381\n",
            "Epoch: 9 | Iteration: 2021 | Classification loss: 0.00009 | Regression loss: 0.02819 | Running loss: 0.03381\n",
            "Epoch: 9 | Iteration: 2022 | Classification loss: 0.00009 | Regression loss: 0.01638 | Running loss: 0.03378\n",
            "Epoch: 9 | Iteration: 2023 | Classification loss: 0.00807 | Regression loss: 0.04468 | Running loss: 0.03386\n",
            "Epoch: 9 | Iteration: 2024 | Classification loss: 0.00007 | Regression loss: 0.03458 | Running loss: 0.03389\n",
            "Epoch: 9 | Iteration: 2025 | Classification loss: 0.00025 | Regression loss: 0.02730 | Running loss: 0.03390\n",
            "Epoch: 9 | Iteration: 2026 | Classification loss: 0.00009 | Regression loss: 0.01872 | Running loss: 0.03391\n",
            "Epoch: 9 | Iteration: 2027 | Classification loss: 0.00008 | Regression loss: 0.02697 | Running loss: 0.03392\n",
            "Epoch: 9 | Iteration: 2028 | Classification loss: 0.00025 | Regression loss: 0.02687 | Running loss: 0.03395\n",
            "Epoch: 9 | Iteration: 2029 | Classification loss: 0.00032 | Regression loss: 0.02550 | Running loss: 0.03397\n",
            "Epoch: 9 | Iteration: 2030 | Classification loss: 0.00010 | Regression loss: 0.01514 | Running loss: 0.03397\n",
            "Epoch: 9 | Iteration: 2031 | Classification loss: 0.00003 | Regression loss: 0.01724 | Running loss: 0.03395\n",
            "Epoch: 9 | Iteration: 2032 | Classification loss: 0.00006 | Regression loss: 0.02086 | Running loss: 0.03395\n",
            "Epoch: 9 | Iteration: 2033 | Classification loss: 0.02451 | Regression loss: 0.10001 | Running loss: 0.03415\n",
            "Epoch: 9 | Iteration: 2034 | Classification loss: 0.00004 | Regression loss: 0.02180 | Running loss: 0.03413\n",
            "Epoch: 9 | Iteration: 2035 | Classification loss: 0.00099 | Regression loss: 0.02583 | Running loss: 0.03416\n",
            "Epoch: 9 | Iteration: 2036 | Classification loss: 0.00012 | Regression loss: 0.01519 | Running loss: 0.03415\n",
            "Epoch: 9 | Iteration: 2037 | Classification loss: 0.00014 | Regression loss: 0.01148 | Running loss: 0.03410\n",
            "Epoch: 9 | Iteration: 2038 | Classification loss: 0.01885 | Regression loss: 0.01888 | Running loss: 0.03416\n",
            "Epoch: 9 | Iteration: 2039 | Classification loss: 0.00003 | Regression loss: 0.01876 | Running loss: 0.03410\n",
            "Epoch: 9 | Iteration: 2040 | Classification loss: 0.00034 | Regression loss: 0.03642 | Running loss: 0.03414\n",
            "Epoch: 9 | Iteration: 2041 | Classification loss: 0.00066 | Regression loss: 0.02878 | Running loss: 0.03416\n",
            "Epoch: 9 | Iteration: 2042 | Classification loss: 0.00025 | Regression loss: 0.02885 | Running loss: 0.03414\n",
            "Epoch: 9 | Iteration: 2043 | Classification loss: 0.00041 | Regression loss: 0.01130 | Running loss: 0.03402\n",
            "Epoch: 9 | Iteration: 2044 | Classification loss: 0.00103 | Regression loss: 0.06378 | Running loss: 0.03408\n",
            "Epoch: 9 | Iteration: 2045 | Classification loss: 0.00006 | Regression loss: 0.01305 | Running loss: 0.03407\n",
            "Epoch: 9 | Iteration: 2046 | Classification loss: 0.02362 | Regression loss: 0.05267 | Running loss: 0.03419\n",
            "Epoch: 9 | Iteration: 2047 | Classification loss: 0.00003 | Regression loss: 0.03073 | Running loss: 0.03420\n",
            "Epoch: 9 | Iteration: 2048 | Classification loss: 0.00003 | Regression loss: 0.01503 | Running loss: 0.03419\n",
            "Epoch: 9 | Iteration: 2049 | Classification loss: 0.00003 | Regression loss: 0.01240 | Running loss: 0.03418\n",
            "Epoch: 9 | Iteration: 2050 | Classification loss: 0.00004 | Regression loss: 0.02310 | Running loss: 0.03418\n",
            "Epoch: 9 | Iteration: 2051 | Classification loss: 0.00116 | Regression loss: 0.06031 | Running loss: 0.03413\n",
            "Epoch: 9 | Iteration: 2052 | Classification loss: 0.00012 | Regression loss: 0.02342 | Running loss: 0.03414\n",
            "Epoch: 9 | Iteration: 2053 | Classification loss: 0.00028 | Regression loss: 0.02009 | Running loss: 0.03412\n",
            "Epoch: 9 | Iteration: 2054 | Classification loss: 0.00020 | Regression loss: 0.02825 | Running loss: 0.03408\n",
            "Epoch: 9 | Iteration: 2055 | Classification loss: 0.00017 | Regression loss: 0.01960 | Running loss: 0.03407\n",
            "Epoch: 9 | Iteration: 2056 | Classification loss: 0.00004 | Regression loss: 0.02893 | Running loss: 0.03401\n",
            "Epoch: 9 | Iteration: 2057 | Classification loss: 0.00006 | Regression loss: 0.02687 | Running loss: 0.03403\n",
            "Epoch: 9 | Iteration: 2058 | Classification loss: 0.00102 | Regression loss: 0.02668 | Running loss: 0.03405\n",
            "Epoch: 9 | Iteration: 2059 | Classification loss: 0.00018 | Regression loss: 0.02339 | Running loss: 0.03401\n",
            "Epoch: 9 | Iteration: 2060 | Classification loss: 0.00017 | Regression loss: 0.03431 | Running loss: 0.03405\n",
            "Epoch: 9 | Iteration: 2061 | Classification loss: 0.00017 | Regression loss: 0.01397 | Running loss: 0.03397\n",
            "Epoch: 9 | Iteration: 2062 | Classification loss: 0.00011 | Regression loss: 0.01205 | Running loss: 0.03394\n",
            "Epoch: 9 | Iteration: 2063 | Classification loss: 0.00011 | Regression loss: 0.02330 | Running loss: 0.03391\n",
            "Epoch: 9 | Iteration: 2064 | Classification loss: 0.00204 | Regression loss: 0.01432 | Running loss: 0.03382\n",
            "Epoch: 9 | Iteration: 2065 | Classification loss: 0.00061 | Regression loss: 0.00852 | Running loss: 0.03380\n",
            "Epoch: 9 | Iteration: 2066 | Classification loss: 0.00014 | Regression loss: 0.01961 | Running loss: 0.03375\n",
            "Epoch: 9 | Iteration: 2067 | Classification loss: 0.00137 | Regression loss: 0.03518 | Running loss: 0.03379\n",
            "Epoch: 9 | Iteration: 2068 | Classification loss: 0.00042 | Regression loss: 0.01396 | Running loss: 0.03378\n",
            "Epoch: 9 | Iteration: 2069 | Classification loss: 0.00004 | Regression loss: 0.01321 | Running loss: 0.03377\n",
            "Epoch: 9 | Iteration: 2070 | Classification loss: 0.00008 | Regression loss: 0.02021 | Running loss: 0.03374\n",
            "Epoch: 9 | Iteration: 2071 | Classification loss: 0.00026 | Regression loss: 0.02383 | Running loss: 0.03368\n",
            "Epoch: 9 | Iteration: 2072 | Classification loss: 0.00007 | Regression loss: 0.01728 | Running loss: 0.03364\n",
            "Epoch: 9 | Iteration: 2073 | Classification loss: 0.00007 | Regression loss: 0.01871 | Running loss: 0.03361\n",
            "Epoch: 9 | Iteration: 2074 | Classification loss: 0.00004 | Regression loss: 0.02237 | Running loss: 0.03359\n",
            "Epoch: 9 | Iteration: 2075 | Classification loss: 0.00003 | Regression loss: 0.02024 | Running loss: 0.03361\n",
            "Epoch: 9 | Iteration: 2076 | Classification loss: 0.00019 | Regression loss: 0.01785 | Running loss: 0.03359\n",
            "Epoch: 9 | Iteration: 2077 | Classification loss: 0.00012 | Regression loss: 0.01855 | Running loss: 0.03358\n",
            "Epoch: 9 | Iteration: 2078 | Classification loss: 0.00034 | Regression loss: 0.03289 | Running loss: 0.03359\n",
            "Epoch: 9 | Iteration: 2079 | Classification loss: 0.00004 | Regression loss: 0.01085 | Running loss: 0.03345\n",
            "Epoch: 9 | Iteration: 2080 | Classification loss: 0.00292 | Regression loss: 0.06170 | Running loss: 0.03355\n",
            "Epoch: 9 | Iteration: 2081 | Classification loss: 0.00015 | Regression loss: 0.02293 | Running loss: 0.03357\n",
            "Epoch: 9 | Iteration: 2082 | Classification loss: 0.00065 | Regression loss: 0.02495 | Running loss: 0.03361\n",
            "Epoch: 9 | Iteration: 2083 | Classification loss: 0.00004 | Regression loss: 0.01908 | Running loss: 0.03362\n",
            "Epoch: 9 | Iteration: 2084 | Classification loss: 0.00011 | Regression loss: 0.04791 | Running loss: 0.03368\n",
            "Epoch: 9 | Iteration: 2085 | Classification loss: 0.00366 | Regression loss: 0.03947 | Running loss: 0.03373\n",
            "Epoch: 9 | Iteration: 2086 | Classification loss: 0.00025 | Regression loss: 0.05301 | Running loss: 0.03382\n",
            "Epoch: 9 | Iteration: 2087 | Classification loss: 0.00021 | Regression loss: 0.03209 | Running loss: 0.03381\n",
            "Epoch: 9 | Iteration: 2088 | Classification loss: 0.00014 | Regression loss: 0.04897 | Running loss: 0.03385\n",
            "Epoch: 9 | Iteration: 2089 | Classification loss: 0.00031 | Regression loss: 0.04743 | Running loss: 0.03390\n",
            "Epoch: 9 | Iteration: 2090 | Classification loss: 0.00081 | Regression loss: 0.02869 | Running loss: 0.03392\n",
            "Epoch: 9 | Iteration: 2091 | Classification loss: 0.00007 | Regression loss: 0.02275 | Running loss: 0.03393\n",
            "Epoch: 9 | Iteration: 2092 | Classification loss: 0.00033 | Regression loss: 0.02966 | Running loss: 0.03395\n",
            "Epoch: 9 | Iteration: 2093 | Classification loss: 0.00005 | Regression loss: 0.01740 | Running loss: 0.03395\n",
            "Epoch: 9 | Iteration: 2094 | Classification loss: 0.00053 | Regression loss: 0.05763 | Running loss: 0.03401\n",
            "Epoch: 9 | Iteration: 2095 | Classification loss: 0.00038 | Regression loss: 0.05265 | Running loss: 0.03409\n",
            "Epoch: 9 | Iteration: 2096 | Classification loss: 0.00003 | Regression loss: 0.01925 | Running loss: 0.03408\n",
            "Epoch: 9 | Iteration: 2097 | Classification loss: 0.00017 | Regression loss: 0.01760 | Running loss: 0.03405\n",
            "Epoch: 9 | Iteration: 2098 | Classification loss: 0.00013 | Regression loss: 0.01158 | Running loss: 0.03402\n",
            "Epoch: 9 | Iteration: 2099 | Classification loss: 0.00005 | Regression loss: 0.03088 | Running loss: 0.03392\n",
            "Epoch: 9 | Iteration: 2100 | Classification loss: 0.00022 | Regression loss: 0.02233 | Running loss: 0.03393\n",
            "Epoch: 9 | Iteration: 2101 | Classification loss: 0.00013 | Regression loss: 0.00640 | Running loss: 0.03391\n",
            "Epoch: 9 | Iteration: 2102 | Classification loss: 0.00023 | Regression loss: 0.03520 | Running loss: 0.03392\n",
            "Epoch: 9 | Iteration: 2103 | Classification loss: 0.00009 | Regression loss: 0.00912 | Running loss: 0.03388\n",
            "Epoch: 9 | Iteration: 2104 | Classification loss: 0.00018 | Regression loss: 0.00955 | Running loss: 0.03378\n",
            "Epoch: 9 | Iteration: 2105 | Classification loss: 0.00023 | Regression loss: 0.02605 | Running loss: 0.03378\n",
            "Epoch: 9 | Iteration: 2106 | Classification loss: 0.00006 | Regression loss: 0.02087 | Running loss: 0.03376\n",
            "Epoch: 9 | Iteration: 2107 | Classification loss: 0.00046 | Regression loss: 0.04439 | Running loss: 0.03379\n",
            "Epoch: 9 | Iteration: 2108 | Classification loss: 0.00013 | Regression loss: 0.02842 | Running loss: 0.03382\n",
            "Epoch: 9 | Iteration: 2109 | Classification loss: 0.00020 | Regression loss: 0.01192 | Running loss: 0.03345\n",
            "Epoch: 9 | Iteration: 2110 | Classification loss: 0.00005 | Regression loss: 0.00752 | Running loss: 0.03341\n",
            "Epoch: 9 | Iteration: 2111 | Classification loss: 0.00757 | Regression loss: 0.03982 | Running loss: 0.03343\n",
            "Epoch: 9 | Iteration: 2112 | Classification loss: 0.00508 | Regression loss: 0.05351 | Running loss: 0.03350\n",
            "Epoch: 9 | Iteration: 2113 | Classification loss: 0.00034 | Regression loss: 0.04746 | Running loss: 0.03354\n",
            "Epoch: 9 | Iteration: 2114 | Classification loss: 0.00020 | Regression loss: 0.01823 | Running loss: 0.03355\n",
            "Epoch: 9 | Iteration: 2115 | Classification loss: 0.00038 | Regression loss: 0.02476 | Running loss: 0.03357\n",
            "Epoch: 9 | Iteration: 2116 | Classification loss: 0.00002 | Regression loss: 0.02140 | Running loss: 0.03356\n",
            "Epoch: 9 | Iteration: 2117 | Classification loss: 0.00007 | Regression loss: 0.03078 | Running loss: 0.03360\n",
            "Epoch: 9 | Iteration: 2118 | Classification loss: 0.00015 | Regression loss: 0.01932 | Running loss: 0.03359\n",
            "Epoch: 9 | Iteration: 2119 | Classification loss: 0.00019 | Regression loss: 0.01704 | Running loss: 0.03356\n",
            "Epoch: 9 | Iteration: 2120 | Classification loss: 0.00017 | Regression loss: 0.01352 | Running loss: 0.03352\n",
            "Epoch: 9 | Iteration: 2121 | Classification loss: 0.00620 | Regression loss: 0.04282 | Running loss: 0.03359\n",
            "Epoch: 9 | Iteration: 2122 | Classification loss: 0.00004 | Regression loss: 0.01650 | Running loss: 0.03358\n",
            "Epoch: 9 | Iteration: 2123 | Classification loss: 0.00110 | Regression loss: 0.05390 | Running loss: 0.03354\n",
            "Epoch: 9 | Iteration: 2124 | Classification loss: 0.00005 | Regression loss: 0.02772 | Running loss: 0.03357\n",
            "Epoch: 9 | Iteration: 2125 | Classification loss: 0.00002 | Regression loss: 0.01424 | Running loss: 0.03352\n",
            "Epoch: 9 | Iteration: 2126 | Classification loss: 0.00002 | Regression loss: 0.01718 | Running loss: 0.03350\n",
            "Epoch: 9 | Iteration: 2127 | Classification loss: 0.00005 | Regression loss: 0.04953 | Running loss: 0.03356\n",
            "Epoch: 9 | Iteration: 2128 | Classification loss: 0.00006 | Regression loss: 0.01114 | Running loss: 0.03346\n",
            "Epoch: 9 | Iteration: 2129 | Classification loss: 0.00002 | Regression loss: 0.02324 | Running loss: 0.03340\n",
            "Epoch: 9 | Iteration: 2130 | Classification loss: 0.00008 | Regression loss: 0.02987 | Running loss: 0.03343\n",
            "Epoch: 9 | Iteration: 2131 | Classification loss: 0.00019 | Regression loss: 0.01141 | Running loss: 0.03343\n",
            "Epoch: 9 | Iteration: 2132 | Classification loss: 0.00034 | Regression loss: 0.01614 | Running loss: 0.03319\n",
            "Epoch: 9 | Iteration: 2133 | Classification loss: 0.00264 | Regression loss: 0.03708 | Running loss: 0.03323\n",
            "Epoch: 9 | Iteration: 2134 | Classification loss: 0.00021 | Regression loss: 0.02198 | Running loss: 0.03314\n",
            "Epoch: 9 | Iteration: 2135 | Classification loss: 0.00037 | Regression loss: 0.01438 | Running loss: 0.03310\n",
            "Epoch: 9 | Iteration: 2136 | Classification loss: 0.00002 | Regression loss: 0.01510 | Running loss: 0.03298\n",
            "Epoch: 9 | Iteration: 2137 | Classification loss: 0.00046 | Regression loss: 0.02814 | Running loss: 0.03298\n",
            "Epoch: 9 | Iteration: 2138 | Classification loss: 0.00048 | Regression loss: 0.02094 | Running loss: 0.03295\n",
            "Epoch: 9 | Iteration: 2139 | Classification loss: 0.00001 | Regression loss: 0.01465 | Running loss: 0.03224\n",
            "Epoch: 9 | Iteration: 2140 | Classification loss: 0.00004 | Regression loss: 0.02328 | Running loss: 0.03222\n",
            "Epoch: 9 | Iteration: 2141 | Classification loss: 0.00511 | Regression loss: 0.07546 | Running loss: 0.03223\n",
            "Epoch: 9 | Iteration: 2142 | Classification loss: 0.00003 | Regression loss: 0.02320 | Running loss: 0.03226\n",
            "Epoch: 9 | Iteration: 2143 | Classification loss: 0.00001 | Regression loss: 0.00886 | Running loss: 0.03220\n",
            "Epoch: 9 | Iteration: 2144 | Classification loss: 0.00045 | Regression loss: 0.05827 | Running loss: 0.03228\n",
            "Epoch: 9 | Iteration: 2145 | Classification loss: 0.00012 | Regression loss: 0.03203 | Running loss: 0.03224\n",
            "Epoch: 9 | Iteration: 2146 | Classification loss: 0.00005 | Regression loss: 0.01869 | Running loss: 0.03216\n",
            "Epoch: 9 | Iteration: 2147 | Classification loss: 0.00001 | Regression loss: 0.01013 | Running loss: 0.03211\n",
            "Epoch: 9 | Iteration: 2148 | Classification loss: 0.00001 | Regression loss: 0.00983 | Running loss: 0.03207\n",
            "Epoch: 9 | Iteration: 2149 | Classification loss: 0.00001 | Regression loss: 0.02437 | Running loss: 0.03206\n",
            "Epoch: 9 | Iteration: 2150 | Classification loss: 0.00003 | Regression loss: 0.02641 | Running loss: 0.03207\n",
            "Epoch: 9 | Iteration: 2151 | Classification loss: 0.00055 | Regression loss: 0.03925 | Running loss: 0.03210\n",
            "Epoch: 9 | Iteration: 2152 | Classification loss: 0.00007 | Regression loss: 0.01507 | Running loss: 0.03207\n",
            "Epoch: 9 | Iteration: 2153 | Classification loss: 0.00202 | Regression loss: 0.03044 | Running loss: 0.03207\n",
            "Epoch: 9 | Iteration: 2154 | Classification loss: 0.00005 | Regression loss: 0.01138 | Running loss: 0.03195\n",
            "Epoch: 9 | Iteration: 2155 | Classification loss: 0.00032 | Regression loss: 0.00842 | Running loss: 0.03192\n",
            "Epoch: 9 | Iteration: 2156 | Classification loss: 0.00004 | Regression loss: 0.01370 | Running loss: 0.03181\n",
            "Epoch: 9 | Iteration: 2157 | Classification loss: 0.00008 | Regression loss: 0.01100 | Running loss: 0.03180\n",
            "Epoch: 9 | Iteration: 2158 | Classification loss: 0.00008 | Regression loss: 0.01334 | Running loss: 0.03176\n",
            "Epoch: 9 | Iteration: 2159 | Classification loss: 0.00002 | Regression loss: 0.02163 | Running loss: 0.03175\n",
            "Epoch: 9 | Iteration: 2160 | Classification loss: 0.00222 | Regression loss: 0.03973 | Running loss: 0.03176\n",
            "Epoch: 9 | Iteration: 2161 | Classification loss: 0.00001 | Regression loss: 0.00784 | Running loss: 0.03167\n",
            "Epoch: 9 | Iteration: 2162 | Classification loss: 0.00002 | Regression loss: 0.01088 | Running loss: 0.03160\n",
            "Epoch: 9 | Iteration: 2163 | Classification loss: 0.00046 | Regression loss: 0.04072 | Running loss: 0.03162\n",
            "Epoch: 9 | Iteration: 2164 | Classification loss: 0.00042 | Regression loss: 0.08508 | Running loss: 0.03174\n",
            "Epoch: 9 | Iteration: 2165 | Classification loss: 0.35397 | Regression loss: 0.22617 | Running loss: 0.03287\n",
            "Epoch: 9 | Iteration: 2166 | Classification loss: 0.00003 | Regression loss: 0.03007 | Running loss: 0.03290\n",
            "Epoch: 9 | Iteration: 2167 | Classification loss: 0.00015 | Regression loss: 0.02155 | Running loss: 0.03282\n",
            "Epoch: 9 | Iteration: 2168 | Classification loss: 0.00004 | Regression loss: 0.03252 | Running loss: 0.03286\n",
            "Epoch: 9 | Iteration: 2169 | Classification loss: 0.00007 | Regression loss: 0.04053 | Running loss: 0.03292\n",
            "Epoch: 9 | Iteration: 2170 | Classification loss: 0.00003 | Regression loss: 0.02774 | Running loss: 0.03292\n",
            "Epoch: 9 | Iteration: 2171 | Classification loss: 0.00007 | Regression loss: 0.01912 | Running loss: 0.03288\n",
            "Epoch: 9 | Iteration: 2172 | Classification loss: 0.00003 | Regression loss: 0.06493 | Running loss: 0.03298\n",
            "Epoch: 9 | Iteration: 2173 | Classification loss: 0.00006 | Regression loss: 0.02577 | Running loss: 0.03298\n",
            "Epoch: 9 | Iteration: 2174 | Classification loss: 0.00004 | Regression loss: 0.01237 | Running loss: 0.03286\n",
            "Epoch: 9 | Iteration: 2175 | Classification loss: 0.00019 | Regression loss: 0.03379 | Running loss: 0.03288\n",
            "Epoch: 9 | Iteration: 2176 | Classification loss: 0.00923 | Regression loss: 0.05081 | Running loss: 0.03293\n",
            "Epoch: 9 | Iteration: 2177 | Classification loss: 0.00016 | Regression loss: 0.02539 | Running loss: 0.03294\n",
            "Epoch: 9 | Iteration: 2178 | Classification loss: 0.00010 | Regression loss: 0.02239 | Running loss: 0.03294\n",
            "Epoch: 9 | Iteration: 2179 | Classification loss: 0.00011 | Regression loss: 0.03935 | Running loss: 0.03300\n",
            "Epoch: 9 | Iteration: 2180 | Classification loss: 0.00282 | Regression loss: 0.03278 | Running loss: 0.03305\n",
            "Epoch: 9 | Iteration: 2181 | Classification loss: 0.00182 | Regression loss: 0.08064 | Running loss: 0.03311\n",
            "Epoch: 9 | Iteration: 2182 | Classification loss: 0.00005 | Regression loss: 0.03104 | Running loss: 0.03311\n",
            "Epoch: 9 | Iteration: 2183 | Classification loss: 0.05594 | Regression loss: 0.09176 | Running loss: 0.03336\n",
            "Epoch: 9 | Iteration: 2184 | Classification loss: 0.00073 | Regression loss: 0.03247 | Running loss: 0.03330\n",
            "Epoch: 9 | Iteration: 2185 | Classification loss: 0.00026 | Regression loss: 0.02408 | Running loss: 0.03331\n",
            "Epoch: 9 | Iteration: 2186 | Classification loss: 0.00061 | Regression loss: 0.03646 | Running loss: 0.03332\n",
            "Epoch: 9 | Iteration: 2187 | Classification loss: 0.00003 | Regression loss: 0.02831 | Running loss: 0.03330\n",
            "Epoch: 9 | Iteration: 2188 | Classification loss: 0.00083 | Regression loss: 0.03175 | Running loss: 0.03331\n",
            "Epoch: 9 | Iteration: 2189 | Classification loss: 0.00015 | Regression loss: 0.03648 | Running loss: 0.03334\n",
            "Epoch: 9 | Iteration: 2190 | Classification loss: 0.00032 | Regression loss: 0.03200 | Running loss: 0.03335\n",
            "Epoch: 9 | Iteration: 2191 | Classification loss: 0.00008 | Regression loss: 0.02603 | Running loss: 0.03337\n",
            "Epoch: 9 | Iteration: 2192 | Classification loss: 0.00005 | Regression loss: 0.01023 | Running loss: 0.03334\n",
            "Epoch: 9 | Iteration: 2193 | Classification loss: 0.00003 | Regression loss: 0.02284 | Running loss: 0.03336\n",
            "Epoch: 9 | Iteration: 2194 | Classification loss: 0.00023 | Regression loss: 0.03581 | Running loss: 0.03333\n",
            "Epoch: 9 | Iteration: 2195 | Classification loss: 0.00119 | Regression loss: 0.02332 | Running loss: 0.03335\n",
            "Epoch: 9 | Iteration: 2196 | Classification loss: 0.00008 | Regression loss: 0.01872 | Running loss: 0.03336\n",
            "Epoch: 9 | Iteration: 2197 | Classification loss: 0.00021 | Regression loss: 0.03384 | Running loss: 0.03341\n",
            "Epoch: 9 | Iteration: 2198 | Classification loss: 0.00041 | Regression loss: 0.01787 | Running loss: 0.03341\n",
            "Epoch: 9 | Iteration: 2199 | Classification loss: 0.00019 | Regression loss: 0.02981 | Running loss: 0.03339\n",
            "Epoch: 9 | Iteration: 2200 | Classification loss: 0.00003 | Regression loss: 0.01488 | Running loss: 0.03336\n",
            "Epoch: 9 | Iteration: 2201 | Classification loss: 0.00400 | Regression loss: 0.06757 | Running loss: 0.03345\n",
            "Epoch: 9 | Iteration: 2202 | Classification loss: 0.00009 | Regression loss: 0.00829 | Running loss: 0.03344\n",
            "Epoch: 9 | Iteration: 2203 | Classification loss: 0.00008 | Regression loss: 0.03128 | Running loss: 0.03347\n",
            "Epoch: 9 | Iteration: 2204 | Classification loss: 0.00004 | Regression loss: 0.02515 | Running loss: 0.03335\n",
            "Epoch: 9 | Iteration: 2205 | Classification loss: 0.01793 | Regression loss: 0.04145 | Running loss: 0.03341\n",
            "Epoch: 9 | Iteration: 2206 | Classification loss: 0.22141 | Regression loss: 0.31013 | Running loss: 0.03441\n",
            "Epoch: 9 | Iteration: 2207 | Classification loss: 0.00005 | Regression loss: 0.02794 | Running loss: 0.03439\n",
            "Epoch: 9 | Iteration: 2208 | Classification loss: 0.00003 | Regression loss: 0.01503 | Running loss: 0.03439\n",
            "Epoch: 9 | Iteration: 2209 | Classification loss: 0.00009 | Regression loss: 0.01438 | Running loss: 0.03431\n",
            "Epoch: 9 | Iteration: 2210 | Classification loss: 0.00015 | Regression loss: 0.02331 | Running loss: 0.03427\n",
            "Epoch: 9 | Iteration: 2211 | Classification loss: 0.00057 | Regression loss: 0.01897 | Running loss: 0.03425\n",
            "Epoch: 9 | Iteration: 2212 | Classification loss: 0.00034 | Regression loss: 0.02492 | Running loss: 0.03424\n",
            "Epoch: 9 | Iteration: 2213 | Classification loss: 0.00044 | Regression loss: 0.02184 | Running loss: 0.03422\n",
            "Epoch: 9 | Iteration: 2214 | Classification loss: 0.00716 | Regression loss: 0.02595 | Running loss: 0.03423\n",
            "Epoch: 9 | Iteration: 2215 | Classification loss: 0.00008 | Regression loss: 0.05206 | Running loss: 0.03426\n",
            "Epoch: 9 | Iteration: 2216 | Classification loss: 0.00024 | Regression loss: 0.03750 | Running loss: 0.03416\n",
            "Epoch: 9 | Iteration: 2217 | Classification loss: 0.00016 | Regression loss: 0.02656 | Running loss: 0.03407\n",
            "Epoch: 9 | Iteration: 2218 | Classification loss: 0.00057 | Regression loss: 0.02321 | Running loss: 0.03408\n",
            "Epoch: 9 | Iteration: 2219 | Classification loss: 0.00136 | Regression loss: 0.01998 | Running loss: 0.03404\n",
            "Epoch: 9 | Iteration: 2220 | Classification loss: 0.00145 | Regression loss: 0.01361 | Running loss: 0.03401\n",
            "Epoch: 9 | Iteration: 2221 | Classification loss: 0.00007 | Regression loss: 0.00923 | Running loss: 0.03401\n",
            "Epoch: 9 | Iteration: 2222 | Classification loss: 0.00049 | Regression loss: 0.01672 | Running loss: 0.03402\n",
            "Epoch: 9 | Iteration: 2223 | Classification loss: 0.00083 | Regression loss: 0.08612 | Running loss: 0.03345\n",
            "Epoch: 9 | Iteration: 2224 | Classification loss: 0.00038 | Regression loss: 0.02818 | Running loss: 0.03343\n",
            "Epoch: 9 | Iteration: 2225 | Classification loss: 0.00190 | Regression loss: 0.05232 | Running loss: 0.03348\n",
            "Epoch: 9 | Iteration: 2226 | Classification loss: 0.00025 | Regression loss: 0.01795 | Running loss: 0.03344\n",
            "Epoch: 9 | Iteration: 2227 | Classification loss: 0.00036 | Regression loss: 0.01654 | Running loss: 0.03344\n",
            "Epoch: 9 | Iteration: 2228 | Classification loss: 0.00066 | Regression loss: 0.01906 | Running loss: 0.03330\n",
            "Epoch: 9 | Iteration: 2229 | Classification loss: 0.01030 | Regression loss: 0.07412 | Running loss: 0.03344\n",
            "Epoch: 9 | Iteration: 2230 | Classification loss: 0.00033 | Regression loss: 0.06841 | Running loss: 0.03339\n",
            "Epoch: 9 | Iteration: 2231 | Classification loss: 0.00007 | Regression loss: 0.02472 | Running loss: 0.03337\n",
            "Epoch: 9 | Iteration: 2232 | Classification loss: 0.00006 | Regression loss: 0.02578 | Running loss: 0.03340\n",
            "Epoch: 9 | Iteration: 2233 | Classification loss: 0.00047 | Regression loss: 0.03107 | Running loss: 0.03335\n",
            "Epoch: 9 | Iteration: 2234 | Classification loss: 0.00191 | Regression loss: 0.01810 | Running loss: 0.03331\n",
            "Epoch: 9 | Iteration: 2235 | Classification loss: 0.00011 | Regression loss: 0.03821 | Running loss: 0.03330\n",
            "Epoch: 9 | Iteration: 2236 | Classification loss: 0.00106 | Regression loss: 0.02038 | Running loss: 0.03326\n",
            "Epoch: 9 | Iteration: 2237 | Classification loss: 0.00034 | Regression loss: 0.01624 | Running loss: 0.03303\n",
            "Epoch: 9 | Iteration: 2238 | Classification loss: 0.00142 | Regression loss: 0.04241 | Running loss: 0.03309\n",
            "Epoch: 9 | Iteration: 2239 | Classification loss: 0.00049 | Regression loss: 0.02012 | Running loss: 0.03308\n",
            "Epoch: 9 | Iteration: 2240 | Classification loss: 0.00009 | Regression loss: 0.01458 | Running loss: 0.03302\n",
            "Epoch: 9 | Iteration: 2241 | Classification loss: 0.00020 | Regression loss: 0.02578 | Running loss: 0.03302\n",
            "Epoch: 9 | Iteration: 2242 | Classification loss: 0.00004 | Regression loss: 0.03012 | Running loss: 0.03304\n",
            "Epoch: 9 | Iteration: 2243 | Classification loss: 0.00018 | Regression loss: 0.04040 | Running loss: 0.03309\n",
            "Epoch: 9 | Iteration: 2244 | Classification loss: 0.00019 | Regression loss: 0.03936 | Running loss: 0.03302\n",
            "Epoch: 9 | Iteration: 2245 | Classification loss: 0.00051 | Regression loss: 0.01375 | Running loss: 0.03298\n",
            "Epoch: 9 | Iteration: 2246 | Classification loss: 0.00393 | Regression loss: 0.05423 | Running loss: 0.03306\n",
            "Epoch: 9 | Iteration: 2247 | Classification loss: 0.00014 | Regression loss: 0.00850 | Running loss: 0.03295\n",
            "Epoch: 9 | Iteration: 2248 | Classification loss: 0.07108 | Regression loss: 0.11305 | Running loss: 0.03319\n",
            "Epoch: 9 | Iteration: 2249 | Classification loss: 0.00007 | Regression loss: 0.03278 | Running loss: 0.03314\n",
            "Epoch: 9 | Iteration: 2250 | Classification loss: 0.00073 | Regression loss: 0.03866 | Running loss: 0.03307\n",
            "Epoch: 9 | Iteration: 2251 | Classification loss: 0.00348 | Regression loss: 0.04544 | Running loss: 0.03305\n",
            "Epoch: 9 | Iteration: 2252 | Classification loss: 0.00023 | Regression loss: 0.02846 | Running loss: 0.03305\n",
            "Epoch: 9 | Iteration: 2253 | Classification loss: 0.00048 | Regression loss: 0.01883 | Running loss: 0.03295\n",
            "Epoch: 9 | Iteration: 2254 | Classification loss: 0.00009 | Regression loss: 0.02329 | Running loss: 0.03290\n",
            "Epoch: 9 | Iteration: 2255 | Classification loss: 0.00109 | Regression loss: 0.03343 | Running loss: 0.03291\n",
            "Epoch: 9 | Iteration: 2256 | Classification loss: 0.00007 | Regression loss: 0.02091 | Running loss: 0.03293\n",
            "Epoch: 9 | Iteration: 2257 | Classification loss: 0.00017 | Regression loss: 0.02366 | Running loss: 0.03291\n",
            "Epoch: 9 | Iteration: 2258 | Classification loss: 0.00066 | Regression loss: 0.02165 | Running loss: 0.03291\n",
            "Epoch: 9 | Iteration: 2259 | Classification loss: 0.01619 | Regression loss: 0.17207 | Running loss: 0.03320\n",
            "Epoch: 9 | Iteration: 2260 | Classification loss: 0.01989 | Regression loss: 0.20980 | Running loss: 0.03361\n",
            "Epoch: 9 | Iteration: 2261 | Classification loss: 0.00006 | Regression loss: 0.02941 | Running loss: 0.03364\n",
            "Epoch: 9 | Iteration: 2262 | Classification loss: 0.00050 | Regression loss: 0.01541 | Running loss: 0.03365\n",
            "Epoch: 9 | Iteration: 2263 | Classification loss: 0.00023 | Regression loss: 0.01713 | Running loss: 0.03365\n",
            "Epoch: 9 | Iteration: 2264 | Classification loss: 0.00005 | Regression loss: 0.03667 | Running loss: 0.03369\n",
            "Epoch: 9 | Iteration: 2265 | Classification loss: 0.04568 | Regression loss: 0.06431 | Running loss: 0.03371\n",
            "Epoch: 9 | Iteration: 2266 | Classification loss: 0.00442 | Regression loss: 0.09845 | Running loss: 0.03368\n",
            "Epoch: 9 | Iteration: 2267 | Classification loss: 0.00005 | Regression loss: 0.02135 | Running loss: 0.03368\n",
            "Epoch: 9 | Iteration: 2268 | Classification loss: 0.00011 | Regression loss: 0.04335 | Running loss: 0.03358\n",
            "Epoch: 9 | Iteration: 2269 | Classification loss: 0.00026 | Regression loss: 0.01912 | Running loss: 0.03357\n",
            "Epoch: 9 | Iteration: 2270 | Classification loss: 0.00060 | Regression loss: 0.06542 | Running loss: 0.03360\n",
            "Epoch: 9 | Iteration: 2271 | Classification loss: 0.00004 | Regression loss: 0.03548 | Running loss: 0.03355\n",
            "Epoch: 9 | Iteration: 2272 | Classification loss: 0.00009 | Regression loss: 0.02127 | Running loss: 0.03356\n",
            "Epoch: 9 | Iteration: 2273 | Classification loss: 0.00079 | Regression loss: 0.01065 | Running loss: 0.03356\n",
            "Epoch: 9 | Iteration: 2274 | Classification loss: 0.00081 | Regression loss: 0.01486 | Running loss: 0.03355\n",
            "Epoch: 9 | Iteration: 2275 | Classification loss: 0.00021 | Regression loss: 0.02960 | Running loss: 0.03360\n",
            "Epoch: 9 | Iteration: 2276 | Classification loss: 0.03313 | Regression loss: 0.06439 | Running loss: 0.03374\n",
            "Epoch: 9 | Iteration: 2277 | Classification loss: 0.00006 | Regression loss: 0.01263 | Running loss: 0.03366\n",
            "Epoch: 9 | Iteration: 2278 | Classification loss: 0.00005 | Regression loss: 0.02933 | Running loss: 0.03364\n",
            "Epoch: 9 | Iteration: 2279 | Classification loss: 0.00027 | Regression loss: 0.02914 | Running loss: 0.03366\n",
            "Epoch: 9 | Iteration: 2280 | Classification loss: 0.00008 | Regression loss: 0.03735 | Running loss: 0.03306\n",
            "Epoch: 9 | Iteration: 2281 | Classification loss: 0.00002 | Regression loss: 0.01383 | Running loss: 0.03303\n",
            "Epoch: 9 | Iteration: 2282 | Classification loss: 0.00016 | Regression loss: 0.01196 | Running loss: 0.03299\n",
            "Epoch: 9 | Iteration: 2283 | Classification loss: 0.03010 | Regression loss: 0.04283 | Running loss: 0.03303\n",
            "Epoch: 9 | Iteration: 2284 | Classification loss: 0.00020 | Regression loss: 0.02272 | Running loss: 0.03299\n",
            "Epoch: 9 | Iteration: 2285 | Classification loss: 0.00131 | Regression loss: 0.03163 | Running loss: 0.03296\n",
            "Epoch: 9 | Iteration: 2286 | Classification loss: 0.00001 | Regression loss: 0.02182 | Running loss: 0.03296\n",
            "Epoch: 9 | Iteration: 2287 | Classification loss: 0.00003 | Regression loss: 0.01815 | Running loss: 0.03294\n",
            "Epoch: 9 | Iteration: 2288 | Classification loss: 0.00019 | Regression loss: 0.03150 | Running loss: 0.03295\n",
            "Epoch: 9 | Iteration: 2289 | Classification loss: 0.00010 | Regression loss: 0.02266 | Running loss: 0.03296\n",
            "Epoch: 9 | Iteration: 2290 | Classification loss: 0.00004 | Regression loss: 0.02251 | Running loss: 0.03291\n",
            "Epoch: 9 | Iteration: 2291 | Classification loss: 0.00009 | Regression loss: 0.01526 | Running loss: 0.03290\n",
            "Epoch: 9 | Iteration: 2292 | Classification loss: 0.00012 | Regression loss: 0.00625 | Running loss: 0.03288\n",
            "Epoch: 9 | Iteration: 2293 | Classification loss: 0.00002 | Regression loss: 0.03736 | Running loss: 0.03295\n",
            "Epoch: 9 | Iteration: 2294 | Classification loss: 0.00108 | Regression loss: 0.02860 | Running loss: 0.03295\n",
            "Epoch: 9 | Iteration: 2295 | Classification loss: 0.00084 | Regression loss: 0.06828 | Running loss: 0.03307\n",
            "Epoch: 9 | Iteration: 2296 | Classification loss: 0.00083 | Regression loss: 0.02738 | Running loss: 0.03308\n",
            "Epoch: 9 | Iteration: 2297 | Classification loss: 0.00025 | Regression loss: 0.02253 | Running loss: 0.03307\n",
            "Epoch: 9 | Iteration: 2298 | Classification loss: 0.00014 | Regression loss: 0.02269 | Running loss: 0.03308\n",
            "Epoch: 9 | Iteration: 2299 | Classification loss: 0.00004 | Regression loss: 0.02164 | Running loss: 0.03311\n",
            "Epoch: 9 | Iteration: 2300 | Classification loss: 0.00012 | Regression loss: 0.02082 | Running loss: 0.03310\n",
            "Epoch: 9 | Iteration: 2301 | Classification loss: 0.00006 | Regression loss: 0.03722 | Running loss: 0.03315\n",
            "Epoch: 9 | Iteration: 2302 | Classification loss: 0.00003 | Regression loss: 0.00915 | Running loss: 0.03306\n",
            "Epoch: 9 | Iteration: 2303 | Classification loss: 0.00018 | Regression loss: 0.01734 | Running loss: 0.03307\n",
            "Epoch: 9 | Iteration: 2304 | Classification loss: 0.00018 | Regression loss: 0.04392 | Running loss: 0.03311\n",
            "Epoch: 9 | Iteration: 2305 | Classification loss: 0.00001 | Regression loss: 0.01775 | Running loss: 0.03305\n",
            "Epoch: 9 | Iteration: 2306 | Classification loss: 0.00016 | Regression loss: 0.02802 | Running loss: 0.03302\n",
            "Epoch: 9 | Iteration: 2307 | Classification loss: 0.00085 | Regression loss: 0.03020 | Running loss: 0.03302\n",
            "Epoch: 9 | Iteration: 2308 | Classification loss: 0.00004 | Regression loss: 0.01679 | Running loss: 0.03294\n",
            "Epoch: 9 | Iteration: 2309 | Classification loss: 0.00034 | Regression loss: 0.01154 | Running loss: 0.03293\n",
            "Epoch: 9 | Iteration: 2310 | Classification loss: 0.00015 | Regression loss: 0.03066 | Running loss: 0.03296\n",
            "Epoch: 9 | Iteration: 2311 | Classification loss: 0.00005 | Regression loss: 0.03837 | Running loss: 0.03301\n",
            "Epoch: 9 | Iteration: 2312 | Classification loss: 0.00019 | Regression loss: 0.02596 | Running loss: 0.03295\n",
            "Epoch: 9 | Iteration: 2313 | Classification loss: 0.00009 | Regression loss: 0.01350 | Running loss: 0.03293\n",
            "Epoch: 9 | Iteration: 2314 | Classification loss: 0.00029 | Regression loss: 0.04944 | Running loss: 0.03299\n",
            "Epoch: 9 | Iteration: 2315 | Classification loss: 0.00007 | Regression loss: 0.01870 | Running loss: 0.03299\n",
            "Epoch: 9 | Iteration: 2316 | Classification loss: 0.00012 | Regression loss: 0.01515 | Running loss: 0.03297\n",
            "Epoch: 9 | Iteration: 2317 | Classification loss: 0.00050 | Regression loss: 0.00821 | Running loss: 0.03295\n",
            "Epoch: 9 | Iteration: 2318 | Classification loss: 0.00059 | Regression loss: 0.01508 | Running loss: 0.03293\n",
            "Epoch: 9 | Iteration: 2319 | Classification loss: 0.00004 | Regression loss: 0.02306 | Running loss: 0.03288\n",
            "Epoch: 9 | Iteration: 2320 | Classification loss: 0.00003 | Regression loss: 0.03222 | Running loss: 0.03289\n",
            "Epoch: 9 | Iteration: 2321 | Classification loss: 0.00018 | Regression loss: 0.02040 | Running loss: 0.03287\n",
            "Epoch: 9 | Iteration: 2322 | Classification loss: 0.00099 | Regression loss: 0.03148 | Running loss: 0.03287\n",
            "Epoch: 9 | Iteration: 2323 | Classification loss: 0.00011 | Regression loss: 0.01549 | Running loss: 0.03285\n",
            "Epoch: 9 | Iteration: 2324 | Classification loss: 0.00002 | Regression loss: 0.03246 | Running loss: 0.03284\n",
            "Epoch: 9 | Iteration: 2325 | Classification loss: 0.00002 | Regression loss: 0.02131 | Running loss: 0.03279\n",
            "Epoch: 9 | Iteration: 2326 | Classification loss: 0.00010 | Regression loss: 0.05477 | Running loss: 0.03286\n",
            "Epoch: 9 | Iteration: 2327 | Classification loss: 0.00003 | Regression loss: 0.03965 | Running loss: 0.03291\n",
            "Epoch: 9 | Iteration: 2328 | Classification loss: 0.00021 | Regression loss: 0.01024 | Running loss: 0.03286\n",
            "Epoch: 9 | Iteration: 2329 | Classification loss: 0.00008 | Regression loss: 0.02748 | Running loss: 0.03289\n",
            "Epoch: 9 | Iteration: 2330 | Classification loss: 0.00019 | Regression loss: 0.03794 | Running loss: 0.03294\n",
            "Epoch: 9 | Iteration: 2331 | Classification loss: 0.00004 | Regression loss: 0.03968 | Running loss: 0.03299\n",
            "Epoch: 9 | Iteration: 2332 | Classification loss: 0.00036 | Regression loss: 0.01989 | Running loss: 0.03300\n",
            "Epoch: 9 | Iteration: 2333 | Classification loss: 0.00091 | Regression loss: 0.05138 | Running loss: 0.03307\n",
            "Epoch: 9 | Iteration: 2334 | Classification loss: 0.00002 | Regression loss: 0.02218 | Running loss: 0.03308\n",
            "Epoch: 9 | Iteration: 2335 | Classification loss: 0.00021 | Regression loss: 0.02500 | Running loss: 0.03308\n",
            "Epoch: 9 | Iteration: 2336 | Classification loss: 0.00006 | Regression loss: 0.01820 | Running loss: 0.03306\n",
            "Epoch: 9 | Iteration: 2337 | Classification loss: 0.00005 | Regression loss: 0.01606 | Running loss: 0.03306\n",
            "Epoch: 9 | Iteration: 2338 | Classification loss: 0.00012 | Regression loss: 0.01167 | Running loss: 0.03304\n",
            "Epoch: 9 | Iteration: 2339 | Classification loss: 0.00015 | Regression loss: 0.00843 | Running loss: 0.03302\n",
            "Epoch: 9 | Iteration: 2340 | Classification loss: 0.00011 | Regression loss: 0.04039 | Running loss: 0.03308\n",
            "Epoch: 9 | Iteration: 2341 | Classification loss: 0.00013 | Regression loss: 0.01949 | Running loss: 0.03308\n",
            "Epoch: 9 | Iteration: 2342 | Classification loss: 0.00008 | Regression loss: 0.03736 | Running loss: 0.03310\n",
            "Epoch: 9 | Iteration: 2343 | Classification loss: 0.00038 | Regression loss: 0.03703 | Running loss: 0.03316\n",
            "Epoch: 9 | Iteration: 2344 | Classification loss: 0.00004 | Regression loss: 0.04854 | Running loss: 0.03304\n",
            "Epoch: 9 | Iteration: 2345 | Classification loss: 0.00596 | Regression loss: 0.08458 | Running loss: 0.03318\n",
            "Epoch: 9 | Iteration: 2346 | Classification loss: 0.00006 | Regression loss: 0.03792 | Running loss: 0.03322\n",
            "Epoch: 9 | Iteration: 2347 | Classification loss: 0.00011 | Regression loss: 0.04127 | Running loss: 0.03325\n",
            "Epoch: 9 | Iteration: 2348 | Classification loss: 0.00004 | Regression loss: 0.00995 | Running loss: 0.03323\n",
            "Epoch: 9 | Iteration: 2349 | Classification loss: 0.00038 | Regression loss: 0.04263 | Running loss: 0.03325\n",
            "Epoch: 9 | Iteration: 2350 | Classification loss: 0.00004 | Regression loss: 0.01924 | Running loss: 0.03323\n",
            "Epoch: 9 | Iteration: 2351 | Classification loss: 0.00005 | Regression loss: 0.01720 | Running loss: 0.03317\n",
            "Epoch: 9 | Iteration: 2352 | Classification loss: 0.00069 | Regression loss: 0.02725 | Running loss: 0.03319\n",
            "Epoch: 9 | Iteration: 2353 | Classification loss: 0.00039 | Regression loss: 0.03772 | Running loss: 0.03323\n",
            "Epoch: 9 | Iteration: 2354 | Classification loss: 0.00033 | Regression loss: 0.01239 | Running loss: 0.03323\n",
            "Epoch: 9 | Iteration: 2355 | Classification loss: 0.00157 | Regression loss: 0.04256 | Running loss: 0.03328\n",
            "Epoch: 9 | Iteration: 2356 | Classification loss: 0.00002 | Regression loss: 0.03072 | Running loss: 0.03330\n",
            "Epoch: 9 | Iteration: 2357 | Classification loss: 0.00041 | Regression loss: 0.02517 | Running loss: 0.03332\n",
            "Epoch: 9 | Iteration: 2358 | Classification loss: 0.00022 | Regression loss: 0.01137 | Running loss: 0.03330\n",
            "Epoch: 9 | Iteration: 2359 | Classification loss: 0.00099 | Regression loss: 0.02922 | Running loss: 0.03332\n",
            "Epoch: 9 | Iteration: 2360 | Classification loss: 0.00007 | Regression loss: 0.01452 | Running loss: 0.03331\n",
            "Epoch: 9 | Iteration: 2361 | Classification loss: 0.00013 | Regression loss: 0.00844 | Running loss: 0.03329\n",
            "Epoch: 9 | Iteration: 2362 | Classification loss: 0.00011 | Regression loss: 0.02357 | Running loss: 0.03332\n",
            "Epoch: 9 | Iteration: 2363 | Classification loss: 0.00006 | Regression loss: 0.02260 | Running loss: 0.03318\n",
            "Epoch: 9 | Iteration: 2364 | Classification loss: 0.01232 | Regression loss: 0.07487 | Running loss: 0.03331\n",
            "Epoch: 9 | Iteration: 2365 | Classification loss: 0.00010 | Regression loss: 0.03542 | Running loss: 0.03335\n",
            "Epoch: 9 | Iteration: 2366 | Classification loss: 0.00040 | Regression loss: 0.07716 | Running loss: 0.03348\n",
            "Epoch: 9 | Iteration: 2367 | Classification loss: 0.00002 | Regression loss: 0.02647 | Running loss: 0.03351\n",
            "Epoch: 9 | Iteration: 2368 | Classification loss: 0.00074 | Regression loss: 0.06804 | Running loss: 0.03359\n",
            "Epoch: 9 | Iteration: 2369 | Classification loss: 0.00050 | Regression loss: 0.02281 | Running loss: 0.03359\n",
            "Epoch: 9 | Iteration: 2370 | Classification loss: 0.00002 | Regression loss: 0.05251 | Running loss: 0.03366\n",
            "Epoch: 9 | Iteration: 2371 | Classification loss: 0.00022 | Regression loss: 0.03340 | Running loss: 0.03359\n",
            "Epoch: 9 | Iteration: 2372 | Classification loss: 0.00002 | Regression loss: 0.02281 | Running loss: 0.03356\n",
            "Epoch: 9 | Iteration: 2373 | Classification loss: 0.00368 | Regression loss: 0.09095 | Running loss: 0.03373\n",
            "Epoch: 9 | Iteration: 2374 | Classification loss: 0.00002 | Regression loss: 0.02790 | Running loss: 0.03366\n",
            "Epoch: 9 | Iteration: 2375 | Classification loss: 0.00002 | Regression loss: 0.02362 | Running loss: 0.03363\n",
            "Epoch: 9 | Iteration: 2376 | Classification loss: 0.00003 | Regression loss: 0.03169 | Running loss: 0.03367\n",
            "Epoch: 9 | Iteration: 2377 | Classification loss: 0.00002 | Regression loss: 0.01479 | Running loss: 0.03362\n",
            "Epoch: 9 | Iteration: 2378 | Classification loss: 0.00583 | Regression loss: 0.05303 | Running loss: 0.03369\n",
            "Epoch: 9 | Iteration: 2379 | Classification loss: 0.00003 | Regression loss: 0.01202 | Running loss: 0.03365\n",
            "Epoch: 9 | Iteration: 2380 | Classification loss: 0.00037 | Regression loss: 0.05826 | Running loss: 0.03373\n",
            "Epoch: 9 | Iteration: 2381 | Classification loss: 0.00003 | Regression loss: 0.02199 | Running loss: 0.03372\n",
            "Epoch: 9 | Iteration: 2382 | Classification loss: 0.00003 | Regression loss: 0.01409 | Running loss: 0.03370\n",
            "Epoch: 9 | Iteration: 2383 | Classification loss: 0.00671 | Regression loss: 0.05295 | Running loss: 0.03377\n",
            "Epoch: 9 | Iteration: 2384 | Classification loss: 0.00014 | Regression loss: 0.01593 | Running loss: 0.03376\n",
            "Epoch: 9 | Iteration: 2385 | Classification loss: 0.00007 | Regression loss: 0.03428 | Running loss: 0.03377\n",
            "Epoch: 9 | Iteration: 2386 | Classification loss: 0.00007 | Regression loss: 0.02358 | Running loss: 0.03368\n",
            "Epoch: 9 | Iteration: 2387 | Classification loss: 0.00004 | Regression loss: 0.02186 | Running loss: 0.03366\n",
            "Epoch: 9 | Iteration: 2388 | Classification loss: 0.00009 | Regression loss: 0.02821 | Running loss: 0.03369\n",
            "Epoch: 9 | Iteration: 2389 | Classification loss: 0.00007 | Regression loss: 0.01011 | Running loss: 0.03367\n",
            "Epoch: 9 | Iteration: 2390 | Classification loss: 0.00555 | Regression loss: 0.05012 | Running loss: 0.03376\n",
            "Epoch: 9 | Iteration: 2391 | Classification loss: 0.00038 | Regression loss: 0.02237 | Running loss: 0.03376\n",
            "Epoch: 9 | Iteration: 2392 | Classification loss: 0.00012 | Regression loss: 0.01720 | Running loss: 0.03374\n",
            "Epoch: 9 | Iteration: 2393 | Classification loss: 0.00477 | Regression loss: 0.09328 | Running loss: 0.03388\n",
            "Epoch: 9 | Iteration: 2394 | Classification loss: 0.00276 | Regression loss: 0.03373 | Running loss: 0.03394\n",
            "Epoch: 9 | Iteration: 2395 | Classification loss: 0.00050 | Regression loss: 0.02767 | Running loss: 0.03394\n",
            "Epoch: 9 | Iteration: 2396 | Classification loss: 0.00094 | Regression loss: 0.01084 | Running loss: 0.03389\n",
            "Epoch: 9 | Iteration: 2397 | Classification loss: 0.00151 | Regression loss: 0.01894 | Running loss: 0.03388\n",
            "Epoch: 9 | Iteration: 2398 | Classification loss: 0.00003 | Regression loss: 0.02469 | Running loss: 0.03386\n",
            "Epoch: 9 | Iteration: 2399 | Classification loss: 0.00025 | Regression loss: 0.02702 | Running loss: 0.03387\n",
            "Epoch: 9 | Iteration: 2400 | Classification loss: 0.00145 | Regression loss: 0.04481 | Running loss: 0.03389\n",
            "Epoch: 9 | Iteration: 2401 | Classification loss: 0.00014 | Regression loss: 0.02712 | Running loss: 0.03391\n",
            "Epoch: 9 | Iteration: 2402 | Classification loss: 0.00038 | Regression loss: 0.02688 | Running loss: 0.03394\n",
            "Epoch: 9 | Iteration: 2403 | Classification loss: 0.00390 | Regression loss: 0.04712 | Running loss: 0.03399\n",
            "Epoch: 9 | Iteration: 2404 | Classification loss: 0.00008 | Regression loss: 0.01513 | Running loss: 0.03397\n",
            "Epoch: 9 | Iteration: 2405 | Classification loss: 0.00019 | Regression loss: 0.02316 | Running loss: 0.03397\n",
            "Epoch: 9 | Iteration: 2406 | Classification loss: 0.00003 | Regression loss: 0.01982 | Running loss: 0.03393\n",
            "Epoch: 9 | Iteration: 2407 | Classification loss: 0.00002 | Regression loss: 0.02558 | Running loss: 0.03395\n",
            "Epoch: 9 | Iteration: 2408 | Classification loss: 0.00024 | Regression loss: 0.01578 | Running loss: 0.03384\n",
            "Epoch: 9 | Iteration: 2409 | Classification loss: 0.00013 | Regression loss: 0.01644 | Running loss: 0.03379\n",
            "Epoch: 9 | Iteration: 2410 | Classification loss: 0.00006 | Regression loss: 0.01836 | Running loss: 0.03379\n",
            "Epoch: 9 | Iteration: 2411 | Classification loss: 0.00086 | Regression loss: 0.04816 | Running loss: 0.03386\n",
            "Epoch: 9 | Iteration: 2412 | Classification loss: 0.00100 | Regression loss: 0.03959 | Running loss: 0.03390\n",
            "Epoch: 9 | Iteration: 2413 | Classification loss: 0.00004 | Regression loss: 0.01458 | Running loss: 0.03387\n",
            "Epoch: 9 | Iteration: 2414 | Classification loss: 0.00069 | Regression loss: 0.03206 | Running loss: 0.03384\n",
            "Epoch: 9 | Iteration: 2415 | Classification loss: 0.00032 | Regression loss: 0.03572 | Running loss: 0.03386\n",
            "Epoch: 9 | Iteration: 2416 | Classification loss: 0.00010 | Regression loss: 0.01385 | Running loss: 0.03379\n",
            "Epoch: 9 | Iteration: 2417 | Classification loss: 0.00008 | Regression loss: 0.02082 | Running loss: 0.03379\n",
            "Epoch: 9 | Iteration: 2418 | Classification loss: 0.00056 | Regression loss: 0.03564 | Running loss: 0.03379\n",
            "Epoch: 9 | Iteration: 2419 | Classification loss: 0.06528 | Regression loss: 0.14238 | Running loss: 0.03417\n",
            "Epoch: 9 | Iteration: 2420 | Classification loss: 0.00002 | Regression loss: 0.02573 | Running loss: 0.03420\n",
            "Epoch: 9 | Iteration: 2421 | Classification loss: 0.00002 | Regression loss: 0.02804 | Running loss: 0.03419\n",
            "Epoch: 9 | Iteration: 2422 | Classification loss: 0.00013 | Regression loss: 0.02225 | Running loss: 0.03421\n",
            "Epoch: 9 | Iteration: 2423 | Classification loss: 0.00008 | Regression loss: 0.02099 | Running loss: 0.03419\n",
            "Epoch: 9 | Iteration: 2424 | Classification loss: 0.00015 | Regression loss: 0.01285 | Running loss: 0.03418\n",
            "Epoch: 9 | Iteration: 2425 | Classification loss: 0.00007 | Regression loss: 0.01618 | Running loss: 0.03417\n",
            "Epoch: 9 | Iteration: 2426 | Classification loss: 0.00008 | Regression loss: 0.00946 | Running loss: 0.03415\n",
            "Epoch: 9 | Iteration: 2427 | Classification loss: 0.00252 | Regression loss: 0.01604 | Running loss: 0.03416\n",
            "Epoch: 9 | Iteration: 2428 | Classification loss: 0.00016 | Regression loss: 0.02089 | Running loss: 0.03404\n",
            "Epoch: 9 | Iteration: 2429 | Classification loss: 0.00006 | Regression loss: 0.04689 | Running loss: 0.03410\n",
            "Epoch: 9 | Iteration: 2430 | Classification loss: 0.00045 | Regression loss: 0.04844 | Running loss: 0.03411\n",
            "Epoch: 9 | Iteration: 2431 | Classification loss: 0.00015 | Regression loss: 0.03042 | Running loss: 0.03414\n",
            "Epoch: 9 | Iteration: 2432 | Classification loss: 0.00005 | Regression loss: 0.02773 | Running loss: 0.03406\n",
            "Epoch: 9 | Iteration: 2433 | Classification loss: 0.00053 | Regression loss: 0.01330 | Running loss: 0.03396\n",
            "Epoch: 9 | Iteration: 2434 | Classification loss: 0.00073 | Regression loss: 0.01417 | Running loss: 0.03397\n",
            "Epoch: 9 | Iteration: 2435 | Classification loss: 0.00002 | Regression loss: 0.01503 | Running loss: 0.03395\n",
            "Epoch: 9 | Iteration: 2436 | Classification loss: 0.00002 | Regression loss: 0.01752 | Running loss: 0.03396\n",
            "Epoch: 9 | Iteration: 2437 | Classification loss: 0.00338 | Regression loss: 0.05281 | Running loss: 0.03401\n",
            "Epoch: 9 | Iteration: 2438 | Classification loss: 0.00092 | Regression loss: 0.02546 | Running loss: 0.03404\n",
            "Epoch: 9 | Iteration: 2439 | Classification loss: 0.00002 | Regression loss: 0.01532 | Running loss: 0.03402\n",
            "Epoch: 9 | Iteration: 2440 | Classification loss: 0.00014 | Regression loss: 0.02911 | Running loss: 0.03406\n",
            "Epoch: 9 | Iteration: 2441 | Classification loss: 0.00020 | Regression loss: 0.02874 | Running loss: 0.03404\n",
            "Epoch: 9 | Iteration: 2442 | Classification loss: 0.00541 | Regression loss: 0.02365 | Running loss: 0.03405\n",
            "Epoch: 9 | Iteration: 2443 | Classification loss: 0.00298 | Regression loss: 0.02889 | Running loss: 0.03408\n",
            "Epoch: 9 | Iteration: 2444 | Classification loss: 0.00013 | Regression loss: 0.03507 | Running loss: 0.03409\n",
            "Epoch: 9 | Iteration: 2445 | Classification loss: 0.00025 | Regression loss: 0.02055 | Running loss: 0.03410\n",
            "Epoch: 9 | Iteration: 2446 | Classification loss: 0.00008 | Regression loss: 0.01537 | Running loss: 0.03406\n",
            "Epoch: 9 | Iteration: 2447 | Classification loss: 0.00009 | Regression loss: 0.02919 | Running loss: 0.03409\n",
            "Epoch: 9 | Iteration: 2448 | Classification loss: 0.00007 | Regression loss: 0.00879 | Running loss: 0.03400\n",
            "Epoch: 9 | Iteration: 2449 | Classification loss: 0.00004 | Regression loss: 0.01184 | Running loss: 0.03399\n",
            "Epoch: 9 | Iteration: 2450 | Classification loss: 0.00090 | Regression loss: 0.01867 | Running loss: 0.03395\n",
            "Epoch: 9 | Iteration: 2451 | Classification loss: 0.00015 | Regression loss: 0.04222 | Running loss: 0.03400\n",
            "Epoch: 9 | Iteration: 2452 | Classification loss: 0.00004 | Regression loss: 0.02098 | Running loss: 0.03398\n",
            "Epoch: 9 | Iteration: 2453 | Classification loss: 0.00024 | Regression loss: 0.03420 | Running loss: 0.03399\n",
            "Epoch: 9 | Iteration: 2454 | Classification loss: 0.00044 | Regression loss: 0.01802 | Running loss: 0.03391\n",
            "Epoch: 9 | Iteration: 2455 | Classification loss: 0.00005 | Regression loss: 0.02863 | Running loss: 0.03385\n",
            "Epoch: 9 | Iteration: 2456 | Classification loss: 0.00032 | Regression loss: 0.02190 | Running loss: 0.03384\n",
            "Epoch: 9 | Iteration: 2457 | Classification loss: 0.00002 | Regression loss: 0.01745 | Running loss: 0.03381\n",
            "Epoch: 9 | Iteration: 2458 | Classification loss: 0.00065 | Regression loss: 0.03981 | Running loss: 0.03383\n",
            "Epoch: 9 | Iteration: 2459 | Classification loss: 0.00002 | Regression loss: 0.01440 | Running loss: 0.03383\n",
            "Epoch: 9 | Iteration: 2460 | Classification loss: 0.00020 | Regression loss: 0.04712 | Running loss: 0.03385\n",
            "Epoch: 9 | Iteration: 2461 | Classification loss: 0.00010 | Regression loss: 0.02478 | Running loss: 0.03387\n",
            "Epoch: 9 | Iteration: 2462 | Classification loss: 0.00000 | Regression loss: 0.02646 | Running loss: 0.03389\n",
            "Epoch: 9 | Iteration: 2463 | Classification loss: 0.00007 | Regression loss: 0.03566 | Running loss: 0.03394\n",
            "Epoch: 9 | Iteration: 2464 | Classification loss: 0.00005 | Regression loss: 0.01739 | Running loss: 0.03394\n",
            "Epoch: 9 | Iteration: 2465 | Classification loss: 0.00012 | Regression loss: 0.01053 | Running loss: 0.03391\n",
            "Epoch: 9 | Iteration: 2466 | Classification loss: 0.00079 | Regression loss: 0.01433 | Running loss: 0.03390\n",
            "Epoch: 9 | Iteration: 2467 | Classification loss: 0.00004 | Regression loss: 0.01295 | Running loss: 0.03389\n",
            "Epoch: 9 | Iteration: 2468 | Classification loss: 0.00004 | Regression loss: 0.04105 | Running loss: 0.03391\n",
            "Epoch: 9 | Iteration: 2469 | Classification loss: 0.00004 | Regression loss: 0.01003 | Running loss: 0.03379\n",
            "Epoch: 9 | Iteration: 2470 | Classification loss: 0.00002 | Regression loss: 0.03712 | Running loss: 0.03382\n",
            "Epoch: 9 | Iteration: 2471 | Classification loss: 0.00020 | Regression loss: 0.00985 | Running loss: 0.03377\n",
            "Epoch: 9 | Iteration: 2472 | Classification loss: 0.00020 | Regression loss: 0.02773 | Running loss: 0.03377\n",
            "Epoch: 9 | Iteration: 2473 | Classification loss: 0.00029 | Regression loss: 0.06856 | Running loss: 0.03386\n",
            "Epoch: 9 | Iteration: 2474 | Classification loss: 0.00014 | Regression loss: 0.02341 | Running loss: 0.03385\n",
            "Epoch: 9 | Iteration: 2475 | Classification loss: 0.00003 | Regression loss: 0.02685 | Running loss: 0.03383\n",
            "Epoch: 9 | Iteration: 2476 | Classification loss: 0.00004 | Regression loss: 0.03215 | Running loss: 0.03381\n",
            "Epoch: 9 | Iteration: 2477 | Classification loss: 0.00025 | Regression loss: 0.02161 | Running loss: 0.03371\n",
            "Epoch: 9 | Iteration: 2478 | Classification loss: 0.00005 | Regression loss: 0.00980 | Running loss: 0.03370\n",
            "Epoch: 9 | Iteration: 2479 | Classification loss: 0.00021 | Regression loss: 0.02418 | Running loss: 0.03371\n",
            "Epoch: 9 | Iteration: 2480 | Classification loss: 0.00001 | Regression loss: 0.02703 | Running loss: 0.03374\n",
            "Epoch: 9 | Iteration: 2481 | Classification loss: 0.00023 | Regression loss: 0.11289 | Running loss: 0.03392\n",
            "Epoch: 9 | Iteration: 2482 | Classification loss: 0.00004 | Regression loss: 0.04705 | Running loss: 0.03396\n",
            "Epoch: 9 | Iteration: 2483 | Classification loss: 0.00005 | Regression loss: 0.04264 | Running loss: 0.03399\n",
            "Epoch: 9 | Iteration: 2484 | Classification loss: 0.00004 | Regression loss: 0.04296 | Running loss: 0.03400\n",
            "Epoch: 9 | Iteration: 2485 | Classification loss: 0.00119 | Regression loss: 0.03266 | Running loss: 0.03394\n",
            "Epoch: 9 | Iteration: 2486 | Classification loss: 0.00005 | Regression loss: 0.05203 | Running loss: 0.03401\n",
            "Epoch: 9 | Iteration: 2487 | Classification loss: 0.00066 | Regression loss: 0.03666 | Running loss: 0.03397\n",
            "Epoch: 9 | Iteration: 2488 | Classification loss: 0.00047 | Regression loss: 0.03168 | Running loss: 0.03402\n",
            "Epoch: 9 | Iteration: 2489 | Classification loss: 0.00062 | Regression loss: 0.01995 | Running loss: 0.03393\n",
            "Epoch: 9 | Iteration: 2490 | Classification loss: 0.00031 | Regression loss: 0.03336 | Running loss: 0.03394\n",
            "Epoch: 9 | Iteration: 2491 | Classification loss: 0.00008 | Regression loss: 0.02120 | Running loss: 0.03394\n",
            "Epoch: 9 | Iteration: 2492 | Classification loss: 0.00002 | Regression loss: 0.02378 | Running loss: 0.03391\n",
            "Epoch: 9 | Iteration: 2493 | Classification loss: 0.00003 | Regression loss: 0.04765 | Running loss: 0.03397\n",
            "Epoch: 9 | Iteration: 2494 | Classification loss: 0.00007 | Regression loss: 0.01748 | Running loss: 0.03396\n",
            "Epoch: 9 | Iteration: 2495 | Classification loss: 0.00001 | Regression loss: 0.03277 | Running loss: 0.03397\n",
            "Epoch: 9 | Iteration: 2496 | Classification loss: 0.00007 | Regression loss: 0.03269 | Running loss: 0.03396\n",
            "Epoch: 9 | Iteration: 2497 | Classification loss: 0.00002 | Regression loss: 0.01568 | Running loss: 0.03396\n",
            "Epoch: 9 | Iteration: 2498 | Classification loss: 0.00628 | Regression loss: 0.10953 | Running loss: 0.03415\n",
            "Epoch: 9 | Iteration: 2499 | Classification loss: 0.00001 | Regression loss: 0.00890 | Running loss: 0.03404\n",
            "Epoch: 9 | Iteration: 2500 | Classification loss: 0.00045 | Regression loss: 0.05100 | Running loss: 0.03408\n",
            "Epoch: 9 | Iteration: 2501 | Classification loss: 0.00610 | Regression loss: 0.06182 | Running loss: 0.03416\n",
            "Epoch: 9 | Iteration: 2502 | Classification loss: 0.00004 | Regression loss: 0.02358 | Running loss: 0.03416\n",
            "Epoch: 9 | Iteration: 2503 | Classification loss: 0.00080 | Regression loss: 0.04921 | Running loss: 0.03419\n",
            "Epoch: 9 | Iteration: 2504 | Classification loss: 0.00013 | Regression loss: 0.01397 | Running loss: 0.03419\n",
            "Epoch: 9 | Iteration: 2505 | Classification loss: 0.00025 | Regression loss: 0.05355 | Running loss: 0.03412\n",
            "Epoch: 9 | Iteration: 2506 | Classification loss: 0.00002 | Regression loss: 0.03807 | Running loss: 0.03416\n",
            "Epoch: 9 | Iteration: 2507 | Classification loss: 0.00244 | Regression loss: 0.04102 | Running loss: 0.03415\n",
            "Epoch: 9 | Iteration: 2508 | Classification loss: 0.00002 | Regression loss: 0.02989 | Running loss: 0.03416\n",
            "Epoch: 9 | Iteration: 2509 | Classification loss: 0.00022 | Regression loss: 0.04761 | Running loss: 0.03417\n",
            "Epoch: 9 | Iteration: 2510 | Classification loss: 0.00174 | Regression loss: 0.02061 | Running loss: 0.03417\n",
            "Epoch: 9 | Iteration: 2511 | Classification loss: 0.00007 | Regression loss: 0.03525 | Running loss: 0.03417\n",
            "Epoch: 9 | Iteration: 2512 | Classification loss: 0.00049 | Regression loss: 0.03317 | Running loss: 0.03420\n",
            "Epoch: 9 | Iteration: 2513 | Classification loss: 0.00481 | Regression loss: 0.05157 | Running loss: 0.03426\n",
            "Epoch: 9 | Iteration: 2514 | Classification loss: 0.00154 | Regression loss: 0.02592 | Running loss: 0.03428\n",
            "Epoch: 9 | Iteration: 2515 | Classification loss: 0.00004 | Regression loss: 0.01150 | Running loss: 0.03350\n",
            "Epoch: 9 | Iteration: 2516 | Classification loss: 0.00011 | Regression loss: 0.01759 | Running loss: 0.03351\n",
            "Epoch: 9 | Iteration: 2517 | Classification loss: 0.00023 | Regression loss: 0.01077 | Running loss: 0.03349\n",
            "Epoch: 9 | Iteration: 2518 | Classification loss: 0.00050 | Regression loss: 0.01142 | Running loss: 0.03349\n",
            "Epoch: 9 | Iteration: 2519 | Classification loss: 0.00009 | Regression loss: 0.02582 | Running loss: 0.03352\n",
            "Epoch: 9 | Iteration: 2520 | Classification loss: 0.00048 | Regression loss: 0.02095 | Running loss: 0.03344\n",
            "Epoch: 9 | Iteration: 2521 | Classification loss: 0.00067 | Regression loss: 0.02222 | Running loss: 0.03343\n",
            "Epoch: 9 | Iteration: 2522 | Classification loss: 0.00092 | Regression loss: 0.01843 | Running loss: 0.03343\n",
            "Epoch: 9 | Iteration: 2523 | Classification loss: 0.00008 | Regression loss: 0.01528 | Running loss: 0.03336\n",
            "Epoch: 9 | Iteration: 2524 | Classification loss: 0.00045 | Regression loss: 0.02070 | Running loss: 0.03333\n",
            "Epoch: 9 | Iteration: 2525 | Classification loss: 0.00002 | Regression loss: 0.01425 | Running loss: 0.03330\n",
            "Epoch: 9 | Iteration: 2526 | Classification loss: 0.01504 | Regression loss: 0.05601 | Running loss: 0.03341\n",
            "Epoch: 9 | Iteration: 2527 | Classification loss: 0.00001 | Regression loss: 0.01661 | Running loss: 0.03339\n",
            "Epoch: 9 | Iteration: 2528 | Classification loss: 0.00060 | Regression loss: 0.03578 | Running loss: 0.03341\n",
            "Epoch: 9 | Iteration: 2529 | Classification loss: 0.00004 | Regression loss: 0.01303 | Running loss: 0.03338\n",
            "Epoch: 9 | Iteration: 2530 | Classification loss: 0.00002 | Regression loss: 0.01237 | Running loss: 0.03338\n",
            "Epoch: 9 | Iteration: 2531 | Classification loss: 0.00024 | Regression loss: 0.00946 | Running loss: 0.03336\n",
            "Epoch: 9 | Iteration: 2532 | Classification loss: 0.00021 | Regression loss: 0.01795 | Running loss: 0.03335\n",
            "Epoch: 9 | Iteration: 2533 | Classification loss: 0.00006 | Regression loss: 0.01355 | Running loss: 0.03313\n",
            "Epoch: 9 | Iteration: 2534 | Classification loss: 0.00007 | Regression loss: 0.03886 | Running loss: 0.03317\n",
            "Epoch: 9 | Iteration: 2535 | Classification loss: 0.00001 | Regression loss: 0.02080 | Running loss: 0.03316\n",
            "Epoch: 9 | Iteration: 2536 | Classification loss: 0.00004 | Regression loss: 0.01309 | Running loss: 0.03315\n",
            "Epoch: 9 | Iteration: 2537 | Classification loss: 0.00173 | Regression loss: 0.01884 | Running loss: 0.03317\n",
            "Epoch: 9 | Iteration: 2538 | Classification loss: 0.00014 | Regression loss: 0.01951 | Running loss: 0.03313\n",
            "Epoch: 9 | Iteration: 2539 | Classification loss: 0.00024 | Regression loss: 0.01870 | Running loss: 0.03313\n",
            "Epoch: 9 | Iteration: 2540 | Classification loss: 0.00013 | Regression loss: 0.02474 | Running loss: 0.03311\n",
            "Epoch: 9 | Iteration: 2541 | Classification loss: 0.00009 | Regression loss: 0.01491 | Running loss: 0.03308\n",
            "Epoch: 9 | Iteration: 2542 | Classification loss: 0.00012 | Regression loss: 0.01384 | Running loss: 0.03305\n",
            "Epoch: 9 | Iteration: 2543 | Classification loss: 0.00179 | Regression loss: 0.01324 | Running loss: 0.03306\n",
            "Epoch: 9 | Iteration: 2544 | Classification loss: 0.00024 | Regression loss: 0.02026 | Running loss: 0.03297\n",
            "Epoch: 9 | Iteration: 2545 | Classification loss: 0.00001 | Regression loss: 0.01887 | Running loss: 0.03298\n",
            "Epoch: 9 | Iteration: 2546 | Classification loss: 0.00005 | Regression loss: 0.03011 | Running loss: 0.03289\n",
            "Epoch: 9 | Iteration: 2547 | Classification loss: 0.10367 | Regression loss: 0.32494 | Running loss: 0.03368\n",
            "Epoch: 9 | Iteration: 2548 | Classification loss: 0.00006 | Regression loss: 0.02175 | Running loss: 0.03370\n",
            "Epoch: 9 | Iteration: 2549 | Classification loss: 0.00370 | Regression loss: 0.04402 | Running loss: 0.03377\n",
            "Epoch: 9 | Iteration: 2550 | Classification loss: 0.00793 | Regression loss: 0.04475 | Running loss: 0.03383\n",
            "Epoch: 9 | Iteration: 2551 | Classification loss: 0.00038 | Regression loss: 0.01611 | Running loss: 0.03374\n",
            "Epoch: 9 | Iteration: 2552 | Classification loss: 0.00188 | Regression loss: 0.04094 | Running loss: 0.03377\n",
            "Epoch: 9 | Iteration: 2553 | Classification loss: 0.00005 | Regression loss: 0.01822 | Running loss: 0.03377\n",
            "Epoch: 9 | Iteration: 2554 | Classification loss: 0.00003 | Regression loss: 0.03834 | Running loss: 0.03379\n",
            "Epoch: 9 | Iteration: 2555 | Classification loss: 0.00022 | Regression loss: 0.02435 | Running loss: 0.03380\n",
            "Epoch: 9 | Iteration: 2556 | Classification loss: 0.00038 | Regression loss: 0.02493 | Running loss: 0.03379\n",
            "Epoch: 9 | Iteration: 2557 | Classification loss: 0.00202 | Regression loss: 0.06260 | Running loss: 0.03387\n",
            "Epoch: 9 | Iteration: 2558 | Classification loss: 0.00009 | Regression loss: 0.03938 | Running loss: 0.03389\n",
            "Epoch: 9 | Iteration: 2559 | Classification loss: 0.00029 | Regression loss: 0.05466 | Running loss: 0.03395\n",
            "Epoch: 9 | Iteration: 2560 | Classification loss: 0.00005 | Regression loss: 0.02875 | Running loss: 0.03394\n",
            "Epoch: 9 | Iteration: 2561 | Classification loss: 0.00685 | Regression loss: 0.02936 | Running loss: 0.03399\n",
            "Epoch: 9 | Iteration: 2562 | Classification loss: 0.01832 | Regression loss: 0.08991 | Running loss: 0.03418\n",
            "Epoch: 9 | Iteration: 2563 | Classification loss: 0.00005 | Regression loss: 0.02690 | Running loss: 0.03419\n",
            "Epoch: 9 | Iteration: 2564 | Classification loss: 0.00014 | Regression loss: 0.00830 | Running loss: 0.03417\n",
            "Epoch: 9 | Iteration: 2565 | Classification loss: 0.00026 | Regression loss: 0.04101 | Running loss: 0.03423\n",
            "Epoch: 9 | Iteration: 2566 | Classification loss: 0.00021 | Regression loss: 0.03306 | Running loss: 0.03426\n",
            "Epoch: 9 | Iteration: 2567 | Classification loss: 0.00071 | Regression loss: 0.04506 | Running loss: 0.03428\n",
            "Epoch: 9 | Iteration: 2568 | Classification loss: 0.00011 | Regression loss: 0.00707 | Running loss: 0.03427\n",
            "Epoch: 9 | Iteration: 2569 | Classification loss: 0.00023 | Regression loss: 0.03362 | Running loss: 0.03431\n",
            "Epoch: 9 | Iteration: 2570 | Classification loss: 0.00003 | Regression loss: 0.02014 | Running loss: 0.03431\n",
            "Epoch: 9 | Iteration: 2571 | Classification loss: 0.00002 | Regression loss: 0.02126 | Running loss: 0.03430\n",
            "Epoch: 9 | Iteration: 2572 | Classification loss: 0.00003 | Regression loss: 0.01646 | Running loss: 0.03430\n",
            "Epoch: 9 | Iteration: 2573 | Classification loss: 0.00016 | Regression loss: 0.01939 | Running loss: 0.03430\n",
            "Epoch: 9 | Iteration: 2574 | Classification loss: 0.00002 | Regression loss: 0.01405 | Running loss: 0.03428\n",
            "Epoch: 9 | Iteration: 2575 | Classification loss: 0.00123 | Regression loss: 0.03878 | Running loss: 0.03432\n",
            "Epoch: 9 | Iteration: 2576 | Classification loss: 0.00158 | Regression loss: 0.12549 | Running loss: 0.03454\n",
            "Epoch: 9 | Iteration: 2577 | Classification loss: 0.00165 | Regression loss: 0.01469 | Running loss: 0.03454\n",
            "Epoch: 9 | Iteration: 2578 | Classification loss: 0.00004 | Regression loss: 0.03471 | Running loss: 0.03454\n",
            "Epoch: 9 | Iteration: 2579 | Classification loss: 0.00003 | Regression loss: 0.01254 | Running loss: 0.03454\n",
            "Epoch: 9 | Iteration: 2580 | Classification loss: 0.00076 | Regression loss: 0.00907 | Running loss: 0.03443\n",
            "Epoch: 9 | Iteration: 2581 | Classification loss: 0.00018 | Regression loss: 0.01803 | Running loss: 0.03442\n",
            "Epoch: 9 | Iteration: 2582 | Classification loss: 0.00003 | Regression loss: 0.00976 | Running loss: 0.03439\n",
            "Epoch: 9 | Iteration: 2583 | Classification loss: 0.00013 | Regression loss: 0.06945 | Running loss: 0.03449\n",
            "Epoch: 9 | Iteration: 2584 | Classification loss: 0.00020 | Regression loss: 0.01316 | Running loss: 0.03442\n",
            "Epoch: 9 | Iteration: 2585 | Classification loss: 0.00060 | Regression loss: 0.02843 | Running loss: 0.03440\n",
            "Epoch: 9 | Iteration: 2586 | Classification loss: 0.00023 | Regression loss: 0.02986 | Running loss: 0.03435\n",
            "Epoch: 9 | Iteration: 2587 | Classification loss: 0.00024 | Regression loss: 0.03298 | Running loss: 0.03435\n",
            "Epoch: 9 | Iteration: 2588 | Classification loss: 0.00007 | Regression loss: 0.01579 | Running loss: 0.03429\n",
            "Epoch: 9 | Iteration: 2589 | Classification loss: 0.00160 | Regression loss: 0.02246 | Running loss: 0.03424\n",
            "Epoch: 9 | Iteration: 2590 | Classification loss: 0.00005 | Regression loss: 0.03621 | Running loss: 0.03425\n",
            "Epoch: 9 | Iteration: 2591 | Classification loss: 0.00001 | Regression loss: 0.01784 | Running loss: 0.03424\n",
            "Epoch: 9 | Iteration: 2592 | Classification loss: 0.00068 | Regression loss: 0.01943 | Running loss: 0.03422\n",
            "Epoch: 9 | Iteration: 2593 | Classification loss: 0.00026 | Regression loss: 0.07137 | Running loss: 0.03433\n",
            "Epoch: 9 | Iteration: 2594 | Classification loss: 0.00006 | Regression loss: 0.02945 | Running loss: 0.03427\n",
            "Epoch: 9 | Iteration: 2595 | Classification loss: 0.00022 | Regression loss: 0.00711 | Running loss: 0.03418\n",
            "Epoch: 9 | Iteration: 2596 | Classification loss: 0.00006 | Regression loss: 0.00853 | Running loss: 0.03416\n",
            "Epoch: 9 | Iteration: 2597 | Classification loss: 0.00301 | Regression loss: 0.03826 | Running loss: 0.03421\n",
            "Epoch: 9 | Iteration: 2598 | Classification loss: 0.00006 | Regression loss: 0.01446 | Running loss: 0.03421\n",
            "Epoch: 9 | Iteration: 2599 | Classification loss: 0.00003 | Regression loss: 0.02079 | Running loss: 0.03419\n",
            "Epoch: 9 | Iteration: 2600 | Classification loss: 0.00436 | Regression loss: 0.05386 | Running loss: 0.03426\n",
            "Epoch: 9 | Iteration: 2601 | Classification loss: 0.00029 | Regression loss: 0.01448 | Running loss: 0.03428\n",
            "Epoch: 9 | Iteration: 2602 | Classification loss: 0.00003 | Regression loss: 0.03529 | Running loss: 0.03428\n",
            "Epoch: 9 | Iteration: 2603 | Classification loss: 0.00586 | Regression loss: 0.01794 | Running loss: 0.03431\n",
            "Epoch: 9 | Iteration: 2604 | Classification loss: 0.00015 | Regression loss: 0.02899 | Running loss: 0.03435\n",
            "Epoch: 9 | Iteration: 2605 | Classification loss: 0.00048 | Regression loss: 0.01395 | Running loss: 0.03432\n",
            "Epoch: 9 | Iteration: 2606 | Classification loss: 0.00018 | Regression loss: 0.01638 | Running loss: 0.03432\n",
            "Epoch: 9 | Iteration: 2607 | Classification loss: 0.00020 | Regression loss: 0.02089 | Running loss: 0.03427\n",
            "Epoch: 9 | Iteration: 2608 | Classification loss: 0.00034 | Regression loss: 0.01304 | Running loss: 0.03424\n",
            "Epoch: 9 | Iteration: 2609 | Classification loss: 0.01585 | Regression loss: 0.06233 | Running loss: 0.03437\n",
            "Epoch: 9 | Iteration: 2610 | Classification loss: 0.00006 | Regression loss: 0.01892 | Running loss: 0.03439\n",
            "Epoch: 9 | Iteration: 2611 | Classification loss: 0.00050 | Regression loss: 0.01347 | Running loss: 0.03433\n",
            "Epoch: 9 | Iteration: 2612 | Classification loss: 0.00018 | Regression loss: 0.04149 | Running loss: 0.03429\n",
            "Epoch: 9 | Iteration: 2613 | Classification loss: 0.00157 | Regression loss: 0.02830 | Running loss: 0.03426\n",
            "Epoch: 9 | Iteration: 2614 | Classification loss: 0.00009 | Regression loss: 0.03983 | Running loss: 0.03430\n",
            "Epoch: 9 | Iteration: 2615 | Classification loss: 0.00703 | Regression loss: 0.03490 | Running loss: 0.03433\n",
            "Epoch: 9 | Iteration: 2616 | Classification loss: 0.00067 | Regression loss: 0.03591 | Running loss: 0.03436\n",
            "Epoch: 9 | Iteration: 2617 | Classification loss: 0.00021 | Regression loss: 0.03089 | Running loss: 0.03436\n",
            "Epoch: 9 | Iteration: 2618 | Classification loss: 0.00019 | Regression loss: 0.01407 | Running loss: 0.03435\n",
            "Epoch: 9 | Iteration: 2619 | Classification loss: 0.00056 | Regression loss: 0.02808 | Running loss: 0.03438\n",
            "Epoch: 9 | Iteration: 2620 | Classification loss: 0.00013 | Regression loss: 0.01987 | Running loss: 0.03439\n",
            "Epoch: 9 | Iteration: 2621 | Classification loss: 0.00003 | Regression loss: 0.04272 | Running loss: 0.03438\n",
            "Epoch: 9 | Iteration: 2622 | Classification loss: 0.00017 | Regression loss: 0.02729 | Running loss: 0.03440\n",
            "Epoch: 9 | Iteration: 2623 | Classification loss: 0.00025 | Regression loss: 0.01549 | Running loss: 0.03432\n",
            "Epoch: 9 | Iteration: 2624 | Classification loss: 0.00035 | Regression loss: 0.02582 | Running loss: 0.03432\n",
            "Epoch: 9 | Iteration: 2625 | Classification loss: 0.00021 | Regression loss: 0.01278 | Running loss: 0.03431\n",
            "Epoch: 9 | Iteration: 2626 | Classification loss: 0.00002 | Regression loss: 0.01730 | Running loss: 0.03431\n",
            "Epoch: 9 | Iteration: 2627 | Classification loss: 0.00020 | Regression loss: 0.03904 | Running loss: 0.03429\n",
            "Epoch: 9 | Iteration: 2628 | Classification loss: 0.00033 | Regression loss: 0.02436 | Running loss: 0.03432\n",
            "Epoch: 9 | Iteration: 2629 | Classification loss: 0.00173 | Regression loss: 0.04528 | Running loss: 0.03437\n",
            "Epoch: 9 | Iteration: 2630 | Classification loss: 0.00921 | Regression loss: 0.16661 | Running loss: 0.03466\n",
            "Epoch: 9 | Iteration: 2631 | Classification loss: 0.00008 | Regression loss: 0.01912 | Running loss: 0.03467\n",
            "Epoch: 9 | Iteration: 2632 | Classification loss: 0.00011 | Regression loss: 0.01254 | Running loss: 0.03467\n",
            "Epoch: 9 | Iteration: 2633 | Classification loss: 0.00029 | Regression loss: 0.03483 | Running loss: 0.03466\n",
            "Epoch: 9 | Iteration: 2634 | Classification loss: 0.01243 | Regression loss: 0.03953 | Running loss: 0.03472\n",
            "Epoch: 9 | Iteration: 2635 | Classification loss: 0.00019 | Regression loss: 0.01946 | Running loss: 0.03473\n",
            "Epoch: 9 | Iteration: 2636 | Classification loss: 0.00012 | Regression loss: 0.01330 | Running loss: 0.03472\n",
            "Epoch: 9 | Iteration: 2637 | Classification loss: 0.00003 | Regression loss: 0.01128 | Running loss: 0.03469\n",
            "Epoch: 9 | Iteration: 2638 | Classification loss: 0.00093 | Regression loss: 0.02276 | Running loss: 0.03469\n",
            "Epoch: 9 | Iteration: 2639 | Classification loss: 0.00022 | Regression loss: 0.01493 | Running loss: 0.03469\n",
            "Epoch: 9 | Iteration: 2640 | Classification loss: 0.00010 | Regression loss: 0.01214 | Running loss: 0.03467\n",
            "Epoch: 9 | Iteration: 2641 | Classification loss: 0.00019 | Regression loss: 0.00754 | Running loss: 0.03453\n",
            "Epoch: 9 | Iteration: 2642 | Classification loss: 0.00007 | Regression loss: 0.02673 | Running loss: 0.03453\n",
            "Epoch: 9 | Iteration: 2643 | Classification loss: 0.00097 | Regression loss: 0.03334 | Running loss: 0.03458\n",
            "Epoch: 9 | Iteration: 2644 | Classification loss: 0.00036 | Regression loss: 0.03293 | Running loss: 0.03453\n",
            "Epoch: 9 | Iteration: 2645 | Classification loss: 0.00001 | Regression loss: 0.02018 | Running loss: 0.03451\n",
            "Epoch: 9 | Iteration: 2646 | Classification loss: 0.00001 | Regression loss: 0.02657 | Running loss: 0.03453\n",
            "Epoch: 9 | Iteration: 2647 | Classification loss: 0.00004 | Regression loss: 0.02438 | Running loss: 0.03455\n",
            "Epoch: 9 | Iteration: 2648 | Classification loss: 0.00093 | Regression loss: 0.01701 | Running loss: 0.03457\n",
            "Epoch: 9 | Iteration: 2649 | Classification loss: 0.00016 | Regression loss: 0.02330 | Running loss: 0.03457\n",
            "Epoch: 9 | Iteration: 2650 | Classification loss: 0.00115 | Regression loss: 0.02347 | Running loss: 0.03456\n",
            "Epoch: 9 | Iteration: 2651 | Classification loss: 0.00019 | Regression loss: 0.03371 | Running loss: 0.03455\n",
            "Epoch: 9 | Iteration: 2652 | Classification loss: 0.00006 | Regression loss: 0.01794 | Running loss: 0.03456\n",
            "Epoch: 9 | Iteration: 2653 | Classification loss: 0.00002 | Regression loss: 0.01165 | Running loss: 0.03452\n",
            "Epoch: 9 | Iteration: 2654 | Classification loss: 0.00008 | Regression loss: 0.01583 | Running loss: 0.03453\n",
            "Epoch: 9 | Iteration: 2655 | Classification loss: 0.00001 | Regression loss: 0.00959 | Running loss: 0.03453\n",
            "Epoch: 9 | Iteration: 2656 | Classification loss: 0.00022 | Regression loss: 0.01388 | Running loss: 0.03453\n",
            "Epoch: 9 | Iteration: 2657 | Classification loss: 0.00006 | Regression loss: 0.01539 | Running loss: 0.03454\n",
            "Epoch: 9 | Iteration: 2658 | Classification loss: 0.00047 | Regression loss: 0.02588 | Running loss: 0.03456\n",
            "Epoch: 9 | Iteration: 2659 | Classification loss: 0.00008 | Regression loss: 0.01654 | Running loss: 0.03455\n",
            "Epoch: 9 | Iteration: 2660 | Classification loss: 0.00005 | Regression loss: 0.02888 | Running loss: 0.03453\n",
            "Epoch: 9 | Iteration: 2661 | Classification loss: 0.00015 | Regression loss: 0.01985 | Running loss: 0.03455\n",
            "Epoch: 9 | Iteration: 2662 | Classification loss: 0.00004 | Regression loss: 0.00678 | Running loss: 0.03454\n",
            "Epoch: 9 | Iteration: 2663 | Classification loss: 0.00009 | Regression loss: 0.01369 | Running loss: 0.03449\n",
            "Epoch: 9 | Iteration: 2664 | Classification loss: 0.00007 | Regression loss: 0.03950 | Running loss: 0.03440\n",
            "Epoch: 9 | Iteration: 2665 | Classification loss: 0.00001 | Regression loss: 0.01680 | Running loss: 0.03327\n",
            "Epoch: 9 | Iteration: 2666 | Classification loss: 0.00066 | Regression loss: 0.03643 | Running loss: 0.03328\n",
            "Epoch: 9 | Iteration: 2667 | Classification loss: 0.00016 | Regression loss: 0.04284 | Running loss: 0.03333\n",
            "Epoch: 9 | Iteration: 2668 | Classification loss: 0.00013 | Regression loss: 0.02526 | Running loss: 0.03331\n",
            "Epoch: 9 | Iteration: 2669 | Classification loss: 0.00081 | Regression loss: 0.12855 | Running loss: 0.03349\n",
            "Epoch: 9 | Iteration: 2670 | Classification loss: 0.00007 | Regression loss: 0.04312 | Running loss: 0.03352\n",
            "Epoch: 9 | Iteration: 2671 | Classification loss: 0.00005 | Regression loss: 0.02330 | Running loss: 0.03353\n",
            "Epoch: 9 | Iteration: 2672 | Classification loss: 0.00001 | Regression loss: 0.01839 | Running loss: 0.03344\n",
            "Epoch: 9 | Iteration: 2673 | Classification loss: 0.00028 | Regression loss: 0.03568 | Running loss: 0.03346\n",
            "Evaluating dataset\n",
            "254/254\n",
            "mAP:\n",
            "fatigued: 0.9984976996321656\n",
            "Precision:  0.5852272727272727\n",
            "Recall:  1.0\n",
            "awake: 0.9979375022425844\n",
            "Precision:  0.5852272727272727\n",
            "Recall:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "csv_path = r\"/content/fatigue-dataset-1/train/_annotations.csv\"\n",
        "folder = \"/content/fatigue-dataset-1/train\"\n",
        "\n",
        "fixed_lines = []\n",
        "with open(csv_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        if line.strip():\n",
        "            parts = line.strip().split(\",\")\n",
        "            # Prepend the folder to the filename if not already present\n",
        "            if not parts[0].startswith(folder):\n",
        "                parts[0] = f\"{folder}/{parts[0]}\"\n",
        "            fixed_lines.append(\",\".join(parts))\n",
        "\n",
        "with open(csv_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for line in fixed_lines:\n",
        "        f.write(line + \"\\n\")"
      ],
      "metadata": {
        "id": "5hR9Fa_EHufX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r pytorch-retinanet.zip /content/pytorch-retinanet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rIYInHbyzg_",
        "outputId": "26f32402-2dd5-494b-e5e9-ebaf8469e03d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/pytorch-retinanet/ (stored 0%)\n",
            "  adding: content/pytorch-retinanet/csv_retinanet_7.pt (deflated 7%)\n",
            "  adding: content/pytorch-retinanet/csv_retinanet_6.pt (deflated 7%)\n",
            "  adding: content/pytorch-retinanet/csv_retinanet_2.pt (deflated 7%)\n",
            "  adding: content/pytorch-retinanet/csv_retinanet_1.pt (deflated 7%)\n",
            "  adding: content/pytorch-retinanet/visualize_single_image.py (deflated 63%)\n",
            "  adding: content/pytorch-retinanet/README.md (deflated 63%)\n",
            "  adding: content/pytorch-retinanet/csv_retinanet_4.pt (deflated 7%)\n",
            "  adding: content/pytorch-retinanet/csv_retinanet_0.pt (deflated 7%)\n",
            "  adding: content/pytorch-retinanet/csv_retinanet_8.pt (deflated 7%)\n",
            "  adding: content/pytorch-retinanet/model_final.pt (deflated 7%)\n",
            "  adding: content/pytorch-retinanet/visualize.py (deflated 60%)\n",
            "  adding: content/pytorch-retinanet/csv_retinanet_5.pt (deflated 7%)\n",
            "  adding: content/pytorch-retinanet/train.py (deflated 73%)\n",
            "  adding: content/pytorch-retinanet/csv_validation.py (deflated 63%)\n",
            "  adding: content/pytorch-retinanet/csv_retinanet_3.pt (deflated 7%)\n",
            "  adding: content/pytorch-retinanet/retinanet/ (stored 0%)\n",
            "  adding: content/pytorch-retinanet/retinanet/model.py (deflated 79%)\n",
            "  adding: content/pytorch-retinanet/retinanet/oid_dataset.py (deflated 74%)\n",
            "  adding: content/pytorch-retinanet/retinanet/coco_eval.py (deflated 66%)\n",
            "  adding: content/pytorch-retinanet/retinanet/dataloader.py (deflated 74%)\n",
            "  adding: content/pytorch-retinanet/retinanet/__pycache__/ (stored 0%)\n",
            "  adding: content/pytorch-retinanet/retinanet/__pycache__/losses.cpython-311.pyc (deflated 61%)\n",
            "  adding: content/pytorch-retinanet/retinanet/__pycache__/anchors.cpython-311.pyc (deflated 54%)\n",
            "  adding: content/pytorch-retinanet/retinanet/__pycache__/__init__.cpython-311.pyc (deflated 27%)\n",
            "  adding: content/pytorch-retinanet/retinanet/__pycache__/model.cpython-311.pyc (deflated 63%)\n",
            "  adding: content/pytorch-retinanet/retinanet/__pycache__/utils.cpython-311.pyc (deflated 66%)\n",
            "  adding: content/pytorch-retinanet/retinanet/__pycache__/csv_eval.cpython-311.pyc (deflated 58%)\n",
            "  adding: content/pytorch-retinanet/retinanet/__pycache__/coco_eval.cpython-311.pyc (deflated 52%)\n",
            "  adding: content/pytorch-retinanet/retinanet/__pycache__/dataloader.cpython-311.pyc (deflated 58%)\n",
            "  adding: content/pytorch-retinanet/retinanet/utils.py (deflated 78%)\n",
            "  adding: content/pytorch-retinanet/retinanet/losses.py (deflated 79%)\n",
            "  adding: content/pytorch-retinanet/retinanet/anchors.py (deflated 71%)\n",
            "  adding: content/pytorch-retinanet/retinanet/__init__.py (stored 0%)\n",
            "  adding: content/pytorch-retinanet/retinanet/csv_eval.py (deflated 73%)\n",
            "  adding: content/pytorch-retinanet/LICENSE (deflated 65%)\n",
            "  adding: content/pytorch-retinanet/.git/ (stored 0%)\n",
            "  adding: content/pytorch-retinanet/.git/info/ (stored 0%)\n",
            "  adding: content/pytorch-retinanet/.git/info/exclude (deflated 28%)\n",
            "  adding: content/pytorch-retinanet/.git/index (deflated 47%)\n",
            "  adding: content/pytorch-retinanet/.git/HEAD (stored 0%)\n",
            "  adding: content/pytorch-retinanet/.git/config (deflated 34%)\n",
            "  adding: content/pytorch-retinanet/.git/objects/ (stored 0%)\n",
            "  adding: content/pytorch-retinanet/.git/objects/info/ (stored 0%)\n",
            "  adding: content/pytorch-retinanet/.git/objects/pack/ (stored 0%)\n",
            "  adding: content/pytorch-retinanet/.git/objects/pack/pack-160d9864ee8e58be59bdba42745fb72f6ce73874.pack (deflated 0%)\n",
            "  adding: content/pytorch-retinanet/.git/objects/pack/pack-160d9864ee8e58be59bdba42745fb72f6ce73874.idx (deflated 10%)\n",
            "  adding: content/pytorch-retinanet/.git/refs/ (stored 0%)\n",
            "  adding: content/pytorch-retinanet/.git/refs/heads/ (stored 0%)\n",
            "  adding: content/pytorch-retinanet/.git/refs/heads/master (stored 0%)\n",
            "  adding: content/pytorch-retinanet/.git/refs/tags/ (stored 0%)\n",
            "  adding: content/pytorch-retinanet/.git/refs/remotes/ (stored 0%)\n",
            "  adding: content/pytorch-retinanet/.git/refs/remotes/origin/ (stored 0%)\n",
            "  adding: content/pytorch-retinanet/.git/refs/remotes/origin/HEAD (stored 0%)\n",
            "  adding: content/pytorch-retinanet/.git/packed-refs (deflated 27%)\n",
            "  adding: content/pytorch-retinanet/.git/description (deflated 14%)\n",
            "  adding: content/pytorch-retinanet/.git/logs/ (stored 0%)\n",
            "  adding: content/pytorch-retinanet/.git/logs/HEAD (deflated 28%)\n",
            "  adding: content/pytorch-retinanet/.git/logs/refs/ (stored 0%)\n",
            "  adding: content/pytorch-retinanet/.git/logs/refs/heads/ (stored 0%)\n",
            "  adding: content/pytorch-retinanet/.git/logs/refs/heads/master (deflated 28%)\n",
            "  adding: content/pytorch-retinanet/.git/logs/refs/remotes/ (stored 0%)\n",
            "  adding: content/pytorch-retinanet/.git/logs/refs/remotes/origin/ (stored 0%)\n",
            "  adding: content/pytorch-retinanet/.git/logs/refs/remotes/origin/HEAD (deflated 28%)\n",
            "  adding: content/pytorch-retinanet/.git/hooks/ (stored 0%)\n",
            "  adding: content/pytorch-retinanet/.git/hooks/pre-merge-commit.sample (deflated 39%)\n",
            "  adding: content/pytorch-retinanet/.git/hooks/update.sample (deflated 68%)\n",
            "  adding: content/pytorch-retinanet/.git/hooks/commit-msg.sample (deflated 44%)\n",
            "  adding: content/pytorch-retinanet/.git/hooks/pre-applypatch.sample (deflated 38%)\n",
            "  adding: content/pytorch-retinanet/.git/hooks/push-to-checkout.sample (deflated 55%)\n",
            "  adding: content/pytorch-retinanet/.git/hooks/pre-rebase.sample (deflated 59%)\n",
            "  adding: content/pytorch-retinanet/.git/hooks/fsmonitor-watchman.sample (deflated 62%)\n",
            "  adding: content/pytorch-retinanet/.git/hooks/pre-commit.sample (deflated 45%)\n",
            "  adding: content/pytorch-retinanet/.git/hooks/applypatch-msg.sample (deflated 42%)\n",
            "  adding: content/pytorch-retinanet/.git/hooks/post-update.sample (deflated 27%)\n",
            "  adding: content/pytorch-retinanet/.git/hooks/prepare-commit-msg.sample (deflated 50%)\n",
            "  adding: content/pytorch-retinanet/.git/hooks/pre-receive.sample (deflated 40%)\n",
            "  adding: content/pytorch-retinanet/.git/hooks/pre-push.sample (deflated 49%)\n",
            "  adding: content/pytorch-retinanet/.git/branches/ (stored 0%)\n",
            "  adding: content/pytorch-retinanet/resnet50-19c8e357.pth (deflated 7%)\n",
            "  adding: content/pytorch-retinanet/coco_validation.py (deflated 59%)\n",
            "  adding: content/pytorch-retinanet/.gitignore (deflated 45%)\n",
            "  adding: content/pytorch-retinanet/images/ (stored 0%)\n",
            "  adding: content/pytorch-retinanet/images/3.jpg (deflated 0%)\n",
            "  adding: content/pytorch-retinanet/images/6.jpg (deflated 1%)\n",
            "  adding: content/pytorch-retinanet/images/1.jpg (deflated 2%)\n",
            "  adding: content/pytorch-retinanet/images/5.jpg (deflated 1%)\n",
            "  adding: content/pytorch-retinanet/images/7.jpg (deflated 0%)\n",
            "  adding: content/pytorch-retinanet/images/4.jpg (deflated 0%)\n",
            "  adding: content/pytorch-retinanet/images/8.jpg (deflated 1%)\n",
            "  adding: content/pytorch-retinanet/csv_retinanet_9.pt (deflated 7%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('pytorch-retinanet.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "pPdeow01zZp7",
        "outputId": "7de8f8b3-3758-45af-8f3b-0fc8243e5df8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_de3615f0-de47-4aa7-8de9-002c23d0034d\", \"pytorch-retinanet.zip\", 1584454565)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/content/pytorch-retinanet\n",
        "!python csv_validation.py --csv_annotations_path \"/content/fatigue-dataset-1/valid/_annotations.csv\" --model_path '/content/content/pytorch-retinanet/model_final.pt' --images_path '/content/fatigue-dataset-1/test/002_frame8_jpg.rf.50946f27072a59c48dadf69c2c9fc4fb.jpg' --class_list_path \"/content/fatigue-dataset-1/train/class_list.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvBeoHZkz5cv",
        "outputId": "d3a078e0-04be-4c88-905d-faf0a83bbcba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/content/pytorch-retinanet\n",
            "CUDA available: True\n",
            "254/254\n",
            "mAP:\n",
            "fatigued: 0.9984976996321656\n",
            "Precision:  0.5852272727272727\n",
            "Recall:  1.0\n",
            "awake: 0.9979375022425844\n",
            "Precision:  0.5852272727272727\n",
            "Recall:  1.0\n",
            "{0: (np.float64(0.9984976996321656), 151.0), 1: (np.float64(0.9979375022425844), 103.0)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/content/pytorch-retinanet\n",
        "!python visualize.py --dataset csv --csv_classes \"/content/fatigue-dataset-1/train/class_list.csv\"  --csv_val \"/content/fatigue-dataset-1/valid/_annotations.csv\" --model '/content/content/pytorch-retinanet/model_final.pt'"
      ],
      "metadata": {
        "id": "iJbvbs_S4-ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e961769-bbcd-40ca-8acc-b5ea04c6b99e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/content/pytorch-retinanet\n",
            "Elapsed time: 0.810516357421875\n",
            "fatigued\n",
            "awake\n",
            "Saved image to /content/visualized_0.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.09230637550354004\n",
            "fatigued\n",
            "fatigued\n",
            "Saved image to /content/visualized_1.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.09234881401062012\n",
            "fatigued\n",
            "Saved image to /content/visualized_2.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05889177322387695\n",
            "fatigued\n",
            "Saved image to /content/visualized_3.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.06836199760437012\n",
            "fatigued\n",
            "Saved image to /content/visualized_4.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05641794204711914\n",
            "awake\n",
            "Saved image to /content/visualized_5.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05571556091308594\n",
            "awake\n",
            "Saved image to /content/visualized_6.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05512380599975586\n",
            "awake\n",
            "Saved image to /content/visualized_7.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05563950538635254\n",
            "fatigued\n",
            "Saved image to /content/visualized_8.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05500340461730957\n",
            "fatigued\n",
            "awake\n",
            "Saved image to /content/visualized_9.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05391693115234375\n",
            "awake\n",
            "Saved image to /content/visualized_10.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.058585166931152344\n",
            "awake\n",
            "Saved image to /content/visualized_11.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.053961992263793945\n",
            "awake\n",
            "Saved image to /content/visualized_12.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05354452133178711\n",
            "fatigued\n",
            "Saved image to /content/visualized_13.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0569150447845459\n",
            "awake\n",
            "Saved image to /content/visualized_14.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0562281608581543\n",
            "fatigued\n",
            "Saved image to /content/visualized_15.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05219697952270508\n",
            "awake\n",
            "Saved image to /content/visualized_16.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.055901288986206055\n",
            "awake\n",
            "Saved image to /content/visualized_17.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.052820682525634766\n",
            "awake\n",
            "Saved image to /content/visualized_18.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05265188217163086\n",
            "awake\n",
            "Saved image to /content/visualized_19.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05232644081115723\n",
            "awake\n",
            "Saved image to /content/visualized_20.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.052327871322631836\n",
            "fatigued\n",
            "awake\n",
            "Saved image to /content/visualized_21.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05169320106506348\n",
            "awake\n",
            "Saved image to /content/visualized_22.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05208253860473633\n",
            "fatigued\n",
            "Saved image to /content/visualized_23.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05390667915344238\n",
            "fatigued\n",
            "Saved image to /content/visualized_24.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.052352190017700195\n",
            "awake\n",
            "Saved image to /content/visualized_25.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05118680000305176\n",
            "awake\n",
            "Saved image to /content/visualized_26.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.050817012786865234\n",
            "awake\n",
            "Saved image to /content/visualized_27.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05098915100097656\n",
            "awake\n",
            "Saved image to /content/visualized_28.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05125594139099121\n",
            "awake\n",
            "Saved image to /content/visualized_29.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.051325321197509766\n",
            "fatigued\n",
            "Saved image to /content/visualized_30.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05198311805725098\n",
            "awake\n",
            "Saved image to /content/visualized_31.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05201601982116699\n",
            "fatigued\n",
            "Saved image to /content/visualized_32.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.050827980041503906\n",
            "fatigued\n",
            "Saved image to /content/visualized_33.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05106329917907715\n",
            "fatigued\n",
            "Saved image to /content/visualized_34.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05250668525695801\n",
            "fatigued\n",
            "Saved image to /content/visualized_35.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05179286003112793\n",
            "fatigued\n",
            "Saved image to /content/visualized_36.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05178570747375488\n",
            "awake\n",
            "Saved image to /content/visualized_37.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.051405906677246094\n",
            "awake\n",
            "Saved image to /content/visualized_38.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05266904830932617\n",
            "fatigued\n",
            "Saved image to /content/visualized_39.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05142974853515625\n",
            "awake\n",
            "Saved image to /content/visualized_40.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.050775766372680664\n",
            "awake\n",
            "Saved image to /content/visualized_41.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.051731109619140625\n",
            "awake\n",
            "Saved image to /content/visualized_42.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05099749565124512\n",
            "fatigued\n",
            "Saved image to /content/visualized_43.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.053458213806152344\n",
            "fatigued\n",
            "Saved image to /content/visualized_44.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05526113510131836\n",
            "fatigued\n",
            "Saved image to /content/visualized_45.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0507965087890625\n",
            "awake\n",
            "Saved image to /content/visualized_46.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0558619499206543\n",
            "awake\n",
            "Saved image to /content/visualized_47.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05154585838317871\n",
            "fatigued\n",
            "Saved image to /content/visualized_48.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05201435089111328\n",
            "fatigued\n",
            "Saved image to /content/visualized_49.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05097532272338867\n",
            "fatigued\n",
            "Saved image to /content/visualized_50.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05469226837158203\n",
            "fatigued\n",
            "Saved image to /content/visualized_51.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.052710771560668945\n",
            "fatigued\n",
            "Saved image to /content/visualized_52.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05417823791503906\n",
            "fatigued\n",
            "awake\n",
            "Saved image to /content/visualized_53.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05330777168273926\n",
            "awake\n",
            "Saved image to /content/visualized_54.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.053696393966674805\n",
            "awake\n",
            "Saved image to /content/visualized_55.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05322599411010742\n",
            "fatigued\n",
            "Saved image to /content/visualized_56.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05607414245605469\n",
            "fatigued\n",
            "Saved image to /content/visualized_57.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05564570426940918\n",
            "fatigued\n",
            "Saved image to /content/visualized_58.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0531306266784668\n",
            "fatigued\n",
            "Saved image to /content/visualized_59.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.052361249923706055\n",
            "fatigued\n",
            "Saved image to /content/visualized_60.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05210614204406738\n",
            "awake\n",
            "Saved image to /content/visualized_61.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05144667625427246\n",
            "awake\n",
            "Saved image to /content/visualized_62.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05260801315307617\n",
            "fatigued\n",
            "Saved image to /content/visualized_63.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.052359580993652344\n",
            "awake\n",
            "Saved image to /content/visualized_64.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05090737342834473\n",
            "awake\n",
            "Saved image to /content/visualized_65.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05234098434448242\n",
            "fatigued\n",
            "Saved image to /content/visualized_66.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05208897590637207\n",
            "fatigued\n",
            "Saved image to /content/visualized_67.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05228734016418457\n",
            "fatigued\n",
            "Saved image to /content/visualized_68.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05233144760131836\n",
            "fatigued\n",
            "Saved image to /content/visualized_69.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05857658386230469\n",
            "awake\n",
            "Saved image to /content/visualized_70.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.06229519844055176\n",
            "awake\n",
            "Saved image to /content/visualized_71.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0675511360168457\n",
            "fatigued\n",
            "Saved image to /content/visualized_72.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.06517624855041504\n",
            "awake\n",
            "Saved image to /content/visualized_73.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.058992624282836914\n",
            "fatigued\n",
            "Saved image to /content/visualized_74.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0607149600982666\n",
            "fatigued\n",
            "Saved image to /content/visualized_75.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0800776481628418\n",
            "awake\n",
            "Saved image to /content/visualized_76.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.07372856140136719\n",
            "awake\n",
            "Saved image to /content/visualized_77.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.08006119728088379\n",
            "awake\n",
            "Saved image to /content/visualized_78.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0777132511138916\n",
            "awake\n",
            "Saved image to /content/visualized_79.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.06943464279174805\n",
            "fatigued\n",
            "Saved image to /content/visualized_80.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.07173776626586914\n",
            "fatigued\n",
            "Saved image to /content/visualized_81.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.069091796875\n",
            "fatigued\n",
            "Saved image to /content/visualized_82.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0697324275970459\n",
            "awake\n",
            "Saved image to /content/visualized_83.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.06736397743225098\n",
            "fatigued\n",
            "Saved image to /content/visualized_84.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.06284594535827637\n",
            "fatigued\n",
            "Saved image to /content/visualized_85.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.06212258338928223\n",
            "fatigued\n",
            "Saved image to /content/visualized_86.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.06990337371826172\n",
            "awake\n",
            "Saved image to /content/visualized_87.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.07455587387084961\n",
            "fatigued\n",
            "Saved image to /content/visualized_88.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.06168103218078613\n",
            "fatigued\n",
            "Saved image to /content/visualized_89.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.061074018478393555\n",
            "awake\n",
            "Saved image to /content/visualized_90.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.060323476791381836\n",
            "awake\n",
            "Saved image to /content/visualized_91.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.059848785400390625\n",
            "awake\n",
            "Saved image to /content/visualized_92.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.061379432678222656\n",
            "fatigued\n",
            "Saved image to /content/visualized_93.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05368924140930176\n",
            "fatigued\n",
            "Saved image to /content/visualized_94.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05675339698791504\n",
            "awake\n",
            "Saved image to /content/visualized_95.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05413699150085449\n",
            "awake\n",
            "Saved image to /content/visualized_96.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05406045913696289\n",
            "fatigued\n",
            "Saved image to /content/visualized_97.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05435895919799805\n",
            "awake\n",
            "Saved image to /content/visualized_98.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05351448059082031\n",
            "awake\n",
            "Saved image to /content/visualized_99.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05366158485412598\n",
            "awake\n",
            "Saved image to /content/visualized_100.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05368351936340332\n",
            "awake\n",
            "Saved image to /content/visualized_101.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05299639701843262\n",
            "awake\n",
            "Saved image to /content/visualized_102.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.054404258728027344\n",
            "fatigued\n",
            "Saved image to /content/visualized_103.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05453062057495117\n",
            "fatigued\n",
            "Saved image to /content/visualized_104.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05418515205383301\n",
            "fatigued\n",
            "Saved image to /content/visualized_105.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05333828926086426\n",
            "fatigued\n",
            "fatigued\n",
            "Saved image to /content/visualized_106.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.053876638412475586\n",
            "fatigued\n",
            "Saved image to /content/visualized_107.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05382704734802246\n",
            "fatigued\n",
            "Saved image to /content/visualized_108.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.053160667419433594\n",
            "awake\n",
            "Saved image to /content/visualized_109.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05293011665344238\n",
            "fatigued\n",
            "Saved image to /content/visualized_110.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.052351951599121094\n",
            "awake\n",
            "Saved image to /content/visualized_111.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.052430152893066406\n",
            "fatigued\n",
            "Saved image to /content/visualized_112.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05257463455200195\n",
            "awake\n",
            "Saved image to /content/visualized_113.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05435895919799805\n",
            "awake\n",
            "Saved image to /content/visualized_114.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0540468692779541\n",
            "awake\n",
            "Saved image to /content/visualized_115.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05242657661437988\n",
            "fatigued\n",
            "Saved image to /content/visualized_116.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.06891059875488281\n",
            "fatigued\n",
            "awake\n",
            "Saved image to /content/visualized_117.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.052813053131103516\n",
            "fatigued\n",
            "Saved image to /content/visualized_118.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05279254913330078\n",
            "fatigued\n",
            "Saved image to /content/visualized_119.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0533139705657959\n",
            "fatigued\n",
            "Saved image to /content/visualized_120.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05350995063781738\n",
            "fatigued\n",
            "Saved image to /content/visualized_121.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05287981033325195\n",
            "fatigued\n",
            "Saved image to /content/visualized_122.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.053177833557128906\n",
            "awake\n",
            "Saved image to /content/visualized_123.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05336785316467285\n",
            "fatigued\n",
            "Saved image to /content/visualized_124.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05174708366394043\n",
            "awake\n",
            "Saved image to /content/visualized_125.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0522456169128418\n",
            "awake\n",
            "Saved image to /content/visualized_126.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.051789283752441406\n",
            "awake\n",
            "Saved image to /content/visualized_127.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05468297004699707\n",
            "fatigued\n",
            "Saved image to /content/visualized_128.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.052043914794921875\n",
            "awake\n",
            "Saved image to /content/visualized_129.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05351996421813965\n",
            "awake\n",
            "Saved image to /content/visualized_130.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.053304195404052734\n",
            "fatigued\n",
            "Saved image to /content/visualized_131.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05106830596923828\n",
            "fatigued\n",
            "Saved image to /content/visualized_132.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0509943962097168\n",
            "fatigued\n",
            "Saved image to /content/visualized_133.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05245852470397949\n",
            "fatigued\n",
            "Saved image to /content/visualized_134.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05437016487121582\n",
            "awake\n",
            "Saved image to /content/visualized_135.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05135631561279297\n",
            "awake\n",
            "Saved image to /content/visualized_136.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.052280426025390625\n",
            "awake\n",
            "Saved image to /content/visualized_137.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0517730712890625\n",
            "awake\n",
            "Saved image to /content/visualized_138.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.055403947830200195\n",
            "fatigued\n",
            "Saved image to /content/visualized_139.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.052277565002441406\n",
            "fatigued\n",
            "awake\n",
            "Saved image to /content/visualized_140.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05104422569274902\n",
            "awake\n",
            "Saved image to /content/visualized_141.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05217385292053223\n",
            "fatigued\n",
            "Saved image to /content/visualized_142.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.050850868225097656\n",
            "fatigued\n",
            "Saved image to /content/visualized_143.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05474352836608887\n",
            "fatigued\n",
            "Saved image to /content/visualized_144.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05518484115600586\n",
            "awake\n",
            "Saved image to /content/visualized_145.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.07101559638977051\n",
            "fatigued\n",
            "awake\n",
            "Saved image to /content/visualized_146.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.052129268646240234\n",
            "fatigued\n",
            "awake\n",
            "Saved image to /content/visualized_147.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05229926109313965\n",
            "fatigued\n",
            "Saved image to /content/visualized_148.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.07398867607116699\n",
            "fatigued\n",
            "Saved image to /content/visualized_149.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.08028149604797363\n",
            "fatigued\n",
            "Saved image to /content/visualized_150.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0565495491027832\n",
            "fatigued\n",
            "Saved image to /content/visualized_151.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.08804154396057129\n",
            "awake\n",
            "Saved image to /content/visualized_152.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.08995938301086426\n",
            "awake\n",
            "Saved image to /content/visualized_153.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05751299858093262\n",
            "awake\n",
            "Saved image to /content/visualized_154.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.07461333274841309\n",
            "fatigued\n",
            "Saved image to /content/visualized_155.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.08485078811645508\n",
            "fatigued\n",
            "Saved image to /content/visualized_156.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.08030867576599121\n",
            "fatigued\n",
            "Saved image to /content/visualized_157.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.07544207572937012\n",
            "fatigued\n",
            "Saved image to /content/visualized_158.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0735619068145752\n",
            "fatigued\n",
            "Saved image to /content/visualized_159.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.08442854881286621\n",
            "awake\n",
            "Saved image to /content/visualized_160.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0770263671875\n",
            "fatigued\n",
            "Saved image to /content/visualized_161.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.07816123962402344\n",
            "fatigued\n",
            "Saved image to /content/visualized_162.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.06222224235534668\n",
            "fatigued\n",
            "Saved image to /content/visualized_163.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.062206268310546875\n",
            "fatigued\n",
            "Saved image to /content/visualized_164.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.06078052520751953\n",
            "fatigued\n",
            "Saved image to /content/visualized_165.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05969095230102539\n",
            "fatigued\n",
            "Saved image to /content/visualized_166.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05730867385864258\n",
            "awake\n",
            "Saved image to /content/visualized_167.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05762934684753418\n",
            "fatigued\n",
            "Saved image to /content/visualized_168.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0568084716796875\n",
            "fatigued\n",
            "Saved image to /content/visualized_169.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05741477012634277\n",
            "fatigued\n",
            "Saved image to /content/visualized_170.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05680704116821289\n",
            "fatigued\n",
            "Saved image to /content/visualized_171.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.07122325897216797\n",
            "fatigued\n",
            "awake\n",
            "Saved image to /content/visualized_172.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05750560760498047\n",
            "fatigued\n",
            "Saved image to /content/visualized_173.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05745744705200195\n",
            "fatigued\n",
            "Saved image to /content/visualized_174.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05318164825439453\n",
            "fatigued\n",
            "Saved image to /content/visualized_175.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.052754878997802734\n",
            "fatigued\n",
            "Saved image to /content/visualized_176.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05220460891723633\n",
            "fatigued\n",
            "Saved image to /content/visualized_177.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05124664306640625\n",
            "awake\n",
            "Saved image to /content/visualized_178.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.056025028228759766\n",
            "fatigued\n",
            "Saved image to /content/visualized_179.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05257105827331543\n",
            "awake\n",
            "Saved image to /content/visualized_180.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05091977119445801\n",
            "awake\n",
            "Saved image to /content/visualized_181.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05658292770385742\n",
            "fatigued\n",
            "Saved image to /content/visualized_182.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.051043033599853516\n",
            "fatigued\n",
            "Saved image to /content/visualized_183.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05093097686767578\n",
            "fatigued\n",
            "Saved image to /content/visualized_184.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05139732360839844\n",
            "awake\n",
            "Saved image to /content/visualized_185.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05120372772216797\n",
            "awake\n",
            "Saved image to /content/visualized_186.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05162334442138672\n",
            "awake\n",
            "Saved image to /content/visualized_187.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05165600776672363\n",
            "awake\n",
            "Saved image to /content/visualized_188.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.07550549507141113\n",
            "awake\n",
            "Saved image to /content/visualized_189.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0530552864074707\n",
            "fatigued\n",
            "Saved image to /content/visualized_190.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0521845817565918\n",
            "awake\n",
            "Saved image to /content/visualized_191.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.051911115646362305\n",
            "awake\n",
            "Saved image to /content/visualized_192.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05253958702087402\n",
            "fatigued\n",
            "Saved image to /content/visualized_193.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05130815505981445\n",
            "awake\n",
            "Saved image to /content/visualized_194.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.051123857498168945\n",
            "awake\n",
            "Saved image to /content/visualized_195.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05250883102416992\n",
            "awake\n",
            "Saved image to /content/visualized_196.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05293679237365723\n",
            "fatigued\n",
            "Saved image to /content/visualized_197.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.055510520935058594\n",
            "fatigued\n",
            "awake\n",
            "Saved image to /content/visualized_198.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05201125144958496\n",
            "awake\n",
            "Saved image to /content/visualized_199.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05217742919921875\n",
            "awake\n",
            "Saved image to /content/visualized_200.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0518646240234375\n",
            "fatigued\n",
            "Saved image to /content/visualized_201.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05125236511230469\n",
            "fatigued\n",
            "Saved image to /content/visualized_202.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.052712440490722656\n",
            "awake\n",
            "Saved image to /content/visualized_203.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.059630632400512695\n",
            "fatigued\n",
            "Saved image to /content/visualized_204.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05212688446044922\n",
            "awake\n",
            "Saved image to /content/visualized_205.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.052646636962890625\n",
            "fatigued\n",
            "awake\n",
            "Saved image to /content/visualized_206.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.052544593811035156\n",
            "awake\n",
            "Saved image to /content/visualized_207.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.051540374755859375\n",
            "awake\n",
            "Saved image to /content/visualized_208.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05239391326904297\n",
            "fatigued\n",
            "Saved image to /content/visualized_209.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05621027946472168\n",
            "awake\n",
            "Saved image to /content/visualized_210.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.07808160781860352\n",
            "fatigued\n",
            "awake\n",
            "Saved image to /content/visualized_211.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0561220645904541\n",
            "fatigued\n",
            "awake\n",
            "Saved image to /content/visualized_212.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05571722984313965\n",
            "fatigued\n",
            "Saved image to /content/visualized_213.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05714011192321777\n",
            "fatigued\n",
            "Saved image to /content/visualized_214.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05784153938293457\n",
            "fatigued\n",
            "Saved image to /content/visualized_215.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0530393123626709\n",
            "fatigued\n",
            "Saved image to /content/visualized_216.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05319499969482422\n",
            "fatigued\n",
            "Saved image to /content/visualized_217.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.057511091232299805\n",
            "fatigued\n",
            "Saved image to /content/visualized_218.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05171990394592285\n",
            "awake\n",
            "Saved image to /content/visualized_219.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.052870988845825195\n",
            "fatigued\n",
            "Saved image to /content/visualized_220.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05350136756896973\n",
            "fatigued\n",
            "Saved image to /content/visualized_221.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.052037715911865234\n",
            "fatigued\n",
            "Saved image to /content/visualized_222.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05155134201049805\n",
            "fatigued\n",
            "Saved image to /content/visualized_223.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.051351070404052734\n",
            "awake\n",
            "Saved image to /content/visualized_224.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.051125526428222656\n",
            "awake\n",
            "Saved image to /content/visualized_225.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.051715850830078125\n",
            "fatigued\n",
            "Saved image to /content/visualized_226.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05159926414489746\n",
            "awake\n",
            "Saved image to /content/visualized_227.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05341362953186035\n",
            "fatigued\n",
            "Saved image to /content/visualized_228.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.051763296127319336\n",
            "fatigued\n",
            "Saved image to /content/visualized_229.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.07910537719726562\n",
            "fatigued\n",
            "Saved image to /content/visualized_230.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0675506591796875\n",
            "fatigued\n",
            "Saved image to /content/visualized_231.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.06395673751831055\n",
            "fatigued\n",
            "Saved image to /content/visualized_232.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.06336641311645508\n",
            "fatigued\n",
            "Saved image to /content/visualized_233.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0562591552734375\n",
            "fatigued\n",
            "Saved image to /content/visualized_234.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05333876609802246\n",
            "fatigued\n",
            "Saved image to /content/visualized_235.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05745434761047363\n",
            "fatigued\n",
            "Saved image to /content/visualized_236.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.07909083366394043\n",
            "fatigued\n",
            "awake\n",
            "Saved image to /content/visualized_237.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.07614994049072266\n",
            "awake\n",
            "Saved image to /content/visualized_238.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.07735657691955566\n",
            "awake\n",
            "Saved image to /content/visualized_239.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.07909011840820312\n",
            "awake\n",
            "Saved image to /content/visualized_240.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.07374191284179688\n",
            "fatigued\n",
            "awake\n",
            "Saved image to /content/visualized_241.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.07457423210144043\n",
            "fatigued\n",
            "awake\n",
            "Saved image to /content/visualized_242.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.06506109237670898\n",
            "awake\n",
            "Saved image to /content/visualized_243.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.0648658275604248\n",
            "awake\n",
            "Saved image to /content/visualized_244.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.06470870971679688\n",
            "awake\n",
            "Saved image to /content/visualized_245.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05781865119934082\n",
            "fatigued\n",
            "Saved image to /content/visualized_246.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.06332659721374512\n",
            "fatigued\n",
            "Saved image to /content/visualized_247.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05637097358703613\n",
            "fatigued\n",
            "Saved image to /content/visualized_248.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05602693557739258\n",
            "fatigued\n",
            "Saved image to /content/visualized_249.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.056002140045166016\n",
            "awake\n",
            "Saved image to /content/visualized_250.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05546236038208008\n",
            "fatigued\n",
            "Saved image to /content/visualized_251.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.05615234375\n",
            "fatigued\n",
            "Saved image to /content/visualized_252.jpg\n",
            "<IPython.core.display.Image object>\n",
            "Elapsed time: 0.04987764358520508\n",
            "fatigued\n",
            "Saved image to /content/visualized_253.jpg\n",
            "<IPython.core.display.Image object>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/pytorch-retinanet.zip -d /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJzfTcCROT8q",
        "outputId": "703c51a1-7a97-42bd-fcb9-99a5ef693718"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/pytorch-retinanet.zip\n",
            "   creating: /content/content/pytorch-retinanet/\n",
            "  inflating: /content/content/pytorch-retinanet/csv_retinanet_7.pt  \n",
            "  inflating: /content/content/pytorch-retinanet/csv_retinanet_6.pt  \n",
            "  inflating: /content/content/pytorch-retinanet/csv_retinanet_2.pt  \n",
            "  inflating: /content/content/pytorch-retinanet/csv_retinanet_1.pt  \n",
            "  inflating: /content/content/pytorch-retinanet/visualize_single_image.py  \n",
            "  inflating: /content/content/pytorch-retinanet/README.md  \n",
            "  inflating: /content/content/pytorch-retinanet/csv_retinanet_4.pt  \n",
            "  inflating: /content/content/pytorch-retinanet/csv_retinanet_0.pt  \n",
            "  inflating: /content/content/pytorch-retinanet/csv_retinanet_8.pt  \n",
            "  inflating: /content/content/pytorch-retinanet/model_final.pt  \n",
            "  inflating: /content/content/pytorch-retinanet/visualize.py  \n",
            "  inflating: /content/content/pytorch-retinanet/csv_retinanet_5.pt  \n",
            "  inflating: /content/content/pytorch-retinanet/train.py  \n",
            "  inflating: /content/content/pytorch-retinanet/csv_validation.py  \n",
            "  inflating: /content/content/pytorch-retinanet/csv_retinanet_3.pt  \n",
            "   creating: /content/content/pytorch-retinanet/retinanet/\n",
            "  inflating: /content/content/pytorch-retinanet/retinanet/model.py  \n",
            "  inflating: /content/content/pytorch-retinanet/retinanet/oid_dataset.py  \n",
            "  inflating: /content/content/pytorch-retinanet/retinanet/coco_eval.py  \n",
            "  inflating: /content/content/pytorch-retinanet/retinanet/dataloader.py  \n",
            "   creating: /content/content/pytorch-retinanet/retinanet/__pycache__/\n",
            "  inflating: /content/content/pytorch-retinanet/retinanet/__pycache__/losses.cpython-311.pyc  \n",
            "  inflating: /content/content/pytorch-retinanet/retinanet/__pycache__/anchors.cpython-311.pyc  \n",
            "  inflating: /content/content/pytorch-retinanet/retinanet/__pycache__/__init__.cpython-311.pyc  \n",
            "  inflating: /content/content/pytorch-retinanet/retinanet/__pycache__/model.cpython-311.pyc  \n",
            "  inflating: /content/content/pytorch-retinanet/retinanet/__pycache__/utils.cpython-311.pyc  \n",
            "  inflating: /content/content/pytorch-retinanet/retinanet/__pycache__/csv_eval.cpython-311.pyc  \n",
            "  inflating: /content/content/pytorch-retinanet/retinanet/__pycache__/coco_eval.cpython-311.pyc  \n",
            "  inflating: /content/content/pytorch-retinanet/retinanet/__pycache__/dataloader.cpython-311.pyc  \n",
            "  inflating: /content/content/pytorch-retinanet/retinanet/utils.py  \n",
            "  inflating: /content/content/pytorch-retinanet/retinanet/losses.py  \n",
            "  inflating: /content/content/pytorch-retinanet/retinanet/anchors.py  \n",
            " extracting: /content/content/pytorch-retinanet/retinanet/__init__.py  \n",
            "  inflating: /content/content/pytorch-retinanet/retinanet/csv_eval.py  \n",
            "  inflating: /content/content/pytorch-retinanet/LICENSE  \n",
            "   creating: /content/content/pytorch-retinanet/.git/\n",
            "   creating: /content/content/pytorch-retinanet/.git/info/\n",
            "  inflating: /content/content/pytorch-retinanet/.git/info/exclude  \n",
            "  inflating: /content/content/pytorch-retinanet/.git/index  \n",
            " extracting: /content/content/pytorch-retinanet/.git/HEAD  \n",
            "  inflating: /content/content/pytorch-retinanet/.git/config  \n",
            "   creating: /content/content/pytorch-retinanet/.git/objects/\n",
            "   creating: /content/content/pytorch-retinanet/.git/objects/info/\n",
            "   creating: /content/content/pytorch-retinanet/.git/objects/pack/\n",
            "  inflating: /content/content/pytorch-retinanet/.git/objects/pack/pack-160d9864ee8e58be59bdba42745fb72f6ce73874.pack  \n",
            "  inflating: /content/content/pytorch-retinanet/.git/objects/pack/pack-160d9864ee8e58be59bdba42745fb72f6ce73874.idx  \n",
            "   creating: /content/content/pytorch-retinanet/.git/refs/\n",
            "   creating: /content/content/pytorch-retinanet/.git/refs/heads/\n",
            " extracting: /content/content/pytorch-retinanet/.git/refs/heads/master  \n",
            "   creating: /content/content/pytorch-retinanet/.git/refs/tags/\n",
            "   creating: /content/content/pytorch-retinanet/.git/refs/remotes/\n",
            "   creating: /content/content/pytorch-retinanet/.git/refs/remotes/origin/\n",
            " extracting: /content/content/pytorch-retinanet/.git/refs/remotes/origin/HEAD  \n",
            "  inflating: /content/content/pytorch-retinanet/.git/packed-refs  \n",
            "  inflating: /content/content/pytorch-retinanet/.git/description  \n",
            "   creating: /content/content/pytorch-retinanet/.git/logs/\n",
            "  inflating: /content/content/pytorch-retinanet/.git/logs/HEAD  \n",
            "   creating: /content/content/pytorch-retinanet/.git/logs/refs/\n",
            "   creating: /content/content/pytorch-retinanet/.git/logs/refs/heads/\n",
            "  inflating: /content/content/pytorch-retinanet/.git/logs/refs/heads/master  \n",
            "   creating: /content/content/pytorch-retinanet/.git/logs/refs/remotes/\n",
            "   creating: /content/content/pytorch-retinanet/.git/logs/refs/remotes/origin/\n",
            "  inflating: /content/content/pytorch-retinanet/.git/logs/refs/remotes/origin/HEAD  \n",
            "   creating: /content/content/pytorch-retinanet/.git/hooks/\n",
            "  inflating: /content/content/pytorch-retinanet/.git/hooks/pre-merge-commit.sample  \n",
            "  inflating: /content/content/pytorch-retinanet/.git/hooks/update.sample  \n",
            "  inflating: /content/content/pytorch-retinanet/.git/hooks/commit-msg.sample  \n",
            "  inflating: /content/content/pytorch-retinanet/.git/hooks/pre-applypatch.sample  \n",
            "  inflating: /content/content/pytorch-retinanet/.git/hooks/push-to-checkout.sample  \n",
            "  inflating: /content/content/pytorch-retinanet/.git/hooks/pre-rebase.sample  \n",
            "  inflating: /content/content/pytorch-retinanet/.git/hooks/fsmonitor-watchman.sample  \n",
            "  inflating: /content/content/pytorch-retinanet/.git/hooks/pre-commit.sample  \n",
            "  inflating: /content/content/pytorch-retinanet/.git/hooks/applypatch-msg.sample  \n",
            "  inflating: /content/content/pytorch-retinanet/.git/hooks/post-update.sample  \n",
            "  inflating: /content/content/pytorch-retinanet/.git/hooks/prepare-commit-msg.sample  \n",
            "  inflating: /content/content/pytorch-retinanet/.git/hooks/pre-receive.sample  \n",
            "  inflating: /content/content/pytorch-retinanet/.git/hooks/pre-push.sample  \n",
            "   creating: /content/content/pytorch-retinanet/.git/branches/\n",
            "  inflating: /content/content/pytorch-retinanet/resnet50-19c8e357.pth  \n",
            "  inflating: /content/content/pytorch-retinanet/coco_validation.py  \n",
            "  inflating: /content/content/pytorch-retinanet/.gitignore  \n",
            "   creating: /content/content/pytorch-retinanet/images/\n",
            "  inflating: /content/content/pytorch-retinanet/images/3.jpg  \n",
            "  inflating: /content/content/pytorch-retinanet/images/6.jpg  \n",
            "  inflating: /content/content/pytorch-retinanet/images/1.jpg  \n",
            "  inflating: /content/content/pytorch-retinanet/images/5.jpg  \n",
            "  inflating: /content/content/pytorch-retinanet/images/7.jpg  \n",
            "  inflating: /content/content/pytorch-retinanet/images/4.jpg  \n",
            "  inflating: /content/content/pytorch-retinanet/images/8.jpg  \n",
            "  inflating: /content/content/pytorch-retinanet/csv_retinanet_9.pt  \n"
          ]
        }
      ]
    }
  ]
}